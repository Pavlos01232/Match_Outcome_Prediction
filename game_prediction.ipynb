{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEhPaF2CTy2tSYcMoRwCmY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavlos01232/Match_Outcome_Prediction/blob/main/game_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzVKKLMBRPxZ",
        "outputId": "27b440c8-b383-442a-b274-85e291952f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================================================\n",
            "\n",
            "teams:\n",
            "['Burnley', 'Arsenal', 'Bournemouth', 'Brighton', 'Everton', 'Sheffield United', 'Newcastle', 'Brentford', 'Chelsea', 'Man United', \"Nott'm Forest\", 'Fulham', 'Liverpool', 'Wolves', 'Tottenham', 'Man City', 'Aston Villa', 'West Ham', 'Crystal Palace', 'Luton']\n",
            "\n",
            "\n",
            "data: (team names respective goals scored, respective shots on target, respective red cards)\n",
            "[['Burnley', 'Man City', '0', '3', '1', '8', '1', '0', '6', '17', '6', '5', '11', '8'], ['Arsenal', \"Nott'm Forest\", '2', '1', '7', '2', '0', '0', '15', '6', '8', '3', '12', '12'], ['Bournemouth', 'West Ham', '1', '1', '5', '3', '0', '0', '14', '16', '10', '4', '9', '14'], ['Brighton', 'Luton', '4', '1', '12', '3', '0', '0', '27', '9', '6', '7', '11', '12'], ['Everton', 'Fulham', '0', '1', '9', '2', '0', '0', '19', '9', '10', '4', '12', '6'], ['Sheffield United', 'Crystal Palace', '0', '1', '1', '8', '0', '0', '8', '24', '5', '5', '18', '11'], ['Newcastle', 'Aston Villa', '5', '1', '13', '6', '0', '0', '17', '16', '6', '5', '12', '17'], ['Brentford', 'Tottenham', '2', '2', '6', '6', '0', '0', '11', '18', '3', '6', '12', '13'], ['Chelsea', 'Liverpool', '1', '1', '4', '1', '0', '0', '10', '13', '4', '4', '5', '12'], ['Man United', 'Wolves', '1', '0', '3', '6', '0', '0', '15', '23', '8', '7', '14', '10'], [\"Nott'm Forest\", 'Sheffield United', '2', '1', '4', '3', '0', '0', '16', '7', '6', '7', '5', '9'], ['Fulham', 'Brentford', '0', '3', '2', '8', '1', '0', '10', '17', '5', '5', '13', '12'], ['Liverpool', 'Bournemouth', '3', '1', '10', '5', '1', '0', '26', '13', '10', '2', '11', '13'], ['Wolves', 'Brighton', '1', '4', '5', '8', '1', '0', '16', '16', '5', '3', '14', '11'], ['Tottenham', 'Man United', '2', '0', '6', '6', '0', '0', '17', '22', '5', '6', '9', '8'], ['Man City', 'Newcastle', '1', '0', '4', '1', '0', '0', '14', '7', '3', '0', '12', '11'], ['Aston Villa', 'Everton', '4', '0', '7', '2', '0', '0', '13', '9', '7', '6', '8', '12'], ['West Ham', 'Chelsea', '3', '1', '6', '4', '1', '0', '12', '17', '3', '9', '12', '9'], ['Crystal Palace', 'Arsenal', '0', '1', '2', '3', '0', '1', '14', '14', '1', '8', '14', '10'], ['Chelsea', 'Luton', '3', '0', '8', '1', '0', '0', '19', '11', '6', '4', '15', '12'], ['Bournemouth', 'Tottenham', '0', '2', '3', '6', '0', '0', '11', '17', '6', '2', '18', '11'], ['Arsenal', 'Fulham', '2', '2', '11', '3', '0', '1', '19', '8', '8', '3', '6', '5'], ['Brentford', 'Crystal Palace', '1', '1', '1', '5', '0', '0', '12', '15', '8', '6', '9', '15'], ['Everton', 'Wolves', '0', '1', '7', '2', '0', '0', '15', '11', '7', '0', '10', '14'], ['Man United', \"Nott'm Forest\", '3', '2', '9', '4', '0', '1', '18', '9', '11', '3', '13', '11'], ['Brighton', 'West Ham', '1', '3', '10', '3', '0', '0', '25', '12', '17', '4', '10', '9'], ['Burnley', 'Aston Villa', '1', '3', '2', '6', '0', '0', '9', '16', '4', '6', '12', '11'], ['Sheffield United', 'Man City', '1', '2', '2', '9', '0', '0', '6', '30', '1', '12', '11', '2'], ['Newcastle', 'Liverpool', '1', '2', '8', '4', '0', '1', '23', '9', '5', '9', '16', '10'], ['Luton', 'West Ham', '1', '2', '1', '3', '0', '0', '16', '9', '9', '6', '8', '13'], ['Sheffield United', 'Everton', '2', '2', '8', '6', '0', '0', '13', '16', '4', '6', '11', '13'], ['Brentford', 'Bournemouth', '2', '2', '7', '5', '0', '0', '21', '12', '5', '2', '6', '13'], ['Burnley', 'Tottenham', '2', '5', '4', '10', '0', '0', '16', '20', '7', '4', '15', '9'], ['Chelsea', \"Nott'm Forest\", '0', '1', '2', '3', '0', '0', '21', '7', '8', '0', '10', '9'], ['Man City', 'Fulham', '5', '1', '5', '4', '0', '0', '7', '6', '4', '5', '12', '12'], ['Brighton', 'Newcastle', '3', '1', '6', '2', '0', '0', '15', '9', '5', '3', '14', '17'], ['Crystal Palace', 'Wolves', '3', '2', '11', '4', '0', '0', '16', '12', '4', '2', '12', '12'], ['Liverpool', 'Aston Villa', '3', '0', '4', '3', '0', '0', '17', '9', '7', '3', '12', '7'], ['Arsenal', 'Man United', '3', '1', '5', '2', '0', '0', '17', '10', '12', '3', '8', '7'], ['Wolves', 'Liverpool', '1', '3', '2', '6', '0', '0', '11', '16', '4', '4', '10', '4'], ['Aston Villa', 'Crystal Palace', '3', '1', '5', '3', '0', '0', '16', '6', '4', '2', '13', '9'], ['Fulham', 'Luton', '1', '0', '2', '2', '0', '0', '13', '7', '6', '2', '6', '14'], ['Man United', 'Brighton', '1', '3', '4', '8', '0', '0', '14', '10', '8', '1', '8', '9'], ['Tottenham', 'Sheffield United', '2', '1', '10', '5', '0', '1', '28', '7', '15', '2', '13', '14'], ['West Ham', 'Man City', '1', '3', '3', '15', '0', '0', '6', '29', '4', '11', '7', '11'], ['Newcastle', 'Brentford', '1', '0', '2', '2', '0', '0', '9', '11', '8', '3', '8', '12'], ['Bournemouth', 'Chelsea', '0', '0', '4', '6', '0', '0', '13', '14', '1', '7', '15', '20'], ['Everton', 'Arsenal', '0', '1', '1', '4', '0', '0', '8', '13', '1', '11', '12', '10'], [\"Nott'm Forest\", 'Burnley', '1', '1', '4', '3', '0', '1', '14', '10', '5', '4', '16', '10'], ['Crystal Palace', 'Fulham', '0', '0', '3', '5', '0', '0', '7', '10', '3', '2', '10', '15'], ['Luton', 'Wolves', '1', '1', '4', '3', '0', '1', '20', '3', '10', '1', '12', '17'], ['Man City', \"Nott'm Forest\", '2', '0', '4', '3', '1', '0', '7', '10', '6', '6', '5', '17'], ['Brentford', 'Everton', '1', '3', '2', '6', '0', '0', '12', '18', '1', '4', '9', '12'], ['Burnley', 'Man United', '0', '1', '4', '4', '0', '0', '12', '11', '9', '5', '6', '12'], ['Arsenal', 'Tottenham', '2', '2', '6', '5', '0', '0', '13', '13', '11', '4', '12', '19'], ['Brighton', 'Bournemouth', '3', '1', '4', '4', '0', '0', '13', '12', '4', '4', '12', '17'], ['Chelsea', 'Aston Villa', '0', '1', '4', '7', '0', '0', '10', '15', '5', '11', '9', '11'], ['Liverpool', 'West Ham', '3', '1', '7', '4', '0', '0', '22', '11', '7', '4', '12', '13'], ['Sheffield United', 'Newcastle', '0', '8', '1', '15', '0', '0', '9', '22', '2', '6', '12', '8'], ['Aston Villa', 'Brighton', '6', '1', '9', '3', '0', '0', '19', '11', '1', '3', '19', '21'], ['Bournemouth', 'Arsenal', '0', '4', '1', '8', '0', '0', '8', '15', '6', '6', '11', '10'], ['Everton', 'Luton', '1', '2', '5', '2', '0', '0', '23', '9', '3', '6', '8', '10'], ['Man United', 'Crystal Palace', '0', '1', '4', '2', '0', '0', '19', '8', '10', '4', '10', '8'], ['Newcastle', 'Burnley', '2', '0', '8', '2', '0', '0', '20', '8', '5', '3', '7', '15'], ['West Ham', 'Sheffield United', '2', '0', '9', '2', '0', '0', '20', '16', '7', '4', '6', '9'], ['Wolves', 'Man City', '2', '1', '1', '8', '0', '0', '3', '23', '0', '6', '18', '12'], ['Tottenham', 'Liverpool', '2', '1', '8', '4', '0', '2', '24', '12', '12', '5', '11', '17'], [\"Nott'm Forest\", 'Brentford', '1', '1', '1', '5', '1', '0', '6', '18', '1', '11', '6', '10'], ['Fulham', 'Chelsea', '0', '2', '3', '4', '0', '0', '10', '11', '8', '1', '15', '12'], ['Luton', 'Burnley', '1', '2', '3', '4', '0', '0', '18', '14', '7', '6', '14', '6'], ['Luton', 'Tottenham', '0', '1', '2', '4', '0', '1', '12', '15', '5', '6', '16', '7'], ['Burnley', 'Chelsea', '1', '4', '3', '5', '0', '0', '10', '9', '7', '3', '11', '8'], ['Everton', 'Bournemouth', '3', '0', '8', '4', '0', '0', '25', '11', '8', '7', '14', '15'], ['Fulham', 'Sheffield United', '3', '1', '6', '2', '0', '0', '20', '5', '9', '4', '8', '10'], ['Man United', 'Brentford', '2', '1', '8', '3', '0', '0', '21', '11', '7', '5', '10', '17'], ['Crystal Palace', \"Nott'm Forest\", '0', '0', '2', '5', '0', '0', '8', '16', '3', '7', '7', '12'], ['Brighton', 'Liverpool', '2', '2', '3', '4', '0', '0', '14', '14', '8', '1', '12', '20'], ['West Ham', 'Newcastle', '2', '2', '3', '3', '0', '0', '5', '10', '4', '2', '11', '18'], ['Wolves', 'Aston Villa', '1', '1', '3', '4', '1', '0', '8', '18', '2', '10', '19', '9'], ['Arsenal', 'Man City', '1', '0', '2', '1', '0', '0', '12', '4', '5', '4', '8', '7'], ['Liverpool', 'Everton', '2', '0', '6', '1', '0', '1', '26', '6', '12', '4', '9', '9'], ['Bournemouth', 'Wolves', '1', '2', '4', '7', '1', '0', '7', '20', '3', '12', '15', '10'], ['Brentford', 'Burnley', '3', '0', '10', '1', '0', '1', '23', '6', '5', '5', '14', '12'], ['Man City', 'Brighton', '2', '1', '6', '3', '1', '0', '10', '5', '2', '2', '9', '11'], ['Newcastle', 'Crystal Palace', '4', '0', '7', '3', '0', '0', '10', '17', '6', '8', '7', '12'], [\"Nott'm Forest\", 'Luton', '2', '2', '8', '4', '0', '0', '19', '13', '4', '2', '12', '11'], ['Chelsea', 'Arsenal', '2', '2', '5', '3', '0', '0', '11', '13', '2', '7', '7', '14'], ['Sheffield United', 'Man United', '1', '2', '6', '5', '0', '0', '12', '14', '5', '4', '12', '10'], ['Aston Villa', 'West Ham', '4', '1', '7', '4', '0', '0', '15', '14', '8', '7', '9', '15'], ['Tottenham', 'Fulham', '2', '0', '5', '3', '0', '0', '15', '10', '3', '5', '10', '14'], ['Crystal Palace', 'Tottenham', '1', '2', '3', '1', '0', '0', '13', '10', '11', '2', '19', '11'], ['Chelsea', 'Brentford', '0', '2', '2', '5', '0', '0', '17', '7', '10', '1', '12', '7'], ['Arsenal', 'Sheffield United', '5', '0', '8', '0', '0', '0', '13', '2', '6', '1', '9', '13'], ['Bournemouth', 'Burnley', '2', '1', '6', '3', '0', '0', '13', '6', '10', '5', '9', '12'], ['Wolves', 'Newcastle', '2', '2', '6', '5', '0', '0', '11', '13', '8', '7', '13', '15'], ['West Ham', 'Everton', '0', '1', '2', '4', '0', '0', '12', '10', '4', '3', '7', '11'], ['Aston Villa', 'Luton', '3', '1', '6', '1', '0', '0', '17', '7', '6', '4', '11', '10'], ['Brighton', 'Fulham', '1', '1', '7', '5', '0', '0', '18', '10', '7', '3', '12', '8'], ['Liverpool', \"Nott'm Forest\", '3', '0', '8', '1', '0', '0', '21', '9', '8', '3', '9', '13'], ['Man United', 'Man City', '0', '3', '3', '10', '0', '0', '7', '21', '7', '12', '9', '4'], ['Fulham', 'Man United', '0', '1', '3', '5', '0', '0', '18', '12', '9', '4', '9', '15'], ['Brentford', 'West Ham', '3', '2', '4', '2', '0', '0', '16', '12', '4', '3', '12', '14'], ['Burnley', 'Crystal Palace', '0', '2', '5', '3', '0', '0', '17', '4', '12', '1', '9', '12'], ['Everton', 'Brighton', '1', '1', '4', '2', '0', '0', '10', '7', '3', '3', '15', '5'], ['Man City', 'Bournemouth', '6', '1', '8', '1', '0', '0', '21', '5', '12', '1', '8', '9'], ['Sheffield United', 'Wolves', '2', '1', '2', '3', '0', '0', '11', '10', '4', '4', '13', '10'], ['Newcastle', 'Arsenal', '1', '0', '2', '1', '0', '0', '9', '14', '0', '11', '14', '9'], [\"Nott'm Forest\", 'Aston Villa', '2', '0', '3', '3', '0', '0', '5', '13', '0', '10', '6', '9'], ['Luton', 'Liverpool', '1', '1', '5', '6', '0', '0', '8', '24', '4', '7', '7', '13'], ['Tottenham', 'Chelsea', '1', '4', '5', '8', '2', '0', '8', '17', '1', '6', '12', '21'], ['Wolves', 'Tottenham', '2', '1', '4', '2', '0', '0', '17', '6', '11', '3', '19', '15'], ['Arsenal', 'Burnley', '3', '1', '6', '5', '1', '0', '16', '8', '3', '3', '8', '9'], ['Crystal Palace', 'Everton', '2', '3', '4', '4', '0', '0', '13', '8', '9', '2', '9', '18'], ['Man United', 'Luton', '1', '0', '4', '4', '0', '0', '15', '10', '11', '3', '9', '11'], ['Bournemouth', 'Newcastle', '2', '0', '10', '5', '0', '0', '19', '8', '6', '5', '10', '4'], ['Aston Villa', 'Fulham', '3', '1', '6', '5', '0', '0', '12', '9', '2', '2', '4', '17'], ['Brighton', 'Sheffield United', '1', '1', '6', '1', '1', '0', '11', '9', '6', '3', '13', '16'], ['Liverpool', 'Brentford', '3', '0', '10', '3', '0', '0', '17', '16', '6', '8', '16', '12'], ['West Ham', \"Nott'm Forest\", '3', '2', '6', '5', '0', '0', '16', '10', '9', '4', '9', '12'], ['Chelsea', 'Man City', '4', '4', '9', '10', '0', '0', '17', '15', '3', '3', '12', '15'], ['Man City', 'Liverpool', '1', '1', '5', '3', '0', '0', '16', '8', '9', '6', '9', '11'], ['Burnley', 'West Ham', '1', '2', '5', '3', '0', '0', '11', '11', '4', '5', '11', '7'], ['Luton', 'Crystal Palace', '2', '1', '3', '8', '0', '0', '8', '16', '4', '5', '15', '12'], ['Newcastle', 'Chelsea', '4', '1', '5', '4', '0', '1', '14', '7', '4', '2', '13', '19'], [\"Nott'm Forest\", 'Brighton', '2', '3', '5', '5', '0', '1', '18', '11', '6', '4', '12', '7'], ['Sheffield United', 'Bournemouth', '1', '3', '2', '11', '0', '0', '10', '23', '4', '7', '6', '8'], ['Brentford', 'Arsenal', '0', '1', '3', '4', '0', '0', '9', '15', '1', '8', '9', '7'], ['Tottenham', 'Aston Villa', '1', '2', '8', '5', '0', '0', '18', '15', '9', '3', '11', '13'], ['Everton', 'Man United', '0', '3', '6', '4', '0', '0', '24', '9', '6', '5', '10', '8'], ['Fulham', 'Wolves', '3', '2', '6', '6', '0', '0', '12', '10', '6', '2', '13', '13'], ['Arsenal', 'Wolves', '2', '1', '6', '3', '0', '0', '19', '6', '4', '0', '10', '10'], ['Brentford', 'Luton', '3', '1', '6', '1', '0', '0', '27', '7', '7', '5', '10', '8'], ['Burnley', 'Sheffield United', '5', '0', '7', '3', '0', '1', '19', '6', '6', '1', '9', '12'], [\"Nott'm Forest\", 'Everton', '0', '1', '2', '3', '0', '0', '13', '12', '4', '3', '15', '14'], ['Newcastle', 'Man United', '1', '0', '4', '1', '0', '0', '22', '8', '7', '3', '6', '13'], ['Bournemouth', 'Aston Villa', '2', '2', '7', '3', '0', '0', '15', '11', '7', '7', '16', '12'], ['Chelsea', 'Brighton', '3', '2', '5', '9', '1', '0', '8', '18', '5', '8', '16', '12'], ['Liverpool', 'Fulham', '4', '3', '12', '5', '0', '0', '26', '9', '3', '4', '6', '7'], ['West Ham', 'Crystal Palace', '1', '1', '3', '2', '0', '0', '9', '9', '2', '3', '17', '7'], ['Man City', 'Tottenham', '3', '3', '4', '4', '0', '0', '18', '8', '10', '8', '14', '14'], ['Wolves', 'Burnley', '1', '0', '4', '3', '0', '0', '7', '12', '6', '8', '11', '15'], ['Luton', 'Arsenal', '3', '4', '4', '9', '0', '0', '6', '23', '3', '8', '14', '7'], ['Brighton', 'Brentford', '2', '1', '7', '2', '0', '0', '18', '8', '7', '3', '10', '8'], ['Crystal Palace', 'Bournemouth', '0', '2', '3', '4', '0', '0', '16', '11', '3', '9', '10', '17'], ['Fulham', \"Nott'm Forest\", '5', '0', '6', '1', '0', '0', '14', '4', '6', '1', '7', '10'], ['Sheffield United', 'Liverpool', '0', '2', '1', '8', '0', '0', '6', '15', '2', '12', '12', '8'], ['Aston Villa', 'Man City', '1', '0', '7', '2', '0', '0', '22', '2', '6', '0', '13', '13'], ['Man United', 'Chelsea', '2', '1', '9', '3', '0', '0', '28', '13', '12', '4', '12', '12'], ['Everton', 'Newcastle', '3', '0', '6', '3', '0', '0', '21', '13', '5', '2', '18', '8'], ['Tottenham', 'West Ham', '1', '2', '7', '5', '0', '0', '23', '11', '8', '4', '11', '12'], ['Crystal Palace', 'Liverpool', '1', '2', '4', '2', '1', '0', '8', '14', '6', '5', '17', '17'], ['Brighton', 'Burnley', '1', '1', '11', '3', '0', '0', '29', '6', '9', '1', '5', '8'], ['Man United', 'Bournemouth', '0', '3', '3', '4', '0', '0', '20', '10', '10', '4', '7', '10'], ['Sheffield United', 'Brentford', '1', '0', '4', '4', '0', '0', '9', '10', '3', '4', '14', '13'], ['Wolves', \"Nott'm Forest\", '1', '1', '4', '2', '0', '0', '10', '8', '4', '3', '9', '11'], ['Aston Villa', 'Arsenal', '1', '0', '3', '5', '0', '0', '10', '12', '3', '3', '16', '11'], ['Everton', 'Chelsea', '2', '0', '5', '4', '0', '0', '9', '16', '4', '8', '12', '12'], ['Fulham', 'West Ham', '5', '0', '8', '5', '0', '0', '14', '9', '3', '6', '5', '10'], ['Luton', 'Man City', '1', '2', '2', '6', '0', '0', '4', '18', '6', '3', '16', '6'], ['Tottenham', 'Newcastle', '4', '1', '12', '3', '0', '0', '23', '9', '3', '6', '10', '12'], [\"Nott'm Forest\", 'Tottenham', '0', '2', '1', '6', '0', '1', '15', '12', '6', '4', '16', '11'], ['Chelsea', 'Sheffield United', '2', '0', '6', '1', '0', '0', '15', '6', '7', '6', '9', '14'], ['Man City', 'Crystal Palace', '2', '2', '9', '2', '0', '0', '19', '5', '6', '1', '12', '9'], ['Newcastle', 'Fulham', '3', '0', '10', '4', '0', '1', '27', '6', '5', '1', '7', '12'], ['Burnley', 'Everton', '0', '2', '2', '6', '0', '0', '14', '9', '8', '6', '9', '8'], ['Arsenal', 'Brighton', '2', '0', '9', '1', '0', '0', '26', '6', '10', '1', '11', '9'], ['Brentford', 'Aston Villa', '1', '2', '3', '5', '1', '1', '4', '15', '7', '12', '19', '6'], ['West Ham', 'Wolves', '3', '0', '4', '3', '0', '0', '13', '14', '6', '6', '12', '15'], ['Liverpool', 'Man United', '0', '0', '8', '1', '0', '1', '34', '6', '12', '0', '13', '8'], ['Crystal Palace', 'Brighton', '1', '1', '3', '6', '0', '0', '11', '18', '3', '1', '12', '11'], ['Aston Villa', 'Sheffield United', '1', '1', '4', '2', '0', '0', '12', '5', '9', '1', '11', '16'], ['West Ham', 'Man United', '2', '0', '5', '3', '0', '0', '12', '11', '4', '4', '13', '15'], ['Fulham', 'Burnley', '0', '2', '5', '2', '0', '0', '19', '7', '8', '6', '5', '17'], ['Luton', 'Newcastle', '1', '0', '5', '2', '0', '0', '16', '15', '6', '7', '11', '5'], [\"Nott'm Forest\", 'Bournemouth', '2', '3', '5', '7', '1', '0', '11', '18', '6', '6', '10', '10'], ['Tottenham', 'Everton', '2', '1', '6', '8', '0', '0', '13', '18', '3', '8', '6', '18'], ['Liverpool', 'Arsenal', '1', '1', '3', '2', '0', '0', '13', '13', '4', '5', '13', '14'], ['Wolves', 'Chelsea', '2', '1', '6', '5', '0', '0', '14', '16', '10', '6', '11', '9'], ['Newcastle', \"Nott'm Forest\", '1', '3', '7', '6', '0', '0', '19', '15', '10', '2', '10', '11'], ['Bournemouth', 'Fulham', '3', '0', '4', '3', '0', '0', '16', '8', '6', '5', '10', '10'], ['Sheffield United', 'Luton', '2', '3', '6', '4', '0', '0', '21', '12', '9', '4', '13', '13'], ['Burnley', 'Liverpool', '0', '2', '0', '10', '0', '0', '9', '19', '4', '4', '7', '10'], ['Man United', 'Aston Villa', '3', '2', '7', '4', '0', '0', '13', '10', '3', '6', '10', '10'], ['Brentford', 'Wolves', '1', '4', '4', '5', '0', '0', '14', '11', '8', '2', '5', '14'], ['Chelsea', 'Crystal Palace', '2', '1', '4', '5', '0', '0', '9', '13', '4', '3', '13', '16'], ['Everton', 'Man City', '1', '3', '2', '9', '0', '0', '7', '23', '8', '4', '13', '5'], ['Brighton', 'Tottenham', '4', '2', '9', '3', '0', '0', '15', '19', '7', '6', '18', '6'], ['Arsenal', 'West Ham', '0', '2', '8', '3', '0', '0', '30', '6', '10', '3', '8', '8'], ['Luton', 'Chelsea', '2', '3', '6', '8', '0', '0', '15', '12', '7', '2', '14', '21'], ['Aston Villa', 'Burnley', '3', '2', '7', '5', '0', '1', '19', '9', '6', '2', '9', '14'], ['Crystal Palace', 'Brentford', '3', '1', '6', '4', '0', '0', '13', '9', '7', '4', '14', '10'], ['Man City', 'Sheffield United', '2', '0', '4', '2', '0', '0', '18', '4', '12', '2', '5', '6'], ['Wolves', 'Everton', '3', '0', '6', '0', '0', '0', '12', '10', '5', '2', '9', '14'], [\"Nott'm Forest\", 'Man United', '2', '1', '2', '5', '0', '0', '8', '10', '4', '5', '9', '11'], ['Fulham', 'Arsenal', '2', '1', '4', '3', '0', '0', '15', '13', '5', '4', '11', '10'], ['Tottenham', 'Bournemouth', '3', '1', '6', '4', '0', '0', '12', '24', '4', '13', '9', '18'], ['Liverpool', 'Newcastle', '4', '2', '15', '3', '0', '0', '34', '5', '7', '3', '16', '15'], ['West Ham', 'Brighton', '0', '0', '2', '8', '0', '0', '6', '22', '2', '0', '4', '6'], ['Burnley', 'Luton', '1', '1', '7', '5', '0', '0', '13', '14', '2', '8', '7', '12'], ['Chelsea', 'Fulham', '1', '0', '3', '4', '0', '0', '17', '14', '6', '4', '13', '9'], ['Newcastle', 'Man City', '2', '3', '5', '11', '0', '0', '12', '27', '3', '13', '7', '7'], ['Everton', 'Aston Villa', '0', '0', '2', '5', '0', '0', '10', '16', '4', '5', '13', '14'], ['Man United', 'Tottenham', '2', '2', '2', '6', '0', '0', '9', '16', '8', '13', '8', '5'], ['Arsenal', 'Crystal Palace', '5', '0', '6', '5', '0', '0', '21', '12', '6', '7', '8', '12'], ['Brentford', \"Nott'm Forest\", '3', '2', '5', '3', '0', '0', '11', '12', '6', '4', '10', '14'], ['Sheffield United', 'West Ham', '2', '2', '6', '5', '1', '1', '21', '16', '4', '1', '11', '10'], ['Bournemouth', 'Liverpool', '0', '4', '1', '7', '0', '0', '11', '14', '8', '5', '9', '12'], ['Brighton', 'Wolves', '0', '0', '4', '3', '0', '0', '11', '8', '8', '2', '10', '13'], [\"Nott'm Forest\", 'Arsenal', '1', '2', '3', '3', '0', '0', '9', '19', '2', '11', '6', '7'], ['Fulham', 'Everton', '0', '0', '6', '4', '0', '0', '25', '21', '15', '6', '6', '13'], ['Luton', 'Brighton', '4', '0', '8', '2', '0', '0', '18', '9', '7', '4', '13', '14'], ['Crystal Palace', 'Sheffield United', '3', '2', '4', '5', '0', '0', '12', '9', '11', '1', '8', '18'], ['Aston Villa', 'Newcastle', '1', '3', '6', '5', '0', '0', '12', '14', '8', '7', '14', '12'], ['Man City', 'Burnley', '3', '1', '4', '3', '0', '0', '14', '8', '7', '3', '3', '13'], ['Tottenham', 'Brentford', '3', '2', '5', '5', '0', '0', '19', '9', '5', '3', '13', '15'], ['Liverpool', 'Chelsea', '4', '1', '13', '3', '0', '0', '28', '4', '8', '1', '15', '16'], ['West Ham', 'Bournemouth', '1', '1', '3', '4', '0', '0', '9', '9', '1', '5', '13', '11'], ['Wolves', 'Man United', '3', '4', '7', '8', '0', '0', '16', '21', '4', '5', '10', '10'], ['Everton', 'Tottenham', '2', '2', '5', '6', '0', '0', '14', '9', '9', '5', '8', '14'], ['Brighton', 'Crystal Palace', '4', '1', '6', '5', '0', '0', '13', '7', '3', '2', '8', '14'], ['Burnley', 'Fulham', '2', '2', '4', '7', '0', '0', '12', '15', '2', '13', '11', '7'], ['Newcastle', 'Luton', '4', '4', '6', '8', '0', '0', '19', '11', '8', '2', '13', '16'], ['Sheffield United', 'Aston Villa', '0', '5', '5', '10', '0', '0', '10', '14', '3', '4', '10', '7'], ['Bournemouth', \"Nott'm Forest\", '1', '1', '2', '6', '1', '0', '9', '8', '11', '6', '19', '12'], ['Chelsea', 'Wolves', '2', '4', '6', '7', '0', '0', '15', '14', '10', '1', '15', '11'], ['Man United', 'West Ham', '3', '0', '5', '3', '0', '0', '12', '22', '5', '8', '10', '5'], ['Arsenal', 'Liverpool', '3', '1', '7', '1', '0', '1', '15', '10', '2', '4', '11', '11'], ['Brentford', 'Man City', '1', '3', '3', '15', '0', '0', '9', '25', '8', '13', '2', '4'], ['Man City', 'Everton', '2', '0', '3', '1', '0', '0', '19', '5', '9', '0', '6', '11'], ['Fulham', 'Bournemouth', '3', '1', '6', '4', '0', '0', '7', '25', '1', '14', '11', '11'], ['Liverpool', 'Burnley', '3', '1', '10', '4', '0', '0', '25', '9', '9', '3', '11', '13'], ['Luton', 'Sheffield United', '1', '3', '5', '3', '0', '0', '20', '7', '13', '1', '7', '12'], ['Tottenham', 'Brighton', '2', '1', '6', '3', '0', '0', '16', '6', '9', '6', '14', '13'], ['Wolves', 'Brentford', '0', '2', '5', '6', '0', '0', '17', '9', '7', '4', '11', '9'], [\"Nott'm Forest\", 'Newcastle', '2', '3', '3', '5', '0', '0', '13', '7', '4', '4', '9', '6'], ['West Ham', 'Arsenal', '0', '6', '1', '12', '0', '0', '5', '25', '2', '6', '17', '11'], ['Aston Villa', 'Man United', '1', '2', '10', '5', '0', '0', '23', '17', '10', '8', '9', '7'], ['Crystal Palace', 'Chelsea', '1', '3', '4', '5', '0', '0', '13', '14', '1', '7', '14', '7'], ['Brentford', 'Liverpool', '1', '4', '6', '8', '0', '0', '15', '15', '1', '6', '4', '18'], ['Burnley', 'Arsenal', '0', '5', '0', '7', '0', '0', '8', '16', '4', '6', '11', '8'], ['Fulham', 'Aston Villa', '1', '2', '4', '3', '0', '0', '15', '12', '4', '4', '11', '6'], ['Newcastle', 'Bournemouth', '2', '2', '5', '7', '0', '0', '17', '12', '4', '2', '9', '22'], [\"Nott'm Forest\", 'West Ham', '2', '0', '8', '3', '0', '1', '19', '10', '5', '3', '13', '15'], ['Tottenham', 'Wolves', '1', '2', '4', '7', '0', '0', '15', '12', '10', '4', '8', '13'], ['Man City', 'Chelsea', '1', '1', '5', '6', '0', '0', '31', '9', '12', '1', '7', '12'], ['Sheffield United', 'Brighton', '0', '5', '1', '10', '1', '0', '6', '24', '5', '10', '3', '5'], ['Luton', 'Man United', '1', '2', '4', '9', '0', '0', '22', '21', '8', '6', '7', '21'], ['Everton', 'Crystal Palace', '1', '1', '4', '4', '0', '0', '19', '10', '3', '6', '8', '12'], []]\n",
            "\n",
            "\n",
            "Index assigned to Everton:\n",
            "4\n",
            "\n",
            "\n",
            "data2, using the team's index number instead of name\n",
            "[[0, 15, '0', '3', '1', '8', '1', '0', '6', '17', '6', '5', '11', '8'], [1, 10, '2', '1', '7', '2', '0', '0', '15', '6', '8', '3', '12', '12'], [2, 17, '1', '1', '5', '3', '0', '0', '14', '16', '10', '4', '9', '14'], [3, 19, '4', '1', '12', '3', '0', '0', '27', '9', '6', '7', '11', '12'], [4, 11, '0', '1', '9', '2', '0', '0', '19', '9', '10', '4', '12', '6'], [5, 18, '0', '1', '1', '8', '0', '0', '8', '24', '5', '5', '18', '11'], [6, 16, '5', '1', '13', '6', '0', '0', '17', '16', '6', '5', '12', '17'], [7, 14, '2', '2', '6', '6', '0', '0', '11', '18', '3', '6', '12', '13'], [8, 12, '1', '1', '4', '1', '0', '0', '10', '13', '4', '4', '5', '12'], [9, 13, '1', '0', '3', '6', '0', '0', '15', '23', '8', '7', '14', '10'], [10, 5, '2', '1', '4', '3', '0', '0', '16', '7', '6', '7', '5', '9'], [11, 7, '0', '3', '2', '8', '1', '0', '10', '17', '5', '5', '13', '12'], [12, 2, '3', '1', '10', '5', '1', '0', '26', '13', '10', '2', '11', '13'], [13, 3, '1', '4', '5', '8', '1', '0', '16', '16', '5', '3', '14', '11'], [14, 9, '2', '0', '6', '6', '0', '0', '17', '22', '5', '6', '9', '8'], [15, 6, '1', '0', '4', '1', '0', '0', '14', '7', '3', '0', '12', '11'], [16, 4, '4', '0', '7', '2', '0', '0', '13', '9', '7', '6', '8', '12'], [17, 8, '3', '1', '6', '4', '1', '0', '12', '17', '3', '9', '12', '9'], [18, 1, '0', '1', '2', '3', '0', '1', '14', '14', '1', '8', '14', '10'], [8, 19, '3', '0', '8', '1', '0', '0', '19', '11', '6', '4', '15', '12'], [2, 14, '0', '2', '3', '6', '0', '0', '11', '17', '6', '2', '18', '11'], [1, 11, '2', '2', '11', '3', '0', '1', '19', '8', '8', '3', '6', '5'], [7, 18, '1', '1', '1', '5', '0', '0', '12', '15', '8', '6', '9', '15'], [4, 13, '0', '1', '7', '2', '0', '0', '15', '11', '7', '0', '10', '14'], [9, 10, '3', '2', '9', '4', '0', '1', '18', '9', '11', '3', '13', '11'], [3, 17, '1', '3', '10', '3', '0', '0', '25', '12', '17', '4', '10', '9'], [0, 16, '1', '3', '2', '6', '0', '0', '9', '16', '4', '6', '12', '11'], [5, 15, '1', '2', '2', '9', '0', '0', '6', '30', '1', '12', '11', '2'], [6, 12, '1', '2', '8', '4', '0', '1', '23', '9', '5', '9', '16', '10'], [19, 17, '1', '2', '1', '3', '0', '0', '16', '9', '9', '6', '8', '13'], [5, 4, '2', '2', '8', '6', '0', '0', '13', '16', '4', '6', '11', '13'], [7, 2, '2', '2', '7', '5', '0', '0', '21', '12', '5', '2', '6', '13'], [0, 14, '2', '5', '4', '10', '0', '0', '16', '20', '7', '4', '15', '9'], [8, 10, '0', '1', '2', '3', '0', '0', '21', '7', '8', '0', '10', '9'], [15, 11, '5', '1', '5', '4', '0', '0', '7', '6', '4', '5', '12', '12'], [3, 6, '3', '1', '6', '2', '0', '0', '15', '9', '5', '3', '14', '17'], [18, 13, '3', '2', '11', '4', '0', '0', '16', '12', '4', '2', '12', '12'], [12, 16, '3', '0', '4', '3', '0', '0', '17', '9', '7', '3', '12', '7'], [1, 9, '3', '1', '5', '2', '0', '0', '17', '10', '12', '3', '8', '7'], [13, 12, '1', '3', '2', '6', '0', '0', '11', '16', '4', '4', '10', '4'], [16, 18, '3', '1', '5', '3', '0', '0', '16', '6', '4', '2', '13', '9'], [11, 19, '1', '0', '2', '2', '0', '0', '13', '7', '6', '2', '6', '14'], [9, 3, '1', '3', '4', '8', '0', '0', '14', '10', '8', '1', '8', '9'], [14, 5, '2', '1', '10', '5', '0', '1', '28', '7', '15', '2', '13', '14'], [17, 15, '1', '3', '3', '15', '0', '0', '6', '29', '4', '11', '7', '11'], [6, 7, '1', '0', '2', '2', '0', '0', '9', '11', '8', '3', '8', '12'], [2, 8, '0', '0', '4', '6', '0', '0', '13', '14', '1', '7', '15', '20'], [4, 1, '0', '1', '1', '4', '0', '0', '8', '13', '1', '11', '12', '10'], [10, 0, '1', '1', '4', '3', '0', '1', '14', '10', '5', '4', '16', '10'], [18, 11, '0', '0', '3', '5', '0', '0', '7', '10', '3', '2', '10', '15'], [19, 13, '1', '1', '4', '3', '0', '1', '20', '3', '10', '1', '12', '17'], [15, 10, '2', '0', '4', '3', '1', '0', '7', '10', '6', '6', '5', '17'], [7, 4, '1', '3', '2', '6', '0', '0', '12', '18', '1', '4', '9', '12'], [0, 9, '0', '1', '4', '4', '0', '0', '12', '11', '9', '5', '6', '12'], [1, 14, '2', '2', '6', '5', '0', '0', '13', '13', '11', '4', '12', '19'], [3, 2, '3', '1', '4', '4', '0', '0', '13', '12', '4', '4', '12', '17'], [8, 16, '0', '1', '4', '7', '0', '0', '10', '15', '5', '11', '9', '11'], [12, 17, '3', '1', '7', '4', '0', '0', '22', '11', '7', '4', '12', '13'], [5, 6, '0', '8', '1', '15', '0', '0', '9', '22', '2', '6', '12', '8'], [16, 3, '6', '1', '9', '3', '0', '0', '19', '11', '1', '3', '19', '21'], [2, 1, '0', '4', '1', '8', '0', '0', '8', '15', '6', '6', '11', '10'], [4, 19, '1', '2', '5', '2', '0', '0', '23', '9', '3', '6', '8', '10'], [9, 18, '0', '1', '4', '2', '0', '0', '19', '8', '10', '4', '10', '8'], [6, 0, '2', '0', '8', '2', '0', '0', '20', '8', '5', '3', '7', '15'], [17, 5, '2', '0', '9', '2', '0', '0', '20', '16', '7', '4', '6', '9'], [13, 15, '2', '1', '1', '8', '0', '0', '3', '23', '0', '6', '18', '12'], [14, 12, '2', '1', '8', '4', '0', '2', '24', '12', '12', '5', '11', '17'], [10, 7, '1', '1', '1', '5', '1', '0', '6', '18', '1', '11', '6', '10'], [11, 8, '0', '2', '3', '4', '0', '0', '10', '11', '8', '1', '15', '12'], [19, 0, '1', '2', '3', '4', '0', '0', '18', '14', '7', '6', '14', '6'], [19, 14, '0', '1', '2', '4', '0', '1', '12', '15', '5', '6', '16', '7'], [0, 8, '1', '4', '3', '5', '0', '0', '10', '9', '7', '3', '11', '8'], [4, 2, '3', '0', '8', '4', '0', '0', '25', '11', '8', '7', '14', '15'], [11, 5, '3', '1', '6', '2', '0', '0', '20', '5', '9', '4', '8', '10'], [9, 7, '2', '1', '8', '3', '0', '0', '21', '11', '7', '5', '10', '17'], [18, 10, '0', '0', '2', '5', '0', '0', '8', '16', '3', '7', '7', '12'], [3, 12, '2', '2', '3', '4', '0', '0', '14', '14', '8', '1', '12', '20'], [17, 6, '2', '2', '3', '3', '0', '0', '5', '10', '4', '2', '11', '18'], [13, 16, '1', '1', '3', '4', '1', '0', '8', '18', '2', '10', '19', '9'], [1, 15, '1', '0', '2', '1', '0', '0', '12', '4', '5', '4', '8', '7'], [12, 4, '2', '0', '6', '1', '0', '1', '26', '6', '12', '4', '9', '9'], [2, 13, '1', '2', '4', '7', '1', '0', '7', '20', '3', '12', '15', '10'], [7, 0, '3', '0', '10', '1', '0', '1', '23', '6', '5', '5', '14', '12'], [15, 3, '2', '1', '6', '3', '1', '0', '10', '5', '2', '2', '9', '11'], [6, 18, '4', '0', '7', '3', '0', '0', '10', '17', '6', '8', '7', '12'], [10, 19, '2', '2', '8', '4', '0', '0', '19', '13', '4', '2', '12', '11'], [8, 1, '2', '2', '5', '3', '0', '0', '11', '13', '2', '7', '7', '14'], [5, 9, '1', '2', '6', '5', '0', '0', '12', '14', '5', '4', '12', '10'], [16, 17, '4', '1', '7', '4', '0', '0', '15', '14', '8', '7', '9', '15'], [14, 11, '2', '0', '5', '3', '0', '0', '15', '10', '3', '5', '10', '14'], [18, 14, '1', '2', '3', '1', '0', '0', '13', '10', '11', '2', '19', '11'], [8, 7, '0', '2', '2', '5', '0', '0', '17', '7', '10', '1', '12', '7'], [1, 5, '5', '0', '8', '0', '0', '0', '13', '2', '6', '1', '9', '13'], [2, 0, '2', '1', '6', '3', '0', '0', '13', '6', '10', '5', '9', '12'], [13, 6, '2', '2', '6', '5', '0', '0', '11', '13', '8', '7', '13', '15'], [17, 4, '0', '1', '2', '4', '0', '0', '12', '10', '4', '3', '7', '11'], [16, 19, '3', '1', '6', '1', '0', '0', '17', '7', '6', '4', '11', '10'], [3, 11, '1', '1', '7', '5', '0', '0', '18', '10', '7', '3', '12', '8'], [12, 10, '3', '0', '8', '1', '0', '0', '21', '9', '8', '3', '9', '13'], [9, 15, '0', '3', '3', '10', '0', '0', '7', '21', '7', '12', '9', '4'], [11, 9, '0', '1', '3', '5', '0', '0', '18', '12', '9', '4', '9', '15'], [7, 17, '3', '2', '4', '2', '0', '0', '16', '12', '4', '3', '12', '14'], [0, 18, '0', '2', '5', '3', '0', '0', '17', '4', '12', '1', '9', '12'], [4, 3, '1', '1', '4', '2', '0', '0', '10', '7', '3', '3', '15', '5'], [15, 2, '6', '1', '8', '1', '0', '0', '21', '5', '12', '1', '8', '9'], [5, 13, '2', '1', '2', '3', '0', '0', '11', '10', '4', '4', '13', '10'], [6, 1, '1', '0', '2', '1', '0', '0', '9', '14', '0', '11', '14', '9'], [10, 16, '2', '0', '3', '3', '0', '0', '5', '13', '0', '10', '6', '9'], [19, 12, '1', '1', '5', '6', '0', '0', '8', '24', '4', '7', '7', '13'], [14, 8, '1', '4', '5', '8', '2', '0', '8', '17', '1', '6', '12', '21'], [13, 14, '2', '1', '4', '2', '0', '0', '17', '6', '11', '3', '19', '15'], [1, 0, '3', '1', '6', '5', '1', '0', '16', '8', '3', '3', '8', '9'], [18, 4, '2', '3', '4', '4', '0', '0', '13', '8', '9', '2', '9', '18'], [9, 19, '1', '0', '4', '4', '0', '0', '15', '10', '11', '3', '9', '11'], [2, 6, '2', '0', '10', '5', '0', '0', '19', '8', '6', '5', '10', '4'], [16, 11, '3', '1', '6', '5', '0', '0', '12', '9', '2', '2', '4', '17'], [3, 5, '1', '1', '6', '1', '1', '0', '11', '9', '6', '3', '13', '16'], [12, 7, '3', '0', '10', '3', '0', '0', '17', '16', '6', '8', '16', '12'], [17, 10, '3', '2', '6', '5', '0', '0', '16', '10', '9', '4', '9', '12'], [8, 15, '4', '4', '9', '10', '0', '0', '17', '15', '3', '3', '12', '15'], [15, 12, '1', '1', '5', '3', '0', '0', '16', '8', '9', '6', '9', '11'], [0, 17, '1', '2', '5', '3', '0', '0', '11', '11', '4', '5', '11', '7'], [19, 18, '2', '1', '3', '8', '0', '0', '8', '16', '4', '5', '15', '12'], [6, 8, '4', '1', '5', '4', '0', '1', '14', '7', '4', '2', '13', '19'], [10, 3, '2', '3', '5', '5', '0', '1', '18', '11', '6', '4', '12', '7'], [5, 2, '1', '3', '2', '11', '0', '0', '10', '23', '4', '7', '6', '8'], [7, 1, '0', '1', '3', '4', '0', '0', '9', '15', '1', '8', '9', '7'], [14, 16, '1', '2', '8', '5', '0', '0', '18', '15', '9', '3', '11', '13'], [4, 9, '0', '3', '6', '4', '0', '0', '24', '9', '6', '5', '10', '8'], [11, 13, '3', '2', '6', '6', '0', '0', '12', '10', '6', '2', '13', '13'], [1, 13, '2', '1', '6', '3', '0', '0', '19', '6', '4', '0', '10', '10'], [7, 19, '3', '1', '6', '1', '0', '0', '27', '7', '7', '5', '10', '8'], [0, 5, '5', '0', '7', '3', '0', '1', '19', '6', '6', '1', '9', '12'], [10, 4, '0', '1', '2', '3', '0', '0', '13', '12', '4', '3', '15', '14'], [6, 9, '1', '0', '4', '1', '0', '0', '22', '8', '7', '3', '6', '13'], [2, 16, '2', '2', '7', '3', '0', '0', '15', '11', '7', '7', '16', '12'], [8, 3, '3', '2', '5', '9', '1', '0', '8', '18', '5', '8', '16', '12'], [12, 11, '4', '3', '12', '5', '0', '0', '26', '9', '3', '4', '6', '7'], [17, 18, '1', '1', '3', '2', '0', '0', '9', '9', '2', '3', '17', '7'], [15, 14, '3', '3', '4', '4', '0', '0', '18', '8', '10', '8', '14', '14'], [13, 0, '1', '0', '4', '3', '0', '0', '7', '12', '6', '8', '11', '15'], [19, 1, '3', '4', '4', '9', '0', '0', '6', '23', '3', '8', '14', '7'], [3, 7, '2', '1', '7', '2', '0', '0', '18', '8', '7', '3', '10', '8'], [18, 2, '0', '2', '3', '4', '0', '0', '16', '11', '3', '9', '10', '17'], [11, 10, '5', '0', '6', '1', '0', '0', '14', '4', '6', '1', '7', '10'], [5, 12, '0', '2', '1', '8', '0', '0', '6', '15', '2', '12', '12', '8'], [16, 15, '1', '0', '7', '2', '0', '0', '22', '2', '6', '0', '13', '13'], [9, 8, '2', '1', '9', '3', '0', '0', '28', '13', '12', '4', '12', '12'], [4, 6, '3', '0', '6', '3', '0', '0', '21', '13', '5', '2', '18', '8'], [14, 17, '1', '2', '7', '5', '0', '0', '23', '11', '8', '4', '11', '12'], [18, 12, '1', '2', '4', '2', '1', '0', '8', '14', '6', '5', '17', '17'], [3, 0, '1', '1', '11', '3', '0', '0', '29', '6', '9', '1', '5', '8'], [9, 2, '0', '3', '3', '4', '0', '0', '20', '10', '10', '4', '7', '10'], [5, 7, '1', '0', '4', '4', '0', '0', '9', '10', '3', '4', '14', '13'], [13, 10, '1', '1', '4', '2', '0', '0', '10', '8', '4', '3', '9', '11'], [16, 1, '1', '0', '3', '5', '0', '0', '10', '12', '3', '3', '16', '11'], [4, 8, '2', '0', '5', '4', '0', '0', '9', '16', '4', '8', '12', '12'], [11, 17, '5', '0', '8', '5', '0', '0', '14', '9', '3', '6', '5', '10'], [19, 15, '1', '2', '2', '6', '0', '0', '4', '18', '6', '3', '16', '6'], [14, 6, '4', '1', '12', '3', '0', '0', '23', '9', '3', '6', '10', '12'], [10, 14, '0', '2', '1', '6', '0', '1', '15', '12', '6', '4', '16', '11'], [8, 5, '2', '0', '6', '1', '0', '0', '15', '6', '7', '6', '9', '14'], [15, 18, '2', '2', '9', '2', '0', '0', '19', '5', '6', '1', '12', '9'], [6, 11, '3', '0', '10', '4', '0', '1', '27', '6', '5', '1', '7', '12'], [0, 4, '0', '2', '2', '6', '0', '0', '14', '9', '8', '6', '9', '8'], [1, 3, '2', '0', '9', '1', '0', '0', '26', '6', '10', '1', '11', '9'], [7, 16, '1', '2', '3', '5', '1', '1', '4', '15', '7', '12', '19', '6'], [17, 13, '3', '0', '4', '3', '0', '0', '13', '14', '6', '6', '12', '15'], [12, 9, '0', '0', '8', '1', '0', '1', '34', '6', '12', '0', '13', '8'], [18, 3, '1', '1', '3', '6', '0', '0', '11', '18', '3', '1', '12', '11'], [16, 5, '1', '1', '4', '2', '0', '0', '12', '5', '9', '1', '11', '16'], [17, 9, '2', '0', '5', '3', '0', '0', '12', '11', '4', '4', '13', '15'], [11, 0, '0', '2', '5', '2', '0', '0', '19', '7', '8', '6', '5', '17'], [19, 6, '1', '0', '5', '2', '0', '0', '16', '15', '6', '7', '11', '5'], [10, 2, '2', '3', '5', '7', '1', '0', '11', '18', '6', '6', '10', '10'], [14, 4, '2', '1', '6', '8', '0', '0', '13', '18', '3', '8', '6', '18'], [12, 1, '1', '1', '3', '2', '0', '0', '13', '13', '4', '5', '13', '14'], [13, 8, '2', '1', '6', '5', '0', '0', '14', '16', '10', '6', '11', '9'], [6, 10, '1', '3', '7', '6', '0', '0', '19', '15', '10', '2', '10', '11'], [2, 11, '3', '0', '4', '3', '0', '0', '16', '8', '6', '5', '10', '10'], [5, 19, '2', '3', '6', '4', '0', '0', '21', '12', '9', '4', '13', '13'], [0, 12, '0', '2', '0', '10', '0', '0', '9', '19', '4', '4', '7', '10'], [9, 16, '3', '2', '7', '4', '0', '0', '13', '10', '3', '6', '10', '10'], [7, 13, '1', '4', '4', '5', '0', '0', '14', '11', '8', '2', '5', '14'], [8, 18, '2', '1', '4', '5', '0', '0', '9', '13', '4', '3', '13', '16'], [4, 15, '1', '3', '2', '9', '0', '0', '7', '23', '8', '4', '13', '5'], [3, 14, '4', '2', '9', '3', '0', '0', '15', '19', '7', '6', '18', '6'], [1, 17, '0', '2', '8', '3', '0', '0', '30', '6', '10', '3', '8', '8'], [19, 8, '2', '3', '6', '8', '0', '0', '15', '12', '7', '2', '14', '21'], [16, 0, '3', '2', '7', '5', '0', '1', '19', '9', '6', '2', '9', '14'], [18, 7, '3', '1', '6', '4', '0', '0', '13', '9', '7', '4', '14', '10'], [15, 5, '2', '0', '4', '2', '0', '0', '18', '4', '12', '2', '5', '6'], [13, 4, '3', '0', '6', '0', '0', '0', '12', '10', '5', '2', '9', '14'], [10, 9, '2', '1', '2', '5', '0', '0', '8', '10', '4', '5', '9', '11'], [11, 1, '2', '1', '4', '3', '0', '0', '15', '13', '5', '4', '11', '10'], [14, 2, '3', '1', '6', '4', '0', '0', '12', '24', '4', '13', '9', '18'], [12, 6, '4', '2', '15', '3', '0', '0', '34', '5', '7', '3', '16', '15'], [17, 3, '0', '0', '2', '8', '0', '0', '6', '22', '2', '0', '4', '6'], [0, 19, '1', '1', '7', '5', '0', '0', '13', '14', '2', '8', '7', '12'], [8, 11, '1', '0', '3', '4', '0', '0', '17', '14', '6', '4', '13', '9'], [6, 15, '2', '3', '5', '11', '0', '0', '12', '27', '3', '13', '7', '7'], [4, 16, '0', '0', '2', '5', '0', '0', '10', '16', '4', '5', '13', '14'], [9, 14, '2', '2', '2', '6', '0', '0', '9', '16', '8', '13', '8', '5'], [1, 18, '5', '0', '6', '5', '0', '0', '21', '12', '6', '7', '8', '12'], [7, 10, '3', '2', '5', '3', '0', '0', '11', '12', '6', '4', '10', '14'], [5, 17, '2', '2', '6', '5', '1', '1', '21', '16', '4', '1', '11', '10'], [2, 12, '0', '4', '1', '7', '0', '0', '11', '14', '8', '5', '9', '12'], [3, 13, '0', '0', '4', '3', '0', '0', '11', '8', '8', '2', '10', '13'], [10, 1, '1', '2', '3', '3', '0', '0', '9', '19', '2', '11', '6', '7'], [11, 4, '0', '0', '6', '4', '0', '0', '25', '21', '15', '6', '6', '13'], [19, 3, '4', '0', '8', '2', '0', '0', '18', '9', '7', '4', '13', '14'], [18, 5, '3', '2', '4', '5', '0', '0', '12', '9', '11', '1', '8', '18'], [16, 6, '1', '3', '6', '5', '0', '0', '12', '14', '8', '7', '14', '12'], [15, 0, '3', '1', '4', '3', '0', '0', '14', '8', '7', '3', '3', '13'], [14, 7, '3', '2', '5', '5', '0', '0', '19', '9', '5', '3', '13', '15'], [12, 8, '4', '1', '13', '3', '0', '0', '28', '4', '8', '1', '15', '16'], [17, 2, '1', '1', '3', '4', '0', '0', '9', '9', '1', '5', '13', '11'], [13, 9, '3', '4', '7', '8', '0', '0', '16', '21', '4', '5', '10', '10'], [4, 14, '2', '2', '5', '6', '0', '0', '14', '9', '9', '5', '8', '14'], [3, 18, '4', '1', '6', '5', '0', '0', '13', '7', '3', '2', '8', '14'], [0, 11, '2', '2', '4', '7', '0', '0', '12', '15', '2', '13', '11', '7'], [6, 19, '4', '4', '6', '8', '0', '0', '19', '11', '8', '2', '13', '16'], [5, 16, '0', '5', '5', '10', '0', '0', '10', '14', '3', '4', '10', '7'], [2, 10, '1', '1', '2', '6', '1', '0', '9', '8', '11', '6', '19', '12'], [8, 13, '2', '4', '6', '7', '0', '0', '15', '14', '10', '1', '15', '11'], [9, 17, '3', '0', '5', '3', '0', '0', '12', '22', '5', '8', '10', '5'], [1, 12, '3', '1', '7', '1', '0', '1', '15', '10', '2', '4', '11', '11'], [7, 15, '1', '3', '3', '15', '0', '0', '9', '25', '8', '13', '2', '4'], [15, 4, '2', '0', '3', '1', '0', '0', '19', '5', '9', '0', '6', '11'], [11, 2, '3', '1', '6', '4', '0', '0', '7', '25', '1', '14', '11', '11'], [12, 0, '3', '1', '10', '4', '0', '0', '25', '9', '9', '3', '11', '13'], [19, 5, '1', '3', '5', '3', '0', '0', '20', '7', '13', '1', '7', '12'], [14, 3, '2', '1', '6', '3', '0', '0', '16', '6', '9', '6', '14', '13'], [13, 7, '0', '2', '5', '6', '0', '0', '17', '9', '7', '4', '11', '9'], [10, 6, '2', '3', '3', '5', '0', '0', '13', '7', '4', '4', '9', '6'], [17, 1, '0', '6', '1', '12', '0', '0', '5', '25', '2', '6', '17', '11'], [16, 9, '1', '2', '10', '5', '0', '0', '23', '17', '10', '8', '9', '7'], [18, 8, '1', '3', '4', '5', '0', '0', '13', '14', '1', '7', '14', '7'], [7, 12, '1', '4', '6', '8', '0', '0', '15', '15', '1', '6', '4', '18'], [0, 1, '0', '5', '0', '7', '0', '0', '8', '16', '4', '6', '11', '8'], [11, 16, '1', '2', '4', '3', '0', '0', '15', '12', '4', '4', '11', '6'], [6, 2, '2', '2', '5', '7', '0', '0', '17', '12', '4', '2', '9', '22'], [10, 17, '2', '0', '8', '3', '0', '1', '19', '10', '5', '3', '13', '15'], [14, 13, '1', '2', '4', '7', '0', '0', '15', '12', '10', '4', '8', '13'], [15, 8, '1', '1', '5', '6', '0', '0', '31', '9', '12', '1', '7', '12'], [5, 3, '0', '5', '1', '10', '1', '0', '6', '24', '5', '10', '3', '5'], [19, 9, '1', '2', '4', '9', '0', '0', '22', '21', '8', '6', '7', '21'], [4, 18, '1', '1', '4', '4', '0', '0', '19', '10', '3', '6', '8', '12'], []]\n",
            "\n",
            "\n",
            "est probability before training of team 2 landing 5 goals against team 3\n",
            " when team 2 has (ST,R,S,C,F)= (1,0,2,1,3): 0.010052732453946856\n",
            "\n",
            "\n",
            "\n",
            "exclude [4,5,6] as unseen validation set\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(732.4490966797, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8056295514), tensor(1.8165372610), tensor(1.0899741650), tensor(1.4986091852), tensor(0.8660742640), tensor(0.7152472734), tensor(1.6540648937), tensor(1.1523901224), tensor(1.3273270130), tensor(1.0975357294), tensor(1.0107187033), tensor(1.0743565559), tensor(1.8487367630), tensor(1.2307584286), tensor(1.6365678310), tensor(1.8540691137), tensor(1.6325730085), tensor(1.1306068897), tensor(0.8900962472), tensor(1.1089200974)]\n",
            "b:  [tensor(1.7086156607), tensor(0.7066591382), tensor(1.4970642328), tensor(1.2705833912), tensor(1.0283670425), tensor(2.0386443138), tensor(1.2934528589), tensor(1.4058351517), tensor(1.2868323326), tensor(1.0669306517), tensor(1.3787306547), tensor(1.2979890108), tensor(0.7589616776), tensor(1.2589234114), tensor(1.2065541744), tensor(0.8685613275), tensor(1.0252299309), tensor(1.3873727322), tensor(1.3905031681), tensor(1.5427570343)]\n",
            "c:  [tensor(0.0010674244), tensor(0.0010674244), tensor(0.0010674244), tensor(0.0010100615), tensor(0.0009997525), tensor(0.0010056903), tensor(0.0009974471), tensor(0.0010017251), tensor(0.0010100615), tensor(0.0009997525), tensor(0.0010056903), tensor(0.0009974471), tensor(0.0010017251), tensor(0.0010100615), tensor(0.0009997525), tensor(0.0010056903), tensor(0.0009974471), tensor(0.0010017251)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.8720471859,  0.9091836810, -0.7974189520,  1.2256376743,\n",
            "        -1.6212399006, -2.2767276764,  1.4182429314, -0.4814249873,\n",
            "        -0.5319744349,  0.4137090147, -0.3475096822, -0.4160135984,\n",
            "         0.8368672729, -0.3180201054,  0.0203150064,  1.4839967489,\n",
            "         0.4197925329,  0.2542316318, -0.8757982850,  0.5867847204])\n",
            "btensor.grad: tensor([ 2.2584412098, -1.4179136753,  1.1178269386, -1.1528804302,\n",
            "         1.0353016853,  0.7319400311, -0.2921994925,  0.4043720961,\n",
            "         0.3698537946,  0.3265793324,  0.6229457855, -0.7458064556,\n",
            "        -0.3528887331,  0.0131132603, -1.0452308655, -1.6076474190,\n",
            "         1.3490041494, -0.2412726879, -0.5543138981, -0.1726585031])\n",
            "ctensor.grad: tensor([-0.6742436886, -0.6742436886, -0.6742436886, -0.1006145254,\n",
            "         0.0024755334, -0.0569022223,  0.0255300757, -0.0172503572,\n",
            "        -0.1006145254,  0.0024755334, -0.0569022223,  0.0255300757,\n",
            "        -0.0172503572, -0.1006145254,  0.0024755334, -0.0569022223,\n",
            "         0.0255300757, -0.0172503572])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(732.1079711914, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8165054917), tensor(1.8093293905), tensor(1.0954695940), tensor(1.4889893532), tensor(0.8761074543), tensor(0.7277104855), tensor(1.6423919201), tensor(1.1558098793), tensor(1.3310474157), tensor(1.0946626663), tensor(1.0130779743), tensor(1.0778155327), tensor(1.8421392441), tensor(1.2331616879), tensor(1.6367367506), tensor(1.8422945738), tensor(1.6294552088), tensor(1.1288738251), tensor(0.8958705068), tensor(1.1048425436)]\n",
            "b:  [tensor(1.6905889511), tensor(0.7139199376), tensor(1.4881505966), tensor(1.2786351442), tensor(1.0211403370), tensor(2.0328624249), tensor(1.2954987288), tensor(1.4024380445), tensor(1.2840189934), tensor(1.0644465685), tensor(1.3739321232), tensor(1.3032655716), tensor(0.7605832815), tensor(1.2585487366), tensor(1.2138834000), tensor(0.8781455755), tensor(1.0144572258), tensor(1.3889093399), tensor(1.3946070671), tensor(1.5437905788)]\n",
            "c:  [tensor(0.0010851712), tensor(0.0010851712), tensor(0.0010851712), tensor(0.0010207379), tensor(0.0009994844), tensor(0.0010115217), tensor(0.0009946610), tensor(0.0010029945), tensor(0.0010207379), tensor(0.0009994844), tensor(0.0010115217), tensor(0.0009946610), tensor(0.0010029945), tensor(0.0010207379), tensor(0.0009994844), tensor(0.0010115217), tensor(0.0009946610), tensor(0.0010029945)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.0875968933,  0.7207906246, -0.5495460033,  0.9619802237,\n",
            "        -1.0033216476, -1.2463190556,  1.1673007011, -0.3419805765,\n",
            "        -0.3720379472,  0.2873048782, -0.2359236777, -0.3458998203,\n",
            "         0.6597573161, -0.2403208017, -0.0168959051,  1.1774559021,\n",
            "         0.3117823601,  0.1733057499, -0.5774262547,  0.4077513218])\n",
            "btensor.grad: tensor([ 1.8026735783, -0.7260771990,  0.8913656473, -0.8051713705,\n",
            "         0.7226729393,  0.5781992078, -0.2045878172,  0.3397095799,\n",
            "         0.2813361287,  0.2484098673,  0.4798537493, -0.5276615620,\n",
            "        -0.1621626318,  0.0374664664, -0.7329242826, -0.9584264159,\n",
            "         1.0772646666, -0.1536558568, -0.4103894234, -0.1033602357])\n",
            "ctensor.grad: tensor([-0.1774679273, -0.1774679273, -0.1774679273, -0.1067643538,\n",
            "         0.0026805331, -0.0583130643,  0.0278609190, -0.0126941847,\n",
            "        -0.1067643538,  0.0026805331, -0.0583130643,  0.0278609190,\n",
            "        -0.0126941847, -0.1067643538,  0.0026805331, -0.0583130643,\n",
            "         0.0278609190, -0.0126941847])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.9396362305, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8230985999), tensor(1.8037325144), tensor(1.0994031429), tensor(1.4816026688), tensor(0.8825690150), tensor(0.7349278331), tensor(1.6329791546), tensor(1.1583832502), tensor(1.3338079453), tensor(1.0928239822), tensor(1.0148556232), tensor(1.0808390379), tensor(1.8371030092), tensor(1.2351135015), tensor(1.6372542381), tensor(1.8330618143), tensor(1.6272737980), tensor(1.1278741360), tensor(0.8998782635), tensor(1.1021693945)]\n",
            "b:  [tensor(1.6763778925), tensor(0.7177823186), tensor(1.4812132120), tensor(1.2844395638), tensor(1.0162630081), tensor(2.0283825397), tensor(1.2970669270), tensor(1.3997564316), tensor(1.2820303440), tensor(1.0626987219), tensor(1.3703988791), tensor(1.3071817160), tensor(0.7613997459), tensor(1.2582255602), tensor(1.2192054987), tensor(0.8840723038), tensor(1.0061955452), tensor(1.3900527954), tensor(1.3978155851), tensor(1.5445868969)]\n",
            "c:  [tensor(0.0010894127), tensor(0.0010894127), tensor(0.0010894127), tensor(0.0010316276), tensor(0.0009992108), tensor(0.0010174910), tensor(0.0009918637), tensor(0.0010040676), tensor(0.0010316276), tensor(0.0009992108), tensor(0.0010174910), tensor(0.0009918637), tensor(0.0010040676), tensor(0.0010316276), tensor(0.0009992108), tensor(0.0010174910), tensor(0.0009918637), tensor(0.0010040676)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.6593130827,  0.5596894026, -0.3933596313,  0.7386633158,\n",
            "        -0.6461564302, -0.7217346430,  0.9412716627, -0.2573376298,\n",
            "        -0.2760485411,  0.1838668883, -0.1777612269, -0.3023563623,\n",
            "         0.5036197305, -0.1951861382, -0.0517514348,  0.9232745767,\n",
            "         0.2181448936,  0.0999652743, -0.4007766843,  0.2673124075])\n",
            "btensor.grad: tensor([ 1.4211106300, -0.3862396777,  0.6937399507, -0.5804417729,\n",
            "         0.4877271652,  0.4479773343, -0.1568182707,  0.2681612372,\n",
            "         0.1988617778,  0.1747858524,  0.3533302546, -0.3916133046,\n",
            "        -0.0816482231,  0.0323222280, -0.5322068334, -0.5926732421,\n",
            "         0.8261719942, -0.1143481433, -0.3208498955, -0.0796343088])\n",
            "ctensor.grad: tensor([-0.0424144715, -0.0424144715, -0.0424144715, -0.1088974774,\n",
            "         0.0027366090, -0.0596931875,  0.0279730484, -0.0107308682,\n",
            "        -0.1088974774,  0.0027366090, -0.0596931875,  0.0279730484,\n",
            "        -0.0107308682, -0.1088974774,  0.0027366090, -0.0596931875,\n",
            "         0.0279730484, -0.0107308682])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.8496093750, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8271973133), tensor(1.7994205952), tensor(1.1022727489), tensor(1.4759886265), tensor(0.8868369460), tensor(0.7392499447), tensor(1.6254602671), tensor(1.1603690386), tensor(1.3359189034), tensor(1.0917191505), tensor(1.0162591934), tensor(1.0834878683), tensor(1.8333221674), tensor(1.2367305756), tensor(1.6379983425), tensor(1.8258512020), tensor(1.6258089542), tensor(1.1274042130), tensor(0.9027429223), tensor(1.1004962921)]\n",
            "b:  [tensor(1.6652420759), tensor(0.7198714018), tensor(1.4758720398), tensor(1.2886906862), tensor(1.0130382776), tensor(2.0249295235), tensor(1.2983145714), tensor(1.3976902962), tensor(1.2806787491), tensor(1.0615084171), tensor(1.3678569794), tensor(1.3101650476), tensor(0.7618535161), tensor(1.2580071688), tensor(1.2231438160), tensor(0.8878201842), tensor(0.9999982715), tensor(1.3909791708), tensor(1.4003864527), tensor(1.5452940464)]\n",
            "c:  [tensor(0.0010921125), tensor(0.0010921125), tensor(0.0010921125), tensor(0.0010426169), tensor(0.0009989358), tensor(0.0010235943), tensor(0.0009891101), tensor(0.0010050612), tensor(0.0010426169), tensor(0.0009989358), tensor(0.0010235943), tensor(0.0009891101), tensor(0.0010050612), tensor(0.0010426169), tensor(0.0009989358), tensor(0.0010235943), tensor(0.0009891101), tensor(0.0010050612)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.4098694324,  0.4311864376, -0.2869588733,  0.5614054203,\n",
            "        -0.4267917871, -0.4322118461,  0.7518841624, -0.1985804439,\n",
            "        -0.2110916823,  0.1104790568, -0.1403566599, -0.2648805380,\n",
            "         0.3780861199, -0.1617133617, -0.0744136870,  0.7210602760,\n",
            "         0.1464881897,  0.0469936728, -0.2864648700,  0.1673050523])\n",
            "btensor.grad: tensor([ 1.1135798693, -0.2089100182,  0.5341214538, -0.4251151383,\n",
            "         0.3224759102,  0.3453009129, -0.1247614622,  0.2066117525,\n",
            "         0.1351618767,  0.1190330982,  0.2541928291, -0.2983339429,\n",
            "        -0.0453758985,  0.0218447149, -0.3938286304, -0.3747866750,\n",
            "         0.6197279692, -0.0926318169, -0.2570809126, -0.0707191229])\n",
            "ctensor.grad: tensor([-0.0269973874, -0.0269973874, -0.0269973874, -0.1098921299,\n",
            "         0.0027494249, -0.0610333048,  0.0275358427, -0.0099355876,\n",
            "        -0.1098921299,  0.0027494249, -0.0610333048,  0.0275358427,\n",
            "        -0.0099355876, -0.1098921299,  0.0027494249, -0.0610333048,\n",
            "         0.0275358427, -0.0099355876])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.8000488281, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8297823668), tensor(1.7961044312), tensor(1.1043832302), tensor(1.4717406034), tensor(0.8897022009), tensor(0.7418943644), tensor(1.6194794178), tensor(1.1619132757), tensor(1.3375544548), tensor(1.0910972357), tensor(1.0173833370), tensor(1.0857779980), tensor(1.8305107355), tensor(1.2380671501), tensor(1.6388531923), tensor(1.8202216625), tensor(1.6248619556), tensor(1.1272755861), tensor(0.9048233628), tensor(1.0994988680)]\n",
            "b:  [tensor(1.6565407515), tensor(0.7210018635), tensor(1.4717780352), tensor(1.2918258905), tensor(1.0109345913), tensor(2.0222637653), tensor(1.2993161678), tensor(1.3961112499), tensor(1.2797826529), tensor(1.0607057810), tensor(1.3660528660), tensor(1.3124692440), tensor(0.7621309757), tensor(1.2578778267), tensor(1.2260873318), tensor(0.8902232647), tensor(0.9954101443), tensor(1.3917559385), tensor(1.4024652243), tensor(1.5459525585)]\n",
            "c:  [tensor(0.0010967576), tensor(0.0010967576), tensor(0.0010967576), tensor(0.0010536866), tensor(0.0009986602), tensor(0.0010298233), tensor(0.0009864001), tensor(0.0010060236), tensor(0.0010536866), tensor(0.0009986602), tensor(0.0010298233), tensor(0.0009864001), tensor(0.0010060236), tensor(0.0010536866), tensor(0.0009986602), tensor(0.0010298233), tensor(0.0009864001), tensor(0.0010060236)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.2585039735,  0.3316142559, -0.2110440135,  0.4247982502,\n",
            "        -0.2865240574, -0.2644440234,  0.5980833173, -0.1544289589,\n",
            "        -0.1635544002,  0.0621916056, -0.1124101430, -0.2290186882,\n",
            "         0.2811450660, -0.1336560249, -0.0854884684,  0.5629495978,\n",
            "         0.0946987867,  0.0128593445, -0.2080469131,  0.0997456908])\n",
            "btensor.grad: tensor([ 0.8701327443, -0.1130451560,  0.4094014466, -0.3135220706,\n",
            "         0.2103669643,  0.2665826678, -0.1001577377,  0.1579042077,\n",
            "         0.0896090865,  0.0802615881,  0.1804149598, -0.2304183245,\n",
            "        -0.0277435537,  0.0129397511, -0.2943538427, -0.2403078079,\n",
            "         0.4588111341, -0.0776745379, -0.2078802586, -0.0658565760])\n",
            "ctensor.grad: tensor([-0.0464505702, -0.0464505702, -0.0464505702, -0.1106971055,\n",
            "         0.0027553202, -0.0622898974,  0.0271007754, -0.0096242586,\n",
            "        -0.1106971055,  0.0027553202, -0.0622898974,  0.0271007754,\n",
            "        -0.0096242586, -0.1106971055,  0.0027553202, -0.0622898974,\n",
            "         0.0271007754, -0.0096242586])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7714233398, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8314241767), tensor(1.7935506105), tensor(1.1059386730), tensor(1.4685305357), tensor(0.8916460276), tensor(0.7435351014), tensor(1.6147294044), tensor(1.1631133556), tensor(1.3388267756), tensor(1.0907765627), tensor(1.0182831287), tensor(1.0877268314), tensor(1.8284330368), tensor(1.2391610146), tensor(1.6397335529), tensor(1.8158202171), tensor(1.6242771149), tensor(1.1273475885), tensor(0.9063466787), tensor(1.0989415646)]\n",
            "b:  [tensor(1.6497493982), tensor(0.7216036916), tensor(1.4686437845), tensor(1.2941424847), tensor(1.0095751286), tensor(2.0201957226), tensor(1.3001176119), tensor(1.3949049711), tensor(1.2791994810), tensor(1.0601619482), tensor(1.3647837639), tensor(1.3142614365), tensor(0.7623149753), tensor(1.2578092813), tensor(1.2282987833), tensor(0.8917771578), tensor(0.9920406938), tensor(1.3924130201), tensor(1.4041494131), tensor(1.5465676785)]\n",
            "c:  [tensor(0.0011039261), tensor(0.0011039261), tensor(0.0011039261), tensor(0.0010648470), tensor(0.0009983837), tensor(0.0010361704), tensor(0.0009837189), tensor(0.0010069751), tensor(0.0010648470), tensor(0.0009983837), tensor(0.0010361704), tensor(0.0009837189), tensor(0.0010069751), tensor(0.0010648470), tensor(0.0009983837), tensor(0.0010361704), tensor(0.0009837189), tensor(0.0010069751)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.1641800404,  0.2553811371, -0.1555393338,  0.3210054636,\n",
            "        -0.1943829656, -0.1640740037,  0.4750056863, -0.1200105548,\n",
            "        -0.1272374690,  0.0320693851, -0.0899770260, -0.1948840618,\n",
            "         0.2077670097, -0.1093899012, -0.0880416930,  0.4401423335,\n",
            "         0.0584783554, -0.0072010159, -0.1523324251,  0.0557254553])\n",
            "btensor.grad: tensor([ 0.6791384816, -0.0601834953,  0.3134225309, -0.2316649258,\n",
            "         0.1359472275,  0.2068088800, -0.0801473856,  0.1206337735,\n",
            "         0.0583141446,  0.0543776751,  0.1269051433, -0.1792173982,\n",
            "        -0.0183977056,  0.0068539381, -0.2211485207, -0.1553919911,\n",
            "         0.3369432092, -0.0657095015, -0.1684235334, -0.0615155697])\n",
            "ctensor.grad: tensor([-0.0716855079, -0.0716855079, -0.0716855079, -0.1116036102,\n",
            "         0.0027653954, -0.0634712726,  0.0268117152, -0.0095149688,\n",
            "        -0.1116036102,  0.0027653954, -0.0634712726,  0.0268117152,\n",
            "        -0.0095149688, -0.1116036102,  0.0027653954, -0.0634712726,\n",
            "         0.0268117152, -0.0095149688])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7551269531, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8324682117), tensor(1.7915782928), tensor(1.1070836782), tensor(1.4661037922), tensor(0.8929736018), tensor(0.7445620298), tensor(1.6109573841), tensor(1.1640418768), tensor(1.3398160934), tensor(1.0906348228), tensor(1.0189988613), tensor(1.0893608332), tensor(1.8269048929), tensor(1.2400465012), tensor(1.6405844688), tensor(1.8123713732), tensor(1.6239398718), tensor(1.1275248528), tensor(0.9074664116), tensor(1.0986623764)]\n",
            "b:  [tensor(1.6444498301), tensor(0.7219117880), tensor(1.4662432671), tensor(1.2958525419), tensor(1.0087026358), tensor(2.0185811520), tensor(1.3007539511), tensor(1.3939801455), tensor(1.2788261175), tensor(1.0597876310), tensor(1.3638975620), tensor(1.3156602383), tensor(0.7624448538), tensor(1.2577776909), tensor(1.2299647331), tensor(0.8927870989), tensor(0.9895786643), tensor(1.3929678202), tensor(1.4055124521), tensor(1.5471355915)]\n",
            "c:  [tensor(0.0011133070), tensor(0.0011133070), tensor(0.0011133070), tensor(0.0010761142), tensor(0.0009981055), tensor(0.0010426301), tensor(0.0009810510), tensor(0.0010079246), tensor(0.0010761142), tensor(0.0009981055), tensor(0.0010426301), tensor(0.0009810510), tensor(0.0010079246), tensor(0.0010761142), tensor(0.0009981055), tensor(0.0010426301), tensor(0.0009810510), tensor(0.0010079246)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.1044051051,  0.1972366869, -0.1144985855,  0.2426772118,\n",
            "        -0.1327603459, -0.1026919335,  0.3771992922, -0.0928505957,\n",
            "        -0.0989281088,  0.0141764283, -0.0715788901, -0.1633996964,\n",
            "         0.1528140306, -0.0885429382, -0.0850920379,  0.3448864222,\n",
            "         0.0337294340, -0.0177248120, -0.1119734049,  0.0279142857])\n",
            "btensor.grad: tensor([ 0.5299594998, -0.0308102369,  0.2400563359, -0.1710095704,\n",
            "         0.0872507095,  0.1614517868, -0.0636388063,  0.0924786702,\n",
            "         0.0373334885,  0.0374268293,  0.0886232257, -0.1398747563,\n",
            "        -0.0129885171,  0.0031589270, -0.1665990353, -0.1009919643,\n",
            "         0.2462040186, -0.0554824769, -0.1363017559, -0.0567854643])\n",
            "ctensor.grad: tensor([-0.0938085467, -0.0938085467, -0.0938085467, -0.1126720160,\n",
            "         0.0027818941, -0.0645966008,  0.0266786404, -0.0094952248,\n",
            "        -0.1126720160,  0.0027818941, -0.0645966008,  0.0266786404,\n",
            "        -0.0094952248, -0.1126720160,  0.0027818941, -0.0645966008,\n",
            "         0.0266786404, -0.0094952248])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7455444336, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8331295848), tensor(1.7900495529), tensor(1.1079241037), tensor(1.4642665386), tensor(0.8938840628), tensor(0.7452077270), tensor(1.6079603434), tensor(1.1647559404), tensor(1.3405830860), tensor(1.0905934572), tensor(1.0195640326), tensor(1.0907135010), tensor(1.8257857561), tensor(1.2407557964), tensor(1.6413741112), tensor(1.8096621037), tensor(1.6237680912), tensor(1.1277468204), tensor(0.9082908630), tensor(1.0985532999)]\n",
            "b:  [tensor(1.6403130293), tensor(0.7220571041), tensor(1.4644020796), tensor(1.2971112728), tensor(1.0081455708), tensor(2.0173120499), tensor(1.3012547493), tensor(1.3932673931), tensor(1.2785910368), tensor(1.0595237017), tensor(1.3632829189), tensor(1.3167537451), tensor(0.7625408769), tensor(1.2577663660), tensor(1.2312216759), tensor(0.8934453130), tensor(0.9877852798), tensor(1.3934336901), tensor(1.4066129923), tensor(1.5476521254)]\n",
            "c:  [tensor(0.0011244144), tensor(0.0011244144), tensor(0.0011244144), tensor(0.0010875030), tensor(0.0009978251), tensor(0.0010491982), tensor(0.0009783835), tensor(0.0010088766), tensor(0.0010875030), tensor(0.0009978251), tensor(0.0010491982), tensor(0.0009783835), tensor(0.0010088766), tensor(0.0010875030), tensor(0.0009978251), tensor(0.0010491982), tensor(0.0009783835), tensor(0.0010088766)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.0661367178,  0.1528735161, -0.0840391219,  0.1837197542,\n",
            "        -0.0910432935, -0.0645725653,  0.2997099161, -0.0714108646,\n",
            "        -0.0766945034,  0.0041338801, -0.0565131307, -0.1352707148,\n",
            "         0.1119135022, -0.0709350109, -0.0789632499,  0.2709219456,\n",
            "         0.0171730518, -0.0221958160, -0.0824427605,  0.0109088421])\n",
            "btensor.grad: tensor([ 0.4136788249, -0.0145313740,  0.1841171682, -0.1258774400,\n",
            "         0.0557050705,  0.1268994808, -0.0500836372,  0.0712698698,\n",
            "         0.0235050917,  0.0263897181,  0.0614596903, -0.1093466282,\n",
            "        -0.0096001867,  0.0011380017, -0.1256914735, -0.0658215880,\n",
            "         0.1793360710, -0.0465902090, -0.1100594997, -0.0516482592])\n",
            "ctensor.grad: tensor([-0.1110744774, -0.1110744774, -0.1110744774, -0.1138885170,\n",
            "         0.0028042477, -0.0656821057,  0.0266750194, -0.0095199998,\n",
            "        -0.1138885170,  0.0028042477, -0.0656821057,  0.0266750194,\n",
            "        -0.0095199998, -0.1138885170,  0.0028042477, -0.0656821057,\n",
            "         0.0266750194, -0.0095199998])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7394409180, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8335446715), tensor(1.7888602018), tensor(1.1085383892), tensor(1.4628729820), tensor(0.8945097923), tensor(0.7456141114), tensor(1.6055765152), tensor(1.1653016806), tensor(1.3411753178), tensor(1.0906040668), tensor(1.0200068951), tensor(1.0918215513), tensor(1.8249698877), tensor(1.2413191795), tensor(1.6420868635), tensor(1.8075286150), tensor(1.6237045527), tensor(1.1279773712), tensor(0.9088981748), tensor(1.0985438824)]\n",
            "b:  [tensor(1.6370819807), tensor(0.7221135497), tensor(1.4629874229), tensor(1.2980340719), tensor(1.0077914000), tensor(2.0163078308), tensor(1.3016453981), tensor(1.3927148581), tensor(1.2784458399), tensor(1.0593320131), tensor(1.3628600836), tensor(1.3176090717), tensor(0.7626142502), tensor(1.2577646971), tensor(1.2321709394), tensor(0.8938749433), tensor(0.9864814878), tensor(1.3938225508), tensor(1.4074995518), tensor(1.5481153727)]\n",
            "c:  [tensor(0.0011368156), tensor(0.0011368156), tensor(0.0011368156), tensor(0.0010990252), tensor(0.0009975419), tensor(0.0010558722), tensor(0.0009757065), tensor(0.0010098336), tensor(0.0010990252), tensor(0.0009975419), tensor(0.0010558722), tensor(0.0009757065), tensor(0.0010098336), tensor(0.0010990252), tensor(0.0009975419), tensor(0.0010558722), tensor(0.0009757065), tensor(0.0010098336)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.0415081978,  0.1189399958, -0.0614342690,  0.1393603086,\n",
            "        -0.0625709891, -0.0406355299,  0.2383842468, -0.0545689464,\n",
            "        -0.0592217557, -0.0010646880, -0.0442871153, -0.1108046770,\n",
            "         0.0815848708, -0.0563331842, -0.0712791681,  0.2133503407,\n",
            "         0.0063531399, -0.0230537057, -0.0607321262,  0.0009391010])\n",
            "btensor.grad: tensor([ 3.2310616970e-01, -5.6439042091e-03,  1.4146733284e-01,\n",
            "        -9.2284828424e-02,  3.5416841507e-02,  1.0041494668e-01,\n",
            "        -3.9070725441e-02,  5.5256336927e-02,  1.4514803886e-02,\n",
            "         1.9165754318e-02,  4.2279452085e-02, -8.5538029671e-02,\n",
            "        -7.3400419205e-03,  1.6620755196e-04, -9.4925731421e-02,\n",
            "        -4.2960584164e-02,  1.3037705421e-01, -3.8885504007e-02,\n",
            "        -8.8655233383e-02, -4.6327948570e-02])\n",
            "ctensor.grad: tensor([-0.1240131408, -0.1240131408, -0.1240131408, -0.1152223870,\n",
            "         0.0028312479, -0.0667397231,  0.0267699286, -0.0095710326,\n",
            "        -0.1152223870,  0.0028312479, -0.0667397231,  0.0267699286,\n",
            "        -0.0095710326, -0.1152223870,  0.0028312479, -0.0667397231,\n",
            "         0.0267699286, -0.0095710326])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7362670898, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8338009119), tensor(1.7879312038), tensor(1.1089854240), tensor(1.4618134499), tensor(0.8949400187), tensor(0.7458689213), tensor(1.6036781073), tensor(1.1657159328), tensor(1.3416304588), tensor(1.0906379223), tensor(1.0203516483), tensor(1.0927212238), tensor(1.8243782520), tensor(1.2417632341), tensor(1.6427177191), tensor(1.8058444262), tensor(1.6237095594), tensor(1.1281963587), tensor(0.9093455672), tensor(1.0985893011)]\n",
            "b:  [tensor(1.6345564127), tensor(0.7221229672), tensor(1.4618982077), tensor(1.2987072468), tensor(1.0075668097), tensor(2.0155081749), tensor(1.3019477129), tensor(1.3922837973), tensor(1.2783583403), tensor(1.0591882467), tensor(1.3625721931), tensor(1.3182784319), tensor(0.7626718283), tensor(1.2577667236), tensor(1.2328884602), tensor(0.8941555023), tensor(0.9855347276), tensor(1.3941452503), tensor(1.4082119465), tensor(1.5485260487)]\n",
            "c:  [tensor(0.0011501787), tensor(0.0011501787), tensor(0.0011501787), tensor(0.0011106897), tensor(0.0009972558), tensor(0.0010626500), tensor(0.0009730128), tensor(0.0010107977), tensor(0.0011106897), tensor(0.0009972558), tensor(0.0010626500), tensor(0.0009730128), tensor(0.0010107977), tensor(0.0011106897), tensor(0.0009972558), tensor(0.0010626500), tensor(0.0009730128), tensor(0.0010107977)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.0256250501,  0.0928968638, -0.0446991026,  0.1059570312,\n",
            "        -0.0430250764, -0.0254794657,  0.1898403764, -0.0414210856,\n",
            "        -0.0455177054, -0.0033876300, -0.0344727784, -0.0899661779,\n",
            "         0.0591649413, -0.0444021225, -0.0630894899,  0.1684143990,\n",
            "        -0.0005028248, -0.0218968987, -0.0447387099, -0.0045472085])\n",
            "btensor.grad: tensor([ 2.5255593657e-01, -9.4285607338e-04,  1.0891723633e-01,\n",
            "        -6.7312389612e-02,  2.2457838058e-02,  7.9975038767e-02,\n",
            "        -3.0226469040e-02,  4.3112024665e-02,  8.7443590164e-03,\n",
            "         1.4370799065e-02,  2.8794020414e-02, -6.6930770874e-02,\n",
            "        -5.7590696961e-03, -2.0024180412e-04, -7.1748137474e-02,\n",
            "        -2.8053581715e-02,  9.4675779343e-02, -3.2268941402e-02,\n",
            "        -7.1242928505e-02, -4.1062831879e-02])\n",
            "ctensor.grad: tensor([-0.1336303204, -0.1336303204, -0.1336303204, -0.1166449487,\n",
            "         0.0028617627, -0.0677781403,  0.0269375853, -0.0096403193,\n",
            "        -0.1166449487,  0.0028617627, -0.0677781403,  0.0269375853,\n",
            "        -0.0096403193, -0.1166449487,  0.0028617627, -0.0677781403,\n",
            "         0.0269375853, -0.0096403193])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7343750000, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8339549303), tensor(1.7872028351), tensor(1.1093087196), tensor(1.4610056877), tensor(0.8952355981), tensor(0.7460271716), tensor(1.6021641493), tensor(1.1660281420), tensor(1.3419785500), tensor(1.0906786919), tensor(1.0206183195), tensor(1.0934462547), tensor(1.8239519596), tensor(1.2421109676), tensor(1.6432681084), tensor(1.8045120239), tensor(1.6237560511), tensor(1.1283937693), tensor(0.9096750021), tensor(1.0986616611)]\n",
            "b:  [tensor(1.6325806379), tensor(0.7221089602), tensor(1.4610579014), tensor(1.2991951704), tensor(1.0074245930), tensor(2.0148673058), tensor(1.3021796942), tensor(1.3919453621), tensor(1.2783073187), tensor(1.0590771437), tensor(1.3623785973), tensor(1.3188021183), tensor(0.7627178431), tensor(1.2577691078), tensor(1.2334312201), tensor(0.8943386674), tensor(0.9848476052), tensor(1.3944116831), tensor(1.4087833166), tensor(1.5488862991)]\n",
            "c:  [tensor(0.0011642643), tensor(0.0011642643), tensor(0.0011642643), tensor(0.0011225031), tensor(0.0009969663), tensor(0.0010695304), tensor(0.0009702969), tensor(0.0010117701), tensor(0.0011225031), tensor(0.0009969663), tensor(0.0010695304), tensor(0.0009702969), tensor(0.0010117701), tensor(0.0011225031), tensor(0.0009969663), tensor(0.0010695304), tensor(0.0009702969), tensor(0.0010117701)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.0154016018,  0.0728332549, -0.0323355198,  0.0807735920,\n",
            "        -0.0295574069, -0.0158244781,  0.1513926983, -0.0312223434,\n",
            "        -0.0348053463, -0.0040799975, -0.0266715288, -0.0725055933,\n",
            "         0.0426348448, -0.0347781181, -0.0550349057,  0.1332383156,\n",
            "        -0.0046443939, -0.0197381377, -0.0329409242, -0.0072359443])\n",
            "btensor.grad: tensor([ 0.1975788772,  0.0014010668,  0.0840351284, -0.0487946570,\n",
            "         0.0142257214,  0.0640887395, -0.0231986046,  0.0338480771,\n",
            "         0.0051010847,  0.0111149549,  0.0193603039, -0.0523637533,\n",
            "        -0.0046023689, -0.0002442598, -0.0542766154, -0.0183139443,\n",
            "         0.0687108040, -0.0266424417, -0.0571334362, -0.0360263586])\n",
            "ctensor.grad: tensor([-0.1408552229, -0.1408552229, -0.1408552229, -0.1181335598,\n",
            "         0.0028949010, -0.0688039511,  0.0271585509, -0.0097236186,\n",
            "        -0.1181335598,  0.0028949010, -0.0688039511,  0.0271585509,\n",
            "        -0.0097236186, -0.1181335598,  0.0028949010, -0.0688039511,\n",
            "         0.0271585509, -0.0097236186])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7326660156, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8340433836), tensor(1.7866296768), tensor(1.1095411777), tensor(1.4603883028), tensor(0.8954380155), tensor(0.7461236119), tensor(1.6009551287), tensor(1.1662617922), tensor(1.3422431946), tensor(1.0907177925), tensor(1.0208235979), tensor(1.0940268040), tensor(1.8236471415), tensor(1.2423819304), tensor(1.6437429190), tensor(1.8034558296), tensor(1.6238255501), tensor(1.1285656691), tensor(0.9099173546), tensor(1.0987439156)]\n",
            "b:  [tensor(1.6310335398), tensor(0.7220846415), tensor(1.4604080915), tensor(1.2995462418), tensor(1.0073342323), tensor(2.0143508911), tensor(1.3023563623), tensor(1.3916779757), tensor(1.2782789469), tensor(1.0589886904), tensor(1.3622506857), tensor(1.3192116022), tensor(0.7627551556), tensor(1.2577705383), tensor(1.2338421345), tensor(0.8944581151), tensor(0.9843490720), tensor(1.3946306705), tensor(1.4092406034), tensor(1.5491997004)]\n",
            "c:  [tensor(0.0011789080), tensor(0.0011789080), tensor(0.0011789080), tensor(0.0011344703), tensor(0.0009966732), tensor(0.0010765126), tensor(0.0009675550), tensor(0.0010127519), tensor(0.0011344703), tensor(0.0009966732), tensor(0.0010765126), tensor(0.0009675550), tensor(0.0010127519), tensor(0.0011344703), tensor(0.0009966732), tensor(0.0010765126), tensor(0.0009675550), tensor(0.0010127519)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.0088461041,  0.0573149472, -0.0232436657,  0.0617443323,\n",
            "        -0.0202432275, -0.0096457154,  0.1209071279, -0.0233633518,\n",
            "        -0.0264641289, -0.0039132535, -0.0205229670, -0.0580602884,\n",
            "         0.0304840803, -0.0270948410, -0.0474803895,  0.1056249216,\n",
            "        -0.0069544315, -0.0171898007, -0.0242355466, -0.0082275569])\n",
            "btensor.grad: tensor([ 1.5471529961e-01,  2.4336278439e-03,  6.4983934164e-02,\n",
            "        -3.5111606121e-02,  9.0301036835e-03,  5.1649168134e-02,\n",
            "        -1.7664432526e-02,  2.6736214757e-02,  2.8418302536e-03,\n",
            "         8.8407993317e-03,  1.2788921595e-02, -4.0953636169e-02,\n",
            "        -3.7314891815e-03, -1.3849139214e-04, -4.1096717119e-02,\n",
            "        -1.1944353580e-02,  4.9856126308e-02, -2.1902710199e-02,\n",
            "        -4.5727491379e-02, -3.1341195107e-02])\n",
            "ctensor.grad: tensor([-0.1464376301, -0.1464376301, -0.1464376301, -0.1196728796,\n",
            "         0.0029300109, -0.0698222816,  0.0274187010, -0.0098186750,\n",
            "        -0.1196728796,  0.0029300109, -0.0698222816,  0.0274187010,\n",
            "        -0.0098186750, -0.1196728796,  0.0029300109, -0.0698222816,\n",
            "         0.0274187010, -0.0098186750])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7319946289, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8340901136), tensor(1.7861770391), tensor(1.1097068787), tensor(1.4599149227), tensor(0.8955758810), tensor(0.7461804748), tensor(1.5999879837), tensor(1.1664352417), tensor(1.3424431086), tensor(1.0907511711), tensor(1.0209805965), tensor(1.0944892168), tensor(1.8234313726), tensor(1.2425919771), tensor(1.6441490650), tensor(1.8026168346), tensor(1.6239060163), tensor(1.1287118196), tensor(0.9100954533), tensor(1.0988262892)]\n",
            "b:  [tensor(1.6298208237), tensor(0.7220570445), tensor(1.4599044323), tensor(1.2997965813), tensor(1.0072765350), tensor(2.0139324665), tensor(1.3024897575), tensor(1.3914655447), tensor(1.2782641649), tensor(1.0589166880), tensor(1.3621681929), tensor(1.3195317984), tensor(0.7627856731), tensor(1.2577702999), tensor(1.2341536283), tensor(0.8945358992), tensor(0.9839872718), tensor(1.3948099613), tensor(1.4096059799), tensor(1.5494703054)]\n",
            "c:  [tensor(0.0011939968), tensor(0.0011939968), tensor(0.0011939968), tensor(0.0011465956), tensor(0.0009963766), tensor(0.0010835964), tensor(0.0009647842), tensor(0.0010137443), tensor(0.0011465956), tensor(0.0009963766), tensor(0.0010835964), tensor(0.0009647842), tensor(0.0010137443), tensor(0.0011465956), tensor(0.0009963766), tensor(0.0010835964), tensor(0.0009647842), tensor(0.0010137443)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.0046758652,  0.0452695191, -0.0165737569,  0.0473425388,\n",
            "        -0.0137893558, -0.0056860782,  0.0967137218, -0.0173413455,\n",
            "        -0.0199921019, -0.0033407211, -0.0157054663, -0.0462374687,\n",
            "         0.0215811729, -0.0210065842, -0.0406125188,  0.0838938802,\n",
            "        -0.0080521107, -0.0146119595, -0.0178099871, -0.0082317591])\n",
            "btensor.grad: tensor([ 1.2126921862e-01,  2.7604401112e-03,  5.0365477800e-02,\n",
            "        -2.5039106607e-02,  5.7649612427e-03,  4.1848730296e-02,\n",
            "        -1.3342380524e-02,  2.1242737770e-02,  1.4814138412e-03,\n",
            "         7.1967840195e-03,  8.2457959652e-03, -3.2014012337e-02,\n",
            "        -3.0521638691e-03,  2.4169683456e-05, -3.1148225069e-02,\n",
            "        -7.7790617943e-03,  3.6180019379e-02, -1.7934799194e-02,\n",
            "        -3.6539196968e-02, -2.7064919472e-02])\n",
            "ctensor.grad: tensor([-0.1508874595, -0.1508874595, -0.1508874595, -0.1212520152,\n",
            "         0.0029666419, -0.0708372593,  0.0277081411, -0.0099235922,\n",
            "        -0.1212520152,  0.0029666419, -0.0708372593,  0.0277081411,\n",
            "        -0.0099235922, -0.1212520152,  0.0029666419, -0.0708372593,\n",
            "         0.0277081411, -0.0099235922])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7315673828, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8341106772), tensor(1.7858182192), tensor(1.1098239422), tensor(1.4595507383), tensor(0.8956689239), tensor(0.7462118864), tensor(1.5992131233), tensor(1.1665627956), tensor(1.3425929546), tensor(1.0907773972), tensor(1.0211001635), tensor(1.0948555470), tensor(1.8232804537), tensor(1.2427541018), tensor(1.6444939375), tensor(1.8019493818), tensor(1.6239895821), tensor(1.1288337708), tensor(0.9102260470), tensor(1.0989031792)]\n",
            "b:  [tensor(1.6288692951), tensor(0.7220298052), tensor(1.4595130682), tensor(1.2999731302), tensor(1.0072392225), tensor(2.0135917664), tensor(1.3025896549), tensor(1.3912957907), tensor(1.2782572508), tensor(1.0588569641), tensor(1.3621168137), tensor(1.3197817802), tensor(0.7628107667), tensor(1.2577683926), tensor(1.2343899012), tensor(0.8945863843), tensor(0.9837245941), tensor(1.3949563503), tensor(1.4098974466), tensor(1.5497025251)]\n",
            "c:  [tensor(0.0012094533), tensor(0.0012094533), tensor(0.0012094533), tensor(0.0011588819), tensor(0.0009960762), tensor(0.0010907815), tensor(0.0009619822), tensor(0.0010147480), tensor(0.0011588819), tensor(0.0009960762), tensor(0.0010907815), tensor(0.0009619822), tensor(0.0010147480), tensor(0.0011588819), tensor(0.0009960762), tensor(0.0010907815), tensor(0.0009619822), tensor(0.0010147480)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.0020535588,  0.0358838737, -0.0117015541,  0.0364173651,\n",
            "        -0.0093069673, -0.0031397808,  0.0774843693, -0.0127500892,\n",
            "        -0.0149901975, -0.0026230514, -0.0119543225, -0.0366381407,\n",
            "         0.0150892735, -0.0162105560, -0.0344931334,  0.0667506754,\n",
            "        -0.0083566904, -0.0121929049, -0.0130593181, -0.0076873600])\n",
            "btensor.grad: tensor([ 0.0951559991,  0.0027253032,  0.0391319692, -0.0176539123,\n",
            "         0.0037362576,  0.0340800770, -0.0099846125,  0.0169795007,\n",
            "         0.0006928444,  0.0059670210,  0.0051350892, -0.0250041485,\n",
            "        -0.0025093183,  0.0001898110, -0.0236300230, -0.0050488114,\n",
            "         0.0262671113, -0.0146336555, -0.0291458368, -0.0232262611])\n",
            "ctensor.grad: tensor([-0.1545657218, -0.1545657218, -0.1545657218, -0.1228641123,\n",
            "         0.0030044774, -0.0718519986,  0.0280199386, -0.0100371242,\n",
            "        -0.1228641123,  0.0030044774, -0.0718519986,  0.0280199386,\n",
            "        -0.0100371242, -0.1228641123,  0.0030044774, -0.0718519986,\n",
            "         0.0280199386, -0.0100371242])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7314453125, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8341149688), tensor(1.7855327129), tensor(1.1099054813), tensor(1.4592696428), tensor(0.8957307935), tensor(0.7462269068), tensor(1.5985913277), tensor(1.1666554213), tensor(1.3427044153), tensor(1.0907964706), tensor(1.0211905241), tensor(1.0951445103), tensor(1.8231766224), tensor(1.2428785563), tensor(1.6447852850), tensor(1.8014173508), tensor(1.6240711212), tensor(1.1289340258), tensor(0.9103214741), tensor(1.0989719629)]\n",
            "b:  [tensor(1.6281217337), tensor(0.7220046520), tensor(1.4592082500), tensor(1.3000957966), tensor(1.0072144270), tensor(2.0133128166), tensor(1.3026635647), tensor(1.3911592960), tensor(1.2782546282), tensor(1.0588067770), tensor(1.3620864153), tensor(1.3199768066), tensor(0.7628314495), tensor(1.2577650547), tensor(1.2345693111), tensor(0.8946189880), tensor(0.9835337400), tensor(1.3950753212), tensor(1.4101295471), tensor(1.5499007702)]\n",
            "c:  [tensor(0.0012252240), tensor(0.0012252240), tensor(0.0012252240), tensor(0.0011713324), tensor(0.0009957718), tensor(0.0010980684), tensor(0.0009591473), tensor(0.0010157638), tensor(0.0011713324), tensor(0.0009957718), tensor(0.0010980684), tensor(0.0009591473), tensor(0.0010157638), tensor(0.0011713324), tensor(0.0009957718), tensor(0.0010980684), tensor(0.0009591473), tensor(0.0010157638)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.0004270673,  0.0285506845, -0.0081494451,  0.0281126499,\n",
            "        -0.0061876774, -0.0015049614,  0.0621830821, -0.0092654526,\n",
            "        -0.0111408755, -0.0019060671, -0.0090397596, -0.0288940668,\n",
            "         0.0103840828, -0.0124498606, -0.0291317403,  0.0532017872,\n",
            "        -0.0081590414, -0.0100216866, -0.0095413923, -0.0068773627])\n",
            "btensor.grad: tensor([ 0.0747512281,  0.0025174916,  0.0304825008, -0.0122655630,\n",
            "         0.0024845600,  0.0278904624, -0.0073952675,  0.0136542618,\n",
            "         0.0002679825,  0.0050189495,  0.0030345321, -0.0195074081,\n",
            "        -0.0020658858,  0.0003358424, -0.0179401338, -0.0032599568,\n",
            "         0.0190876722, -0.0118921697, -0.0232112408, -0.0198187828])\n",
            "ctensor.grad: tensor([-0.1577070653, -0.1577070653, -0.1577070653, -0.1245045364,\n",
            "         0.0030433033, -0.0728691593,  0.0283491854, -0.0101581365,\n",
            "        -0.1245045364,  0.0030433033, -0.0728691593,  0.0283491854,\n",
            "        -0.0101581365, -0.1245045364,  0.0030433033, -0.0728691593,\n",
            "         0.0283491854, -0.0101581365])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7314453125, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8341094255), tensor(1.7853047848), tensor(1.1099611521), tensor(1.4590517282), tensor(0.8957709074), tensor(0.7462314367), tensor(1.5980913639), tensor(1.1667218208), tensor(1.3427863121), tensor(1.0908089876), tensor(1.0212583542), tensor(1.0953713655), tensor(1.8231066465), tensor(1.2429736853), tensor(1.6450301409), tensor(1.8009927273), tensor(1.6241477728), tensor(1.1290153265), tensor(0.9103907943), tensor(1.0990316868)]\n",
            "b:  [tensor(1.6275337934), tensor(0.7219821811), tensor(1.4589700699), tensor(1.3001793623), tensor(1.0071972609), tensor(2.0130834579), tensor(1.3027176857), tensor(1.3910487890), tensor(1.2782540321), tensor(1.0587641001), tensor(1.3620699644), tensor(1.3201287985), tensor(0.7628483772), tensor(1.2577605247), tensor(1.2347055674), tensor(0.8946397901), tensor(0.9833948612), tensor(1.3951716423), tensor(1.4103140831), tensor(1.5500689745)]\n",
            "c:  [tensor(0.0012412739), tensor(0.0012412739), tensor(0.0012412739), tensor(0.0011839494), tensor(0.0009954636), tensor(0.0011054575), tensor(0.0009562781), tensor(0.0010167924), tensor(0.0011839494), tensor(0.0009954636), tensor(0.0011054575), tensor(0.0009562781), tensor(0.0010167924), tensor(0.0011839494), tensor(0.0009954636), tensor(0.0011054575), tensor(0.0009562781), tensor(0.0010167924)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0005553365,  0.0227963477, -0.0055729449,  0.0217871666,\n",
            "        -0.0040115118, -0.0004554838,  0.0499918461, -0.0066354871,\n",
            "        -0.0081845839, -0.0012552142, -0.0067866594, -0.0226821899,\n",
            "         0.0069950223, -0.0095084906, -0.0244810283,  0.0424676612,\n",
            "        -0.0076675415, -0.0081329346, -0.0069310069, -0.0059724450])\n",
            "btensor.grad: tensor([ 5.8794077486e-02,  2.2450387478e-03,  2.3812860250e-02,\n",
            "        -8.3532035351e-03,  1.7209053040e-03,  2.2929178551e-02,\n",
            "        -5.4066181183e-03,  1.1047780514e-02,  6.4134597778e-05,\n",
            "         4.2661428452e-03,  1.6412734985e-03, -1.5193939209e-02,\n",
            "        -1.6952045262e-03,  4.5442581177e-04, -1.3625472784e-02,\n",
            "        -2.0818114281e-03,  1.3889670372e-02, -9.6306204796e-03,\n",
            "        -1.8450975418e-02, -1.6822457314e-02])\n",
            "ctensor.grad: tensor([-0.1604997963, -0.1604997963, -0.1604997963, -0.1261702627,\n",
            "         0.0030829664, -0.0738907307,  0.0286923572, -0.0102855144,\n",
            "        -0.1261702627,  0.0030829664, -0.0738907307,  0.0286923572,\n",
            "        -0.0102855144, -0.1261702627,  0.0030829664, -0.0738907307,\n",
            "         0.0286923572, -0.0102855144])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7312622070, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8340981603), tensor(1.7851220369), tensor(1.1099982262), tensor(1.4588822126), tensor(0.8957958221), tensor(0.7462293506), tensor(1.5976886749), tensor(1.1667683125), tensor(1.3428455591), tensor(1.0908160210), tensor(1.0213087797), tensor(1.0955486298), tensor(1.8230608702), tensor(1.2430458069), tensor(1.6452349424), tensor(1.8006532192), tensor(1.6242178679), tensor(1.1290805340), tensor(0.9104406834), tensor(1.0990823507)]\n",
            "b:  [tensor(1.6270706654), tensor(0.7219625115), tensor(1.4587835073), tensor(1.3002346754), tensor(1.0071846247), tensor(2.0128941536), tensor(1.3027565479), tensor(1.3909589052), tensor(1.2782540321), tensor(1.0587275028), tensor(1.3620625734), tensor(1.3202468157), tensor(0.7628622055), tensor(1.2577550411), tensor(1.2348090410), tensor(0.8946528435), tensor(0.9832935929), tensor(1.3952492476), tensor(1.4104604721), tensor(1.5502110720)]\n",
            "c:  [tensor(0.0012575790), tensor(0.0012575790), tensor(0.0012575790), tensor(0.0011967354), tensor(0.0009951512), tensor(0.0011129495), tensor(0.0009533734), tensor(0.0010178342), tensor(0.0011967354), tensor(0.0009951512), tensor(0.0011129495), tensor(0.0009533734), tensor(0.0010178342), tensor(0.0011967354), tensor(0.0009951512), tensor(0.0011129495), tensor(0.0009533734), tensor(0.0010178342)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0011260509,  0.0182724148, -0.0037114620,  0.0169565678,\n",
            "        -0.0024927258,  0.0002111159,  0.0402646661, -0.0046549439,\n",
            "        -0.0059243906, -0.0007043481, -0.0050428212, -0.0177212954,\n",
            "         0.0045773387, -0.0072176456, -0.0204839259,  0.0339558981,\n",
            "        -0.0070092678, -0.0065209270, -0.0049899817, -0.0050687492])\n",
            "btensor.grad: tensor([ 4.6310160309e-02,  1.9645094872e-03,  1.8662005663e-02,\n",
            "        -5.5338740349e-03,  1.2578964233e-03,  1.8940016627e-02,\n",
            "        -3.8821697235e-03,  8.9912861586e-03, -4.1723251343e-06,\n",
            "         3.6591291428e-03,  7.4410438538e-04, -1.1805057526e-02,\n",
            "        -1.3853013515e-03,  5.4454803467e-04, -1.0350704193e-02,\n",
            "        -1.3054013252e-03,  1.0128140450e-02, -7.7660679817e-03,\n",
            "        -1.4637947083e-02, -1.4211654663e-02])\n",
            "ctensor.grad: tensor([-0.1630498916, -0.1630498916, -0.1630498916, -0.1278595626,\n",
            "         0.0031233665, -0.0749185532,  0.0290470216, -0.0104185548,\n",
            "        -0.1278595626,  0.0031233665, -0.0749185532,  0.0290470216,\n",
            "        -0.0104185548, -0.1278595626,  0.0031233665, -0.0749185532,\n",
            "         0.0290470216, -0.0104185548])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7313232422, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8340837955), tensor(1.7849750519), tensor(1.1100219488), tensor(1.4587495327), tensor(0.8958101273), tensor(0.7462229729), tensor(1.5973637104), tensor(1.1668000221), tensor(1.3428876400), tensor(1.0908185244), tensor(1.0213457346), tensor(1.0956864357), tensor(1.8230321407), tensor(1.2431001663), tensor(1.6454056501), tensor(1.8003813028), tensor(1.6242806911), tensor(1.1291321516), tensor(0.9104760885), tensor(1.0991244316)]\n",
            "b:  [tensor(1.6267052889), tensor(0.7219455242), tensor(1.4586367607), tensor(1.3002698421), tensor(1.0071748495), tensor(2.0127370358), tensor(1.3027837276), tensor(1.3908852339), tensor(1.2782540321), tensor(1.0586959124), tensor(1.3620606661), tensor(1.3203382492), tensor(0.7628734708), tensor(1.2577489614), tensor(1.2348875999), tensor(0.8946607113), tensor(0.9832195044), tensor(1.3953115940), tensor(1.4105763435), tensor(1.5503305197)]\n",
            "c:  [tensor(0.0012741226), tensor(0.0012741226), tensor(0.0012741226), tensor(0.0012096926), tensor(0.0009948348), tensor(0.0011205449), tensor(0.0009504323), tensor(0.0010188898), tensor(0.0012096926), tensor(0.0009948348), tensor(0.0011205449), tensor(0.0009504323), tensor(0.0010188898), tensor(0.0012096926), tensor(0.0009948348), tensor(0.0011205449), tensor(0.0009504323), tensor(0.0010188898)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0014345646,  0.0147008449, -0.0023687482,  0.0132664442,\n",
            "        -0.0014309287,  0.0006374288,  0.0324941874, -0.0031746626,\n",
            "        -0.0042021498, -0.0002534389, -0.0036945641, -0.0137763023,\n",
            "         0.0028737783, -0.0054337978, -0.0170723051,  0.0271943361,\n",
            "        -0.0062780380, -0.0051648021, -0.0035423636, -0.0042139888])\n",
            "btensor.grad: tensor([ 3.6537081003e-02,  1.7004609108e-03,  1.4679193497e-02,\n",
            "        -3.5119950771e-03,  9.8109245300e-04,  1.5719441697e-02,\n",
            "        -2.7188062668e-03,  7.3685795069e-03,  5.3644180298e-06,\n",
            "         3.1582117081e-03,  1.9150972366e-04, -9.1439485550e-03,\n",
            "        -1.1237598956e-03,  6.0978531837e-04, -7.8533589840e-03,\n",
            "        -7.8731775284e-04,  7.4080228806e-03, -6.2324106693e-03,\n",
            "        -1.1582612991e-02, -1.1947989464e-02])\n",
            "ctensor.grad: tensor([-0.1654366255, -0.1654366255, -0.1654366255, -0.1295712292,\n",
            "         0.0031644364, -0.0759536028,  0.0294114240, -0.0105565954,\n",
            "        -0.1295712292,  0.0031644364, -0.0759536028,  0.0294114240,\n",
            "        -0.0105565954, -0.1295712292,  0.0031644364, -0.0759536028,\n",
            "         0.0294114240, -0.0105565954])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7308959961, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8340679407), tensor(1.7848563194), tensor(1.1100360155), tensor(1.4586452246), tensor(0.8958169818), tensor(0.7462139130), tensor(1.5971008539), tensor(1.1668206453), tensor(1.3429166079), tensor(1.0908174515), tensor(1.0213723183), tensor(1.0957928896), tensor(1.8230152130), tensor(1.2431405783), tensor(1.6455473900), tensor(1.8001631498), tensor(1.6243360043), tensor(1.1291725636), tensor(0.9105007052), tensor(1.0991588831)]\n",
            "b:  [tensor(1.6264164448), tensor(0.7219308019), tensor(1.4585207701), tensor(1.3002905846), tensor(1.0071666241), tensor(2.0126059055), tensor(1.3028020859), tensor(1.3908244371), tensor(1.2782534361), tensor(1.0586684942), tensor(1.3620619774), tensor(1.3204088211), tensor(0.7628824115), tensor(1.2577424049), tensor(1.2349470854), tensor(0.8946651220), tensor(0.9831650853), tensor(1.3953613043), tensor(1.4106676579), tensor(1.5504305363)]\n",
            "c:  [tensor(0.0012908926), tensor(0.0012908926), tensor(0.0012908926), tensor(0.0012228230), tensor(0.0009945142), tensor(0.0011282446), tensor(0.0009474538), tensor(0.0010199597), tensor(0.0012228230), tensor(0.0009945142), tensor(0.0011282446), tensor(0.0009474538), tensor(0.0010199597), tensor(0.0012228230), tensor(0.0009945142), tensor(0.0011282446), tensor(0.0009474538), tensor(0.0010199597)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0015842915,  0.0118783563, -0.0014016926,  0.0104361773,\n",
            "        -0.0006871223,  0.0009031110,  0.0262800455, -0.0020677447,\n",
            "        -0.0028985366,  0.0001037419, -0.0026527345, -0.0106430054,\n",
            "         0.0016933680, -0.0040448904, -0.0141770095,  0.0218190700,\n",
            "        -0.0055290461, -0.0040361881, -0.0024593472, -0.0034428537])\n",
            "btensor.grad: tensor([ 2.8879329562e-02,  1.4725029469e-03,  1.1599540710e-02,\n",
            "        -2.0751953125e-03,  8.2087516785e-04,  1.3111119159e-02,\n",
            "        -1.8391609192e-03,  6.0807168484e-03,  5.8770179749e-05,\n",
            "         2.7430057526e-03, -1.2698769569e-04, -7.0531368256e-03,\n",
            "        -8.9416280389e-04,  6.5714120865e-04, -5.9462189674e-03,\n",
            "        -4.4113397598e-04,  5.4444074631e-03, -4.9690008163e-03,\n",
            "        -9.1334581375e-03, -9.9978446960e-03])\n",
            "ctensor.grad: tensor([-0.1676995307, -0.1676995307, -0.1676995307, -0.1313047558,\n",
            "         0.0032061262, -0.0769973248,  0.0297843069, -0.0106989909,\n",
            "        -0.1313047558,  0.0032061262, -0.0769973248,  0.0297843069,\n",
            "        -0.0106989909, -0.1313047558,  0.0032061262, -0.0769973248,\n",
            "         0.0297843069, -0.0106989909])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7308349609, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8340515494), tensor(1.7847598791), tensor(1.1100430489), tensor(1.4585626125), tensor(0.8958186507), tensor(0.7462032437), tensor(1.5968878269), tensor(1.1668331623), tensor(1.3429356813), tensor(1.0908136368), tensor(1.0213907957), tensor(1.0958745480), tensor(1.8230062723), tensor(1.2431702614), tensor(1.6456646919), tensor(1.7999877930), tensor(1.6243840456), tensor(1.1292035580), tensor(0.9105171561), tensor(1.0991864204)]\n",
            "b:  [tensor(1.6261876822), tensor(0.7219180465), tensor(1.4584287405), tensor(1.3003011942), tensor(1.0071593523), tensor(2.0124959946), tensor(1.3028137684), tensor(1.3907738924), tensor(1.2782521248), tensor(1.0586445332), tensor(1.3620648384), tensor(1.3204628229), tensor(0.7628894448), tensor(1.2577354908), tensor(1.2349919081), tensor(0.8946671486), tensor(0.9831247926), tensor(1.3954006433), tensor(1.4107394218), tensor(1.5505137444)]\n",
            "c:  [tensor(0.0013078818), tensor(0.0013078818), tensor(0.0013078818), tensor(0.0012361290), tensor(0.0009941894), tensor(0.0011360496), tensor(0.0009444374), tensor(0.0010210442), tensor(0.0012361290), tensor(0.0009941894), tensor(0.0011360496), tensor(0.0009444374), tensor(0.0010210442), tensor(0.0012361290), tensor(0.0009941894), tensor(0.0011360496), tensor(0.0009444374), tensor(0.0010210442)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0016364455,  0.0096418262, -0.0007069111,  0.0082621574,\n",
            "        -0.0001661181,  0.0010650232,  0.0213027596, -0.0012465417,\n",
            "        -0.0019113123,  0.0003789067, -0.0018486679, -0.0081681013,\n",
            "         0.0008891821, -0.0029679537, -0.0117299557,  0.0175361112,\n",
            "        -0.0048034191, -0.0031042099, -0.0016444325, -0.0027568340])\n",
            "btensor.grad: tensor([ 0.0228797942,  0.0012747049,  0.0092077851, -0.0010646880,\n",
            "         0.0007281303,  0.0109903160, -0.0011738539,  0.0050557405,\n",
            "         0.0001305342,  0.0023950338, -0.0002867877, -0.0054055452,\n",
            "        -0.0007004254,  0.0006891489, -0.0044824779, -0.0002055764,\n",
            "         0.0040293932, -0.0039337575, -0.0071761608, -0.0083229542])\n",
            "ctensor.grad: tensor([-0.1698915064, -0.1698915064, -0.1698915064, -0.1330595165,\n",
            "         0.0032484005, -0.0780503377,  0.0301646236, -0.0108454684,\n",
            "        -0.1330595165,  0.0032484005, -0.0780503377,  0.0301646236,\n",
            "        -0.0108454684, -0.1330595165,  0.0032484005, -0.0780503377,\n",
            "         0.0301646236, -0.0108454684])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7312622070, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8340352178), tensor(1.7846813202), tensor(1.1100451946), tensor(1.4584966898), tensor(0.8958166242), tensor(0.7461916208), tensor(1.5967147350), tensor(1.1668394804), tensor(1.3429473639), tensor(1.0908077955), tensor(1.0214030743), tensor(1.0959366560), tensor(1.8230026960), tensor(1.2431915998), tensor(1.6457613707), tensor(1.7998465300), tensor(1.6244252920), tensor(1.1292270422), tensor(0.9105274677), tensor(1.0992081165)]\n",
            "b:  [tensor(1.6260058880), tensor(0.7219069600), tensor(1.4583551884), tensor(1.3003047705), tensor(1.0071525574), tensor(2.0124034882), tensor(1.3028204441), tensor(1.3907315731), tensor(1.2782499790), tensor(1.0586235523), tensor(1.3620682955), tensor(1.3205039501), tensor(0.7628947496), tensor(1.2577284575), tensor(1.2350255251), tensor(0.8946675658), tensor(0.9830946922), tensor(1.3954315186), tensor(1.4107954502), tensor(1.5505826473)]\n",
            "c:  [tensor(0.0013250854), tensor(0.0013250854), tensor(0.0013250854), tensor(0.0012496125), tensor(0.0009938603), tensor(0.0011439610), tensor(0.0009413822), tensor(0.0010221438), tensor(0.0012496125), tensor(0.0009938603), tensor(0.0011439610), tensor(0.0009413822), tensor(0.0010221438), tensor(0.0012496125), tensor(0.0009938603), tensor(0.0011439610), tensor(0.0009413822), tensor(0.0010221438)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0016340017,  0.0078591257, -0.0002167821,  0.0065892935,\n",
            "         0.0002022386,  0.0011609010,  0.0173128247, -0.0006365478,\n",
            "        -0.0011702161,  0.0005861223, -0.0012254417, -0.0062146187,\n",
            "         0.0003589988, -0.0021307468, -0.0096665323,  0.0141236000,\n",
            "        -0.0041222572, -0.0023425221, -0.0010287166, -0.0021651685])\n",
            "btensor.grad: tensor([ 1.8174625933e-02,  1.1098980904e-03,  7.3546767235e-03,\n",
            "        -3.6090612411e-04,  6.7639350891e-04,  9.2589836568e-03,\n",
            "        -6.7079067230e-04,  4.2367428541e-03,  2.0945072174e-04,\n",
            "         2.1038055420e-03, -3.4224987030e-04, -4.1140317917e-03,\n",
            "        -5.3155794740e-04,  7.0732831955e-04, -3.3594071865e-03,\n",
            "        -4.2021274567e-05,  3.0099749565e-03, -3.0825436115e-03,\n",
            "        -5.6066513062e-03, -6.8918466568e-03])\n",
            "ctensor.grad: tensor([-0.1720361710, -0.1720361710, -0.1720361710, -0.1348354816,\n",
            "         0.0032912393, -0.0791135132,  0.0305517763, -0.0109955370,\n",
            "        -0.1348354816,  0.0032912393, -0.0791135132,  0.0305517763,\n",
            "        -0.0109955370, -0.1348354816,  0.0032912393, -0.0791135132,\n",
            "         0.0305517763, -0.0109955370])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7308959961, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8340191841), tensor(1.7846168280), tensor(1.1100438833), tensor(1.4584436417), tensor(0.8958120346), tensor(0.7461794615), tensor(1.5965735912), tensor(1.1668413877), tensor(1.3429535627), tensor(1.0908004045), tensor(1.0214104652), tensor(1.0959833860), tensor(1.8230024576), tensor(1.2432063818), tensor(1.6458406448), tensor(1.7997325659), tensor(1.6244602203), tensor(1.1292442083), tensor(0.9105330706), tensor(1.0992246866)]\n",
            "b:  [tensor(1.6258610487), tensor(0.7218971848), tensor(1.4582960606), tensor(1.3003035784), tensor(1.0071461201), tensor(2.0123250484), tensor(1.3028233051), tensor(1.3906956911), tensor(1.2782471180), tensor(1.0586049557), tensor(1.3620715141), tensor(1.3205348253), tensor(0.7628986239), tensor(1.2577213049), tensor(1.2350504398), tensor(0.8946667910), tensor(0.9830719233), tensor(1.3954553604), tensor(1.4108389616), tensor(1.5506393909)]\n",
            "c:  [tensor(0.0013424997), tensor(0.0013424997), tensor(0.0013424997), tensor(0.0012632757), tensor(0.0009935269), tensor(0.0011519797), tensor(0.0009382876), tensor(0.0010232587), tensor(0.0012632757), tensor(0.0009935269), tensor(0.0011519797), tensor(0.0009382876), tensor(0.0010232587), tensor(0.0012632757), tensor(0.0009935269), tensor(0.0011519797), tensor(0.0009382876), tensor(0.0010232587)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.6007423401e-03,  6.4444541931e-03,  1.3554096222e-04,\n",
            "         5.3004026413e-03,  4.6122074127e-04,  1.2149382383e-03,\n",
            "         1.4110624790e-02, -1.8912553787e-04, -6.1504356563e-04,\n",
            "         7.4097514153e-04, -7.4252486229e-04, -4.6759843826e-03,\n",
            "         2.6762485504e-05, -1.4760494232e-03, -7.9332888126e-03,\n",
            "         1.1402010918e-02, -3.4965276718e-03, -1.7170310020e-03,\n",
            "        -5.5968761444e-04, -1.6512274742e-03])\n",
            "btensor.grad: tensor([ 1.4485348016e-02,  9.7516179085e-04,  5.9145689011e-03,\n",
            "         1.2198090553e-04,  6.4969062805e-04,  7.8472588211e-03,\n",
            "        -2.8920173645e-04,  3.5855323076e-03,  2.8634071350e-04,\n",
            "         1.8628835678e-03, -3.2636523247e-04, -3.0907392502e-03,\n",
            "        -3.8879364729e-04,  7.2073936462e-04, -2.4906694889e-03,\n",
            "         7.5340270996e-05,  2.2774934769e-03, -2.3830235004e-03,\n",
            "        -4.3523311615e-03, -5.6705474854e-03])\n",
            "ctensor.grad: tensor([-0.1741439104, -0.1741439104, -0.1741439104, -0.1366324723,\n",
            "         0.0033346266, -0.0801874027,  0.0309452433, -0.0111489892,\n",
            "        -0.1366324723,  0.0033346266, -0.0801874027,  0.0309452433,\n",
            "        -0.0111489892, -0.1366324723,  0.0033346266, -0.0801874027,\n",
            "         0.0309452433, -0.0111489892])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7307739258, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8340036869), tensor(1.7845637798), tensor(1.1100400686), tensor(1.4584006071), tensor(0.8958055973), tensor(0.7461670041), tensor(1.5964581966), tensor(1.1668399572), tensor(1.3429555893), tensor(1.0907918215), tensor(1.0214141607), tensor(1.0960180759), tensor(1.8230041265), tensor(1.2432160378), tensor(1.6459054947), tensor(1.7996402979), tensor(1.6244895458), tensor(1.1292562485), tensor(0.9105350971), tensor(1.0992368460)]\n",
            "b:  [tensor(1.6257451773), tensor(0.7218885422), tensor(1.4582480192), tensor(1.3002991676), tensor(1.0071396828), tensor(2.0122580528), tensor(1.3028234243), tensor(1.3906650543), tensor(1.2782435417), tensor(1.0585883856), tensor(1.3620742559), tensor(1.3205577135), tensor(0.7629012465), tensor(1.2577140331), tensor(1.2350686789), tensor(0.8946651816), tensor(0.9830543995), tensor(1.3954734802), tensor(1.4108724594), tensor(1.5506857634)]\n",
            "c:  [tensor(0.0013601235), tensor(0.0013601235), tensor(0.0013601235), tensor(0.0012771208), tensor(0.0009931891), tensor(0.0011601070), tensor(0.0009351532), tensor(0.0010243892), tensor(0.0012771208), tensor(0.0009931891), tensor(0.0011601070), tensor(0.0009351532), tensor(0.0010243892), tensor(0.0012771208), tensor(0.0009931891), tensor(0.0011601070), tensor(0.0009351532), tensor(0.0010243892)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0015513301,  0.0053100884,  0.0003860295,  0.0043011904,\n",
            "         0.0006448627,  0.0012448411,  0.0115349293,  0.0001414716,\n",
            "        -0.0001983363,  0.0008558631, -0.0003709793, -0.0034639835,\n",
            "        -0.0001670718, -0.0009683371, -0.0064848214,  0.0092312507,\n",
            "        -0.0029325485, -0.0012084842, -0.0002029538, -0.0012165606])\n",
            "btensor.grad: tensor([ 1.1589121073e-02,  8.6471438408e-04,  4.7990381718e-03,\n",
            "         4.4685602188e-04,  6.3824653625e-04,  6.6885408014e-03,\n",
            "        -6.4373016357e-06,  3.0585378408e-03,  3.5905838013e-04,\n",
            "         1.6584396362e-03, -2.7397274971e-04, -2.2865533829e-03,\n",
            "        -2.6502460241e-04,  7.2959065437e-04, -1.8181800842e-03,\n",
            "         1.5813112259e-04,  1.7538070679e-03, -1.8095076084e-03,\n",
            "        -3.3444166183e-03, -4.6318769455e-03])\n",
            "ctensor.grad: tensor([-0.1762372106, -0.1762372106, -0.1762372106, -0.1384505332,\n",
            "         0.0033785510, -0.0812725872,  0.0313446410, -0.0113055054,\n",
            "        -0.1384505332,  0.0033785510, -0.0812725872,  0.0313446410,\n",
            "        -0.0113055054, -0.1384505332,  0.0033785510, -0.0812725872,\n",
            "         0.0313446410, -0.0113055054])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7308959961, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8339886665), tensor(1.7845196724), tensor(1.1100344658), tensor(1.4583653212), tensor(0.8957978487), tensor(0.7461544275), tensor(1.5963635445), tensor(1.1668361425), tensor(1.3429545164), tensor(1.0907825232), tensor(1.0214149952), tensor(1.0960431099), tensor(1.8230067492), tensor(1.2432217598), tensor(1.6459581852), tensor(1.7995653152), tensor(1.6245138645), tensor(1.1292642355), tensor(0.9105343819), tensor(1.0992453098)]\n",
            "b:  [tensor(1.6256520748), tensor(0.7218807936), tensor(1.4582087994), tensor(1.3002924919), tensor(1.0071333647), tensor(2.0122005939), tensor(1.3028213978), tensor(1.3906387091), tensor(1.2782392502), tensor(1.0585734844), tensor(1.3620761633), tensor(1.3205741644), tensor(0.7629028559), tensor(1.2577067614), tensor(1.2350815535), tensor(0.8946629763), tensor(0.9830405712), tensor(1.3954868317), tensor(1.4108977318), tensor(1.5507233143)]\n",
            "c:  [tensor(0.0013779558), tensor(0.0013779558), tensor(0.0013779558), tensor(0.0012911498), tensor(0.0009928468), tensor(0.0011683439), tensor(0.0009319782), tensor(0.0010255356), tensor(0.0012911498), tensor(0.0009928468), tensor(0.0011683439), tensor(0.0009319782), tensor(0.0010255356), tensor(0.0012911498), tensor(0.0009928468), tensor(0.0011683439), tensor(0.0009319782), tensor(0.0010255356)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.5002489090e-03,  4.4052302837e-03,  5.6371092796e-04,\n",
            "         3.5294294357e-03,  7.7503919601e-04,  1.2581571937e-03,\n",
            "         9.4627737999e-03,  3.8152933121e-04,  1.0970979929e-04,\n",
            "         9.3269348145e-04, -7.8767538071e-05, -2.5075674057e-03,\n",
            "        -2.6339292526e-04, -5.7184696198e-04, -5.2703022957e-03,\n",
            "         7.4978359044e-03, -2.4292469025e-03, -7.9900026321e-04,\n",
            "         7.0571899414e-05, -8.4939599037e-04])\n",
            "btensor.grad: tensor([ 0.0093160011,  0.0007775724,  0.0039246380,  0.0006628931,\n",
            "         0.0006277561,  0.0057386234,  0.0002082586,  0.0026362538,\n",
            "         0.0004256964,  0.0014861822, -0.0001924038, -0.0016500950,\n",
            "        -0.0001588911,  0.0007316470, -0.0012911260,  0.0002210140,\n",
            "         0.0013818145, -0.0013381839, -0.0025327206, -0.0037506819])\n",
            "ctensor.grad: tensor([-0.1783227623, -0.1783227623, -0.1783227623, -0.1402899474,\n",
            "         0.0034230107, -0.0823693648,  0.0317496844, -0.0114650447,\n",
            "        -0.1402899474,  0.0034230107, -0.0823693648,  0.0317496844,\n",
            "        -0.0114650447, -0.1402899474,  0.0034230107, -0.0823693648,\n",
            "         0.0317496844, -0.0114650447])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7308349609, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8339741826), tensor(1.7844829559), tensor(1.1100275517), tensor(1.4583359957), tensor(0.8957891464), tensor(0.7461417913), tensor(1.5962855816), tensor(1.1668305397), tensor(1.3429511786), tensor(1.0907726288), tensor(1.0214134455), tensor(1.0960607529), tensor(1.8230097294), tensor(1.2432243824), tensor(1.6460007429), tensor(1.7995041609), tensor(1.6245336533), tensor(1.1292688847), tensor(0.9105315804), tensor(1.0992506742)]\n",
            "b:  [tensor(1.6255767345), tensor(0.7218737602), tensor(1.4581762552), tensor(1.3002845049), tensor(1.0071271658), tensor(2.0121510029), tensor(1.3028177023), tensor(1.3906157017), tensor(1.2782344818), tensor(1.0585601330), tensor(1.3620772362), tensor(1.3205856085), tensor(0.7629035115), tensor(1.2576993704), tensor(1.2350903749), tensor(0.8946602941), tensor(0.9830293655), tensor(1.3954963684), tensor(1.4109165668), tensor(1.5507533550)]\n",
            "c:  [tensor(0.0013959969), tensor(0.0013959969), tensor(0.0013959969), tensor(0.0013053649), tensor(0.0009925000), tensor(0.0011766917), tensor(0.0009287621), tensor(0.0010266984), tensor(0.0013053649), tensor(0.0009925000), tensor(0.0011766917), tensor(0.0009287621), tensor(0.0010266984), tensor(0.0013053649), tensor(0.0009925000), tensor(0.0011766917), tensor(0.0009287621), tensor(0.0010266984)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0014505386,  0.0036773384,  0.0006898940,  0.0029327869,\n",
            "         0.0008682013,  0.0012618080,  0.0077943206,  0.0005555153,\n",
            "         0.0003347043,  0.0009869337,  0.0001500547, -0.0017588139,\n",
            "        -0.0002950430, -0.0002633333, -0.0042585582,  0.0061105303,\n",
            "        -0.0019830465, -0.0004642010,  0.0002815723, -0.0005414188])\n",
            "btensor.grad: tensor([ 7.5324103236e-03,  7.0616602898e-04,  3.2509863377e-03,\n",
            "         7.9631805420e-04,  6.2489509583e-04,  4.9566999078e-03,\n",
            "         3.6752223969e-04,  2.2973120213e-03,  4.8148632050e-04,\n",
            "         1.3395547867e-03, -1.0269880295e-04, -1.1481046677e-03,\n",
            "        -6.3885003328e-05,  7.3513388634e-04, -8.8143348694e-04,\n",
            "         2.6851892471e-04,  1.1184215546e-03, -9.5164775848e-04,\n",
            "        -1.8837451935e-03, -3.0057430267e-03])\n",
            "ctensor.grad: tensor([-0.1804109663, -0.1804109663, -0.1804109663, -0.1421506852,\n",
            "         0.0034679996, -0.0834783018,  0.0321601704, -0.0116276164,\n",
            "        -0.1421506852,  0.0034679996, -0.0834783018,  0.0321601704,\n",
            "        -0.0116276164, -0.1421506852,  0.0034679996, -0.0834783018,\n",
            "         0.0321601704, -0.0116276164])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7308959961, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8339601755), tensor(1.7844519615), tensor(1.1100198030), tensor(1.4583113194), tensor(0.8957797885), tensor(0.7461292148), tensor(1.5962210894), tensor(1.1668237448), tensor(1.3429461718), tensor(1.0907623768), tensor(1.0214101076), tensor(1.0960724354), tensor(1.8230125904), tensor(1.2432246208), tensor(1.6460349560), tensor(1.7994540930), tensor(1.6245496273), tensor(1.1292707920), tensor(0.9105271101), tensor(1.0992535353)]\n",
            "b:  [tensor(1.6255154610), tensor(0.7218672633), tensor(1.4581489563), tensor(1.3002756834), tensor(1.0071209669), tensor(2.0121078491), tensor(1.3028128147), tensor(1.3905954361), tensor(1.2782291174), tensor(1.0585478544), tensor(1.3620773554), tensor(1.3205931187), tensor(0.7629033923), tensor(1.2576919794), tensor(1.2350959778), tensor(0.8946571946), tensor(0.9830200672), tensor(1.3955026865), tensor(1.4109301567), tensor(1.5507770777)]\n",
            "c:  [tensor(0.0014142465), tensor(0.0014142465), tensor(0.0014142465), tensor(0.0013197681), tensor(0.0009921486), tensor(0.0011851516), tensor(0.0009255045), tensor(0.0010278777), tensor(0.0013197681), tensor(0.0009921486), tensor(0.0011851516), tensor(0.0009255045), tensor(0.0010278777), tensor(0.0013197681), tensor(0.0009921486), tensor(0.0011851516), tensor(0.0009255045), tensor(0.0010278777)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.4032125473e-03,  3.0957311392e-03,  7.7575445175e-04,\n",
            "         2.4689435959e-03,  9.3400478363e-04,  1.2597087771e-03,\n",
            "         6.4496397972e-03,  6.8092346191e-04,  5.0192512572e-04,\n",
            "         1.0237991810e-03,  3.2842159271e-04, -1.1703968048e-03,\n",
            "        -2.8222799301e-04, -2.0384788513e-05, -3.4153610468e-03,\n",
            "         5.0035603344e-03, -1.5953779221e-03, -1.9204616547e-04,\n",
            "         4.4834613800e-04, -2.8315186501e-04])\n",
            "btensor.grad: tensor([ 6.1292462051e-03,  6.5031647682e-04,  2.7251541615e-03,\n",
            "         8.7782740593e-04,  6.2465667725e-04,  4.3148286641e-03,\n",
            "         4.8780441284e-04,  2.0224750042e-03,  5.3298473358e-04,\n",
            "         1.2224912643e-03, -6.3776969910e-06, -7.5173377991e-04,\n",
            "         1.4636665583e-05,  7.3468685150e-04, -5.5837631226e-04,\n",
            "         3.1125545502e-04,  9.3108415604e-04, -6.3341856003e-04,\n",
            "        -1.3624429703e-03, -2.3733377457e-03])\n",
            "ctensor.grad: tensor([-0.1824962050, -0.1824962050, -0.1824962050, -0.1440330446,\n",
            "         0.0035135210, -0.0845995247,  0.0325759798, -0.0117927678,\n",
            "        -0.1440330446,  0.0035135210, -0.0845995247,  0.0325759798,\n",
            "        -0.0117927678, -0.1440330446,  0.0035135210, -0.0845995247,\n",
            "         0.0325759798, -0.0117927678])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7305297852, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8339465857), tensor(1.7844257355), tensor(1.1100114584), tensor(1.4582902193), tensor(0.8957699537), tensor(0.7461166382), tensor(1.5961674452), tensor(1.1668159962), tensor(1.3429399729), tensor(1.0907518864), tensor(1.0214054585), tensor(1.0960794687), tensor(1.8230149746), tensor(1.2432229519), tensor(1.6460620165), tensor(1.7994128466), tensor(1.6245621443), tensor(1.1292705536), tensor(0.9105213284), tensor(1.0992541313)]\n",
            "b:  [tensor(1.6254651546), tensor(0.7218611836), tensor(1.4581258297), tensor(1.3002665043), tensor(1.0071146488), tensor(2.0120699406), tensor(1.3028070927), tensor(1.3905774355), tensor(1.2782233953), tensor(1.0585366488), tensor(1.3620764017), tensor(1.3205974102), tensor(0.7629025578), tensor(1.2576845884), tensor(1.2350989580), tensor(0.8946537375), tensor(0.9830120802), tensor(1.3955063820), tensor(1.4109395742), tensor(1.5507954359)]\n",
            "c:  [tensor(0.0014327068), tensor(0.0014327068), tensor(0.0014327068), tensor(0.0013343618), tensor(0.0009917927), tensor(0.0011937249), tensor(0.0009222049), tensor(0.0010290737), tensor(0.0013343618), tensor(0.0009917927), tensor(0.0011937249), tensor(0.0009222049), tensor(0.0010290737), tensor(0.0013343618), tensor(0.0009917927), tensor(0.0011937249), tensor(0.0009222049), tensor(0.0010290737)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.3619661331e-03,  2.6265680790e-03,  8.3872675896e-04,\n",
            "         2.1079778671e-03,  9.8353624344e-04,  1.2568719685e-03,\n",
            "         5.3637027740e-03,  7.7134370804e-04,  6.2277354300e-04,\n",
            "         1.0440945625e-03,  4.6759843826e-04, -7.0738792419e-04,\n",
            "        -2.4008750916e-04,  1.7058849335e-04, -2.7110129595e-03,\n",
            "         4.1191540658e-03, -1.2544393539e-03,  2.7179718018e-05,\n",
            "         5.7870149612e-04, -6.4194202423e-05])\n",
            "btensor.grad: tensor([ 5.0324015319e-03,  6.0570240021e-04,  2.3151636124e-03,\n",
            "         9.2309713364e-04,  6.2751770020e-04,  3.7870872766e-03,\n",
            "         5.7411193848e-04,  1.8024742603e-03,  5.7685375214e-04,\n",
            "         1.1209249496e-03,  8.9615583420e-05, -4.3511390686e-04,\n",
            "         8.3062797785e-05,  7.3432922363e-04, -3.0153989792e-04,\n",
            "         3.4362077713e-04,  8.0078840256e-04, -3.7175416946e-04,\n",
            "        -9.4127655029e-04, -1.8415451050e-03])\n",
            "ctensor.grad: tensor([-0.1846036911, -0.1846036911, -0.1846036911, -0.1459372491,\n",
            "         0.0035595712, -0.0857333541,  0.0329969749, -0.0119607532,\n",
            "        -0.1459372491,  0.0035595712, -0.0857333541,  0.0329969749,\n",
            "        -0.0119607532, -0.1459372491,  0.0035595712, -0.0857333541,\n",
            "         0.0329969749, -0.0119607532])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7306518555, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8339333534), tensor(1.7844032049), tensor(1.1100026369), tensor(1.4582719803), tensor(0.8957597613), tensor(0.7461041212), tensor(1.5961225033), tensor(1.1668076515), tensor(1.3429329395), tensor(1.0907412767), tensor(1.0213996172), tensor(1.0960829258), tensor(1.8230167627), tensor(1.2432197332), tensor(1.6460833549), tensor(1.7993787527), tensor(1.6245718002), tensor(1.1292685270), tensor(0.9105144739), tensor(1.0992529392)]\n",
            "b:  [tensor(1.6254235506), tensor(0.7218554616), tensor(1.4581058025), tensor(1.3002570868), tensor(1.0071083307), tensor(2.0120363235), tensor(1.3028006554), tensor(1.3905612230), tensor(1.2782171965), tensor(1.0585262775), tensor(1.3620746136), tensor(1.3205993176), tensor(0.7629011273), tensor(1.2576771975), tensor(1.2350999117), tensor(0.8946500421), tensor(0.9830049276), tensor(1.3955079317), tensor(1.4109455347), tensor(1.5508093834)]\n",
            "c:  [tensor(0.0014513785), tensor(0.0014513785), tensor(0.0014513785), tensor(0.0013491482), tensor(0.0009914320), tensor(0.0012024130), tensor(0.0009188625), tensor(0.0010302869), tensor(0.0013491482), tensor(0.0009914320), tensor(0.0012024130), tensor(0.0009188625), tensor(0.0010302869), tensor(0.0013491482), tensor(0.0009914320), tensor(0.0012024130), tensor(0.0009188625), tensor(0.0010302869)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0013260841,  0.0022498220,  0.0008838773,  0.0018274784,\n",
            "         0.0010187626,  0.0012535732,  0.0044901967,  0.0008371770,\n",
            "         0.0007091183,  0.0010586679,  0.0005821586, -0.0003440380,\n",
            "        -0.0001827478,  0.0003242493, -0.0021283478,  0.0034102276,\n",
            "        -0.0009615421,  0.0002072453,  0.0006832480,  0.0001143217])\n",
            "btensor.grad: tensor([ 0.0041661263,  0.0005694032,  0.0020001829,  0.0009470284,\n",
            "         0.0006268024,  0.0033504851,  0.0006406307,  0.0016262531,\n",
            "         0.0006141663,  0.0010398626,  0.0001792312, -0.0001864433,\n",
            "         0.0001408495,  0.0007345080, -0.0001002848,  0.0003692508,\n",
            "         0.0007134080, -0.0001560152, -0.0006011724, -0.0013909340])\n",
            "ctensor.grad: tensor([-0.1867167205, -0.1867167205, -0.1867167205, -0.1478634477,\n",
            "         0.0036061555, -0.0868804082,  0.0334231332, -0.0121313650,\n",
            "        -0.1478634477,  0.0036061555, -0.0868804082,  0.0334231332,\n",
            "        -0.0121313650, -0.1478634477,  0.0036061555, -0.0868804082,\n",
            "         0.0334231332, -0.0121313650])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7310180664, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8339203596), tensor(1.7843837738), tensor(1.1099934578), tensor(1.4582558870), tensor(0.8957492709), tensor(0.7460916042), tensor(1.5960847139), tensor(1.1667988300), tensor(1.3429251909), tensor(1.0907305479), tensor(1.0213928223), tensor(1.0960835218), tensor(1.8230179548), tensor(1.2432153225), tensor(1.6460998058), tensor(1.7993502617), tensor(1.6245788336), tensor(1.1292649508), tensor(0.9105068445), tensor(1.0992503166)]\n",
            "b:  [tensor(1.6253886223), tensor(0.7218500376), tensor(1.4580882788), tensor(1.3002475500), tensor(1.0071020126), tensor(2.0120062828), tensor(1.3027937412), tensor(1.3905464411), tensor(1.2782107592), tensor(1.0585165024), tensor(1.3620719910), tensor(1.3205991983), tensor(0.7628992200), tensor(1.2576698065), tensor(1.2350993156), tensor(0.8946461082), tensor(0.9829983711), tensor(1.3955076933), tensor(1.4109488726), tensor(1.5508195162)]\n",
            "c:  [tensor(0.0014702638), tensor(0.0014702638), tensor(0.0014702638), tensor(0.0013641295), tensor(0.0009910667), tensor(0.0012112170), tensor(0.0009154771), tensor(0.0010315174), tensor(0.0013641295), tensor(0.0009910667), tensor(0.0012112170), tensor(0.0009154771), tensor(0.0010315174), tensor(0.0013641295), tensor(0.0009910667), tensor(0.0012112170), tensor(0.0009154771), tensor(0.0010315174)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.2989044189e-03,  1.9431561232e-03,  9.1487169266e-04,\n",
            "         1.6072988510e-03,  1.0462403297e-03,  1.2498088181e-03,\n",
            "         3.7819743156e-03,  8.8557600975e-04,  7.7361613512e-04,\n",
            "         1.0677278042e-03,  6.7377090454e-04, -5.7578086853e-05,\n",
            "        -1.1658668518e-04,  4.4322013855e-04, -1.6414225101e-03,\n",
            "         2.8465501964e-03, -7.0846080780e-04,  3.5434961319e-04,\n",
            "         7.6323747635e-04,  2.6559829712e-04])\n",
            "btensor.grad: tensor([ 3.4906491637e-03,  5.4037570953e-04,  1.7539560795e-03,\n",
            "         9.5427036285e-04,  6.2656402588e-04,  2.9928516597e-03,\n",
            "         6.8950653076e-04,  1.4837682247e-03,  6.4384937286e-04,\n",
            "         9.7310543060e-04,  2.6199221611e-04,  1.6212463379e-05,\n",
            "         1.9240379333e-04,  7.3605775833e-04,  6.2048435211e-05,\n",
            "         3.9267539978e-04,  6.5344572067e-04,  2.3007392883e-05,\n",
            "        -3.2866001129e-04, -1.0125637054e-03])\n",
            "ctensor.grad: tensor([-0.1888533980, -0.1888533980, -0.1888533980, -0.1498120427,\n",
            "         0.0036532772, -0.0880405605,  0.0338543877, -0.0123045649,\n",
            "        -0.1498120427,  0.0036532772, -0.0880405605,  0.0338543877,\n",
            "        -0.0123045649, -0.1498120427,  0.0036532772, -0.0880405605,\n",
            "         0.0338543877, -0.0123045649])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7305908203, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8339076042), tensor(1.7843667269), tensor(1.1099840403), tensor(1.4582414627), tensor(0.8957386017), tensor(0.7460791469), tensor(1.5960526466), tensor(1.1667896509), tensor(1.3429169655), tensor(1.0907198191), tensor(1.0213854313), tensor(1.0960818529), tensor(1.8230184317), tensor(1.2432099581), tensor(1.6461122036), tensor(1.7993263006), tensor(1.6245837212), tensor(1.1292601824), tensor(0.9104985595), tensor(1.0992463827)]\n",
            "b:  [tensor(1.6253590584), tensor(0.7218448520), tensor(1.4580726624), tensor(1.3002380133), tensor(1.0070958138), tensor(2.0119793415), tensor(1.3027864695), tensor(1.3905327320), tensor(1.2782040834), tensor(1.0585073233), tensor(1.3620686531), tensor(1.3205974102), tensor(0.7628968358), tensor(1.2576624155), tensor(1.2350974083), tensor(0.8946419954), tensor(0.9829922318), tensor(1.3955060244), tensor(1.4109499454), tensor(1.5508264303)]\n",
            "c:  [tensor(0.0014893649), tensor(0.0014893649), tensor(0.0014893649), tensor(0.0013793078), tensor(0.0009906966), tensor(0.0012201384), tensor(0.0009120480), tensor(0.0010327655), tensor(0.0013793078), tensor(0.0009906966), tensor(0.0012201384), tensor(0.0009120480), tensor(0.0010327655), tensor(0.0013793078), tensor(0.0009906966), tensor(0.0012201384), tensor(0.0009120480), tensor(0.0010327655)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.2742280960e-03,  1.7001628876e-03,  9.4076991081e-04,\n",
            "         1.4384984970e-03,  1.0682344437e-03,  1.2455843389e-03,\n",
            "         3.2093524933e-03,  9.1937184334e-04,  8.1771984696e-04,\n",
            "         1.0702610016e-03,  7.4362754822e-04,  1.6987323761e-04,\n",
            "        -4.5955181122e-05,  5.3763389587e-04, -1.2358576059e-03,\n",
            "         2.3947991431e-03, -4.9161911011e-04,  4.7111511230e-04,\n",
            "         8.3041191101e-04,  3.9461255074e-04])\n",
            "btensor.grad: tensor([ 0.0029596947,  0.0005190969,  0.0015618205,  0.0009514093,\n",
            "         0.0006244183,  0.0026944093,  0.0007264614,  0.0013692826,\n",
            "         0.0006711483,  0.0009163618,  0.0003381670,  0.0001760721,\n",
            "         0.0002364703,  0.0007377267,  0.0001938343,  0.0004137158,\n",
            "         0.0006154776,  0.0001720190, -0.0001018047, -0.0006918907])\n",
            "ctensor.grad: tensor([-0.1910106987, -0.1910106987, -0.1910106987, -0.1517829597,\n",
            "         0.0037009413, -0.0892141089,  0.0342907272, -0.0124804750,\n",
            "        -0.1517829597,  0.0037009413, -0.0892141089,  0.0342907272,\n",
            "        -0.0124804750, -0.1517829597,  0.0037009413, -0.0892141089,\n",
            "         0.0342907272, -0.0124804750])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7305908203, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8338950276), tensor(1.7843517065), tensor(1.1099745035), tensor(1.4582283497), tensor(0.8957276940), tensor(0.7460666895), tensor(1.5960251093), tensor(1.1667802334), tensor(1.3429085016), tensor(1.0907090902), tensor(1.0213773251), tensor(1.0960783958), tensor(1.8230181932), tensor(1.2432037592), tensor(1.6461211443), tensor(1.7993059158), tensor(1.6245868206), tensor(1.1292544603), tensor(0.9104896784), tensor(1.0992413759)]\n",
            "b:  [tensor(1.6253336668), tensor(0.7218398452), tensor(1.4580584764), tensor(1.3002285957), tensor(1.0070894957), tensor(2.0119547844), tensor(1.3027789593), tensor(1.3905199766), tensor(1.2781971693), tensor(1.0584986210), tensor(1.3620646000), tensor(1.3205944300), tensor(0.7628940940), tensor(1.2576550245), tensor(1.2350944281), tensor(0.8946376443), tensor(0.9829863310), tensor(1.3955030441), tensor(1.4109491110), tensor(1.5508306026)]\n",
            "c:  [tensor(0.0015086832), tensor(0.0015086832), tensor(0.0015086832), tensor(0.0013946855), tensor(0.0009903217), tensor(0.0012291785), tensor(0.0009085748), tensor(0.0010340314), tensor(0.0013946855), tensor(0.0009903217), tensor(0.0012291785), tensor(0.0009085748), tensor(0.0010340314), tensor(0.0013946855), tensor(0.0009903217), tensor(0.0012291785), tensor(0.0009085748), tensor(0.0010340314)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.2556314468e-03,  1.5003234148e-03,  9.5689296722e-04,\n",
            "         1.3056993484e-03,  1.0885596275e-03,  1.2463275343e-03,\n",
            "         2.7480721474e-03,  9.4443559647e-04,  8.4822252393e-04,\n",
            "         1.0731220245e-03,  8.0636143684e-04,  3.4987926483e-04,\n",
            "         2.4795532227e-05,  6.1631202698e-04, -8.9995563030e-04,\n",
            "         2.0342096686e-03, -3.0517578125e-04,  5.6886672974e-04,\n",
            "         8.8840723038e-04,  5.0407648087e-04])\n",
            "btensor.grad: tensor([ 2.5419220328e-03,  5.0359964371e-04,  1.4168620110e-03,\n",
            "         9.4273686409e-04,  6.2942504883e-04,  2.4509392679e-03,\n",
            "         7.5483322144e-04,  1.2758970261e-03,  6.9677829742e-04,\n",
            "         8.7213516235e-04,  4.0906667709e-04,  3.0338764191e-04,\n",
            "         2.7161091566e-04,  7.4225664139e-04,  3.0097365379e-04,\n",
            "         4.3541193008e-04,  5.9175491333e-04,  2.9465556145e-04,\n",
            "         8.0227851868e-05, -4.2057037354e-04])\n",
            "ctensor.grad: tensor([-0.1931833625, -0.1931833625, -0.1931833625, -0.1537768245,\n",
            "         0.0037491524, -0.0904014707,  0.0347321890, -0.0126588726,\n",
            "        -0.1537768245,  0.0037491524, -0.0904014707,  0.0347321890,\n",
            "        -0.0126588726, -0.1537768245,  0.0037491524, -0.0904014707,\n",
            "         0.0347321890, -0.0126588726])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7306518555, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8338826299), tensor(1.7843383551), tensor(1.1099647284), tensor(1.4582163095), tensor(0.8957166672), tensor(0.7460542321), tensor(1.5960013866), tensor(1.1667705774), tensor(1.3428997993), tensor(1.0906983614), tensor(1.0213687420), tensor(1.0960735083), tensor(1.8230172396), tensor(1.2431969643), tensor(1.6461273432), tensor(1.7992883921), tensor(1.6245882511), tensor(1.1292480230), tensor(0.9104803205), tensor(1.0992354155)]\n",
            "b:  [tensor(1.6253114939), tensor(0.7218348980), tensor(1.4580454826), tensor(1.3002192974), tensor(1.0070831776), tensor(2.0119323730), tensor(1.3027712107), tensor(1.3905079365), tensor(1.2781900167), tensor(1.0584902763), tensor(1.3620598316), tensor(1.3205903769), tensor(0.7628910542), tensor(1.2576475143), tensor(1.2350904942), tensor(0.8946331739), tensor(0.9829805493), tensor(1.3954991102), tensor(1.4109468460), tensor(1.5508325100)]\n",
            "c:  [tensor(0.0015282208), tensor(0.0015282208), tensor(0.0015282208), tensor(0.0014102649), tensor(0.0009899420), tensor(0.0012383388), tensor(0.0009050569), tensor(0.0010353155), tensor(0.0014102649), tensor(0.0009899420), tensor(0.0012383388), tensor(0.0009050569), tensor(0.0010353155), tensor(0.0014102649), tensor(0.0009899420), tensor(0.0012383388), tensor(0.0009050569), tensor(0.0010353155)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.2423992157e-03,  1.3405382633e-03,  9.7399950027e-04,\n",
            "         1.2041330338e-03,  1.1048316956e-03,  1.2468006462e-03,\n",
            "         2.3733973503e-03,  9.6380710602e-04,  8.7014399469e-04,\n",
            "         1.0761320591e-03,  8.5482001305e-04,  4.9459934235e-04,\n",
            "         9.3042850494e-05,  6.7818164825e-04, -6.2194466591e-04,\n",
            "         1.7493925989e-03, -1.4412403107e-04,  6.4849853516e-04,\n",
            "         9.3424320221e-04,  5.9407949448e-04])\n",
            "btensor.grad: tensor([ 0.0022166520,  0.0004945695,  0.0013023615,  0.0009319186,\n",
            "         0.0006308556,  0.0022514537,  0.0007754564,  0.0012010038,\n",
            "         0.0007181168,  0.0008366108,  0.0004724264,  0.0004079342,\n",
            "         0.0003038645,  0.0007476807,  0.0003912747,  0.0004493594,\n",
            "         0.0005799532,  0.0003971756,  0.0002282858, -0.0001941919])\n",
            "ctensor.grad: tensor([-0.1953768730, -0.1953768730, -0.1953768730, -0.1557939351,\n",
            "         0.0037979155, -0.0916027054,  0.0351787359, -0.0128400307,\n",
            "        -0.1557939351,  0.0037979155, -0.0916027054,  0.0351787359,\n",
            "        -0.0128400307, -0.1557939351,  0.0037979155, -0.0916027054,\n",
            "         0.0351787359, -0.0128400307])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7308959961, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8338702917), tensor(1.7843261957), tensor(1.1099548340), tensor(1.4582051039), tensor(0.8957055211), tensor(0.7460417151), tensor(1.5959806442), tensor(1.1667608023), tensor(1.3428909779), tensor(1.0906876326), tensor(1.0213598013), tensor(1.0960674286), tensor(1.8230156898), tensor(1.2431896925), tensor(1.6461312771), tensor(1.7992732525), tensor(1.6245883703), tensor(1.1292408705), tensor(0.9104706049), tensor(1.0992287397)]\n",
            "b:  [tensor(1.6252918243), tensor(0.7218300700), tensor(1.4580333233), tensor(1.3002101183), tensor(1.0070768595), tensor(2.0119113922), tensor(1.3027633429), tensor(1.3904964924), tensor(1.2781826258), tensor(1.0584821701), tensor(1.3620545864), tensor(1.3205854893), tensor(0.7628877163), tensor(1.2576400042), tensor(1.2350858450), tensor(0.8946285248), tensor(0.9829748273), tensor(1.3954942226), tensor(1.4109433889), tensor(1.5508325100)]\n",
            "c:  [tensor(0.0015479805), tensor(0.0015479805), tensor(0.0015479805), tensor(0.0014260483), tensor(0.0009895572), tensor(0.0012476206), tensor(0.0009014939), tensor(0.0010366178), tensor(0.0014260483), tensor(0.0009895572), tensor(0.0012476206), tensor(0.0009014939), tensor(0.0010366178), tensor(0.0014260483), tensor(0.0009895572), tensor(0.0012476206), tensor(0.0009014939), tensor(0.0010366178)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.2339353561e-03,  1.2122690678e-03,  9.8606944084e-04,\n",
            "         1.1264085770e-03,  1.1170506477e-03,  1.2487974018e-03,\n",
            "         2.0703673363e-03,  9.7697973251e-04,  8.8790990412e-04,\n",
            "         1.0765492916e-03,  8.9570879936e-04,  6.0808658600e-04,\n",
            "         1.5610456467e-04,  7.2789192200e-04, -3.9091706276e-04,\n",
            "         1.5185289085e-03, -6.5565109253e-06,  7.1829557419e-04,\n",
            "         9.7209215164e-04,  6.6962838173e-04])\n",
            "btensor.grad: tensor([ 1.9618310034e-03,  4.8467516899e-04,  1.2156069279e-03,\n",
            "         9.2175602913e-04,  6.3252449036e-04,  2.0888689905e-03,\n",
            "         7.9226493835e-04,  1.1408030987e-03,  7.3802471161e-04,\n",
            "         8.0931186676e-04,  5.2848458290e-04,  4.9030780792e-04,\n",
            "         3.3312290907e-04,  7.5215101242e-04,  4.5984983444e-04,\n",
            "         4.6700239182e-04,  5.7339668274e-04,  4.8419833183e-04,\n",
            "         3.4952163696e-04, -2.0265579224e-06])\n",
            "ctensor.grad: tensor([-0.1975968778, -0.1975968778, -0.1975968778, -0.1578341424,\n",
            "         0.0038472358, -0.0928181410,  0.0356303602, -0.0130237769,\n",
            "        -0.1578341424,  0.0038472358, -0.0928181410,  0.0356303602,\n",
            "        -0.0130237769, -0.1578341424,  0.0038472358, -0.0928181410,\n",
            "         0.0356303602, -0.0130237769])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7308349609, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8338580132), tensor(1.7843151093), tensor(1.1099448204), tensor(1.4581944942), tensor(0.8956941962), tensor(0.7460291982), tensor(1.5959624052), tensor(1.1667509079), tensor(1.3428819180), tensor(1.0906767845), tensor(1.0213505030), tensor(1.0960603952), tensor(1.8230135441), tensor(1.2431819439), tensor(1.6461333036), tensor(1.7992599010), tensor(1.6245872974), tensor(1.1292331219), tensor(0.9104605317), tensor(1.0992213488)]\n",
            "b:  [tensor(1.6252741814), tensor(0.7218253016), tensor(1.4580218792), tensor(1.3002010584), tensor(1.0070704222), tensor(2.0118918419), tensor(1.3027552366), tensor(1.3904855251), tensor(1.2781751156), tensor(1.0584743023), tensor(1.3620488644), tensor(1.3205798864), tensor(0.7628841400), tensor(1.2576323748), tensor(1.2350807190), tensor(0.8946236968), tensor(0.9829691052), tensor(1.3954887390), tensor(1.4109388590), tensor(1.5508308411)]\n",
            "c:  [tensor(0.0015679651), tensor(0.0015679651), tensor(0.0015679651), tensor(0.0014420381), tensor(0.0009891675), tensor(0.0012570254), tensor(0.0008978852), tensor(0.0010379388), tensor(0.0014420381), tensor(0.0009891675), tensor(0.0012570254), tensor(0.0008978852), tensor(0.0010379388), tensor(0.0014420381), tensor(0.0009891675), tensor(0.0012570254), tensor(0.0008978852), tensor(0.0010379388)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0012292862,  0.0011057705,  0.0009954870,  0.0010654926,\n",
            "         0.0011300445,  0.0012503117,  0.0018235445,  0.0009885728,\n",
            "         0.0009007622,  0.0010804236,  0.0009302497,  0.0006986856,\n",
            "         0.0002158284,  0.0007710457, -0.0001969337,  0.0013383366,\n",
            "         0.0001114607,  0.0007732511,  0.0010063648,  0.0007341802])\n",
            "btensor.grad: tensor([0.0017621480, 0.0004777610, 0.0011486709, 0.0009111166, 0.0006384850,\n",
            "        0.0019537136, 0.0008087158, 0.0010940582, 0.0007522106, 0.0007864237,\n",
            "        0.0005779862, 0.0005581379, 0.0003564060, 0.0007606745, 0.0005172193,\n",
            "        0.0004818439, 0.0005729795, 0.0005541146, 0.0004492998, 0.0001616478])\n",
            "ctensor.grad: tensor([-0.1998471916, -0.1998471916, -0.1998471916, -0.1598981470,\n",
            "         0.0038971193, -0.0940480754,  0.0360871442, -0.0132102026,\n",
            "        -0.1598981470,  0.0038971193, -0.0940480754,  0.0360871442,\n",
            "        -0.0132102026, -0.1598981470,  0.0038971193, -0.0940480754,\n",
            "         0.0360871442, -0.0132102026])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7306518555, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8338457346), tensor(1.7843048573), tensor(1.1099348068), tensor(1.4581842422), tensor(0.8956827521), tensor(0.7460166812), tensor(1.5959461927), tensor(1.1667408943), tensor(1.3428728580), tensor(1.0906659365), tensor(1.0213408470), tensor(1.0960526466), tensor(1.8230108023), tensor(1.2431738377), tensor(1.6461336613), tensor(1.7992479801), tensor(1.6245851517), tensor(1.1292248964), tensor(0.9104501605), tensor(1.0992134809)]\n",
            "b:  [tensor(1.6252580881), tensor(0.7218205333), tensor(1.4580109119), tensor(1.3001919985), tensor(1.0070641041), tensor(2.0118734837), tensor(1.3027470112), tensor(1.3904749155), tensor(1.2781674862), tensor(1.0584666729), tensor(1.3620426655), tensor(1.3205736876), tensor(0.7628803253), tensor(1.2576247454), tensor(1.2350749969), tensor(0.8946188092), tensor(0.9829633236), tensor(1.3954825401), tensor(1.4109336138), tensor(1.5508278608)]\n",
            "c:  [tensor(0.0015881779), tensor(0.0015881779), tensor(0.0015881779), tensor(0.0014582367), tensor(0.0009887727), tensor(0.0012665547), tensor(0.0008942303), tensor(0.0010392787), tensor(0.0014582367), tensor(0.0009887727), tensor(0.0012665547), tensor(0.0008942303), tensor(0.0010392787), tensor(0.0014582367), tensor(0.0009887727), tensor(0.0012665547), tensor(0.0008942303), tensor(0.0010392787)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.2274384499e-03,  1.0214447975e-03,  1.0048449039e-03,\n",
            "         1.0206699371e-03,  1.1414885521e-03,  1.2544821948e-03,\n",
            "         1.6255974770e-03,  9.9697709084e-04,  9.0831518173e-04,\n",
            "         1.0815858841e-03,  9.6103549004e-04,  7.7021121979e-04,\n",
            "         2.6983022690e-04,  8.0585479736e-04, -3.5986304283e-05,\n",
            "         1.1946223676e-03,  2.1135807037e-04,  8.2039833069e-04,\n",
            "         1.0363459587e-03,  7.8648328781e-04])\n",
            "btensor.grad: tensor([0.0016058274, 0.0004740953, 0.0011003911, 0.0009046495, 0.0006361008,\n",
            "        0.0018432420, 0.0008168221, 0.0010564327, 0.0007678270, 0.0007672310,\n",
            "        0.0006248355, 0.0006152391, 0.0003786311, 0.0007664561, 0.0005690455,\n",
            "        0.0004913807, 0.0005755424, 0.0006164312, 0.0005298853, 0.0002990961])\n",
            "ctensor.grad: tensor([-0.2021270692, -0.2021270692, -0.2021270692, -0.1619863361,\n",
            "         0.0039475746, -0.0952926055,  0.0365491062, -0.0133994333,\n",
            "        -0.1619863361,  0.0039475746, -0.0952926055,  0.0365491062,\n",
            "        -0.0133994333, -0.1619863361,  0.0039475746, -0.0952926055,\n",
            "         0.0365491062, -0.0133994333])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7305908203, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8338334560), tensor(1.7842953205), tensor(1.1099246740), tensor(1.4581744671), tensor(0.8956712484), tensor(0.7460040450), tensor(1.5959315300), tensor(1.1667308807), tensor(1.3428636789), tensor(1.0906550884), tensor(1.0213309526), tensor(1.0960443020), tensor(1.8230075836), tensor(1.2431654930), tensor(1.6461327076), tensor(1.7992371321), tensor(1.6245821714), tensor(1.1292163134), tensor(0.9104395509), tensor(1.0992051363)]\n",
            "b:  [tensor(1.6252431870), tensor(0.7218158245), tensor(1.4580003023), tensor(1.3001830578), tensor(1.0070576668), tensor(2.0118558407), tensor(1.3027387857), tensor(1.3904646635), tensor(1.2781597376), tensor(1.0584590435), tensor(1.3620359898), tensor(1.3205671310), tensor(0.7628763318), tensor(1.2576169968), tensor(1.2350689173), tensor(0.8946137428), tensor(0.9829575419), tensor(1.3954758644), tensor(1.4109276533), tensor(1.5508236885)]\n",
            "c:  [tensor(0.0016086204), tensor(0.0016086204), tensor(0.0016086204), tensor(0.0014746466), tensor(0.0009883728), tensor(0.0012762098), tensor(0.0008905287), tensor(0.0010406378), tensor(0.0014746466), tensor(0.0009883728), tensor(0.0012762098), tensor(0.0008905287), tensor(0.0010406378), tensor(0.0014746466), tensor(0.0009883728), tensor(0.0012762098), tensor(0.0008905287), tensor(0.0010406378)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([1.2267827988e-03, 9.5374882221e-04, 1.0177493095e-03, 9.8311901093e-04,\n",
            "        1.1533498764e-03, 1.2625847012e-03, 1.4692544937e-03, 1.0047256947e-03,\n",
            "        9.1535411775e-04, 1.0849535465e-03, 9.8732113838e-04, 8.2862377167e-04,\n",
            "        3.1977891922e-04, 8.3518028259e-04, 9.8064541817e-05, 1.0819323361e-03,\n",
            "        2.9551982880e-04, 8.5991621017e-04, 1.0610222816e-03, 8.3521008492e-04])\n",
            "btensor.grad: tensor([0.0014865473, 0.0004707873, 0.0010645390, 0.0008942187, 0.0006420612,\n",
            "        0.0017555431, 0.0008242130, 0.0010287762, 0.0007792711, 0.0007572174,\n",
            "        0.0006638169, 0.0006588697, 0.0003970489, 0.0007739961, 0.0006097555,\n",
            "        0.0005042553, 0.0005808473, 0.0006679595, 0.0005987883, 0.0004161596])\n",
            "ctensor.grad: tensor([-0.2044251710, -0.2044251710, -0.2044251710, -0.1640987992,\n",
            "         0.0039986097, -0.0965518132,  0.0370163247, -0.0135913733,\n",
            "        -0.1640987992,  0.0039986097, -0.0965518132,  0.0370163247,\n",
            "        -0.0135913733, -0.1640987992,  0.0039986097, -0.0965518132,\n",
            "         0.0370163247, -0.0135913733])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7304687500, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8338211179), tensor(1.7842862606), tensor(1.1099144220), tensor(1.4581649303), tensor(0.8956595659), tensor(0.7459913492), tensor(1.5959181786), tensor(1.1667207479), tensor(1.3428544998), tensor(1.0906442404), tensor(1.0213208199), tensor(1.0960354805), tensor(1.8230038881), tensor(1.2431569099), tensor(1.6461305618), tensor(1.7992272377), tensor(1.6245784760), tensor(1.1292073727), tensor(0.9104287028), tensor(1.0991963148)]\n",
            "b:  [tensor(1.6252292395), tensor(0.7218111157), tensor(1.4579899311), tensor(1.3001741171), tensor(1.0070512295), tensor(2.0118389130), tensor(1.3027304411), tensor(1.3904546499), tensor(1.2781518698), tensor(1.0584515333), tensor(1.3620289564), tensor(1.3205600977), tensor(0.7628722191), tensor(1.2576092482), tensor(1.2350624800), tensor(0.8946086168), tensor(0.9829517007), tensor(1.3954687119), tensor(1.4109210968), tensor(1.5508185625)]\n",
            "c:  [tensor(0.0016292958), tensor(0.0016292958), tensor(0.0016292958), tensor(0.0014912701), tensor(0.0009879678), tensor(0.0012859924), tensor(0.0008867798), tensor(0.0010420164), tensor(0.0014912701), tensor(0.0009879678), tensor(0.0012859924), tensor(0.0008867798), tensor(0.0010420164), tensor(0.0014912701), tensor(0.0009879678), tensor(0.0012859924), tensor(0.0008867798), tensor(0.0010420164)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.0012308955, 0.0009005666, 0.0010294020, 0.0009582043, 0.0011681914,\n",
            "        0.0012699515, 0.0013403893, 0.0010118484, 0.0009204745, 0.0010862648,\n",
            "        0.0010099411, 0.0008772612, 0.0003637671, 0.0008611679, 0.0002100319,\n",
            "        0.0009910688, 0.0003690720, 0.0008938909, 0.0010850430, 0.0008769631])\n",
            "btensor.grad: tensor([0.0013922676, 0.0004696846, 0.0010392368, 0.0008893609, 0.0006470680,\n",
            "        0.0016813222, 0.0008338690, 0.0010069758, 0.0007909536, 0.0007451773,\n",
            "        0.0006986260, 0.0006978512, 0.0004130602, 0.0007807016, 0.0006482005,\n",
            "        0.0005150437, 0.0005866885, 0.0007131100, 0.0006591082, 0.0005155802])\n",
            "ctensor.grad: tensor([-0.2067540586, -0.2067540586, -0.2067540586, -0.1662357450,\n",
            "         0.0040502287, -0.0978262872,  0.0374888182, -0.0137860142,\n",
            "        -0.1662357450,  0.0040502287, -0.0978262872,  0.0374888182,\n",
            "        -0.0137860142, -0.1662357450,  0.0040502287, -0.0978262872,\n",
            "         0.0374888182, -0.0137860142])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7304687500, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8338087797), tensor(1.7842776775), tensor(1.1099040508), tensor(1.4581555128), tensor(0.8956477642), tensor(0.7459785342), tensor(1.5959057808), tensor(1.1667104959), tensor(1.3428452015), tensor(1.0906332731), tensor(1.0213104486), tensor(1.0960263014), tensor(1.8229998350), tensor(1.2431480885), tensor(1.6461275816), tensor(1.7992180586), tensor(1.6245741844), tensor(1.1291980743), tensor(0.9104176164), tensor(1.0991872549)]\n",
            "b:  [tensor(1.6252160072), tensor(0.7218064070), tensor(1.4579796791), tensor(1.3001652956), tensor(1.0070446730), tensor(2.0118227005), tensor(1.3027219772), tensor(1.3904447556), tensor(1.2781438828), tensor(1.0584441423), tensor(1.3620216846), tensor(1.3205528259), tensor(0.7628679276), tensor(1.2576013803), tensor(1.2350556850), tensor(0.8946033716), tensor(0.9829457402), tensor(1.3954612017), tensor(1.4109140635), tensor(1.5508126020)]\n",
            "c:  [tensor(0.0016502073), tensor(0.0016502073), tensor(0.0016502073), tensor(0.0015081100), tensor(0.0009875576), tensor(0.0012959040), tensor(0.0008829831), tensor(0.0010434148), tensor(0.0015081100), tensor(0.0009875576), tensor(0.0012959040), tensor(0.0008829831), tensor(0.0010434148), tensor(0.0015081100), tensor(0.0009875576), tensor(0.0012959040), tensor(0.0008829831), tensor(0.0010434148)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.0012339354, 0.0008564442, 0.0010395646, 0.0009416342, 0.0011801124,\n",
            "        0.0012793094, 0.0012367964, 0.0010210872, 0.0009275619, 0.0010914207,\n",
            "        0.0010323822, 0.0009182692, 0.0004037023, 0.0008866787, 0.0003015250,\n",
            "        0.0009202510, 0.0004317760, 0.0009257197, 0.0011070371, 0.0009104908])\n",
            "btensor.grad: tensor([0.0013226308, 0.0004699826, 0.0010192692, 0.0008845031, 0.0006527901,\n",
            "        0.0016205199, 0.0008429289, 0.0009918511, 0.0008045435, 0.0007385015,\n",
            "        0.0007288158, 0.0007311106, 0.0004305094, 0.0007914305, 0.0006793737,\n",
            "        0.0005273223, 0.0005939603, 0.0007501245, 0.0007054806, 0.0006015301])\n",
            "ctensor.grad: tensor([-0.2091156989, -0.2091156989, -0.2091156989, -0.1683979183,\n",
            "         0.0041024392, -0.0991159230,  0.0379666053, -0.0139834415,\n",
            "        -0.1683979183,  0.0041024392, -0.0991159230,  0.0379666053,\n",
            "        -0.0139834415, -0.1683979183,  0.0041024392, -0.0991159230,\n",
            "         0.0379666053, -0.0139834415])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7305297852, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337963820), tensor(1.7842694521), tensor(1.1098935604), tensor(1.4581462145), tensor(0.8956358433), tensor(0.7459656596), tensor(1.5958942175), tensor(1.1667002439), tensor(1.3428359032), tensor(1.0906223059), tensor(1.0212999582), tensor(1.0960167646), tensor(1.8229954243), tensor(1.2431390285), tensor(1.6461237669), tensor(1.7992093563), tensor(1.6245692968), tensor(1.1291885376), tensor(0.9104063511), tensor(1.0991778374)]\n",
            "b:  [tensor(1.6252032518), tensor(0.7218016982), tensor(1.4579696655), tensor(1.3001564741), tensor(1.0070381165), tensor(2.0118069649), tensor(1.3027135134), tensor(1.3904349804), tensor(1.2781357765), tensor(1.0584367514), tensor(1.3620140553), tensor(1.3205451965), tensor(0.7628634572), tensor(1.2575933933), tensor(1.2350486517), tensor(0.8945980072), tensor(0.9829397202), tensor(1.3954533339), tensor(1.4109065533), tensor(1.5508058071)]\n",
            "c:  [tensor(0.0016713579), tensor(0.0016713579), tensor(0.0016713579), tensor(0.0015251685), tensor(0.0009871421), tensor(0.0013059461), tensor(0.0008791382), tensor(0.0010448332), tensor(0.0015251685), tensor(0.0009871421), tensor(0.0013059461), tensor(0.0008791382), tensor(0.0010448332), tensor(0.0015251685), tensor(0.0009871421), tensor(0.0013059461), tensor(0.0008791382), tensor(0.0010448332)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.0012407899, 0.0008223504, 0.0010504425, 0.0009263754, 0.0011918545,\n",
            "        0.0012878813, 0.0011532903, 0.0010276735, 0.0009335559, 0.0010954738,\n",
            "        0.0010510087, 0.0009530783, 0.0004392862, 0.0009083748, 0.0003819615,\n",
            "        0.0008659996, 0.0004867315, 0.0009510517, 0.0011258125, 0.0009458363])\n",
            "btensor.grad: tensor([0.0012718253, 0.0004712641, 0.0010040104, 0.0008837283, 0.0006549358,\n",
            "        0.0015749205, 0.0008493662, 0.0009805858, 0.0008156300, 0.0007342100,\n",
            "        0.0007570982, 0.0007580519, 0.0004448146, 0.0008001029, 0.0007056594,\n",
            "        0.0005373359, 0.0006023049, 0.0007831752, 0.0007474422, 0.0006753206])\n",
            "ctensor.grad: tensor([-0.2115056664, -0.2115056664, -0.2115056664, -0.1705852151,\n",
            "         0.0041552498, -0.1004212350,  0.0384498276, -0.0141836293,\n",
            "        -0.1705852151,  0.0041552498, -0.1004212350,  0.0384498276,\n",
            "        -0.0141836293, -0.1705852151,  0.0041552498, -0.1004212350,\n",
            "         0.0384498276, -0.0141836293])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(731.7302856445, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337838650), tensor(1.7842614651), tensor(1.1098829508), tensor(1.4581370354), tensor(0.8956238031), tensor(0.7459526658), tensor(1.5958833694), tensor(1.1666898727), tensor(1.3428264856), tensor(1.0906112194), tensor(1.0212892294), tensor(1.0960068703), tensor(1.8229906559), tensor(1.2431297302), tensor(1.6461192369), tensor(1.7992011309), tensor(1.6245639324), tensor(1.1291787624), tensor(0.9103949070), tensor(1.0991680622)]\n",
            "b:  [tensor(1.6251909733), tensor(0.7217969894), tensor(1.4579596519), tensor(1.3001476526), tensor(1.0070314407), tensor(2.0117914677), tensor(1.3027049303), tensor(1.3904252052), tensor(1.2781275511), tensor(1.0584294796), tensor(1.3620061874), tensor(1.3205373287), tensor(0.7628588676), tensor(1.2575852871), tensor(1.2350413799), tensor(0.8945925236), tensor(0.9829335809), tensor(1.3954452276), tensor(1.4108986855), tensor(1.5507984161)]\n",
            "c:  [tensor(0.0016927503), tensor(0.0016927503), tensor(0.0016927503), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.0012491941, 0.0007963181, 0.0010613799, 0.0009180307, 0.0012035370,\n",
            "        0.0012989230, 0.0010865331, 0.0010362267, 0.0009407960, 0.0011030138,\n",
            "        0.0010700822, 0.0009844303, 0.0004725456, 0.0009264946, 0.0004494935,\n",
            "        0.0008229278, 0.0005328655, 0.0009750128, 0.0011458397, 0.0009768903])\n",
            "btensor.grad: tensor([0.0012303516, 0.0004729033, 0.0009975433, 0.0008834004, 0.0006616116,\n",
            "        0.0015398785, 0.0008584261, 0.0009749830, 0.0008263588, 0.0007308722,\n",
            "        0.0007813573, 0.0007820129, 0.0004566833, 0.0008087754, 0.0007310212,\n",
            "        0.0005478263, 0.0006110072, 0.0008127689, 0.0007834435, 0.0007388592])\n",
            "ctensor.grad: tensor([-0.2139238715, -0.2139238715, -0.2139238715, -0.1727984697,\n",
            "         0.0042086686, -0.1017421186,  0.0389384814, -0.0143867945,\n",
            "        -0.1727984697,  0.0042086686, -0.1017421186,  0.0389384814,\n",
            "        -0.0143867945, -0.1727984697,  0.0042086686, -0.1017421186,\n",
            "         0.0389384814, -0.0143867945])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "probability after training of team 2 landing 5 goals against 3: tensor(0.0123937298)\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "\n",
            " Validation:\n",
            "\n",
            "test unseen validation set using only earlier traning\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.9414997101, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337838650), tensor(1.7842614651), tensor(1.1098829508), tensor(1.4581370354), tensor(0.8956238031), tensor(0.7459526658), tensor(1.5958833694), tensor(1.1666898727), tensor(1.3428264856), tensor(1.0906112194), tensor(1.0212892294), tensor(1.0960068703), tensor(1.8229906559), tensor(1.2431297302), tensor(1.6461192369), tensor(1.7992011309), tensor(1.6245639324), tensor(1.1291787624), tensor(0.9103949070), tensor(1.0991680622)]\n",
            "b:  [tensor(1.6251909733), tensor(0.7217969894), tensor(1.4579596519), tensor(1.3001476526), tensor(1.0070314407), tensor(2.0117914677), tensor(1.3027049303), tensor(1.3904252052), tensor(1.2781275511), tensor(1.0584294796), tensor(1.3620061874), tensor(1.3205373287), tensor(0.7628588676), tensor(1.2575852871), tensor(1.2350413799), tensor(0.8945925236), tensor(0.9829335809), tensor(1.3954452276), tensor(1.4108986855), tensor(1.5507984161)]\n",
            "c:  [tensor(0.0016927503), tensor(0.0016927503), tensor(0.0016927503), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.3205372095,  1.4108986855, -2.1473290920,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0957845822,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6876921654,  0.0000000000,  0.9150851965,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.1043798104,  0.4147517681,  0.8583490849,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.8970504403,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -3.4895036221,  0.0000000000,  0.7473539114,  0.0000000000])\n",
            "ctensor.grad: tensor([ 0.6323914528,  0.6323914528,  0.6323914528, -0.0010311031,\n",
            "         0.0000000000,  0.0114627285,  0.0053607994,  0.0128153507,\n",
            "        -0.0010311031,  0.0000000000,  0.0114627285,  0.0053607994,\n",
            "         0.0128153507, -0.0010311031,  0.0000000000,  0.0114627285,\n",
            "         0.0053607994,  0.0128153507])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.9414997101, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337838650), tensor(1.7842614651), tensor(1.1098829508), tensor(1.4581370354), tensor(0.8943032622), tensor(0.7445417643), tensor(1.5980306864), tensor(1.1666898727), tensor(1.3428264856), tensor(1.0906112194), tensor(1.0212892294), tensor(1.0959111452), tensor(1.8229906559), tensor(1.2431297302), tensor(1.6461192369), tensor(1.7992011309), tensor(1.6238762140), tensor(1.1291787624), tensor(0.9094797969), tensor(1.0991680622)]\n",
            "b:  [tensor(1.6251909733), tensor(0.7217969894), tensor(1.4579596519), tensor(1.3001476526), tensor(1.0069270134), tensor(2.0113766193), tensor(1.3018466234), tensor(1.3904252052), tensor(1.2781275511), tensor(1.0584294796), tensor(1.3620061874), tensor(1.3196402788), tensor(0.7628588676), tensor(1.2575852871), tensor(1.2350413799), tensor(0.8945925236), tensor(0.9864230752), tensor(1.3954452276), tensor(1.4101513624), tensor(1.5507984161)]\n",
            "c:  [tensor(0.0016927503), tensor(0.0016927503), tensor(0.0016927503), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.3205372095,  1.4108986855, -2.1473290920,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0957845822,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6876921654,  0.0000000000,  0.9150851965,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.1043798104,  0.4147517681,  0.8583490849,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.8970504403,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -3.4895036221,  0.0000000000,  0.7473539114,  0.0000000000])\n",
            "ctensor.grad: tensor([ 0.6323914528,  0.6323914528,  0.6323914528, -0.0010311031,\n",
            "         0.0000000000,  0.0114627285,  0.0053607994,  0.0128153507,\n",
            "        -0.0010311031,  0.0000000000,  0.0114627285,  0.0053607994,\n",
            "         0.0128153507, -0.0010311031,  0.0000000000,  0.0114627285,\n",
            "         0.0053607994,  0.0128153507])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.9174232483, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337838650), tensor(1.7842614651), tensor(1.1098829508), tensor(1.4581370354), tensor(0.8929836154), tensor(0.7431316376), tensor(1.6001703739), tensor(1.1666898727), tensor(1.3428264856), tensor(1.0906112194), tensor(1.0212892294), tensor(1.0958155394), tensor(1.8229906559), tensor(1.2431297302), tensor(1.6461192369), tensor(1.7992011309), tensor(1.6231896877), tensor(1.1291787624), tensor(0.9085662365), tensor(1.0991680622)]\n",
            "b:  [tensor(1.6251909733), tensor(0.7217969894), tensor(1.4579596519), tensor(1.3001476526), tensor(1.0068228245), tensor(2.0109629631), tensor(1.3009895086), tensor(1.3904252052), tensor(1.2781275511), tensor(1.0584294796), tensor(1.3620061874), tensor(1.3187445402), tensor(0.7628588676), tensor(1.2575852871), tensor(1.2350413799), tensor(0.8945925236), tensor(0.9898924232), tensor(1.3954452276), tensor(1.4094054699), tensor(1.5507984161)]\n",
            "c:  [tensor(0.0016927503), tensor(0.0016927503), tensor(0.0016927503), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.3196402788,  1.4101513624, -2.1396369934,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0956006572,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6865736842,  0.0000000000,  0.9135684967,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.1041811034,  0.4137341082,  0.8571553230,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.8957299590,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -3.4693613052,  0.0000000000,  0.7459430099,  0.0000000000])\n",
            "ctensor.grad: tensor([ 0.6333054900,  0.6333054900,  0.6333054900, -0.0010064798,\n",
            "         0.0000000000,  0.0114804972,  0.0053675054,  0.0128261317,\n",
            "        -0.0010064798,  0.0000000000,  0.0114804972,  0.0053675054,\n",
            "         0.0128261317, -0.0010064798,  0.0000000000,  0.0114804972,\n",
            "         0.0053675054,  0.0128261317])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.8935346603, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337838650), tensor(1.7842614651), tensor(1.1098829508), tensor(1.4581370354), tensor(0.8916648626), tensor(0.7417222261), tensor(1.6023023129), tensor(1.1666898727), tensor(1.3428264856), tensor(1.0906112194), tensor(1.0212892294), tensor(1.0957201719), tensor(1.8229906559), tensor(1.2431297302), tensor(1.6461192369), tensor(1.7992011309), tensor(1.6225042343), tensor(1.1291787624), tensor(0.9076541662), tensor(1.0991680622)]\n",
            "b:  [tensor(1.6251909733), tensor(0.7217969894), tensor(1.4579596519), tensor(1.3001476526), tensor(1.0067188740), tensor(2.0105502605), tensor(1.3001335859), tensor(1.3904252052), tensor(1.2781275511), tensor(1.0584294796), tensor(1.3620061874), tensor(1.3178501129), tensor(0.7628588676), tensor(1.2575852871), tensor(1.2350413799), tensor(0.8945925236), tensor(0.9933418632), tensor(1.3954452276), tensor(1.4086608887), tensor(1.5507984161)]\n",
            "c:  [tensor(0.0016927503), tensor(0.0016927503), tensor(0.0016927503), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.3187444210,  1.4094054699, -2.1319911480,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0954170302,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6854565740,  0.0000000000,  0.9120526910,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.1039826944,  0.4127182662,  0.8559626937,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.8944102526,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -3.4494564533,  0.0000000000,  0.7445328832,  0.0000000000])\n",
            "ctensor.grad: tensor([ 0.6342079639,  0.6342079639,  0.6342079639, -0.0009820536,\n",
            "         0.0000000000,  0.0114980182,  0.0053741252,  0.0128367441,\n",
            "        -0.0009820536,  0.0000000000,  0.0114980182,  0.0053741252,\n",
            "         0.0128367441, -0.0009820536,  0.0000000000,  0.0114980182,\n",
            "         0.0053741252,  0.0128367441])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.8698329926, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337838650), tensor(1.7842614651), tensor(1.1098829508), tensor(1.4581370354), tensor(0.8903470039), tensor(0.7403135896), tensor(1.6044267416), tensor(1.1666898727), tensor(1.3428264856), tensor(1.0906112194), tensor(1.0212892294), tensor(1.0956249237), tensor(1.8229906559), tensor(1.2431297302), tensor(1.6461192369), tensor(1.7992011309), tensor(1.6218198538), tensor(1.1291787624), tensor(0.9067436457), tensor(1.0991680622)]\n",
            "b:  [tensor(1.6251909733), tensor(0.7217969894), tensor(1.4579596519), tensor(1.3001476526), tensor(1.0066150427), tensor(2.0101385117), tensor(1.2992788553), tensor(1.3904252052), tensor(1.2781275511), tensor(1.0584294796), tensor(1.3620061874), tensor(1.3169569969), tensor(0.7628588676), tensor(1.2575852871), tensor(1.2350413799), tensor(0.8945925236), tensor(0.9967716336), tensor(1.3954452276), tensor(1.4079177380), tensor(1.5507984161)]\n",
            "c:  [tensor(0.0016927503), tensor(0.0016927503), tensor(0.0016927503), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.3178501129,  1.4086607695, -2.1243917942,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0952338278,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6843408346,  0.0000000000,  0.9105376005,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.1037847400,  0.4117041528,  0.8547712564,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.8930915594,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -3.4297847748,  0.0000000000,  0.7431234121,  0.0000000000])\n",
            "ctensor.grad: tensor([ 0.6350988150,  0.6350988150,  0.6350988150, -0.0009578234,\n",
            "         0.0000000000,  0.0115152998,  0.0053806617,  0.0128471926,\n",
            "        -0.0009578234,  0.0000000000,  0.0115152998,  0.0053806617,\n",
            "         0.0128471926, -0.0009578234,  0.0000000000,  0.0115152998,\n",
            "         0.0053806617,  0.0128471926])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.8463134766, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337838650), tensor(1.7842614651), tensor(1.1098829508), tensor(1.4581370354), tensor(0.8890300393), tensor(0.7389056683), tensor(1.6065435410), tensor(1.1666898727), tensor(1.3428264856), tensor(1.0906112194), tensor(1.0212892294), tensor(1.0955299139), tensor(1.8229906559), tensor(1.2431297302), tensor(1.6461192369), tensor(1.7992011309), tensor(1.6211366653), tensor(1.1291787624), tensor(0.9058346152), tensor(1.0991680622)]\n",
            "b:  [tensor(1.6251909733), tensor(0.7217969894), tensor(1.4579596519), tensor(1.3001476526), tensor(1.0065114498), tensor(2.0097277164), tensor(1.2984253168), tensor(1.3904252052), tensor(1.2781275511), tensor(1.0584294796), tensor(1.3620061874), tensor(1.3160651922), tensor(0.7628588676), tensor(1.2575852871), tensor(1.2350413799), tensor(0.8945925236), tensor(1.0001820326), tensor(1.3954452276), tensor(1.4071760178), tensor(1.5507984161)]\n",
            "c:  [tensor(0.0016927503), tensor(0.0016927503), tensor(0.0016927503), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.3169569969,  1.4079177380, -2.1168375015,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0950508490,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6832264662,  0.0000000000,  0.9090229869,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.1035870239,  0.4106917381,  0.8535808921,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.8917737007,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -3.4103403091,  0.0000000000,  0.7417148352,  0.0000000000])\n",
            "ctensor.grad: tensor([ 0.6359784007,  0.6359784007,  0.6359784007, -0.0009337855,\n",
            "         0.0000000000,  0.0115323439,  0.0053871162,  0.0128574828,\n",
            "        -0.0009337855,  0.0000000000,  0.0115323439,  0.0053871162,\n",
            "         0.0128574828, -0.0009337855,  0.0000000000,  0.0115323439,\n",
            "         0.0053871162,  0.0128574828])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.8229751587, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337838650), tensor(1.7842614651), tensor(1.1098829508), tensor(1.4581370354), tensor(0.8877139688), tensor(0.7374985218), tensor(1.6086528301), tensor(1.1666898727), tensor(1.3428264856), tensor(1.0906112194), tensor(1.0212892294), tensor(1.0954350233), tensor(1.8229906559), tensor(1.2431297302), tensor(1.6461192369), tensor(1.7992011309), tensor(1.6204545498), tensor(1.1291787624), tensor(0.9049271345), tensor(1.0991680622)]\n",
            "b:  [tensor(1.6251909733), tensor(0.7217969894), tensor(1.4579596519), tensor(1.3001476526), tensor(1.0064080954), tensor(2.0093181133), tensor(1.2975729704), tensor(1.3904252052), tensor(1.2781275511), tensor(1.0584294796), tensor(1.3620061874), tensor(1.3151746988), tensor(0.7628588676), tensor(1.2575852871), tensor(1.2350413799), tensor(0.8945925236), tensor(1.0035731792), tensor(1.3954452276), tensor(1.4064357281), tensor(1.5507984161)]\n",
            "c:  [tensor(0.0016927503), tensor(0.0016927503), tensor(0.0016927503), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.3160651922,  1.4071760178, -2.1093277931,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0948683470,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6821136475,  0.0000000000,  0.9075089693,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.1033898219,  0.4096810818,  0.8523918986,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.8904567361,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -3.3911190033,  0.0000000000,  0.7403069139,  0.0000000000])\n",
            "ctensor.grad: tensor([ 0.6368469000,  0.6368469000,  0.6368469000, -0.0009099357,\n",
            "         0.0000000000,  0.0115491552,  0.0053934911,  0.0128676146,\n",
            "        -0.0009099357,  0.0000000000,  0.0115491552,  0.0053934911,\n",
            "         0.0128676146, -0.0009099357,  0.0000000000,  0.0115491552,\n",
            "         0.0053934911,  0.0128676146])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.7998142242, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337838650), tensor(1.7842614651), tensor(1.1098829508), tensor(1.4581370354), tensor(0.8863987923), tensor(0.7360920906), tensor(1.6107547283), tensor(1.1666898727), tensor(1.3428264856), tensor(1.0906112194), tensor(1.0212892294), tensor(1.0953403711), tensor(1.8229906559), tensor(1.2431297302), tensor(1.6461192369), tensor(1.7992011309), tensor(1.6197735071), tensor(1.1291787624), tensor(0.9040211439), tensor(1.0991680622)]\n",
            "b:  [tensor(1.6251909733), tensor(0.7217969894), tensor(1.4579596519), tensor(1.3001476526), tensor(1.0063048601), tensor(2.0089094639), tensor(1.2967218161), tensor(1.3904252052), tensor(1.2781275511), tensor(1.0584294796), tensor(1.3620061874), tensor(1.3142855167), tensor(0.7628588676), tensor(1.2575852871), tensor(1.2350413799), tensor(0.8945925236), tensor(1.0069452524), tensor(1.3954452276), tensor(1.4056968689), tensor(1.5507984161)]\n",
            "c:  [tensor(0.0016927503), tensor(0.0016927503), tensor(0.0016927503), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.3151746988,  1.4064356089, -2.1018631458,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0946861431,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6810020208,  0.0000000000,  0.9059957266,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.1031929180,  0.4086721241,  0.8512037992,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.8891406655,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -3.3721177578,  0.0000000000,  0.7388997078,  0.0000000000])\n",
            "ctensor.grad: tensor([ 0.6377041340,  0.6377041340,  0.6377041340, -0.0008862754,\n",
            "         0.0000000000,  0.0115657328,  0.0053997850,  0.0128775882,\n",
            "        -0.0008862754,  0.0000000000,  0.0115657328,  0.0053997850,\n",
            "         0.0128775882, -0.0008862754,  0.0000000000,  0.0115657328,\n",
            "         0.0053997850,  0.0128775882])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.7768278122, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337838650), tensor(1.7842614651), tensor(1.1098829508), tensor(1.4581370354), tensor(0.8850845098), tensor(0.7346863747), tensor(1.6128491163), tensor(1.1666898727), tensor(1.3428264856), tensor(1.0906112194), tensor(1.0212892294), tensor(1.0952458382), tensor(1.8229906559), tensor(1.2431297302), tensor(1.6461192369), tensor(1.7992011309), tensor(1.6190936565), tensor(1.1291787624), tensor(0.9031166434), tensor(1.0991680622)]\n",
            "b:  [tensor(1.6251909733), tensor(0.7217969894), tensor(1.4579596519), tensor(1.3001476526), tensor(1.0062018633), tensor(2.0085017681), tensor(1.2958718538), tensor(1.3904252052), tensor(1.2781275511), tensor(1.0584294796), tensor(1.3620061874), tensor(1.3133976460), tensor(0.7628588676), tensor(1.2575852871), tensor(1.2350413799), tensor(0.8945925236), tensor(1.0102986097), tensor(1.3954452276), tensor(1.4049593210), tensor(1.5507984161)]\n",
            "c:  [tensor(0.0016927503), tensor(0.0016927503), tensor(0.0016927503), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.3142855167,  1.4056968689, -2.0944428444,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0945041105,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6798919439,  0.0000000000,  0.9044830203,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.1029962078,  0.4076648951,  0.8500169516,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.8878254890,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -3.3533322811,  0.0000000000,  0.7374933362,  0.0000000000])\n",
            "ctensor.grad: tensor([ 0.6385502815,  0.6385502815,  0.6385502815, -0.0008628070,\n",
            "         0.0000000000,  0.0115820747,  0.0054059960,  0.0128874015,\n",
            "        -0.0008628070,  0.0000000000,  0.0115820747,  0.0054059960,\n",
            "         0.0128874015, -0.0008628070,  0.0000000000,  0.0115820747,\n",
            "         0.0054059960,  0.0128874015])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.7540159225, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337838650), tensor(1.7842614651), tensor(1.1098829508), tensor(1.4581370354), tensor(0.8837711215), tensor(0.7332814336), tensor(1.6149362326), tensor(1.1666898727), tensor(1.3428264856), tensor(1.0906112194), tensor(1.0212892294), tensor(1.0951515436), tensor(1.8229906559), tensor(1.2431297302), tensor(1.6461192369), tensor(1.7992011309), tensor(1.6184148788), tensor(1.1291787624), tensor(0.9022136927), tensor(1.0991680622)]\n",
            "b:  [tensor(1.6251909733), tensor(0.7217969894), tensor(1.4579596519), tensor(1.3001476526), tensor(1.0060991049), tensor(2.0080950260), tensor(1.2950229645), tensor(1.3904252052), tensor(1.2781275511), tensor(1.0584294796), tensor(1.3620061874), tensor(1.3125110865), tensor(0.7628588676), tensor(1.2575852871), tensor(1.2350413799), tensor(0.8945925236), tensor(1.0136333704), tensor(1.3954452276), tensor(1.4042232037), tensor(1.5507984161)]\n",
            "c:  [tensor(0.0016927503), tensor(0.0016927503), tensor(0.0016927503), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.3133976460,  1.4049593210, -2.0870652199,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0943224877,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6787831187,  0.0000000000,  0.9029708505,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.1027999222,  0.4066593051,  0.8488311768,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.8865112066,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -3.3347556591,  0.0000000000,  0.7360876203,  0.0000000000])\n",
            "ctensor.grad: tensor([ 0.6393859386,  0.6393859386,  0.6393859386, -0.0008395175,\n",
            "         0.0000000000,  0.0115981940,  0.0054121306,  0.0128970649,\n",
            "        -0.0008395175,  0.0000000000,  0.0115981940,  0.0054121306,\n",
            "         0.0128970649, -0.0008395175,  0.0000000000,  0.0115981940,\n",
            "         0.0054121306,  0.0128970649])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.7313728333, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8337838650), tensor(1.7842614651), tensor(1.1098829508), tensor(1.4581370354), tensor(0.8824586272), tensor(0.7318772078), tensor(1.6170159578), tensor(1.1666898727), tensor(1.3428264856), tensor(1.0906112194), tensor(1.0212892294), tensor(1.0950573683), tensor(1.8229906559), tensor(1.2431297302), tensor(1.6461192369), tensor(1.7992011309), tensor(1.6177371740), tensor(1.1291787624), tensor(0.9013122320), tensor(1.0991680622)]\n",
            "b:  [tensor(1.6251909733), tensor(0.7217969894), tensor(1.4579596519), tensor(1.3001476526), tensor(1.0059964657), tensor(2.0076894760), tensor(1.2941752672), tensor(1.3904252052), tensor(1.2781275511), tensor(1.0584294796), tensor(1.3620061874), tensor(1.3116258383), tensor(0.7628588676), tensor(1.2575852871), tensor(1.2350413799), tensor(0.8945925236), tensor(1.0169497728), tensor(1.3954452276), tensor(1.4034885168), tensor(1.5507984161)]\n",
            "c:  [tensor(0.0016927503), tensor(0.0016927503), tensor(0.0016927503), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719), tensor(0.0015424484), tensor(0.0009867213), tensor(0.0013161204), tensor(0.0008752443), tensor(0.0010462719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.3125110865,  1.4042232037, -2.0797314644,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0941413492,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6776755452,  0.0000000000,  0.9014596939,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.1026041582,  0.4056555927,  0.8476464748,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.8851978183,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -3.3163871765,  0.0000000000,  0.7346826792,  0.0000000000])\n",
            "ctensor.grad: tensor([ 0.6402106285,  0.6402106285,  0.6402106285, -0.0008164109,\n",
            "         0.0000000000,  0.0116140898,  0.0054181875,  0.0129065746,\n",
            "        -0.0008164109,  0.0000000000,  0.0116140898,  0.0054181875,\n",
            "         0.0129065746, -0.0008164109,  0.0000000000,  0.0116140898,\n",
            "         0.0054181875,  0.0129065746])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "=============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "Historic Bookies Estimate:\n",
        "==========================\n",
        "\n",
        "The historic bookies estimate for goals landed by team i against team j is\n",
        "\n",
        "a_i b_j\n",
        "\n",
        "where\n",
        "\n",
        "a_i = A_i C^{-1/2}\n",
        "b_j = B_j C^{-1/2}\n",
        "\n",
        "A_i = goals landed per game by team i\n",
        "B_j = goals conceded per game by team j\n",
        "C   = average goals per game of all teams\n",
        "\n",
        "\n",
        "The historic 1980's max likelihood models\n",
        "=========================================\n",
        "\n",
        "Starting with Maher, the 1980's max likelihood model starts with this guess and\n",
        "perfects it by max likelihood, when team i lands k goals agaist team j\n",
        "loss was minus the log of the predicted probability by Poisson\n",
        "\n",
        "- log ( e^{-a_ib_j}(a_ib_j)^k /k!)\n",
        "\n",
        "\n",
        "A gitgub user said chi squared shows HST,AST,HR,AR have a significant effect\n",
        "\n",
        "HST = home shots on target\n",
        "AST = away shots on target\n",
        "HR  = home red cards\n",
        "AR  = away red cards\n",
        "HS  = home shots\n",
        "AS  = away shots\n",
        "HC  = home quarter kicks\n",
        "AC  = away corner kicks\n",
        "HF  = home fouls\n",
        "AF  = away fouls\n",
        "\n",
        "\n",
        "New Cross-entropy AI model with a neural layer\n",
        "==========================================\n",
        "\n",
        "Since gradient descent generalizes max likelihood we can replace a_ib_j by\n",
        "\n",
        "a_i b_j  +  (c_0 sigma ( c_3 HST + c_4 HR +c_5 HS + c_6 HC _c_7 HF)\n",
        "             + ...\n",
        "             +c_2 sigma(c_13 HST + c_14 HR + c_15 HS + c_16 HCC + c_17 HF) )b_j\n",
        "\n",
        "when i is the home team and\n",
        "\n",
        "a_i b_j  +  c_0 sigma ( c_1 AST + c_2 AR  ..... +AF  ) b_j\n",
        "\n",
        "when i is the away team, with sigma being the sigmoid function\n",
        "\n",
        "\n",
        "   sigma(x)=softmax(0,x) = e^x/(e^0+e^x) = 1/(1+e^{-x})\n",
        "\n",
        "\n",
        "\n",
        "This puts a *neural layer* behind the standard max likelihood model from the 1980s\n",
        "\n",
        "The weights are now the a_i,  b_i,   and c_i\n",
        "\n",
        "Since the c_i are shared by all teams the training rate for the c_i should be lower\n",
        "\n",
        "As in the model which this generalizes, the training is cross entropy versus the Poisson distribution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "A comment about the way the databases are stored, variables like HST and AST refer to 'home'\n",
        "and 'away' team but we do not make a distinction between home versus away.\n",
        "\n",
        "This means that each row of a data table is interpreted as if it were two rows,\n",
        "one giving information about team i against team j, the other giving information\n",
        "about team j against team i.\n",
        "\n",
        "For instance to calculate the average goals scored by any team over all games\n",
        "each row gives goals scored by a home team and goals scored by an away team\n",
        "and we have to add 2 to total games.\n",
        "\n",
        "That is when we say total games it really means the sum over all teams\n",
        "of the number of games that team played in, which is twice the number\n",
        "of games.\n",
        "\n",
        "That explains the line  totalgames=totalgames+2 each time a row is read in.\n",
        "\n",
        "There is no need to change this architecture to include things causing a home\n",
        "team advantage. This starts with a constant taking the value 1 in the first line\n",
        "\n",
        "loss -=  ...\n",
        "\n",
        "and taking the value 0 in the second line\n",
        "\n",
        "loss -= ...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "import torch as t\n",
        "import torch.nn as n\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "\n",
        "def sigma(x):\n",
        "  return t.exp(x)/(t.exp(t.tensor(1.0))+t.exp(x))\n",
        "\n",
        "\n",
        "\n",
        "t.set_printoptions(precision=10)\n",
        "#print(\"beep boop\")\n",
        "#print(\"Aston Villa loses\")\n",
        "print(\"=============================================================\")\n",
        "\n",
        "#GITHUB LOCATION:\n",
        "#https://github.com/Pavlos01232/Match_Outcome_Prediction\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#pd.read_csv('https://raw.githubusercontent.com/Pavlos01232/Match_Outcome_Prediction/main/TRAINING%20DATA/PL0304.csv?raw=true')\n",
        "\n",
        "\n",
        "#\"DEEP learning\" just means \"hidden\" layers\n",
        "\n",
        "\n",
        "#df.to_csv(r'C:\\Users\\Pavlos\\Desktop\\export_dataframe.csv', sep='\\t', encoding='utf-8')\n",
        "#print (df[2])\n",
        "#file_list = os.listdir('https://raw.githubusercontent.com/Pavlos01232/Match_Outcome_Prediction/main/TRAINING%20DATA/')\n",
        "#df = pd.read_csv('https://raw.githubusercontent.com/Pavlos01232/Match_Outcome_Prediction/main/TRAINING%20DATA/PL0405.csv?raw=true',sep='\\t', lineterminator='\\r')\n",
        "#print(df)\n",
        "\n",
        "#read function\n",
        "\n",
        "first = \"https://raw.githubusercontent.com/Pavlos01232/Match_Outcome_Prediction/main/TRAINING%20DATA/PL\"\n",
        "last = \".csv?raw=true\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Starting with an array of data frames,\n",
        "and an array of column names, make a\n",
        "single array with the chosen columns\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def combine(dataFrames,columnNames):\n",
        " t=[]\n",
        " for i in range(0,len(dataFrames)):\n",
        "    theseColumns=dataFrames[i].columns.values[0].split(\",\")\n",
        "    for j in range(0 ,len(dataFrames[i])):\n",
        "      row=dataFrames[i].values[j][0].split(\",\")\n",
        "      newEntry=[]\n",
        "      for k in range(0, len(columnNames)):\n",
        "         for m in range(0, len(theseColumns)):\n",
        "             if(columnNames[k]==theseColumns[m] and m<=len(row)):\n",
        "                newEntry.append(row[m])\n",
        "      t.append(newEntry)\n",
        " return t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "can read years 3 to 23, 13*********************, there's something wrong with 14\n",
        "since the first two files in the training data are formatted incorrectly\n",
        "converts csv to dataframe\n",
        "'''\n",
        "\n",
        "df=[]\n",
        "\n",
        "for i in range(23, 24):\n",
        "  result = first + str('{:02.0f}'.format(i)) + str('{:02.0f}'.format(i+1)) + last\n",
        "  x = pd.read_csv(result, sep='\\t', encoding = 'unicode_escape', lineterminator='\\r')\n",
        "  df.append(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Get an array with each (home) team listed once\n",
        "from an array of data frames with column \"HomeTeam\"\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def getTeams(df):\n",
        " teams=[]\n",
        " homeTeams=combine(df,[\"HomeTeam\"])\n",
        " for i in range(len(homeTeams)):\n",
        "  if(len(homeTeams[i])>0):\n",
        "   found=False\n",
        "   for j in range(len(teams)):\n",
        "    if homeTeams[i][0] == teams[j]:\n",
        "      found=True\n",
        "      break\n",
        "   if found:\n",
        "    continue\n",
        "   teams.append(homeTeams[i][0])\n",
        " return teams\n",
        "\n",
        "\n",
        "'''\n",
        "Get the list of teams from the array of data frames called df\n",
        "and print it to the console\n",
        "'''\n",
        "\n",
        "\n",
        "teams=getTeams(df)\n",
        "print(\"\\nteams:\")\n",
        "print(teams)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Create an array called Data with just the team names and scores\n",
        "from the data framees in the array of frames df, and print it\n",
        "\n",
        "The list [\"HomeTeam\",\"AwayTeam\",\"FTHG\",\"FTAG\",\"HST\",\"AST\",\"HR\",\"AR\"] can be\n",
        "made longer if other columnts may be useful to use\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "Data=combine(df, [\"HomeTeam\",\"AwayTeam\",\"FTHG\",\"FTAG\",\"HST\",\"AST\",\"HR\",\"AR\", \"HS\",\"AS\",\"HC\",\"AC\",\"HF\",\"AF\"])\n",
        "print(\"\\n\\ndata: (team names respective goals scored, respective shots on target, respective red cards)\")\n",
        "print(Data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Get the numerical index of a team name x in the array teams\n",
        "otherwise just return x\n",
        "'''\n",
        "\n",
        "def getIndex(x,teams):\n",
        "  for i in range(len(teams)):\n",
        "   if(teams[i]==x):\n",
        "    return i\n",
        "  return x\n",
        "\n",
        "\n",
        "print(\"\\n\\nIndex assigned to Everton:\")\n",
        "print(getIndex(\"Everton\",teams))\n",
        "\n",
        "\n",
        "'''\n",
        "Replace any occurrence of names from the array teams\n",
        "which occur anywhere in A by their actual  numbers\n",
        "'''\n",
        "\n",
        "def teamsToNumbers(A,teams):\n",
        "  B=[]\n",
        "  for i in range(len(A)):\n",
        "    B.append([])\n",
        "    for j in range(len(A[i])):\n",
        "      B[i].append(getIndex(A[i][j],teams))\n",
        "  return B\n",
        "\n",
        "\n",
        "'''\n",
        "Create Data2 which is a copy of Data but with team names\n",
        "replaced by their index\n",
        "'''\n",
        "\n",
        "print(\"\\n\\ndata2, using the team's index number instead of name\")\n",
        "Data2=teamsToNumbers(Data,teams)\n",
        "print(Data2)\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "Assume Data2 has team indices in column 0 and 1 and scores\n",
        "in cols 2 and 3\n",
        "\n",
        "A[i] is array of average goals landed per game by tean i\n",
        "B[i] is array of average goals conceded per game by team i\n",
        "C is total games played by all teams (twide the number of games)\n",
        "games[i]=total games played by team i\n",
        "a[i]*b[j]=first approx of expected goals landed by i when playing\n",
        "    against j\n",
        "'''\n",
        "\n",
        "A=[0]*len(teams)\n",
        "B=[0]*len(teams)\n",
        "games=[0]*len(teams)\n",
        "a=[0]*len(teams)\n",
        "b=[0]*len(teams)\n",
        "C=0\n",
        "totalGames=0\n",
        "\n",
        "for i in range(len(Data2)):\n",
        "  if(len(Data2[i])<2):\n",
        "    continue\n",
        "  games[Data2[i][0]]+=1\n",
        "  games[Data2[i][1]]+=1\n",
        "  A[Data2[i][0]]+=int(Data2[i][2])\n",
        "  B[Data2[i][0]]+=int(Data2[i][3])\n",
        "  A[Data2[i][1]]+=int(Data2[i][3])\n",
        "  B[Data2[i][1]]+=int(Data2[i][2])\n",
        "  C+=int(Data2[i][2])+int(Data2[i][3])\n",
        "  totalGames+=2\n",
        "\n",
        "\n",
        "'''\n",
        "Initial estimates of a,b,c\n",
        "'''\n",
        "\n",
        "for i in range(len(A)):\n",
        "  a[i]=A[i]/games[i]*(C/totalGames)**(-1/2)\n",
        "\n",
        "for i in range(len(B)):\n",
        "  b[i]=B[i]/games[i]*(C/totalGames)**(-1/2)\n",
        "\n",
        "#c is another set of hidden weights for our weightrix. they are initally nonzero to avoid a stationary point.\n",
        "\n",
        "c=[0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "AI training function\n",
        "\n",
        "The training is by gradient descent, the loss\n",
        "function will be cross entropy loss function against Poisson\n",
        "using loss.backward()\n",
        "\n",
        "The hidden weights at the moment are the entries of a,b,c\n",
        "the array c  is shared for all teams.\n",
        "These enter into the calculation of mu (which we\n",
        "call muHome or muAway during training) and are\n",
        "hidden as they have no direct meaning.\n",
        "\n",
        "Thus mu as a function of the entries of a,b,c is\n",
        "learned by training, the weights are the entries\n",
        "of the three arrays.\n",
        "\n",
        "\n",
        "\n",
        "tau is the training rate for c which should be small\n",
        "compared to eta\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "'''\n",
        "flag=0   exclude nothing\n",
        "flag=1   exclude entries of exclusions\n",
        "flag=2   exclude entries not in exclusions\n",
        "'''\n",
        "\n",
        "def elementOf(i,A):\n",
        "  for j in range(len(A)):\n",
        "    if(A[j]==i):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def train(eta,tau,flag,exclusions):\n",
        "  loss=t.tensor(0.0)\n",
        "\n",
        "\n",
        "\n",
        "  atensor=t.tensor(a,requires_grad=True)\n",
        "  btensor=t.tensor(b,requires_grad=True)\n",
        "  ctensor=t.tensor(c,requires_grad=True)\n",
        "\n",
        "\n",
        "  for i in range(len(Data2)):\n",
        "    if(len(Data2[i])==0):\n",
        "      continue\n",
        "    if (flag==1 and elementOf(i,exclusions)):\n",
        "      continue\n",
        "    if (flag==2 and not elementOf(i,exclusions)):\n",
        "      continue\n",
        "    homeTeam=int(Data2[i][0])\n",
        "    awayTeam=int(Data2[i][1])\n",
        "    homeGoals=int(Data2[i][2])\n",
        "    awayGoals=int(Data2[i][3])\n",
        "    HST=t.tensor(float(Data2[i][4]))\n",
        "    AST=t.tensor(float(Data2[i][5]))\n",
        "    HR=t.tensor(float(Data2[i][6]))\n",
        "    AR=t.tensor(float(Data2[i][7]))\n",
        "    HS=t.tensor(float(Data2[i][8]))\n",
        "    AS=t.tensor(float(Data2[i][9]))\n",
        "    HC=t.tensor(float(Data2[i][10]))\n",
        "    AC=t.tensor(float(Data2[i][11]))\n",
        "    HF=t.tensor(float(Data2[i][12]))\n",
        "    AF=t.tensor(float(Data2[i][13]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    The reason there are two lines of code for the loss is that\n",
        "    each game can be thought of as  two 'rows' of data where we label\n",
        "    the home team as team i  or team j.\n",
        "\n",
        "    Thus teams are interpreted symmetrically and there is not yet any\n",
        "    home team advantage but this can be put in\n",
        "    without modifying the architecture as a constant which is 1 in the\n",
        "    first line and 0 in the second\n",
        "    '''\n",
        "\n",
        "\n",
        "    muHome=atensor[homeTeam]*btensor[awayTeam]\n",
        "    neural=ctensor[0]*sigma(ctensor[3]*HST+ctensor[4]*HR+ctensor[5]*HS+ctensor[6]*HC+ctensor[7]*HF)\n",
        "    neural+=ctensor[1]*sigma(ctensor[8]*HST+ctensor[9]*HR+ctensor[10]*HS+ctensor[11]*HC+ctensor[12]*HF)\n",
        "    neural+=ctensor[2]*sigma(ctensor[13]*HST+ctensor[14]*HR+ctensor[15]*HS+ctensor[16]*HC+ctensor[17]*HF)\n",
        "    muHome=muHome+neural*btensor[awayTeam]\n",
        "\n",
        "    muAway=atensor[awayTeam]*btensor[homeTeam]\n",
        "    neural=ctensor[0]*sigma(ctensor[3]*AST+ctensor[4]*AR+ctensor[5]*AS+ctensor[6]*AC+ctensor[7]*AF)\n",
        "    neural+=ctensor[1]*sigma(ctensor[8]*AST+ctensor[9]*AR+ctensor[10]*AS+ctensor[11]*AC+ctensor[12]*AF)\n",
        "    neural+=ctensor[2]*sigma(ctensor[13]*AST+ctensor[14]*AR+ctensor[15]*AS+ctensor[16]*AC+ctensor[17]*AF)\n",
        "    muAway=muAway+neural*btensor[homeTeam]\n",
        "\n",
        "\n",
        "    loss-=t.log(t.exp(-muHome)*t.pow(muHome,homeGoals)/math.factorial(homeGoals))\n",
        "    loss-=t.log(t.exp(-muAway)*t.pow(muAway,awayGoals)/math.factorial(awayGoals))\n",
        "\n",
        "  loss.backward()\n",
        "  for i in range(len(c)):\n",
        "    c[i]=c[i]-tau*ctensor.grad[i]\n",
        "  for i in range(len(a)):\n",
        "    a[i]=a[i]-eta*atensor.grad[i]\n",
        "  for i in range(len(b)):\n",
        "    b[i]=b[i]-eta*btensor.grad[i]\n",
        "  print(\"\\n\\nCross-entropy loss vs Poisson: \"+str(loss))\n",
        "  print(\"\\n\\nWeights:\\n\\na:  \"+str(a))\n",
        "  print(\"b:  \"+str(b))\n",
        "  print(\"c:  \"+str(c))\n",
        "  print(\"\\n\\n\\n\")\n",
        "  print(\"Partial derivatives of loss w/r to hidden weights:\")\n",
        "  print(\"\\natensor.grad: \"+str(atensor.grad))\n",
        "  print(\"btensor.grad: \"+str(btensor.grad))\n",
        "  print(\"ctensor.grad: \"+str(ctensor.grad))\n",
        "  print(\"\\n\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Use weights to construct predicted expected goals scored by i\n",
        "against j and then find probability of k goals scored using\n",
        "Poisson when given values of R S ST  C F are provided\n",
        "'''\n",
        "\n",
        "# non-tensor version of sigma for using in the field\n",
        "\n",
        "def mathsigma(x):\n",
        "  return math.exp(x)/(math.exp(0)+math.exp(x))\n",
        "\n",
        "def goalProb(i,j,k,ST,R,S,C,F):\n",
        "  mu=a[i]*b[j]\n",
        "  mu+=c[0]*mathsigma(c[3]*ST+c[4]*R+c[5]*S+c[6]*C+c[7]*F)\n",
        "  mu+=c[1]*mathsigma(c[8]*ST+c[9]*R+c[10]*S+c[11]*C+c[12]*F)\n",
        "  mu+=c[2]*mathsigma(c[13]*ST+c[14]*R+c[15]*S+c[16]*C+c[17]*F)\n",
        "  return math.exp(-mu)*mu**k/math.factorial(k)\n",
        "\n",
        "'''\n",
        "Test training a bit\n",
        "'''\n",
        "\n",
        "print(\"\\n\\nest probability before training of team 2 landing 5 goals against team 3\\n when team 2 has (ST,R,S,C,F)= (1,0,2,1,3): \"+str(goalProb(2,3,5,1,0,2,1,3)))\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\nexclude [4,5,6] as unseen validation set\")\n",
        "for i in range(40):\n",
        "    train(0.01,0.0001,1, [4,5,6])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\nprobability after training of team 2 landing 5 goals against 3: \"+str(goalProb(2,3,5,1,0,2,1,3)))\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "    VALIDATION TESTS\n",
        "\n",
        "With the hidden weights a,b,c still saved, we run it on unseen  data to see\n",
        "what is the loss,  eta=0, tau=0\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "for i in range(20):\n",
        "  print(\"*************************************************\")\n",
        "print(\"\\n Validation:\\n\")\n",
        "print(\"test unseen validation set using only earlier traning\")\n",
        "for i in range(1):\n",
        "    train(0.,0.,2, [4,5,6])\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "The validation set will be able to reduce its loss\n",
        "if we allow it to train on itself (no longer unseen)\n",
        "but if the reduction is small that is good evidence\n",
        "that the  loss when unseen is still acceptable.\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "#allow validation set to train further on itself\n",
        "\n",
        "for i in range(10):\n",
        "  train(.001,0,2, [4,5,6])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"=============================================================\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yb6-hsGw363e"
      }
    }
  ]
}