{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGHTVzWp7iH/uGFl3bYAKN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavlos01232/Match_Outcome_Prediction/blob/main/game_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzVKKLMBRPxZ",
        "outputId": "7ce85945-0762-4d66-88de-d4882f0714e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6779259443), tensor(1.6929436922), tensor(0.9813713431), tensor(1.3398758173), tensor(0.7445289493), tensor(0.5847272873), tensor(1.4914259911), tensor(1.0363712311), tensor(1.2238916159), tensor(0.9546052814), tensor(0.8837510943), tensor(0.9552081823), tensor(1.7317428589), tensor(1.1219511032), tensor(1.5501300097), tensor(1.7081695795), tensor(1.5249159336), tensor(1.0026907921), tensor(0.7666442394), tensor(0.9758633375)]\n",
            "b:  [tensor(1.4854435921), tensor(0.6656912565), tensor(1.3361417055), tensor(1.1910333633), tensor(0.9229326844), tensor(1.8400034904), tensor(1.1914114952), tensor(1.2779901028), tensor(1.1689035892), tensor(0.9662892222), tensor(1.2492042780), tensor(1.2084680796), tensor(0.7008280754), tensor(1.1523430347), tensor(1.1349291801), tensor(0.8245462775), tensor(0.8999795318), tensor(1.2737905979), tensor(1.2967156172), tensor(1.4180768728)]\n",
            "c:  [tensor(-0.1472055614), tensor(0.2857744992), tensor(0.1792520583), tensor(-0.1398004740), tensor(0.0034083787), tensor(0.0055098454), tensor(0.0795648396), tensor(0.0700552613), tensor(0.6490730047), tensor(-0.0204321276), tensor(0.2498929799), tensor(-0.1023880169), tensor(0.1362037808), tensor(0.5631470680), tensor(-0.0106677301), tensor(0.2849010825), tensor(-0.0646404624), tensor(0.1667820960)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.3538841605, -0.0487251729,  0.2635471225,  0.0062195063,\n",
            "         0.2938597798,  0.3212247193,  0.0220800042,  0.2319134474,\n",
            "         0.0965663195,  0.2534602582,  0.3235648870,  0.2755181789,\n",
            "        -0.1372241378,  0.1929613948,  0.0279714018, -0.0470230021,\n",
            "         0.0315066576,  0.3098523021,  0.3449852467,  0.3162711859])\n",
            "btensor.grad: tensor([ 0.1509415060, -0.1162871718,  0.1119289398, -0.0562841296,\n",
            "         0.0249199867,  0.2065439224, -0.0140363574,  0.0225181133,\n",
            "        -0.0083964467,  0.0185785294,  0.0750330240,  0.0418732762,\n",
            "        -0.0616862439,  0.0318437070, -0.0717959106, -0.1148729324,\n",
            "        -0.0947021246,  0.0419507027,  0.1111106873,  0.0648591518])\n",
            "ctensor.grad: tensor([13.9914569855, -0.8133081198,  0.1235260367, 10.5544052124,\n",
            "        -0.3859849870, -0.1048642322, -5.8986864090, -4.2118372917,\n",
            "         0.7062983513,  0.1828286201,  4.5916681290,  2.4738445282,\n",
            "         5.9908185005,  0.2748178244,  0.0803195983,  1.7361917496,\n",
            "         0.9393373728,  2.3355064392])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(728.3520507812, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6763462424), tensor(1.6930241585), tensor(0.9801741838), tensor(1.3396458626), tensor(0.7432157397), tensor(0.5833869576), tensor(1.4911756516), tensor(1.0352013111), tensor(1.2233572006), tensor(0.9533763528), tensor(0.8822220564), tensor(0.9537423253), tensor(1.7322556973), tensor(1.1210219860), tensor(1.5498948097), tensor(1.7082219124), tensor(1.5246367455), tensor(1.0012863874), tensor(0.7651450634), tensor(0.9745212793)]\n",
            "b:  [tensor(1.4846298695), tensor(0.6663870215), tensor(1.3356324434), tensor(1.1913987398), tensor(0.9229002595), tensor(1.8389444351), tensor(1.1915445328), tensor(1.2780189514), tensor(1.1690014601), tensor(0.9662289023), tensor(1.2489572763), tensor(1.2082835436), tensor(0.7012376785), tensor(1.1522998810), tensor(1.1355342865), tensor(0.8252550364), tensor(0.9005538225), tensor(1.2735807896), tensor(1.2963222265), tensor(1.4177610874)]\n",
            "c:  [tensor(-0.1623284817), tensor(0.2868431807), tensor(0.1792065501), tensor(-0.1512805074), tensor(0.0038345070), tensor(0.0058422619), tensor(0.0860540941), tensor(0.0746335238), tensor(0.6483014822), tensor(-0.0206280723), tensor(0.2448452860), tensor(-0.1050985903), tensor(0.1296428889), tensor(0.5628644228), tensor(-0.0107501261), tensor(0.2831082642), tensor(-0.0656088963), tensor(0.1643719822)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.3159397840, -0.0160821378,  0.2394352555,  0.0459895134,\n",
            "         0.2626405358,  0.2680650949,  0.0500715971,  0.2339855134,\n",
            "         0.1068768054,  0.2457883954,  0.3058107793,  0.2931677699,\n",
            "        -0.1025580168,  0.1858280897,  0.0470449030, -0.0104630440,\n",
            "         0.0558459759,  0.2808914781,  0.2998379469,  0.2684169412])\n",
            "btensor.grad: tensor([ 0.1627436876, -0.1391490996,  0.1018597484, -0.0730737448,\n",
            "         0.0064847469,  0.2118085176, -0.0266078711, -0.0057642758,\n",
            "        -0.0195826292,  0.0120607615,  0.0494018495,  0.0369049907,\n",
            "        -0.0819226950,  0.0086316764, -0.1210120320, -0.1417471170,\n",
            "        -0.1148543954,  0.0419664383,  0.0786716938,  0.0631544590])\n",
            "ctensor.grad: tensor([15.1229190826, -1.0686836243,  0.0455010235, 11.4800367355,\n",
            "        -0.4261282980, -0.3324164152, -6.4892530441, -4.5782656670,\n",
            "         0.7715081573,  0.1959448308,  5.0476946831,  2.7105712891,\n",
            "         6.5608854294,  0.2826176286,  0.0823956728,  1.7928298712,\n",
            "         0.9684309959,  2.4101109505])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(727.8139038086, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6749510765), tensor(1.6929405928), tensor(0.9791014194), tensor(1.3392157555), tensor(0.7420603633), tensor(0.5823101997), tensor(1.4907847643), tensor(1.0340182781), tensor(1.2227741480), tensor(0.9521874189), tensor(0.8807759285), tensor(0.9521778822), tensor(1.7326005697), tensor(1.1201307774), tensor(1.5495675802), tensor(1.7080892324), tensor(1.5242353678), tensor(1.0000267029), tensor(0.7638707757), tensor(0.9734274745)]\n",
            "b:  [tensor(1.4837619066), tensor(0.6672226191), tensor(1.3351852894), tensor(1.1918652058), tensor(0.9229770899), tensor(1.8378636837), tensor(1.1917603016), tensor(1.2782108784), tensor(1.1691749096), tensor(0.9662174582), tensor(1.2488520145), tensor(1.2081362009), tensor(0.7017703652), tensor(1.1523916721), tensor(1.1364122629), tensor(0.8261240721), tensor(0.9012508392), tensor(1.2733863592), tensor(1.2961063385), tensor(1.4174686670)]\n",
            "c:  [tensor(-0.1786516160), tensor(0.2882132828), tensor(0.1792419851), tensor(-0.1637700647), tensor(0.0043031201), tensor(0.0063149151), tensor(0.0931089073), tensor(0.0794718340), tensor(0.6474507451), tensor(-0.0208395310), tensor(0.2392411679), tensor(-0.1080966368), tensor(0.1223936826), tensor(0.5625734329), tensor(-0.0108347628), tensor(0.2812543809), tensor(-0.0666085109), tensor(0.1618818343)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.2790374756,  0.0167047530,  0.2145504653,  0.0860173702,\n",
            "         0.2310734987,  0.2153528482,  0.0781731009,  0.2366055250,\n",
            "         0.1166100353,  0.2377886474,  0.2892234325,  0.3128898144,\n",
            "        -0.0689672232,  0.1782362461,  0.0654566139,  0.0265313368,\n",
            "         0.0802842379,  0.2519432306,  0.2548581362,  0.2187590301])\n",
            "btensor.grad: tensor([ 0.1735846996, -0.1671142727,  0.0894205272, -0.0932824612,\n",
            "        -0.0153710842,  0.2161553502, -0.0431608558, -0.0383791775,\n",
            "        -0.0346835852,  0.0022888184,  0.0210611820,  0.0294613242,\n",
            "        -0.1065382808, -0.0183485448, -0.1756014526, -0.1738068461,\n",
            "        -0.1394075751,  0.0388878584,  0.0431845188,  0.0584938526])\n",
            "ctensor.grad: tensor([16.3231334686, -1.3700952530, -0.0354276597, 12.4895544052,\n",
            "        -0.4686128795, -0.4726530015, -7.0548133850, -4.8383092880,\n",
            "         0.8507638574,  0.2114581913,  5.6041216850,  2.9980454445,\n",
            "         7.2492036819,  0.2909815609,  0.0846366212,  1.8538696766,\n",
            "         0.9996109605,  2.4901497364])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(727.1812744141, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6737303734), tensor(1.6926839352), tensor(0.9781489968), tensor(1.3385734558), tensor(0.7410547733), tensor(0.5814917088), tensor(1.4902459383), tensor(1.0328118801), tensor(1.2221357822), tensor(0.9510310888), tensor(0.8794011474), tensor(0.9504961371), tensor(1.7327733040), tensor(1.1192723513), tensor(1.5491439104), tensor(1.7077610493), tensor(1.5237029791), tensor(0.9989068508), tensor(0.7628166080), tensor(0.9725873470)]\n",
            "b:  [tensor(1.4828346968), tensor(0.6682227850), tensor(1.3348045349), tensor(1.1924443245), tensor(0.9231749177), tensor(1.8367569447), tensor(1.1920716763), tensor(1.2785825729), tensor(1.1694352627), tensor(0.9662631154), tensor(1.2488964796), tensor(1.2080320120), tensor(0.7024444342), tensor(1.1526304483), tensor(1.1375825405), tensor(0.8271802068), tensor(0.9020881057), tensor(1.2732135057), tensor(1.2960771322), tensor(1.4172053337)]\n",
            "c:  [tensor(-0.1962295622), tensor(0.2899318337), tensor(0.1793469936), tensor(-0.1773289442), tensor(0.0048164008), tensor(0.0068615302), tensor(0.1006977484), tensor(0.0844638422), tensor(0.6465017796), tensor(-0.0210695975), tensor(0.2329449654), tensor(-0.1114502326), tensor(0.1142989472), tensor(0.5622734427), tensor(-0.0109218229), tensor(0.2793346047), tensor(-0.0676415637), tensor(0.1593057215)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.2441353202,  0.0513214022,  0.1904875636,  0.1284576654,\n",
            "         0.2011182308,  0.1636927426,  0.1077743769,  0.2412869632,\n",
            "         0.1276653558,  0.2312625945,  0.2749551535,  0.3363491297,\n",
            "        -0.0345584750,  0.1716818213,  0.0847284496,  0.0656290501,\n",
            "         0.1064735651,  0.2239691019,  0.2108281255,  0.1680249572])\n",
            "btensor.grad: tensor([ 0.1854427457, -0.2000337839,  0.0761530399, -0.1158284843,\n",
            "        -0.0395660400,  0.2213480473, -0.0622809529, -0.0743488222,\n",
            "        -0.0520629883, -0.0091369152, -0.0088849962,  0.0208414793,\n",
            "        -0.1348174512, -0.0477570593, -0.2340504676, -0.2112302184,\n",
            "        -0.1674478650,  0.0345630944,  0.0058346987,  0.0526584983])\n",
            "ctensor.grad: tensor([17.5779457092, -1.7185657024, -0.1050117016, 13.5588712692,\n",
            "        -0.5132808089, -0.5466151237, -7.5888409615, -4.9920067787,\n",
            "         0.9489839077,  0.2300658524,  6.2962021828,  3.3535966873,\n",
            "         8.0947360992,  0.2999679148,  0.0870602801,  1.9197760820,\n",
            "         1.0330551863,  2.5761127472])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(726.4391479492, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6726718545), tensor(1.6922378540), tensor(0.9773060679), tensor(1.3376976252), tensor(0.7401818633), tensor(0.5809260011), tensor(1.4895461798), tensor(1.0315657854), tensor(1.2214267254), tensor(0.9498925209), tensor(0.8780823946), tensor(0.9486717582), tensor(1.7327616215), tensor(1.1184353828), tensor(1.5486131907), tensor(1.7072198391), tensor(1.5230236053), tensor(0.9979187846), tensor(0.7619760633), tensor(0.9720044732)]\n",
            "b:  [tensor(1.4818350077), tensor(0.6694155931), tensor(1.3344879150), tensor(1.1931442022), tensor(0.9235023260), tensor(1.8356124163), tensor(1.1924866438), tensor(1.2791479826), tensor(1.1697876453), tensor(0.9663683176), tensor(1.2490950823), tensor(1.2079725266), tensor(0.7032783031), tensor(1.1530237198), tensor(1.1390579939), tensor(0.8284551501), tensor(0.9030807614), tensor(1.2730611563), tensor(1.2962396145), tensor(1.4169696569)]\n",
            "c:  [tensor(-0.2150995433), tensor(0.2920574546), tensor(0.1794989705), tensor(-0.1919848323), tensor(0.0053763893), tensor(0.0074526370), tensor(0.1087866575), tensor(0.0895145535), tensor(0.6454283595), tensor(-0.0213223286), tensor(0.2257688195), tensor(-0.1152528375), tensor(0.1051451862), tensor(0.5619638562), tensor(-0.0110115008), tensor(0.2773438096), tensor(-0.0687103644), tensor(0.1566375643)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.2116998434, 0.0892144740, 0.1685895026, 0.1751767397, 0.1745792031,\n",
            "        0.1131407022, 0.1399582028, 0.2492155433, 0.1418044269, 0.2277106345,\n",
            "        0.2637464404, 0.3648782969, 0.0023412108, 0.1673829556, 0.1061461270,\n",
            "        0.1082466841, 0.1358655691, 0.1976095438, 0.1681038141, 0.1165689826])\n",
            "btensor.grad: tensor([ 0.1999396086, -0.2385669649,  0.0633265972, -0.1399808824,\n",
            "        -0.0654864311,  0.2288999408, -0.0829963088, -0.1130917966,\n",
            "        -0.0704739094, -0.0210441351, -0.0397292674,  0.0118983984,\n",
            "        -0.1667754352, -0.0786527693, -0.2950992882, -0.2549870610,\n",
            "        -0.1985257864,  0.0304788351, -0.0324928761,  0.0471381545])\n",
            "ctensor.grad: tensor([18.8699855804, -2.1256337166, -0.1519803107, 14.6558895111,\n",
            "        -0.5599883795, -0.5911067724, -8.0889081955, -5.0507125854,\n",
            "         1.0733913183,  0.2527309358,  7.1761417389,  3.8026072979,\n",
            "         9.1537647247,  0.3095808327,  0.0896776617,  1.9907863140,\n",
            "         1.0688023567,  2.6681611538])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(725.5682983398, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6717664003), tensor(1.6915811300), tensor(0.9765585065), tensor(1.3365603685), tensor(0.7394191027), tensor(0.5806136727), tensor(1.4886697531), tensor(1.0302616358), tensor(1.2206248045), tensor(0.9487532377), tensor(0.8768049479), tensor(0.9466756582), tensor(1.7325470448), tensor(1.1176058054), tensor(1.5479607582), tensor(1.7064433098), tensor(1.5221762657), tensor(0.9970549941), tensor(0.7613455653), tensor(0.9716855288)]\n",
            "b:  [tensor(1.4807453156), tensor(0.6708387733), tensor(1.3342304230), tensor(1.1939734221), tensor(0.9239693284), tensor(1.8344142437), tensor(1.1930130720), tensor(1.2799226046), tensor(1.1702355146), tensor(0.9665339589), tensor(1.2494533062), tensor(1.2079595327), tensor(0.7042963505), tensor(1.1535786390), tensor(1.1408497095), tensor(0.8299922943), tensor(0.9042465091), tensor(1.2729246616), tensor(1.2965979576), tensor(1.4167563915)]\n",
            "c:  [tensor(-0.2352791727), tensor(0.2946795523), tensor(0.1796708405), tensor(-0.2077329606), tensor(0.0059849774), tensor(0.0080963420), tensor(0.1173385903), tensor(0.0945409983), tensor(0.6441932917), tensor(-0.0216031503), tensor(0.2174445093), tensor(-0.1196364686), tensor(0.0946348384), tensor(0.5616441369), tensor(-0.0111039933), tensor(0.2752769887), tensor(-0.0698170587), tensor(0.1538715959)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.1810877919, 0.1313469559, 0.1495166123, 0.2274622917, 0.1525471807,\n",
            "        0.0624645874, 0.1752779484, 0.2608392835, 0.1603791416, 0.2278608978,\n",
            "        0.2554886937, 0.3992140889, 0.0429173112, 0.1659272909, 0.1304895878,\n",
            "        0.1553096175, 0.1694749594, 0.1727638245, 0.1260961294, 0.0637896657])\n",
            "btensor.grad: tensor([ 0.2179480195, -0.2846361399,  0.0515022278, -0.1658455729,\n",
            "        -0.0934040546,  0.2396445870, -0.1052876115, -0.1549295783,\n",
            "        -0.0895676017, -0.0331282616, -0.0716555715,  0.0026032329,\n",
            "        -0.2036124468, -0.1109870970, -0.3583407700, -0.3074254394,\n",
            "        -0.2331451178,  0.0272995532, -0.0716691017,  0.0426440239])\n",
            "ctensor.grad: tensor([20.1796360016, -2.6220996380, -0.1718641222, 15.7481327057,\n",
            "        -0.6085879803, -0.6437047720, -8.5519351959, -5.0264420509,\n",
            "         1.2350441217,  0.2808224261,  8.3243141174,  4.3836283684,\n",
            "        10.5103464127,  0.3197378516,  0.0924921855,  2.0668082237,\n",
            "         1.1066944599,  2.7659611702])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(724.5449218750, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6710161567), tensor(1.6906901598), tensor(0.9758933783), tensor(1.3351302147), tensor(0.7387430668), tensor(0.5805712342), tensor(1.4876010418), tensor(1.0288830996), tensor(1.2197031975), tensor(0.9475957751), tensor(0.8755599856), tensor(0.9444780946), tensor(1.7321079969), tensor(1.1167701483), tensor(1.5471706390), tensor(1.7054069042), tensor(1.5211368799), tensor(0.9963131547), tensor(0.7609311342), tensor(0.9716469646)]\n",
            "b:  [tensor(1.4795477390), tensor(0.6725482345), tensor(1.3340284824), tensor(1.1949465275), tensor(0.9245927930), tensor(1.8331458569), tensor(1.1936655045), tensor(1.2809296846), tensor(1.1707863808), tensor(0.9667642713), tensor(1.2499835491), tensor(1.2080003023), tensor(0.7055368423), tensor(1.1543080807), tensor(1.1429722309), tensor(0.8318567276), tensor(0.9056120515), tensor(1.2728012800), tensor(1.2971609831), tensor(1.4165618420)]\n",
            "c:  [tensor(-0.2567634881), tensor(0.2979482710), tensor(0.1798394471), tensor(-0.2245405614), tensor(0.0066438657), tensor(0.0088269422), tensor(0.1263082027), tensor(0.0994635671), tensor(0.6427416801), tensor(-0.0219194833), tensor(0.2075745314), tensor(-0.1247939393), tensor(0.0823402926), tensor(0.5613139272), tensor(-0.0111994939), tensor(0.2731297016), tensor(-0.0709633529), tensor(0.1510030925)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.1500509381, 0.1781939715, 0.1330299675, 0.2860237360, 0.1352052689,\n",
            "        0.0084928628, 0.2137537599, 0.2756966352, 0.1843260825, 0.2314932644,\n",
            "        0.2489960194, 0.4395080805, 0.0878019333, 0.1671229005, 0.1580136716,\n",
            "        0.2072740942, 0.2078869343, 0.1483672857, 0.0828824639, 0.0077078044])\n",
            "btensor.grad: tensor([ 0.2395129949, -0.3418900371,  0.0403875709, -0.1946303844,\n",
            "        -0.1246953011,  0.2536782324, -0.1304781437, -0.2014251798,\n",
            "        -0.1101684570, -0.0460683107, -0.1060434580, -0.0081481338,\n",
            "        -0.2480977625, -0.1458954811, -0.4245015681, -0.3728861213,\n",
            "        -0.2731073499,  0.0246689320, -0.1126151085,  0.0389170051])\n",
            "ctensor.grad: tensor([21.4843215942, -3.2687046528, -0.1686041057, 16.8075923920,\n",
            "        -0.6588881612, -0.7305998206, -8.9696083069, -4.9225673676,\n",
            "         1.4516054392,  0.3163338304,  9.8699798584,  5.1574697495,\n",
            "        12.2945480347,  0.3302270174,  0.0955005139,  2.1472904682,\n",
            "         1.1462934017,  2.8685023785])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(723.3301391602, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6704465151), tensor(1.6895403862), tensor(0.9753040671), tensor(1.3333740234), tensor(0.7381333113), tensor(0.5808458328), tensor(1.4863259792), tensor(1.0274215937), tensor(1.2186310291), tensor(0.9464084506), tensor(0.8743511438), tensor(0.9420502782), tensor(1.7314214706), tensor(1.1159206629), tensor(1.5462276936), tensor(1.7040849924), tensor(1.5198794603), tensor(0.9957026839), tensor(0.7607579231), tensor(0.9719252586)]\n",
            "b:  [tensor(1.4782276154), tensor(0.6746309996), tensor(1.3338840008), tensor(1.1960912943), tensor(0.9254033566), tensor(1.8317929506), tensor(1.1944735050), tensor(1.2822080851), tensor(1.1714587212), tensor(0.9670716524), tensor(1.2507128716), tensor(1.2081137896), tensor(0.7070627809), tensor(1.1552379131), tensor(1.1454515457), tensor(0.8341511488), tensor(0.9072223306), tensor(1.2726948261), tensor(1.2979485989), tensor(1.4163882732)]\n",
            "c:  [tensor(-0.2795197964), tensor(0.3021228015), tensor(0.1799945533), tensor(-0.2423510849), tensor(0.0073544821), tensor(0.0096918093), tensor(0.1356345862), tensor(0.1041933224), tensor(0.6409890056), tensor(-0.0222816989), tensor(0.1955434382), tensor(-0.1310180277), tensor(0.0676256120), tensor(0.5609732866), tensor(-0.0112981871), tensor(0.2708986998), tensor(-0.0721500739), tensor(0.1480293870)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.1139324903,  0.2299529463,  0.1178646982,  0.3512492776,\n",
            "         0.1219492555, -0.0549226254,  0.2550147772,  0.2922958136,\n",
            "         0.2144271284,  0.2374651134,  0.2417676151,  0.4855638742,\n",
            "         0.1373062730,  0.1698916554,  0.1885944307,  0.2643882930,\n",
            "         0.2514777184,  0.1220988631,  0.0346422195, -0.0556644499])\n",
            "btensor.grad: tensor([ 0.2640349269, -0.4165542722,  0.0288848877, -0.2289611697,\n",
            "        -0.1621086597,  0.2705834508, -0.1616089940, -0.2556777000,\n",
            "        -0.1344752312, -0.0614718199, -0.1458536088, -0.0227051377,\n",
            "        -0.3051863313, -0.1859734505, -0.4958592653, -0.4588817954,\n",
            "        -0.3220520020,  0.0212859511, -0.1575177908,  0.0347164869])\n",
            "ctensor.grad: tensor([22.7563209534, -4.1745409966, -0.1550995708, 17.8105239868,\n",
            "        -0.7106164098, -0.8648669720, -9.3263883591, -4.7297520638,\n",
            "         1.7527010441,  0.3622162342, 12.0310983658,  6.2240886688,\n",
            "        14.7146816254,  0.3406410217,  0.0986932442,  2.2310149670,\n",
            "         1.1867216825,  2.9737062454])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(721.8624877930, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6701312661), tensor(1.6881073713), tensor(0.9748002291), tensor(1.3312569857), tensor(0.7375781536), tensor(0.5815460086), tensor(1.4848352671), tensor(1.0258846283), tensor(1.2173739672), tensor(0.9451920390), tensor(0.8732066751), tensor(0.9393659234), tensor(1.7304638624), tensor(1.1150625944), tensor(1.5451190472), tensor(1.7024503946), tensor(1.5183768272), tensor(0.9952569604), tensor(0.7608898282), tensor(0.9725964069)]\n",
            "b:  [tensor(1.4767768383), tensor(0.6772295237), tensor(1.3338108063), tensor(1.1974618435), tensor(0.9264585972), tensor(1.8303457499), tensor(1.1954978704), tensor(1.2838255167), tensor(1.1722940207), tensor(0.9674833417), tensor(1.2516984940), tensor(1.2083415985), tensor(0.7089828849), tensor(1.1564208269), tensor(1.1483412981), tensor(0.8370459080), tensor(0.9091585875), tensor(1.2726230621), tensor(1.2990040779), tensor(1.4162515402)]\n",
            "c:  [tensor(-0.3034777939), tensor(0.3076625466), tensor(0.1801544428), tensor(-0.2610863149), tensor(0.0081178136), tensor(0.0107390974), tensor(0.1452312171), tensor(0.1086108685), tensor(0.6387988925), tensor(-0.0227044839), tensor(0.1803511679), tensor(-0.1387711912), tensor(0.0495138392), tensor(0.5606231093), tensor(-0.0114002386), tensor(0.2685832977), tensor(-0.0733763054), tensor(0.1449520439)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0630443096,  0.2866120934,  0.1007683575,  0.4234107137,\n",
            "         0.1110298634, -0.1400400400,  0.2981515527,  0.3073998094,\n",
            "         0.2514238358,  0.2432790697,  0.2288924754,  0.5368669629,\n",
            "         0.1915121078,  0.1716071367,  0.2217202485,  0.3269304335,\n",
            "         0.3005272150,  0.0891392231, -0.0263856649, -0.1342349946])\n",
            "btensor.grad: tensor([ 0.2901651561, -0.5197008848,  0.0146274269, -0.2741132379,\n",
            "        -0.2110457420,  0.2894372344, -0.2048655152, -0.3234825730,\n",
            "        -0.1670581698, -0.0823435783, -0.1971359849, -0.0455705523,\n",
            "        -0.3840181828, -0.2365945876, -0.5779503584, -0.5789550543,\n",
            "        -0.3872538209,  0.0143444240, -0.2110963464,  0.0273377299])\n",
            "ctensor.grad: tensor([23.9580059052, -5.5397424698, -0.1598954201, 18.7352333069,\n",
            "        -0.7633319497, -1.0472884178, -9.5966358185, -4.4175496101,\n",
            "         2.1900994778,  0.4227846265, 15.1922740936,  7.7531614304,\n",
            "        18.1117744446,  0.3501685262,  0.1020511165,  2.3154010773,\n",
            "         1.2262334824,  3.0773401260])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(720.0198974609, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6702585220), tensor(1.6863708496), tensor(0.9744361043), tensor(1.3287457228), tensor(0.7370909452), tensor(0.5829179883), tensor(1.4831317663), tensor(1.0243175030), tensor(1.2158972025), tensor(0.9439772964), tensor(0.8722094893), tensor(0.9364071488), tensor(1.7292150259), tensor(1.1142355204), tensor(1.5438407660), tensor(1.7004748583), tensor(1.5166029930), tensor(0.9950681925), tensor(0.7614833713), tensor(0.9738235474)]\n",
            "b:  [tensor(1.4752045870), tensor(0.6805936694), tensor(1.3338518143), tensor(1.1991724968), tensor(0.9278790355), tensor(1.8288071156), tensor(1.1968668699), tensor(1.2859101295), tensor(1.1733850241), tensor(0.9680615067), tensor(1.2530671358), tensor(1.2087738514), tensor(0.7114998102), tensor(1.1579730511), tensor(1.1517705917), tensor(0.8408430219), tensor(0.9115830660), tensor(1.2726383209), tensor(1.3004289865), tensor(1.4161996841)]\n",
            "c:  [tensor(-0.3285072744), tensor(0.3154190481), tensor(0.1804081649), tensor(-0.2806491852), tensor(0.0089339456), tensor(0.0119918324), tensor(0.1549619585), tensor(0.1125079021), tensor(0.6359437108), tensor(-0.0232082382), tensor(0.1603001505), tensor(-0.1488049626), tensor(0.0264840461), tensor(0.5602660775), tensor(-0.0115057705), tensor(0.2661887109), tensor(-0.0746373236), tensor(0.1417819560)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.0254535675,  0.3472979665,  0.0728207827,  0.5022602081,\n",
            "         0.0974414349, -0.2743968964,  0.3406923115,  0.3134268820,\n",
            "         0.2953594029,  0.2429426610,  0.1994351745,  0.5917561054,\n",
            "         0.2497695088,  0.1654260755,  0.2556529939,  0.3951063156,\n",
            "         0.3547562361,  0.0377530456, -0.1187107563, -0.2454236746])\n",
            "btensor.grad: tensor([ 0.3144385815, -0.6728316545, -0.0082113445, -0.3421373069,\n",
            "        -0.2840932608,  0.3077161610, -0.2737972140, -0.4169269204,\n",
            "        -0.2182052732, -0.1156374216, -0.2737389803, -0.0864488482,\n",
            "        -0.5033895373, -0.3104553223, -0.6858483553, -0.7594249845,\n",
            "        -0.4848980904, -0.0030564666, -0.2849745154,  0.0103802681])\n",
            "ctensor.grad: tensor([25.0294818878, -7.7565135956, -0.2537276149, 19.5628623962,\n",
            "        -0.8161323071, -1.2527351379, -9.7307376862, -3.8970301151,\n",
            "         2.8551533222,  0.5037551522, 20.0510139465, 10.0337762833,\n",
            "        23.0297927856,  0.3570248485,  0.1055315956,  2.3946008682,\n",
            "         1.2610157728,  3.1700928211])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(717.5466918945, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6713179350), tensor(1.6843365431), tensor(0.9744008183), tensor(1.3258217573), tensor(0.7367637157), tensor(0.5855544806), tensor(1.4812592268), tensor(1.0228646994), tensor(1.2141876221), tensor(0.9428786039), tensor(0.8715839982), tensor(0.9331886768), tensor(1.7276744843), tensor(1.1135787964), tensor(1.5424206257), tensor(1.6981375217), tensor(1.5145497322), tensor(0.9953953028), tensor(0.7629547715), tensor(0.9759838581)]\n",
            "b:  [tensor(1.4735760689), tensor(0.6851967573), tensor(1.3341349363), tensor(1.2014937401), tensor(0.9299581051), tensor(1.8272265196), tensor(1.1988681555), tensor(1.2887334824), tensor(1.1749529839), tensor(0.9689686894), tensor(1.2551190853), tensor(1.2096204758), tensor(0.7150293589), tensor(1.1601827145), tensor(1.1560994387), tensor(0.8461115956), tensor(0.9148559570), tensor(1.2728935480), tensor(1.3024884462), tensor(1.4163665771)]\n",
            "c:  [tensor(-0.3543586731), tensor(0.3270548880), tensor(0.1810468584), tensor(-0.3009402752), tensor(0.0098006232), tensor(0.0133502427), tensor(0.1645638198), tensor(0.1153939888), tensor(0.6320585608), tensor(-0.0238181129), tensor(0.1325055808), tensor(-0.1623084992), tensor(-0.0036610980), tensor(0.5599091649), tensor(-0.0116148060), tensor(0.2637342215), tensor(-0.0759194493), tensor(0.1385519356)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.2118796706,  0.4068533182,  0.0070575476,  0.5847822428,\n",
            "         0.0654400587, -0.5272926688,  0.3745065331,  0.2905602157,\n",
            "         0.3419059813,  0.2197415829,  0.1251024306,  0.6436967850,\n",
            "         0.3081188202,  0.1313522458,  0.2840214968,  0.4674651623,\n",
            "         0.4106475115, -0.0654219389, -0.2942803502, -0.4320612848])\n",
            "btensor.grad: tensor([ 0.3257131279, -0.9206188321, -0.0566281378, -0.4642539620,\n",
            "        -0.4158124924,  0.3161292672, -0.4002459049, -0.5646747351,\n",
            "        -0.3135824800, -0.1814327240, -0.4103783369, -0.1693223715,\n",
            "        -0.7059073448, -0.4419271350, -0.8657699823, -1.0537123680,\n",
            "        -0.6545745134, -0.0510543287, -0.4118894339, -0.0333709717])\n",
            "ctensor.grad: tensor([ 25.8514118195, -11.6358499527,  -0.6387006044,  20.2910919189,\n",
            "         -0.8666779399,  -1.3584105968,  -9.6018619537,  -2.8860890865,\n",
            "          3.8851289749,   0.6098744869,  27.7945652008,  13.5035419464,\n",
            "         30.1451435089,   0.3569301367,   0.1090356633,   2.4544928074,\n",
            "          1.2821242809,   3.2300260067])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(713.8996582031, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6746325493), tensor(1.6821365356), tensor(0.9753178954), tensor(1.3225498199), tensor(0.7369598746), tensor(0.5909667611), tensor(1.4794079065), tensor(1.0219453573), tensor(1.2123695612), tensor(0.9422755837), tensor(0.8719692826), tensor(0.9298672080), tensor(1.7259327173), tensor(1.1135661602), tensor(1.5410097837), tensor(1.6954840422), tensor(1.5123072863), tensor(0.9970325828), tensor(0.7665386796), tensor(0.9800186753)]\n",
            "b:  [tensor(1.4721674919), tensor(0.6919780374), tensor(1.3350695372), tensor(1.2051318884), tensor(0.9335135818), tensor(1.8258476257), tensor(1.2021639347), tensor(1.2929359674), tensor(1.1775536537), tensor(0.9707098007), tensor(1.2586004734), tensor(1.2114229202), tensor(0.7204846144), tensor(1.1638466120), tensor(1.1624387503), tensor(0.8539270759), tensor(0.9198391438), tensor(1.2738656998), tensor(1.3059542179), tensor(1.4171326160)]\n",
            "c:  [tensor(-0.3804996014), tensor(0.3458113968), tensor(0.1830012798), tensor(-0.3219603300), tensor(0.0107085444), tensor(0.0141484449), tensor(0.1733590513), tensor(0.1158086807), tensor(0.6268609166), tensor(-0.0245534629), tensor(0.0932219326), tensor(-0.1806134880), tensor(-0.0424164757), tensor(0.5595700145), tensor(-0.0117271747), tensor(0.2612739205), tensor(-0.0771879032), tensor(0.1353464425)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.6629237533,  0.4400044978, -0.1834209263,  0.6543889642,\n",
            "        -0.0392272472, -1.0824589729,  0.3702706397,  0.1838620901,\n",
            "         0.3636111021,  0.1206052303, -0.0770547986,  0.6642917395,\n",
            "         0.3483622074,  0.0025350451,  0.2821572423,  0.5306995511,\n",
            "         0.4484918118, -0.3274573386, -0.7167817354, -0.8069592714])\n",
            "btensor.grad: tensor([ 0.2817144692, -1.3562614918, -0.1869291365, -0.7276301384,\n",
            "        -0.7110942602,  0.2757791877, -0.6591587663, -0.8405086398,\n",
            "        -0.5201391578, -0.3482205868, -0.6962760687, -0.3604848683,\n",
            "        -1.0910514593, -0.7327711582, -1.2678720951, -1.5630968809,\n",
            "        -0.9966374636, -0.1944307387, -0.6931532025, -0.1532042027])\n",
            "ctensor.grad: tensor([ 26.1409187317, -18.7564945221,  -1.9544233084,  21.0200576782,\n",
            "         -0.9079207778,  -0.7982020378,  -8.7952337265,  -0.4146941304,\n",
            "          5.1976714134,   0.7353507280,  39.2836456299,  18.3049831390,\n",
            "         38.7553787231,   0.3391296864,   0.1123687252,   2.4602966309,\n",
            "          1.2684564590,   3.2054901123])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(708.4287719727, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6833125353), tensor(1.6803548336), tensor(0.9792231917), tensor(1.3192991018), tensor(0.7389825583), tensor(0.6025108099), tensor(1.4782382250), tensor(1.0226343870), tensor(1.2112095356), tensor(0.9433201551), tensor(0.8751419783), tensor(0.9271869659), tensor(1.7243705988), tensor(1.1157423258), tensor(1.5401872396), tensor(1.6929161549), tensor(1.5103743076), tensor(1.0023165941), tensor(0.7755526304), tensor(0.9881514311)]\n",
            "b:  [tensor(1.4719980955), tensor(0.7025712132), tensor(1.3379125595), tensor(1.2118234634), tensor(0.9406754375), tensor(1.8256258965), tensor(1.2080779076), tensor(1.2999058962), tensor(1.1824253798), tensor(0.9748647213), tensor(1.2652386427), tensor(1.2156134844), tensor(0.7295601368), tensor(1.1710156202), tensor(1.1736891270), tensor(0.8657894731), tensor(0.9283767343), tensor(1.2768996954), tensor(1.3128885031), tensor(1.4194269180)]\n",
            "c:  [tensor(-0.4058629870), tensor(0.3759305179), tensor(0.1890013665), tensor(-0.3442378640), tensor(0.0116295731), tensor(0.0115365684), tensor(0.1793601364), tensor(0.1094239876), tensor(0.6230025291), tensor(-0.0253755078), tensor(0.0484186783), tensor(-0.2006554455), tensor(-0.0790763348), tensor(0.5592873693), tensor(-0.0118427146), tensor(0.2589232624), tensor(-0.0783743635), tensor(0.1323299110)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.7359920740,  0.3563482165, -0.7810630798,  0.6501478553,\n",
            "        -0.4045380354, -2.3088157177,  0.2339329720, -0.1378174722,\n",
            "         0.2320134342, -0.2089149207, -0.6345421672,  0.5360476971,\n",
            "         0.3124221265, -0.4352223873,  0.1644994766,  0.5135834813,\n",
            "         0.3866075277, -1.0567936897, -1.8027939796, -1.6265472174])\n",
            "btensor.grad: tensor([ 0.0338791683, -2.1186337471, -0.5685967207, -1.3383239508,\n",
            "        -1.4323689938,  0.0443486124, -1.1827864647, -1.3939863443,\n",
            "        -0.9743373990, -0.8309891224, -1.3276234865, -0.8381087780,\n",
            "        -1.8151059151, -1.4337968826, -2.2500681877, -2.3724801540,\n",
            "        -1.7075140476, -0.6068022251, -1.3868507147, -0.4588719606])\n",
            "ctensor.grad: tensor([ 25.3633899689, -30.1191101074,  -6.0000805855,  22.2775478363,\n",
            "         -0.9210290313,   2.6118762493,  -6.0010781288,   6.3846917152,\n",
            "          3.8584113121,   0.8220441341,  44.8032531738,  20.0419578552,\n",
            "         36.6598548889,   0.2826446295,   0.1155398637,   2.3506634235,\n",
            "          1.1864621639,   3.0165379047])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(703.0974731445, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6982465982), tensor(1.6791942120), tensor(0.9879454374), tensor(1.3159726858), tensor(0.7442921996), tensor(0.6205039024), tensor(1.4782063961), tensor(1.0254350901), tensor(1.2115854025), tensor(0.9465687275), tensor(0.8822612166), tensor(0.9261255264), tensor(1.7229253054), tensor(1.1210527420), tensor(1.5404427052), tensor(1.6907590628), tensor(1.5091563463), tensor(1.0128065348), tensor(0.7912889123), tensor(1.0013061762)]\n",
            "b:  [tensor(1.4737504721), tensor(0.7164271474), tensor(1.3434636593), tensor(1.2222653627), tensor(0.9523645639), tensor(1.8273423910), tensor(1.2165083885), tensor(1.3098661900), tensor(1.1898366213), tensor(0.9825936556), tensor(1.2756071091), tensor(1.2228838205), tensor(0.7415630817), tensor(1.1823685169), tensor(1.1902881861), tensor(0.8803049922), tensor(0.9406174421), tensor(1.2824710608), tensor(1.3241590261), tensor(1.4234052896)]\n",
            "c:  [tensor(-0.4301478863), tensor(0.4120742083), tensor(0.2005441636), tensor(-0.3665152192), tensor(0.0125632593), tensor(0.0071090669), tensor(0.1822972149), tensor(0.0967837870), tensor(0.6307659745), tensor(-0.0260866284), tensor(0.0331029370), tensor(-0.2080155462), tensor(-0.0821367428), tensor(0.5590691566), tensor(-0.0119641824), tensor(0.2566661239), tensor(-0.0794885159), tensor(0.1294547170)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-2.9868142605,  0.2321160734, -1.7444499731,  0.6652796865,\n",
            "        -1.0619225502, -3.5986187458,  0.0063672662, -0.5601371527,\n",
            "        -0.0751616657, -0.6497158408, -1.4238439798,  0.2122836113,\n",
            "         0.2890640497, -1.0620737076, -0.0510985851,  0.4314223826,\n",
            "         0.2435956001, -2.0979878902, -3.1472532749, -2.6309378147])\n",
            "btensor.grad: tensor([-0.3504855931, -2.7711904049, -1.1102255583, -2.0883889198,\n",
            "        -2.3378288746, -0.3432987928, -1.6860985756, -1.9920700788,\n",
            "        -1.4822529554, -1.5457900763, -2.0736980438, -1.4540688992,\n",
            "        -2.4005844593, -2.2705793381, -3.3198184967, -2.9031038284,\n",
            "        -2.4481463432, -1.1142721176, -2.2540938854, -0.7956846356])\n",
            "ctensor.grad: tensor([ 24.2848854065, -36.1436805725, -11.5427904129,  22.2773494720,\n",
            "         -0.9336866140,   4.4275012016,  -2.9370753765,  12.6401958466,\n",
            "         -7.7634692192,   0.7111214399,  15.3157415390,   7.3601069450,\n",
            "          3.0604050159,   0.2182353288,   0.1214673221,   2.2571313381,\n",
            "          1.1141548157,   2.8751978874])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(699.9129028320, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7064105868), tensor(1.6750864983), tensor(0.9924358130), tensor(1.3088318110), tensor(0.7435928583), tensor(0.6301600337), tensor(1.4750701189), tensor(1.0243217945), tensor(1.2078042030), tensor(0.9451510906), tensor(0.8846679926), tensor(0.9212716222), tensor(1.7182185650), tensor(1.1220914125), tensor(1.5374857187), tensor(1.6858680248), tensor(1.5048148632), tensor(1.0186223984), tensor(0.8011488914), tensor(1.0097322464)]\n",
            "b:  [tensor(1.4715111256), tensor(0.7252694368), tensor(1.3449846506), tensor(1.2281748056), tensor(0.9600573182), tensor(1.8253322840), tensor(1.2204406261), tensor(1.3157032728), tensor(1.1927453279), tensor(0.9861361384), tensor(1.2819170952), tensor(1.2262153625), tensor(0.7485290170), tensor(1.1895017624), tensor(1.2022018433), tensor(0.8902980089), tensor(0.9481379986), tensor(1.2837064266), tensor(1.3314819336), tensor(1.4231945276)]\n",
            "c:  [tensor(-0.4523708820), tensor(0.4461785555), tensor(0.2035051286), tensor(-0.3766519427), tensor(0.0136992168), tensor(0.0356021971), tensor(0.1973246783), tensor(0.1125673726), tensor(0.6368378997), tensor(-0.0269113742), tensor(0.0112587903), tensor(-0.2178658843), tensor(-0.0912354067), tensor(0.5587505698), tensor(-0.0121007115), tensor(0.2539335787), tensor(-0.0808230937), tensor(0.1259451956)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.6328003407,  0.8215309381, -0.8980760574,  1.4281785488,\n",
            "         0.1398625374, -1.9312286377,  0.6272595525,  0.2226698101,\n",
            "         0.7562368512,  0.2835317254, -0.4813548923,  0.9707852602,\n",
            "         0.9413458109, -0.2077314854,  0.5913900733,  0.9782091379,\n",
            "         0.8683052063, -1.1631622314, -1.9719903469, -1.6852232218])\n",
            "btensor.grad: tensor([ 0.4478577375, -1.7684519291, -0.3041885197, -1.1818971634,\n",
            "        -1.5385565758,  0.4020147622, -0.7864449620, -1.1674053669,\n",
            "        -0.5817307234, -0.7084963322, -1.2619876862, -0.6663173437,\n",
            "        -1.3931894302, -1.4266431332, -2.3827280998, -1.9986094236,\n",
            "        -1.5041103363, -0.2470832765, -1.4645909071,  0.0421577096])\n",
            "ctensor.grad: tensor([ 22.2230091095, -34.1043586731,  -2.9609634876,  10.1367158890,\n",
            "         -1.1359574795, -28.4931278229, -15.0274696350, -15.7835836411,\n",
            "         -6.0719213486,   0.8247461915,  21.8441448212,   9.8503322601,\n",
            "          9.0986652374,   0.3186039031,   0.1365291178,   2.7325327396,\n",
            "          1.3345777988,   3.5095243454])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(698.2606201172, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7288382649), tensor(1.6762313843), tensor(1.0074189901), tensor(1.3073823452), tensor(0.7589761019), tensor(0.6557968259), tensor(1.4775104523), tensor(1.0321414471), tensor(1.2120268345), tensor(0.9552671909), tensor(0.8978923559), tensor(0.9248380661), tensor(1.7190090418), tensor(1.1315914392), tensor(1.5413857698), tensor(1.6859272718), tensor(1.5064485073), tensor(1.0355640650), tensor(0.8235682249), tensor(1.0297490358)]\n",
            "b:  [tensor(1.4777445793), tensor(0.7411808372), tensor(1.3562246561), tensor(1.2435735464), tensor(0.9768821597), tensor(1.8326338530), tensor(1.2326573133), tensor(1.3310296535), tensor(1.2051030397), tensor(1.0009055138), tensor(1.2977460623), tensor(1.2372384071), tensor(0.7632954717), tensor(1.2060004473), tensor(1.2237389088), tensor(0.9061907530), tensor(0.9640173316), tensor(1.2950060368), tensor(1.3481996059), tensor(1.4329998493)]\n",
            "c:  [tensor(-0.4739545286), tensor(0.4787256420), tensor(0.2250190824), tensor(-0.4153358936), tensor(0.0145587157), tensor(-0.0158627443), tensor(0.1794884801), tensor(0.0623392388), tensor(0.6642177701), tensor(-0.0274760537), tensor(0.0498834774), tensor(-0.2024700791), tensor(-0.0479270555), tensor(0.5586050749), tensor(-0.0122396778), tensor(0.2516379356), tensor(-0.0818997696), tensor(0.1229998320)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-4.4855375290, -0.2289759368, -2.9966251850,  0.2898855209,\n",
            "        -3.0766541958, -5.1273550987, -0.4880722165, -1.5639255047,\n",
            "        -0.8445271254, -2.0232205391, -2.6448712349, -0.7132927179,\n",
            "        -0.1581022143, -1.8999943733, -0.7800070643, -0.0118601210,\n",
            "        -0.3267372251, -3.3883352280, -4.4838714600, -4.0033464432])\n",
            "btensor.grad: tensor([-1.2466973066, -3.1822845936, -2.2480061054, -3.0797519684,\n",
            "        -3.3649666309, -1.4603239298, -2.4433310032, -3.0652821064,\n",
            "        -2.4715502262, -2.9538679123, -3.1657819748, -2.2046053410,\n",
            "        -2.9532940388, -3.2997477055, -4.3074240685, -3.1785507202,\n",
            "        -3.1758623123, -2.2599117756, -3.3435380459, -1.9610760212])\n",
            "ctensor.grad: tensor([ 21.5836582184, -32.5470733643, -21.5139579773,  38.6839332581,\n",
            "         -0.8594993353,  51.4649391174,  17.8361911774,  50.2281303406,\n",
            "        -27.3798522949,   0.5646785498, -38.6246871948, -15.3957996368,\n",
            "        -43.3083496094,   0.1455199420,   0.1389667243,   2.2956571579,\n",
            "          1.0766792297,   2.9453637600])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(707.5074462891, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7068747878), tensor(1.6600755453), tensor(0.9893190861), tensor(1.2869869471), tensor(0.7318913937), tensor(0.6325657964), tensor(1.4609595537), tensor(1.0131433010), tensor(1.1909254789), tensor(0.9332422018), tensor(0.8778496981), tensor(0.9029632211), tensor(1.7022020817), tensor(1.1126966476), tensor(1.5241000652), tensor(1.6698600054), tensor(1.4891109467), tensor(1.0172380209), tensor(0.8051925302), tensor(1.0140398741)]\n",
            "b:  [tensor(1.4557129145), tensor(0.7264962196), tensor(1.3359028101), tensor(1.2247493267), tensor(0.9600677490), tensor(1.8108701706), tensor(1.2149524689), tensor(1.3145939112), tensor(1.1848909855), tensor(0.9793364406), tensor(1.2806071043), tensor(1.2196298838), tensor(0.7468191981), tensor(1.1886868477), tensor(1.2083129883), tensor(0.8957188129), tensor(0.9469211102), tensor(1.2737680674), tensor(1.3316863775), tensor(1.4120894670)]\n",
            "c:  [tensor(-0.4702148438), tensor(0.4950764179), tensor(0.1898107231), tensor(-0.3917641938), tensor(0.0161325671), tensor(0.1073887944), tensor(0.2360336334), tensor(0.1704625338), tensor(0.6380420327), tensor(-0.0290490538), tensor(-0.0743952617), tensor(-0.2569191456), tensor(-0.1568651944), tensor(0.5577109456), tensor(-0.0124225384), tensor(0.2466952950), tensor(-0.0843340680), tensor(0.1165773124)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([4.3927001953, 3.2311768532, 3.6199800968, 4.0790801048, 5.4169445038,\n",
            "        4.6462063789, 3.3101909161, 3.7996337414, 4.2202706337, 4.4049930573,\n",
            "        4.0085344315, 4.3749704361, 3.3613858223, 3.7789585590, 3.4571413994,\n",
            "        3.2134552002, 3.4675025940, 3.6652140617, 3.6751446724, 3.1418235302])\n",
            "btensor.grad: tensor([4.4063439369, 2.9369244576, 4.0643668175, 3.7648460865, 3.3628869057,\n",
            "        4.3527369499, 3.5409765244, 3.2871487141, 4.0424227715, 4.3138117790,\n",
            "        3.4277877808, 3.5217056274, 3.2952530384, 3.4627270699, 3.0851771832,\n",
            "        2.0943849087, 3.4192504883, 4.2475824356, 3.3026528358, 4.1820678711])\n",
            "ctensor.grad: tensor([  -3.7396957874,  -16.3507671356,   35.2083587646,  -23.5716953278,\n",
            "          -1.5738513470, -123.2515258789,  -56.5451507568, -108.1232910156,\n",
            "          26.1757354736,    1.5730001926,  124.2787322998,   54.4490661621,\n",
            "         108.9381408691,    0.8941007853,    0.1828600764,    4.9426355362,\n",
            "           2.4342985153,    6.4225196838])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(757.5218505859, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8276686072), tensor(1.6968057156), tensor(1.0657688379), tensor(1.3337750435), tensor(0.8799720407), tensor(0.7796966434), tensor(1.4973007441), tensor(1.0818165541), tensor(1.2511028051), tensor(1.0276165009), tensor(0.9664127231), tensor(0.9717738628), tensor(1.7402811050), tensor(1.1764515638), tensor(1.5678981543), tensor(1.7033429146), tensor(1.5317211151), tensor(1.0982356071), tensor(0.9016757607), tensor(1.0943440199)]\n",
            "b:  [tensor(1.5068823099), tensor(0.7724695206), tensor(1.3902755976), tensor(1.2788958549), tensor(1.0101524591), tensor(1.8608560562), tensor(1.2649471760), tensor(1.3685834408), tensor(1.2379646301), tensor(1.0369589329), tensor(1.3363212347), tensor(1.2660542727), tensor(0.7952022552), tensor(1.2426131964), tensor(1.2651027441), tensor(0.9386979938), tensor(0.9973838925), tensor(1.3286768198), tensor(1.3861746788), tensor(1.4669530392)]\n",
            "c:  [tensor(-0.3906933069), tensor(0.4213744700), tensor(0.3369294107), tensor(-0.5259056687), tensor(0.0153231453), tensor(-0.1896247566), tensor(0.1358303577), tensor(-0.0660163611), tensor(0.7744706273), tensor(-0.0280465931), tensor(0.2334320545), tensor(-0.1537625045), tensor(0.0810804516), tensor(0.5588064790), tensor(-0.0125295389), tensor(0.2479448467), tensor(-0.0836416930), tensor(0.1181903183)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-24.1587619781,  -7.3460431099, -15.2899522781,  -9.3576316833,\n",
            "        -29.6161327362, -29.4261741638,  -7.2682476044, -13.7346410751,\n",
            "        -12.0354671478, -18.8748645782, -17.7126102448, -13.7621326447,\n",
            "         -7.6158123016, -12.7509803772,  -8.7596187592,  -6.6965932846,\n",
            "         -8.5220241547, -16.1995143890, -19.2966480255, -16.0608215332])\n",
            "btensor.grad: tensor([-10.2338867188,  -9.1946620941, -10.8745565414, -10.8292970657,\n",
            "        -10.0169487000,  -9.9971818924,  -9.9989395142, -10.7979011536,\n",
            "        -10.6147279739, -11.5244913101, -11.1428270340,  -9.2848806381,\n",
            "         -9.6766157150, -10.7852725983, -11.3579454422,  -8.5958318710,\n",
            "        -10.0925512314, -10.9817552567, -10.8976516724, -10.9727172852])\n",
            "ctensor.grad: tensor([-7.9521514893e+01,  7.3701942444e+01, -1.4711868286e+02,\n",
            "         1.3414144897e+02,  8.0942153931e-01,  2.9701354980e+02,\n",
            "         1.0020326996e+02,  2.3647888184e+02, -1.3642857361e+02,\n",
            "        -1.0024597645e+00, -3.0782730103e+02, -1.0315663910e+02,\n",
            "        -2.3794563293e+02, -1.0955045223e+00,  1.0700101405e-01,\n",
            "        -1.2495496273e+00, -6.9237679243e-01, -1.6130037308e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(772.9928588867, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7702947259), tensor(1.6666465998), tensor(1.0212019682), tensor(1.2997829914), tensor(0.8253307939), tensor(0.7177973986), tensor(1.4664530754), tensor(1.0411367416), tensor(1.2133491039), tensor(0.9807443619), tensor(0.9187602997), tensor(0.9319925904), tensor(1.7104496956), tensor(1.1349684000), tensor(1.5354844332), tensor(1.6751946211), tensor(1.5008056164), tensor(1.0512515306), tensor(0.8492308855), tensor(1.0471446514)]\n",
            "b:  [tensor(1.4578619003), tensor(0.7057386041), tensor(1.3384491205), tensor(1.2194195986), tensor(0.9502987266), tensor(1.8134280443), tensor(1.2096749544), tensor(1.3126648664), tensor(1.1807677746), tensor(0.9772140980), tensor(1.2773690224), tensor(1.2133415937), tensor(0.7296416163), tensor(1.1823320389), tensor(1.1988284588), tensor(0.8768277764), tensor(0.9359391928), tensor(1.2734711170), tensor(1.3294726610), tensor(1.4154306650)]\n",
            "c:  [tensor(-0.3098416626), tensor(0.3456255198), tensor(0.2587609887), tensor(-0.5240868330), tensor(0.0155275399), tensor(-0.1811670661), tensor(0.1403570473), tensor(-0.0554522350), tensor(0.7700139284), tensor(-0.0286170896), tensor(0.2112293392), tensor(-0.1655614525), tensor(0.0521714054), tensor(0.5560936332), tensor(-0.0128739532), tensor(0.2356691062), tensor(-0.0899354443), tensor(0.1020229906)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([11.4747762680,  6.0318140984,  8.9133663177,  6.7984089851,\n",
            "        10.9282445908, 12.3798484802,  6.1695418358,  8.1359548569,\n",
            "         7.5507340431,  9.3744306564,  9.5304822922,  7.9562549591,\n",
            "         5.9662785530,  8.2966232300,  6.4827456474,  5.6296668053,\n",
            "         6.1830897331,  9.3968153000, 10.4889726639,  9.4398746490])\n",
            "btensor.grad: tensor([ 9.8040809631, 13.3461856842, 10.3652925491, 11.8952503204,\n",
            "        11.9707469940,  9.4855966568, 11.0544385910, 11.1837120056,\n",
            "        11.4393835068, 11.9489650726, 11.7904415131, 10.5425357819,\n",
            "        13.1121263504, 12.0562353134, 13.2548618317, 12.3740425110,\n",
            "        12.2889432907, 11.0411472321, 11.3403997421, 10.3044776917])\n",
            "ctensor.grad: tensor([-80.8516387939,  75.7489547729,  78.1684188843,  -1.8188652992,\n",
            "         -0.2043941766,  -8.4576845169,  -4.5266866684, -10.5641269684,\n",
            "          4.4567141533,   0.5704964399,  22.2027206421,  11.7989425659,\n",
            "         28.9090442657,   2.7128572464,   0.3444143534,  12.2757434845,\n",
            "          6.2937531471,  16.1673240662])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(740.7473144531, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7335085869), tensor(1.6525609493), tensor(0.9949715137), tensor(1.2839077711), tensor(0.7903941274), tensor(0.6760724783), tensor(1.4516270161), tensor(1.0189522505), tensor(1.1936216354), tensor(0.9538989067), tensor(0.8912816048), tensor(0.9114004970), tensor(1.6964942217), tensor(1.1121872663), tensor(1.5195000172), tensor(1.6624505520), tensor(1.4859490395), tensor(1.0236101151), tensor(0.8162434101), tensor(1.0186113119)]\n",
            "b:  [tensor(1.4347133636), tensor(0.6731421947), tensor(1.3121712208), tensor(1.1878492832), tensor(0.9196563363), tensor(1.7895077467), tensor(1.1811989546), tensor(1.2828909159), tensor(1.1518493891), tensor(0.9475599527), tensor(1.2462160587), tensor(1.1870315075), tensor(0.6981391311), tensor(1.1505231857), tensor(1.1612638235), tensor(0.8448485732), tensor(0.9036161900), tensor(1.2456109524), tensor(1.2988746166), tensor(1.3891265392)]\n",
            "c:  [tensor(-0.2654356956), tensor(0.3087148666), tensor(0.2173367143), tensor(-0.5227939487), tensor(0.0156952366), tensor(-0.1745143086), tensor(0.1439377517), tensor(-0.0472140796), tensor(0.7655696273), tensor(-0.0291739292), tensor(0.1875862777), tensor(-0.1779524833), tensor(0.0224767681), tensor(0.5541229844), tensor(-0.0131558320), tensor(0.2258064449), tensor(-0.0950183421), tensor(0.0891522169)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([7.3572258949, 2.8171238899, 5.2460908890, 3.1750366688, 6.9873366356,\n",
            "        8.3449802399, 2.9652013779, 4.4368915558, 3.9454917908, 5.3690943718,\n",
            "        5.4957380295, 4.1184225082, 2.7910854816, 4.5562176704, 3.1968941689,\n",
            "        2.5488073826, 2.9713149071, 5.5282754898, 6.5974912643, 5.7066578865])\n",
            "btensor.grad: tensor([4.6297168732, 6.5192775726, 5.2555789948, 6.3140544891, 6.1284799576,\n",
            "        4.7840662003, 5.6952095032, 5.9547948837, 5.7836732864, 5.9308233261,\n",
            "        6.2305841446, 5.2620220184, 6.3004937172, 6.3617711067, 7.5129303932,\n",
            "        6.3958382607, 6.4645977020, 5.5720319748, 6.1196188927, 5.2608194351])\n",
            "ctensor.grad: tensor([-44.4059600830,  36.9106597900,  41.4242668152,  -1.2928851843,\n",
            "         -0.1676968038,  -6.6527638435,  -3.5807008743,  -8.2381553650,\n",
            "          4.4443130493,   0.5568396449,  23.6430644989,  12.3910293579,\n",
            "         29.6946353912,   1.9706497192,   0.2818787694,   9.8626537323,\n",
            "          5.0828957558,  12.8707752228])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(730.3586425781, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7102848887), tensor(1.6473048925), tensor(0.9798796177), tensor(1.2782057524), tensor(0.7680497766), tensor(0.6482115388), tensor(1.4457544088), tensor(1.0077887774), tensor(1.1842169762), tensor(0.9392294884), tensor(0.8762525916), tensor(0.9020700455), tensor(1.6912665367), tensor(1.1004945040), tensor(1.5126813650), tensor(1.6581052542), tensor(1.4799853563), tensor(1.0077880621), tensor(0.7957866192), tensor(1.0017302036)]\n",
            "b:  [tensor(1.4252635241), tensor(0.6601877213), tensor(1.2997840643), tensor(1.1720621586), tensor(0.9053207636), tensor(1.7781909704), tensor(1.1677474976), tensor(1.2678655386), tensor(1.1385846138), tensor(0.9343662858), tensor(1.2306728363), tensor(1.1752599478), tensor(0.6858543754), tensor(1.1347091198), tensor(1.1403359175), tensor(0.8304564953), tensor(0.8880585432), tensor(1.2327085733), tensor(1.2829173803), tensor(1.3766447306)]\n",
            "c:  [tensor(-0.2428782135), tensor(0.2973516285), tensor(0.1980317384), tensor(-0.5217944384), tensor(0.0158445109), tensor(-0.1688084006), tensor(0.1470134556), tensor(-0.0402306877), tensor(0.7605280280), tensor(-0.0297602974), tensor(0.1592797041), tensor(-0.1923811138), tensor(-0.0112325046), tensor(0.5525720716), tensor(-0.0134072304), tensor(0.2171677351), tensor(-0.0994725674), tensor(0.0780338570)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([4.6447405815, 1.0512167215, 3.0183761120, 1.1404128075, 4.4688692093,\n",
            "        5.5721855164, 1.1745213270, 2.2326834202, 1.8809390068, 2.9338834286,\n",
            "        3.0057981014, 1.8660893440, 1.0455338955, 2.3385517597, 1.3637200594,\n",
            "        0.8690657020, 1.1927318573, 3.1644177437, 4.0913581848, 3.3762316704])\n",
            "btensor.grad: tensor([1.8899782896, 2.5908899307, 2.4774291515, 3.1574263573, 2.8671126366,\n",
            "        2.2633531094, 2.6903023720, 3.0050675869, 2.6529555321, 2.6387276649,\n",
            "        3.1086421013, 2.3543152809, 2.4569454193, 3.1628031731, 4.1855707169,\n",
            "        2.8784124851, 3.1115233898, 2.5804836750, 3.1914408207, 2.4963719845])\n",
            "ctensor.grad: tensor([-22.5574817657,  11.3632364273,  19.3049812317,  -0.9995359778,\n",
            "         -0.1492750645,  -5.7059054375,  -3.0757081509,  -6.9833917618,\n",
            "          5.0416235924,   0.5863672495,  28.3065681458,  14.4286279678,\n",
            "         33.7092704773,   1.5509389639,   0.2513985038,   8.6387100220,\n",
            "          4.4542226791,  11.1183605194])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(725.6975097656, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6957859397), tensor(1.6463538408), tensor(0.9711461663), tensor(1.2774721384), tensor(0.7531487346), tensor(0.6298843026), tensor(1.4443806410), tensor(1.0026608706), tensor(1.1800522804), tensor(0.9313284159), tensor(0.8684226871), tensor(0.8984736800), tensor(1.6903177500), tensor(1.0949214697), tensor(1.5104559660), tensor(1.6577503681), tensor(1.4783571959), tensor(0.9988868833), tensor(0.7832731605), tensor(0.9919973016)]\n",
            "b:  [tensor(1.4224717617), tensor(0.6581334472), tensor(1.2945688963), tensor(1.1651278734), tensor(0.8998339176), tensor(1.7731440067), tensor(1.1626293659), tensor(1.2611327171), tensor(1.1336987019), tensor(0.9295937419), tensor(1.2237796783), tensor(1.1712322235), tensor(0.6839221716), tensor(1.1277723312), tensor(1.1293166876), tensor(0.8266633749), tensor(0.8821313381), tensor(1.2275981903), tensor(1.2751408815), tensor(1.3714181185)]\n",
            "c:  [tensor(-0.2325686514), tensor(0.3045504391), tensor(0.1912774444), tensor(-0.5209447145), tensor(0.0159875751), tensor(-0.1634774804), tensor(0.1498732567), tensor(-0.0338154063), tensor(0.7539596558), tensor(-0.0304132551), tensor(0.1213297695), tensor(-0.2109383196), tensor(-0.0530611500), tensor(0.5512230992), tensor(-0.0136513039), tensor(0.2088529766), tensor(-0.1037320048), tensor(0.0675488263)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([2.8997895718, 0.1902108788, 1.7466937304, 0.1467244625, 2.9802134037,\n",
            "        3.6654467583, 0.2747626901, 1.0255748034, 0.8329493999, 1.5802141428,\n",
            "        1.5659766197, 0.7192745209, 0.1897642016, 1.1146044731, 0.4450757504,\n",
            "        0.0709726438, 0.3256325722, 1.7802408934, 2.5026938915, 1.9465796947])\n",
            "btensor.grad: tensor([0.5583565235, 0.4108569622, 1.0430350304, 1.3868597746, 1.0973711014,\n",
            "        1.0093840361, 1.0236183405, 1.3465690613, 0.9771752954, 0.9545134306,\n",
            "        1.3786416054, 0.8055513501, 0.3864410222, 1.3873521090, 2.2038354874,\n",
            "        0.7586207390, 1.1854462624, 1.0220723152, 1.5553097725, 1.0453302860])\n",
            "ctensor.grad: tensor([-10.3095636368,  -7.1988134384,   6.7542915344,  -0.8496954441,\n",
            "         -0.1430649608,  -5.3309192657,  -2.8598077297,  -6.4152803421,\n",
            "          6.5683469772,   0.6529583931,  37.9499359131,  18.5572071075,\n",
            "         41.8286437988,   1.3489518166,   0.2440740168,   8.3147611618,\n",
            "          4.2594337463,  10.4850301743])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(720.7775878906, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6882084608), tensor(1.6475203037), tensor(0.9667544961), tensor(1.2790002823), tensor(0.7430396676), tensor(0.6197608709), tensor(1.4453763962), tensor(1.0011576414), tensor(1.1786363125), tensor(0.9275398850), tensor(0.8655533791), tensor(0.8976947069), tensor(1.6914440393), tensor(1.0933557749), tensor(1.5105892420), tensor(1.6591503620), tensor(1.4787933826), tensor(0.9952088594), tensor(0.7773878574), tensor(0.9877813458)]\n",
            "b:  [tensor(1.4232492447), tensor(0.6633366942), tensor(1.2937513590), tensor(1.1644258499), tensor(0.9005479813), tensor(1.7715613842), tensor(1.1631643772), tensor(1.2601492405), tensor(1.1341118813), tensor(0.9299055338), tensor(1.2228231430), tensor(1.1721831560), tensor(0.6887931228), tensor(1.1271852255), tensor(1.1264657974), tensor(0.8307818770), tensor(0.8831613660), tensor(1.2273300886), tensor(1.2733993530), tensor(1.3706190586)]\n",
            "c:  [tensor(-0.2301672846), tensor(0.3303749859), tensor(0.1927241385), tensor(-0.5202016830), tensor(0.0161311608), tensor(-0.1582908332), tensor(0.1526220143), tensor(-0.0277259555), tensor(0.7454844713), tensor(-0.0311529543), tensor(0.0702250302), tensor(-0.2349233925), tensor(-0.1027783304), tensor(0.5500100851), tensor(-0.0139019582), tensor(0.2004325092), tensor(-0.1079815105), tensor(0.0572455414)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.5154975653, -0.2332833707,  0.8783301115, -0.3056271076,\n",
            "         2.0218186378,  2.0246882439, -0.1991437674,  0.3006441295,\n",
            "         0.2832000852,  0.7577077150,  0.5738583803,  0.1557936668,\n",
            "        -0.2252672315,  0.3131352067, -0.0266527981, -0.2799875140,\n",
            "        -0.0872262716,  0.7356075644,  1.1770638227,  0.8431931734])\n",
            "btensor.grad: tensor([-0.1554951072, -1.0406485796,  0.1634975076,  0.1403959692,\n",
            "        -0.1428177357,  0.3165329695, -0.1070138216,  0.1966872215,\n",
            "        -0.0826298594, -0.0623639822,  0.1912974417, -0.1901807785,\n",
            "        -0.9741951823,  0.1174247041,  0.5701868534, -0.8237022758,\n",
            "        -0.2060050368,  0.0536176860,  0.3483119011,  0.1598016620])\n",
            "ctensor.grad: tensor([ -2.4013717175, -25.8245582581,  -1.4466921091,  -0.7430611849,\n",
            "         -0.1435857862,  -5.1866393089,  -2.7487509251,  -6.0894498825,\n",
            "          8.4752016068,   0.7396983504,  51.1047401428,  23.9850673676,\n",
            "         49.7171783447,   1.2130221128,   0.2506547570,   8.4204683304,\n",
            "          4.2495055199,  10.3032836914])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(714.2247924805, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6891159415), tensor(1.6505072117), tensor(0.9682367444), tensor(1.2820791006), tensor(0.7387830615), tensor(0.6197742820), tensor(1.4487472773), tensor(1.0034050941), tensor(1.1805001497), tensor(0.9281126857), tensor(0.8689225316), tensor(0.8997759819), tensor(1.6941606998), tensor(1.0966291428), tensor(1.5130465031), tensor(1.6620208025), tensor(1.4811643362), tensor(0.9989035726), tensor(0.7804067731), tensor(0.9905267358)]\n",
            "b:  [tensor(1.4280973673), tensor(0.6757379770), tensor(1.2982238531), tensor(1.1712419987), tensor(0.9089204669), tensor(1.7740097046), tensor(1.1696690321), tensor(1.2654132843), tensor(1.1399686337), tensor(0.9364103079), tensor(1.2287489176), tensor(1.1789782047), tensor(0.7001709938), tensor(1.1342712641), tensor(1.1334559917), tensor(0.8421198726), tensor(0.8918308616), tensor(1.2325499058), tensor(1.2792625427), tensor(1.3743202686)]\n",
            "c:  [tensor(-0.2368616164), tensor(0.3747304380), tensor(0.2034002542), tensor(-0.5196298361), tensor(0.0162787531), tensor(-0.1533481479), tensor(0.1552045345), tensor(-0.0220854711), tensor(0.7432883382), tensor(-0.0318185054), tensor(0.0327706486), tensor(-0.2527671456), tensor(-0.1301843375), tensor(0.5490685701), tensor(-0.0141664678), tensor(0.1920436323), tensor(-0.1121345088), tensor(0.0473673232)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.1814983487, -0.5973775387, -0.2964439392, -0.6157754660,\n",
            "         0.8513205647, -0.0026813447, -0.6741805673, -0.4494828284,\n",
            "        -0.3727749586, -0.1145544201, -0.6738255024, -0.4162507057,\n",
            "        -0.5433207154, -0.6546697617, -0.4914405942, -0.5740994811,\n",
            "        -0.4741829634, -0.7389467955, -0.6037786603, -0.5490823388])\n",
            "btensor.grad: tensor([-0.9696155190, -2.4802591801, -0.8944982886, -1.3632202148,\n",
            "        -1.6745016575, -0.4896712601, -1.3009202480, -1.0528026819,\n",
            "        -1.1713390350, -1.3009597063, -1.1851650476, -1.3590080738,\n",
            "        -2.2755739689, -1.4171988964, -1.3980319500, -2.2676024437,\n",
            "        -1.7339017391, -1.0439553261, -1.1726484299, -0.7402374148])\n",
            "ctensor.grad: tensor([  6.6943292618, -44.3554382324, -10.6761121750,  -0.5718535781,\n",
            "         -0.1475916654,  -4.9426913261,  -2.5825214386,  -5.6404843330,\n",
            "          2.1961615086,   0.6655510664,  37.4543800354,  17.8437671661,\n",
            "         27.4060096741,   0.9414901733,   0.2645097673,   8.3888740540,\n",
            "          4.1530008316,   9.8782167435])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(710.1855468750, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6952415109), tensor(1.6535667181), tensor(0.9733534455), tensor(1.2849309444), tensor(0.7400161624), tensor(0.6264601946), tensor(1.4531369209), tensor(1.0077809095), tensor(1.1845082045), tensor(0.9313106537), tensor(0.8763005137), tensor(0.9037093520), tensor(1.6969593763), tensor(1.1025644541), tensor(1.5168023109), tensor(1.6649354696), tensor(1.4843040705), tensor(1.0073632002), tensor(0.7889496684), tensor(0.9977237582)]\n",
            "b:  [tensor(1.4348752499), tensor(0.6907598376), tensor(1.3058911562), tensor(1.1825618744), tensor(0.9212179184), tensor(1.7789180279), tensor(1.1791371107), tensor(1.2744884491), tensor(1.1489937305), tensor(0.9467336535), tensor(1.2385745049), tensor(1.1887272596), tensor(0.7133747339), tensor(1.1451306343), tensor(1.1450200081), tensor(0.8558411002), tensor(0.9042444825), tensor(1.2406150103), tensor(1.2894409895), tensor(1.3806440830)]\n",
            "c:  [tensor(-0.2490115315), tensor(0.4210672677), tensor(0.2198584229), tensor(-0.5191522241), tensor(0.0164395906), tensor(-0.1482187510), tensor(0.1578581631), tensor(-0.0163338371), tensor(0.7553368807), tensor(-0.0322928205), tensor(0.0340890810), tensor(-0.2546809614), tensor(-0.1199181005), tensor(0.5482924581), tensor(-0.0144631146), tensor(0.1828930676), tensor(-0.1165907234), tensor(0.0369279347)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.2251186371, -0.6118912697, -1.0233439207, -0.5703608394,\n",
            "        -0.2466170192, -1.3371822834, -0.8779210448, -0.8751610518,\n",
            "        -0.8016157746, -0.6395972371, -1.4755982161, -0.7866764069,\n",
            "        -0.5597296953, -1.1870619059, -0.7511606216, -0.5829357505,\n",
            "        -0.6279477477, -1.6919147968, -1.7085736990, -1.4394043684])\n",
            "btensor.grad: tensor([-1.3555730581, -3.0043764114, -1.5334508419, -2.2639842033,\n",
            "        -2.4594914913, -0.9816619158, -1.8936145306, -1.8150446415,\n",
            "        -1.8050251007, -2.0646719933, -1.9651137590, -1.9498162270,\n",
            "        -2.6407492161, -2.1718745232, -2.3128004074, -2.7442398071,\n",
            "        -2.4827234745, -1.6130183935, -2.0356969833, -1.2647510767])\n",
            "ctensor.grad: tensor([ 12.1499156952, -46.3368148804, -16.4581661224,  -0.4776087403,\n",
            "         -0.1608380973,  -5.1293983459,  -2.6536350250,  -5.7516326904,\n",
            "        -12.0485610962,   0.4743140936,  -1.3184319735,   1.9138112068,\n",
            "        -10.2662391663,   0.7761353254,   0.2966467142,   9.1505584717,\n",
            "          4.4562182426,  10.4393892288])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(706.9543457031, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.6963092089), tensor(1.6529763937), tensor(0.9739910364), tensor(1.2833229303), tensor(0.7356175184), tensor(0.6280584931), tensor(1.4536260366), tensor(1.0076564550), tensor(1.1836029291), tensor(0.9296363592), tensor(0.8784470558), tensor(0.9022899866), tensor(1.6961042881), tensor(1.1038532257), tensor(1.5165686607), tensor(1.6642559767), tensor(1.4834896326), tensor(1.0109007359), tensor(0.7925254703), tensor(1.0009144545)]\n",
            "b:  [tensor(1.4363944530), tensor(0.7005506158), tensor(1.3085666895), tensor(1.1888802052), tensor(0.9282821417), tensor(1.7790453434), tensor(1.1839330196), tensor(1.2792444229), tensor(1.1528153419), tensor(0.9512483478), tensor(1.2436261177), tensor(1.1936933994), tensor(0.7211594582), tensor(1.1512060165), tensor(1.1520737410), tensor(0.8659005761), tensor(0.9117583632), tensor(1.2435145378), tensor(1.2950389385), tensor(1.3822385073)]\n",
            "c:  [tensor(-0.2525826097), tensor(0.4648854136), tensor(0.2289841920), tensor(-0.5184221864), tensor(0.0166286957), tensor(-0.1416768879), tensor(0.1611832678), tensor(-0.0090928413), tensor(0.7601957321), tensor(-0.0329838954), tensor(0.0122248363), tensor(-0.2657572031), tensor(-0.1293505728), tensor(0.5469360352), tensor(-0.0148258945), tensor(0.1702585965), tensor(-0.1226020604), tensor(0.0228619203)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.2135348320,  0.1180670857, -0.1275226176,  0.3216032982,\n",
            "         0.8797277808, -0.3196609020, -0.0978260636,  0.0249014199,\n",
            "         0.1810613275,  0.3348533511, -0.4293037951,  0.2838723660,\n",
            "         0.1710117459, -0.2577454448,  0.0467195362,  0.1358966231,\n",
            "         0.1628897190, -0.7075159550, -0.7151563764, -0.6381410956])\n",
            "btensor.grad: tensor([-0.3038336039, -1.9581590891, -0.5351168513, -1.2636721134,\n",
            "        -1.4128420353, -0.0254658554, -0.9591864944, -0.9511891007,\n",
            "        -0.7643205523, -0.9029425383, -1.0103273392, -0.9932300448,\n",
            "        -1.5569479465, -1.2150655985, -1.4107445478, -2.0118899345,\n",
            "        -1.5027806759, -0.5798954964, -1.1195889711, -0.3188778758])\n",
            "ctensor.grad: tensor([  3.5710749626, -43.8181304932,  -9.1257724762,  -0.7300469279,\n",
            "         -0.1891055703,  -6.5418591499,  -3.3251018524,  -7.2409958839,\n",
            "         -4.8588252068,   0.6910755038,  21.8642444611,  11.0762338638,\n",
            "          9.4324722290,   1.3564250469,   0.3627800941,  12.6344680786,\n",
            "          6.0113329887,  14.0660133362])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(703.9686889648, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7015815377), tensor(1.6526415348), tensor(0.9773142934), tensor(1.2819112539), tensor(0.7359772921), tensor(0.6349597573), tensor(1.4550416470), tensor(1.0095731020), tensor(1.1843444109), tensor(0.9305287004), tensor(0.8837179542), tensor(0.9027156234), tensor(1.6955603361), tensor(1.1072225571), tensor(1.5176302195), tensor(1.6637917757), tensor(1.4835145473), tensor(1.0177631378), tensor(0.7999827862), tensor(1.0074943304)]\n",
            "b:  [tensor(1.4396507740), tensor(0.7126121521), tensor(1.3138422966), tensor(1.1983249187), tensor(0.9380959272), tensor(1.7813532352), tensor(1.1910300255), tensor(1.2870392799), tensor(1.1593347788), tensor(0.9590011835), tensor(1.2517486811), tensor(1.2007892132), tensor(0.7309356332), tensor(1.1598993540), tensor(1.1622208357), tensor(0.8780313134), tensor(0.9220156670), tensor(1.2488975525), tensor(1.3036801815), tensor(1.3863732815)]\n",
            "c:  [tensor(-0.2607969046), tensor(0.5072307587), tensor(0.2436190695), tensor(-0.5177776814), tensor(0.0168353599), tensor(-0.1346939653), tensor(0.1646607518), tensor(-0.0015846160), tensor(0.7758411765), tensor(-0.0335520990), tensor(0.0197179429), tensor(-0.2646631300), tensor(-0.1123505533), tensor(0.5457514524), tensor(-0.0152326375), tensor(0.1558668613), tensor(-0.1292481720), tensor(0.0076827398)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.0544686317,  0.0669835210, -0.6646516919,  0.2823419571,\n",
            "        -0.0719545484, -1.3802573681, -0.2831221223, -0.3833381832,\n",
            "        -0.1483042836, -0.1784651875, -1.0541833639, -0.0851304531,\n",
            "         0.1087917089, -0.6738687158, -0.2123160362,  0.0928364396,\n",
            "        -0.0049917698, -1.3724911213, -1.4914686680, -1.3159788847])\n",
            "btensor.grad: tensor([-0.6512540579, -2.4123110771, -1.0551145077, -1.8889405727,\n",
            "        -1.9627600908, -0.4615718424, -1.4194042683, -1.5589618683,\n",
            "        -1.3038961887, -1.5505642891, -1.6245064735, -1.4191641808,\n",
            "        -1.9552386999, -1.7386593819, -2.0294280052, -2.4261474609,\n",
            "        -2.0514645576, -1.0766025782, -1.7282540798, -0.8269542456])\n",
            "ctensor.grad: tensor([  8.2143077850, -42.3453712463, -14.6348743439,  -0.6445206404,\n",
            "         -0.2066647112,  -6.9829182625,  -3.4774842262,  -7.5082249641,\n",
            "        -15.6454610825,   0.5682021379,  -7.4931063652,  -1.0940868855,\n",
            "        -17.0000209808,   1.1845710278,   0.4067425430,  14.3917293549,\n",
            "          6.6461186409,  15.1791801453])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(701.0350341797, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7015306950), tensor(1.6489230394), tensor(0.9758208394), tensor(1.2763112783), tensor(0.7290232182), tensor(0.6360177994), tensor(1.4524451494), tensor(1.0068261623), tensor(1.1796506643), tensor(0.9261928201), tensor(0.8832713366), tensor(0.8974186778), tensor(1.6915284395), tensor(1.1056196690), tensor(1.5144127607), tensor(1.6599451303), tensor(1.4794875383), tensor(1.0190452337), tensor(0.8019660115), tensor(1.0097734928)]\n",
            "b:  [tensor(1.4374470711), tensor(0.7200063467), tensor(1.3135181665), tensor(1.2020837069), tensor(0.9426084161), tensor(1.7783372402), tensor(1.1932204962), tensor(1.2899295092), tensor(1.1602147818), tensor(0.9603573680), tensor(1.2545894384), tensor(1.2029203176), tensor(0.7359575629), tensor(1.1636511087), tensor(1.1674704552), tensor(0.8869962692), tensor(0.9270751476), tensor(1.2486517429), tensor(1.3071589470), tensor(1.3852087259)]\n",
            "c:  [tensor(-0.2600359619), tensor(0.5471942425), tensor(0.2518120408), tensor(-0.5167560577), tensor(0.0170774050), tensor(-0.1256523728), tensor(0.1690391004), tensor(0.0079026390), tensor(0.7782578468), tensor(-0.0344368517), tensor(-0.0125065520), tensor(-0.2789677978), tensor(-0.1293458790), tensor(0.5434409380), tensor(-0.0157302450), tensor(0.1350605786), tensor(-0.1385572553), tensor(-0.0133686988)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0101737976,  0.7437065840,  0.2986939847,  1.1200034618,\n",
            "         1.3908147812, -0.2116137743,  0.5192998648,  0.5493924618,\n",
            "         0.9387534261,  0.8671743274,  0.0893190503,  1.0593855381,\n",
            "         0.8063845038,  0.3205670118,  0.6434910893,  0.7693372965,\n",
            "         0.8054113388, -0.2564136088, -0.3966484070, -0.4558404982])\n",
            "btensor.grad: tensor([ 0.4407477677, -1.4788403511,  0.0648247600, -0.7517461777,\n",
            "        -0.9024980664,  0.6031982303, -0.4381020069, -0.5780445337,\n",
            "        -0.1760025024, -0.2712393999, -0.5681474209, -0.4262271821,\n",
            "        -1.0043846369, -0.7503420115, -1.0499224663, -1.7929923534,\n",
            "        -1.0118910074,  0.0491656810, -0.6957457066,  0.2329040766])\n",
            "ctensor.grad: tensor([ -0.7609372139, -39.9634819031,  -8.1929712296,  -1.0216238499,\n",
            "         -0.2420444191,  -9.0415964127,  -4.3783473969,  -9.4872541428,\n",
            "         -2.4166493416,   0.8847544789,  32.2244949341,  14.3046712875,\n",
            "         16.9953269958,   2.3104982376,   0.4976071119,  20.8062896729,\n",
            "          9.3090810776,  21.0514373779])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(698.3195190430, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7133654952), tensor(1.6484222412), tensor(0.9823996425), tensor(1.2744965553), tensor(0.7351340055), tensor(0.6509749889), tensor(1.4543498755), tensor(1.0112659931), tensor(1.1813175678), tensor(0.9303868413), tensor(0.8922215700), tensor(0.8993422389), tensor(1.6908055544), tensor(1.1111543179), tensor(1.5164844990), tensor(1.6590927839), tensor(1.4798792601), tensor(1.0297513008), tensor(0.8146166801), tensor(1.0210275650)]\n",
            "b:  [tensor(1.4420558214), tensor(0.7348763347), tensor(1.3213193417), tensor(1.2145881653), tensor(0.9550840855), tensor(1.7826460600), tensor(1.2026734352), tensor(1.3010942936), tensor(1.1693599224), tensor(0.9712551236), tensor(1.2661772966), tensor(1.2119219303), tensor(0.7483534217), tensor(1.1751596928), tensor(1.1813393831), tensor(0.9022653103), tensor(0.9402991533), tensor(1.2566617727), tensor(1.3191045523), tensor(1.3920036554)]\n",
            "c:  [tensor(-0.2738442421), tensor(0.5834829211), tensor(0.2745037377), tensor(-0.5163525939), tensor(0.0173267983), tensor(-0.1174503714), tensor(0.1727724075), tensor(0.0157700069), tensor(0.8052571416), tensor(-0.0349371359), tensor(0.0247358754), tensor(-0.2651279569), tensor(-0.0859321281), tensor(0.5432977676), tensor(-0.0162357632), tensor(0.1165091172), tensor(-0.1462907493), tensor(-0.0292666666)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-2.3669614792,  0.1001651734, -1.3157632351,  0.3629439473,\n",
            "        -1.2221634388, -2.9914398193, -0.3809454441, -0.8879634142,\n",
            "        -0.3333863914, -0.8388086557, -1.7900516987, -0.3847090006,\n",
            "         0.1445796788, -1.1069242954, -0.4143472910,  0.1704640687,\n",
            "        -0.0783561468, -2.1412076950, -2.5301361084, -2.2508182526])\n",
            "btensor.grad: tensor([-0.9217610359, -2.9739971161, -1.5602308512, -2.5008969307,\n",
            "        -2.4951336384, -0.8617579937, -1.8905799389, -2.2329628468,\n",
            "        -1.8290178776, -2.1795537472, -2.3175764084, -1.8003163338,\n",
            "        -2.4791767597, -2.3017051220, -2.7737782001, -3.0538077354,\n",
            "        -2.6448020935, -1.6020107269, -2.3891124725, -1.3589890003])\n",
            "ctensor.grad: tensor([ 13.8082666397, -36.2886962891, -22.6916923523,  -0.4034869969,\n",
            "         -0.2493941933,  -8.2019987106,  -3.7333042622,  -7.8673677444,\n",
            "        -26.9993095398,   0.5002855659, -37.2424240112, -13.8398284912,\n",
            "        -43.4137496948,   0.1431631744,   0.5055190325,  18.5514602661,\n",
            "          7.7334933281,  15.8979663849])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(696.7867431641, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7081053257), tensor(1.6403778791), tensor(0.9756926298), tensor(1.2635465860), tensor(0.7199073434), tensor(0.6462280750), tensor(1.4464086294), tensor(1.0031802654), tensor(1.1695960760), tensor(0.9202519059), tensor(0.8849489689), tensor(0.8869202137), tensor(1.6822340488), tensor(1.1035817862), tensor(1.5077672005), tensor(1.6507211924), tensor(1.4706153870), tensor(1.0241855383), tensor(0.8107470870), tensor(1.0189700127)]\n",
            "b:  [tensor(1.4325784445), tensor(0.7366328239), tensor(1.3137637377), tensor(1.2108824253), tensor(0.9530175924), tensor(1.7726711035), tensor(1.1988413334), tensor(1.2981008291), tensor(1.1632645130), tensor(0.9643390179), tensor(1.2626773119), tensor(1.2076823711), tensor(0.7478723526), tensor(1.1727986336), tensor(1.1812351942), tensor(0.9077565074), tensor(0.9387652874), tensor(1.2492228746), tensor(1.3162275553), tensor(1.3841576576)]\n",
            "c:  [tensor(-0.2633697987), tensor(0.6142191291), tensor(0.2814548910), tensor(-0.5144730210), tensor(0.0176486261), tensor(-0.1033165455), tensor(0.1791390479), tensor(0.0295740254), tensor(0.7908881903), tensor(-0.0362708569), tensor(-0.0610201135), tensor(-0.3003696203), tensor(-0.1499958634), tensor(0.5374689698), tensor(-0.0169545263), tensor(0.0767080784), tensor(-0.1631424129), tensor(-0.0651259050)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([1.0520331860, 1.6088762283, 1.3413987160, 2.1899864674, 3.0453290939,\n",
            "        0.9493814707, 1.5882558823, 1.6171494722, 2.3443076611, 2.0269861221,\n",
            "        1.4545245171, 2.4844031334, 1.7143037319, 1.5144972801, 1.7434488535,\n",
            "        1.6743092537, 1.8527758121, 1.1131447554, 0.7739140987, 0.4115036130])\n",
            "btensor.grad: tensor([ 1.8954685926, -0.3512956202,  1.5111274719,  0.7411403060,\n",
            "         0.4132976532,  1.9950013161,  0.7664244175,  0.5986845493,\n",
            "         1.2190859318,  1.3832180500,  0.6999875307,  0.8479000330,\n",
            "         0.0962162167,  0.4722224474,  0.0208390504, -1.0982363224,\n",
            "         0.3067724705,  1.4877789021,  0.5754073262,  1.5692100525])\n",
            "ctensor.grad: tensor([-10.4744367599, -30.7362327576,  -6.9511485100,  -1.8795717955,\n",
            "         -0.3218286037, -14.1338272095,  -6.3666343689, -13.8040189743,\n",
            "         14.3689565659,   1.3337204456,  85.7559814453,  35.2416458130,\n",
            "         64.0637359619,   5.8287925720,   0.7187631726,  39.8010368347,\n",
            "         16.8516654968,  35.8592376709])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(701.6921997070, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7520848513), tensor(1.6487772465), tensor(1.0031268597), tensor(1.2726089954), tensor(0.7605391145), tensor(0.6974655390), tensor(1.4584168196), tensor(1.0253301859), tensor(1.1870689392), tensor(0.9477170706), tensor(0.9167316556), tensor(0.9067519307), tensor(1.6901180744), tensor(1.1267602444), tensor(1.5218663216), tensor(1.6577126980), tensor(1.4820154905), tensor(1.0570054054), tensor(0.8500483036), tensor(1.0513801575)]\n",
            "b:  [tensor(1.4516144991), tensor(0.7652174830), tensor(1.3383998871), tensor(1.2398346663), tensor(0.9798983335), tensor(1.7922930717), tensor(1.2224533558), tensor(1.3253966570), tensor(1.1882836819), tensor(0.9925143719), tensor(1.2920366526), tensor(1.2302045822), tensor(0.7749238014), tensor(1.2000039816), tensor(1.2134281397), tensor(0.9351453185), tensor(0.9676200747), tensor(1.2742576599), tensor(1.3449920416), tensor(1.4069993496)]\n",
            "c:  [tensor(-0.3119182587), tensor(0.6209050417), tensor(0.3208326101), tensor(-0.5173236132), tensor(0.0178849380), tensor(-0.1021272242), tensor(0.1784166545), tensor(0.0269982293), tensor(0.8655041456), tensor(-0.0360516682), tensor(0.1000426635), tensor(-0.2409527600), tensor(-0.0071298778), tensor(0.5581185222), tensor(-0.0172242932), tensor(0.1089174002), tensor(-0.1484896690), tensor(-0.0250088498)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ -8.7959003448,  -1.6798828840,  -5.4868373871,  -1.8124853373,\n",
            "         -8.1263513565, -10.2474899292,  -2.4016346931,  -4.4299874306,\n",
            "         -3.4945740700,  -5.4930305481,  -6.3565387726,  -3.9663455486,\n",
            "         -1.5768094063,  -4.6356878281,  -2.8198347092,  -1.3982917070,\n",
            "         -2.2800092697,  -6.5639829636,  -7.8602414131,  -6.4820399284])\n",
            "btensor.grad: tensor([-3.8072054386, -5.7169361115, -4.9272413254, -5.7904577255,\n",
            "        -5.3761544228, -3.9244005680, -4.7223930359, -5.4591689110,\n",
            "        -5.0038404465, -5.6350655556, -5.8718667030, -4.5044360161,\n",
            "        -5.4102950096, -5.4410791397, -6.4385852814, -5.4777584076,\n",
            "        -5.7709584236, -5.0069475174, -5.7529039383, -4.5683403015])\n",
            "ctensor.grad: tensor([  48.5484657288,   -6.6859154701,  -39.3777046204,    2.8505902290,\n",
            "          -0.2363115102,   -1.1893217564,    0.7223957777,    2.5757968426,\n",
            "         -74.6159515381,   -0.2191888690, -161.0627746582,  -59.4168548584,\n",
            "        -142.8659820557,  -20.6495609283,    0.2697669864,  -32.2093200684,\n",
            "         -14.6527481079,  -40.1170539856])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(723.3846435547, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7144742608), tensor(1.6277157068), tensor(0.9733684659), tensor(1.2486200333), tensor(0.7224754691), tensor(0.6576688886), tensor(1.4363478422), tensor(0.9983584881), tensor(1.1589938402), tensor(0.9166555405), tensor(0.8845493197), tensor(0.8775929809), tensor(1.6693816185), tensor(1.0982609987), tensor(1.4987481833), tensor(1.6374912262), tensor(1.4596240520), tensor(1.0245579481), tensor(0.8154697418), tensor(1.0234751701)]\n",
            "b:  [tensor(1.4188967943), tensor(0.7343530655), tensor(1.3053218126), tensor(1.2050700188), tensor(0.9445153475), tensor(1.7600227594), tensor(1.1926668882), tensor(1.2960219383), tensor(1.1557034254), tensor(0.9541067481), tensor(1.2590101957), tensor(1.1990263462), tensor(0.7429255843), tensor(1.1655651331), tensor(1.1775332689), tensor(0.9103533626), tensor(0.9340574145), tensor(1.2401709557), tensor(1.3118058443), tensor(1.3755337000)]\n",
            "c:  [tensor(-0.2679291070), tensor(0.5984798670), tensor(0.3065344691), tensor(-0.5100725889), tensor(0.0184456091), tensor(-0.0661738664), tensor(0.1959958971), tensor(0.0650393069), tensor(0.8365265727), tensor(-0.0377040282), tensor(-0.0384596810), tensor(-0.3054576516), tensor(-0.1442319751), tensor(0.5384773612), tensor(-0.0183729865), tensor(0.0206564963), tensor(-0.1888193339), tensor(-0.1132294163)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([7.5221214294, 4.2122979164, 5.9516825676, 4.7977876663, 7.6127333641,\n",
            "        7.9593329430, 4.4137935638, 5.3943448067, 5.6150302887, 6.2123064995,\n",
            "        6.4364705086, 5.8317861557, 4.1472892761, 5.6998443604, 4.6236243248,\n",
            "        4.0442895889, 4.4782996178, 6.4894866943, 6.9157161713, 5.5810079575])\n",
            "btensor.grad: tensor([6.5435452461, 6.1728887558, 6.6156058311, 6.9529180527, 7.0765943527,\n",
            "        6.4540514946, 5.9572958946, 5.8749332428, 6.5160560608, 7.6815242767,\n",
            "        6.6052961349, 6.2356481552, 6.3996415138, 6.8877687454, 7.1789727211,\n",
            "        4.9583921432, 6.7125287056, 6.8173308372, 6.6372413635, 6.2931308746])\n",
            "ctensor.grad: tensor([-43.9891471863,  22.4251823425,  14.2981424332,  -7.2509970665,\n",
            "         -0.5606716871, -35.9533576965, -17.5792484283, -38.0410766602,\n",
            "         28.9775943756,   1.6523616314, 138.5023345947,  64.5049057007,\n",
            "        137.1020965576,  19.6411857605,   1.1486930847,  88.2609024048,\n",
            "         40.3296661377,  88.2205657959])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(702.7544555664, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7776087523), tensor(1.6400970221), tensor(1.0138566494), tensor(1.2614738941), tensor(0.7724568248), tensor(0.7285827994), tensor(1.4536013603), tensor(1.0282824039), tensor(1.1823396683), tensor(0.9510098100), tensor(0.9262005687), tensor(0.9029883146), tensor(1.6810765266), tensor(1.1303989887), tensor(1.5175111294), tensor(1.6479263306), tensor(1.4748824835), tensor(1.0687754154), tensor(0.8722311258), tensor(1.0688443184)]\n",
            "b:  [tensor(1.4420751333), tensor(0.7704710960), tensor(1.3341484070), tensor(1.2403867245), tensor(0.9803103209), tensor(1.7829551697), tensor(1.2221809626), tensor(1.3286200762), tensor(1.1865570545), tensor(0.9892070889), tensor(1.2935988903), tensor(1.2276471853), tensor(0.7771096230), tensor(1.2001020908), tensor(1.2182601690), tensor(0.9434450269), tensor(0.9696664214), tensor(1.2696332932), tensor(1.3471791744), tensor(1.4020044804)]\n",
            "c:  [tensor(-0.3252698183), tensor(0.6030077338), tensor(0.3118086755), tensor(-0.5210557580), tensor(0.0186686460), tensor(-0.0848666653), tensor(0.1835860461), tensor(0.0364717804), tensor(0.9119769335), tensor(-0.0373905078), tensor(0.1331674457), tensor(-0.2369029373), tensor(0.0192473531), tensor(0.5835365653), tensor(-0.0183056872), tensor(0.1193117276), tensor(-0.1490636021), tensor(-0.0177108645)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-12.6268949509,  -2.4762570858,  -8.0976247787,  -2.5707616806,\n",
            "         -9.9962673187, -14.1827783585,  -3.4507153034,  -5.9847760201,\n",
            "         -4.6691641808,  -6.8708519936,  -8.3302450180,  -5.0790638924,\n",
            "         -2.3389778137,  -6.4275918007,  -3.7525916100,  -2.0870244503,\n",
            "         -3.0516839027,  -8.8434839249, -11.3522710800,  -9.0738182068])\n",
            "btensor.grad: tensor([-4.6356763840, -7.2236013412, -5.7653284073, -7.0633373260,\n",
            "        -7.1589984894, -4.5864791870, -5.9028153419, -6.5196323395,\n",
            "        -6.1707367897, -7.0200719833, -6.9177317619, -5.7241754532,\n",
            "        -6.8368053436, -6.9073948860, -8.1453914642, -6.6183333397,\n",
            "        -7.1217985153, -5.8924794197, -7.0746650696, -5.2941646576])\n",
            "ctensor.grad: tensor([ 5.7340721130e+01, -4.5278859138e+00, -5.2742204666e+00,\n",
            "         1.0983160019e+01, -2.2303649783e-01,  1.8692800522e+01,\n",
            "         1.2409847260e+01,  2.8567525864e+01, -7.5450370789e+01,\n",
            "        -3.1352135539e-01, -1.7162710571e+02, -6.8554710388e+01,\n",
            "        -1.6347932434e+02, -4.5059207916e+01, -6.7299321294e-02,\n",
            "        -9.8655227661e+01, -3.9755729675e+01, -9.5518547058e+01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(733.0716552734, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7337306142), tensor(1.6185873747), tensor(0.9807384014), tensor(1.2375420332), tensor(0.7316113114), tensor(0.6815878749), tensor(1.4307328463), tensor(0.9989373684), tensor(1.1536741257), tensor(0.9174768925), tensor(0.8904643059), tensor(0.8730826378), tensor(1.6600160599), tensor(1.0995500088), tensor(1.4936354160), tensor(1.6277365685), tensor(1.4522583485), tensor(1.0325635672), tensor(0.8319211602), tensor(1.0357607603)]\n",
            "b:  [tensor(1.4083756208), tensor(0.7311401367), tensor(1.2984120846), tensor(1.2001500130), tensor(0.9392156601), tensor(1.7493734360), tensor(1.1877456903), tensor(1.2939208746), tensor(1.1499505043), tensor(0.9472056627), tensor(1.2551261187), tensor(1.1925113201), tensor(0.7379388809), tensor(1.1603709459), tensor(1.1749666929), tensor(0.9090572000), tensor(0.9297356009), tensor(1.2325731516), tensor(1.3090920448), tensor(1.3677450418)]\n",
            "c:  [tensor(-0.2817557752), tensor(0.5646063089), tensor(0.2900227308), tensor(-0.5102271438), tensor(0.0193939004), tensor(-0.0328440405), tensor(0.2093021572), tensor(0.0910519063), tensor(0.8933775425), tensor(-0.0387594290), tensor(0.0387751758), tensor(-0.2828887999), tensor(-0.0824865550), tensor(0.5652848482), tensor(-0.0193961989), tensor(0.0376117527), tensor(-0.1871824563), tensor(-0.1031290367)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([8.7756233215, 4.3019347191, 6.6236472130, 4.7863607407, 8.1690998077,\n",
            "        9.3989868164, 4.5736942291, 5.8690118790, 5.7331185341, 6.7065877914,\n",
            "        7.1472587585, 5.9811306000, 4.2120814323, 6.1697902679, 4.7751483917,\n",
            "        4.0379610062, 4.5248169899, 7.2423715591, 8.0619935989, 6.6167016029])\n",
            "btensor.grad: tensor([6.7399063110, 7.8661980629, 7.1472549438, 8.0473384857, 8.2189302444,\n",
            "        6.7163567543, 6.8870491982, 6.9398322105, 7.3213186264, 8.4002838135,\n",
            "        7.6945576668, 7.0271787643, 7.8341536522, 7.9462323189, 8.6587066650,\n",
            "        6.8775691986, 7.9861645699, 7.4120182991, 7.6174216270, 6.8518843651])\n",
            "ctensor.grad: tensor([-43.5140533447,  38.4014053345,  21.7859420776, -10.8286352158,\n",
            "         -0.7252539396, -52.0226211548, -25.7161140442, -54.5801239014,\n",
            "         18.5994167328,   1.3689210415,  94.3922653198,  45.9858589172,\n",
            "        101.7339019775,  18.2517318726,   1.0905123949,  81.6999740601,\n",
            "         38.1188545227,  85.4181671143])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(690.5430908203, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7503802180), tensor(1.6207686663), tensor(0.9929237366), tensor(1.2376441956), tensor(0.7323091626), tensor(0.6970123053), tensor(1.4321733713), tensor(1.0044627190), tensor(1.1532406807), tensor(0.9227906466), tensor(0.8969883919), tensor(0.8717881441), tensor(1.6610939503), tensor(1.1070361137), tensor(1.4947165251), tensor(1.6281375885), tensor(1.4524921179), tensor(1.0414823294), tensor(0.8473324180), tensor(1.0512700081)]\n",
            "b:  [tensor(1.4126145840), tensor(0.7479448318), tensor(1.3048503399), tensor(1.2107369900), tensor(0.9539835453), tensor(1.7520549297), tensor(1.1983873844), tensor(1.3049108982), tensor(1.1590906382), tensor(0.9563567042), tensor(1.2666435242), tensor(1.2025446892), tensor(0.7542947531), tensor(1.1748923063), tensor(1.1947927475), tensor(0.9270332456), tensor(0.9433914423), tensor(1.2397291660), tensor(1.3218894005), tensor(1.3729948997)]\n",
            "c:  [tensor(-0.3003273010), tensor(0.5925410986), tensor(0.3128625751), tensor(-0.5116053820), tensor(0.0199581310), tensor(-0.0149143618), tensor(0.2140424401), tensor(0.0976078734), tensor(0.8935478330), tensor(-0.0396813788), tensor(0.0044699758), tensor(-0.2921479642), tensor(-0.0948546305), tensor(0.5744469762), tensor(-0.0198527128), tensor(0.0380609930), tensor(-0.1864099652), tensor(-0.0927877873)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-3.3299174309, -0.4362542927, -2.4370675087, -0.0204394460,\n",
            "        -0.1395695210, -3.0848851204, -0.2881068587, -1.1050710678,\n",
            "         0.0866841450, -1.0627520084, -1.3048205376,  0.2589037418,\n",
            "        -0.2155838609, -1.4972240925, -0.2162171304, -0.0801933929,\n",
            "        -0.0467561483, -1.7837514877, -3.0822544098, -3.1018424034])\n",
            "btensor.grad: tensor([-0.8478000164, -3.3609397411, -1.2876629829, -2.1173968315,\n",
            "        -2.9535722733, -0.5363091826, -2.1283469200, -2.1979956627,\n",
            "        -1.8280248642, -1.8302122355, -2.3034930229, -2.0066680908,\n",
            "        -3.2711770535, -2.9042720795, -3.9652218819, -3.5952084064,\n",
            "        -2.7311739922, -1.4311919212, -2.5594613552, -1.0499742031])\n",
            "ctensor.grad: tensor([ 18.5715332031, -27.9348087311, -22.8398456573,   1.3782485723,\n",
            "         -0.5642313957, -17.9296779633,  -4.7402868271,  -6.5559635162,\n",
            "         -0.1703053266,   0.9219493866,  34.3051986694,   9.2591581345,\n",
            "         12.3680753708,  -9.1621084213,   0.4565145671,  -0.4492384791,\n",
            "         -0.7724867463, -10.3412513733])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(687.0256958008, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7766723633), tensor(1.6242229939), tensor(1.0117549896), tensor(1.2381407022), tensor(0.7399516702), tensor(0.7226215005), tensor(1.4353702068), tensor(1.0139070749), tensor(1.1551285982), tensor(0.9329560995), tensor(0.9094327688), tensor(0.8731061816), tensor(1.6631636620), tensor(1.1184128523), tensor(1.4978382587), tensor(1.6297458410), tensor(1.4541472197), tensor(1.0573781729), tensor(0.8714398742), tensor(1.0735220909)]\n",
            "b:  [tensor(1.4190263748), tensor(0.7675480843), tensor(1.3144266605), tensor(1.2255706787), tensor(0.9733883142), tensor(1.7574723959), tensor(1.2112107277), tensor(1.3192319870), tensor(1.1708611250), tensor(0.9702634215), tensor(1.2816662788), tensor(1.2152460814), tensor(0.7723583579), tensor(1.1933529377), tensor(1.2183640003), tensor(0.9471052289), tensor(0.9603678584), tensor(1.2498679161), tensor(1.3388707638), tensor(1.3809145689)]\n",
            "c:  [tensor(-0.3201874793), tensor(0.6167392135), tensor(0.3306578398), tensor(-0.5180075765), tensor(0.0205256343), tensor(-0.0115815243), tensor(0.2106613815), tensor(0.0874260217), tensor(0.9058957696), tensor(-0.0404263809), tensor(0.0103313746), tensor(-0.2829741240), tensor(-0.0702888072), tensor(0.5868477821), tensor(-0.0203145742), tensor(0.0498849526), tensor(-0.1787514389), tensor(-0.0707632229)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-5.2584338188, -0.6908645630, -3.7662386894, -0.0993029475,\n",
            "        -1.5285004377, -5.1218414307, -0.6393732429, -1.8888754845,\n",
            "        -0.3775826991, -2.0330862999, -2.4888730049, -0.2636020184,\n",
            "        -0.4139442146, -2.2753517628, -0.6243489385, -0.3216391802,\n",
            "        -0.3310087323, -3.1791725159, -4.8214969635, -4.4504189491])\n",
            "btensor.grad: tensor([-1.2823500633, -3.9206547737, -1.9152522087, -2.9667477608,\n",
            "        -3.8809509277, -1.0835018158, -2.5646617413, -2.8642148972,\n",
            "        -2.3540918827, -2.7813417912, -3.0045599937, -2.5402786732,\n",
            "        -3.6127207279, -3.6921181679, -4.7142558098, -4.0143990517,\n",
            "        -3.3952777386, -2.0277571678, -3.3962795734, -1.5839246511])\n",
            "ctensor.grad: tensor([ 19.8601779938, -24.1981124878, -17.7952671051,   6.4021682739,\n",
            "         -0.5675028563,  -3.3328373432,   3.3810577393,  10.1818504333,\n",
            "        -12.3479347229,   0.7450005412,  -5.8613986969,  -9.1738262177,\n",
            "        -24.5658187866, -12.4007835388,   0.4618616700, -11.8239583969,\n",
            "         -7.6585192680, -22.0245628357])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(685.6418457031, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7782467604), tensor(1.6202423573), tensor(1.0142591000), tensor(1.2301657200), tensor(0.7303650975), tensor(0.7226554155), tensor(1.4295413494), tensor(1.0110654831), tensor(1.1456069946), tensor(0.9293862581), tensor(0.9059329629), tensor(0.8633719087), tensor(1.6578534842), tensor(1.1157716513), tensor(1.4919296503), tensor(1.6245141029), tensor(1.4475948811), tensor(1.0560559034), tensor(0.8743635416), tensor(1.0792111158)]\n",
            "b:  [tensor(1.4138411283), tensor(0.7727748752), tensor(1.3116893768), tensor(1.2256902456), tensor(0.9781791568), tensor(1.7520853281), tensor(1.2116044760), tensor(1.3212492466), tensor(1.1696664095), tensor(0.9695540667), tensor(1.2835371494), tensor(1.2155950069), tensor(0.7764942050), tensor(1.1978067160), tensor(1.2269555330), tensor(0.9550726414), tensor(0.9626359940), tensor(1.2473448515), tensor(1.3421192169), tensor(1.3775256872)]\n",
            "c:  [tensor(-0.3285272717), tensor(0.6374338269), tensor(0.3479960561), tensor(-0.5134384632), tensor(0.0213241857), tensor(0.0275603719), tensor(0.2239367366), tensor(0.1135694981), tensor(0.8949217200), tensor(-0.0416810848), tensor(-0.0568890311), tensor(-0.3051017821), tensor(-0.1163783371), tensor(0.5834186673), tensor(-0.0211251825), tensor(0.0145834498), tensor(-0.1905071139), tensor(-0.0938858837)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.3148768544,  0.7961353064, -0.5008169413,  1.5949989557,\n",
            "         1.9173185825, -0.0067877471,  1.1657607555,  0.5683277249,\n",
            "         1.9043139219,  0.7139660120,  0.6999590993,  1.9468562603,\n",
            "         1.0620417595,  0.5282508135,  1.1817121506,  1.0463525057,\n",
            "         1.3104785681,  0.2644632459, -0.5847275257, -1.1378159523])\n",
            "btensor.grad: tensor([ 1.0370581150, -1.0453529358,  0.5474559069, -0.0239046142,\n",
            "        -0.9581646919,  1.0774194002, -0.0787436962, -0.4034487903,\n",
            "         0.2389433682,  0.1418743134, -0.3741726279, -0.0697944462,\n",
            "        -0.8271734118, -0.8907490969, -1.7183039188, -1.5934827328,\n",
            "        -0.4536328912,  0.5046159625, -0.6496804953,  0.6777662039])\n",
            "ctensor.grad: tensor([  8.3398065567, -20.6946067810, -17.3382282257,  -4.5691337585,\n",
            "         -0.7985518575, -39.1418952942, -13.2753572464, -26.1434764862,\n",
            "         10.9740257263,   1.2547020912,  67.2203979492,  22.1276531219,\n",
            "         46.0895271301,   3.4291100502,   0.8106090426,  35.3015022278,\n",
            "         11.7556734085,  23.1226596832])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(693.4590454102, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8457098007), tensor(1.6336500645), tensor(1.0591785908), tensor(1.2416162491), tensor(0.7844627500), tensor(0.7943629622), tensor(1.4461382627), tensor(1.0432838202), tensor(1.1662875414), tensor(0.9672430754), tensor(0.9474970698), tensor(0.8874803185), tensor(1.6699810028), tensor(1.1476328373), tensor(1.5105862617), tensor(1.6355969906), tensor(1.4619747400), tensor(1.1006933451), tensor(0.9317038655), tensor(1.1270235777)]\n",
            "b:  [tensor(1.4345067739), tensor(0.8047370315), tensor(1.3385856152), tensor(1.2581024170), tensor(1.0128942728), tensor(1.7738993168), tensor(1.2376704216), tensor(1.3518763781), tensor(1.1974242926), tensor(1.0040826797), tensor(1.3153581619), tensor(1.2412515879), tensor(0.8065580130), tensor(1.2312788963), tensor(1.2655924559), tensor(0.9842869639), tensor(0.9945051670), tensor(1.2751184702), tensor(1.3760123253), tensor(1.4027755260)]\n",
            "c:  [tensor(-0.3469415307), tensor(0.6348257065), tensor(0.3500036299), tensor(-0.5520034432), tensor(0.0215740502), tensor(-0.0655896664), tensor(0.1771116108), tensor(0.0147290826), tensor(0.9605735540), tensor(-0.0416136943), tensor(0.1031062007), tensor(-0.2341342717), tensor(0.0380365551), tensor(0.6265130639), tensor(-0.0212103482), tensor(0.1183562875), tensor(-0.1425929964), tensor(0.0082568228)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-13.4926042557,  -2.6815433502,  -8.9839067459,  -2.2901134491,\n",
            "        -10.8195304871, -14.3415069580,  -3.3193757534,  -6.4436697960,\n",
            "         -4.1361165047,  -7.5713672638,  -8.3128194809,  -4.8216848373,\n",
            "         -2.4255144596,  -6.3722333908,  -3.7313315868,  -2.2165730000,\n",
            "         -2.8759753704,  -8.9274845123, -11.4680604935,  -9.5624952316])\n",
            "btensor.grad: tensor([-4.1331243515, -6.3924264908, -5.3792424202, -6.4824414253,\n",
            "        -6.9430136681, -4.3628087044, -5.2131915092, -6.1254243851,\n",
            "        -5.5515723228, -6.9057245255, -6.3641920090, -5.1313076019,\n",
            "        -6.0127558708, -6.6944394112, -7.7273812294, -5.8428702354,\n",
            "        -6.3738408089, -5.5547175407, -6.7786240578, -5.0499567986])\n",
            "ctensor.grad: tensor([ 1.8414262772e+01,  2.6081240177e+00, -2.0075731277e+00,\n",
            "         3.8564979553e+01, -2.4986383319e-01,  9.3150032043e+01,\n",
            "         4.6825122833e+01,  9.8840408325e+01, -6.5651802063e+01,\n",
            "        -6.7388877273e-02, -1.5999522400e+02, -7.0967506409e+01,\n",
            "        -1.5441488647e+02, -4.3094383240e+01,  8.5165001452e-02,\n",
            "        -1.0377282715e+02, -4.7914112091e+01, -1.0214270020e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(747.4019165039, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7896010280), tensor(1.6074832678), tensor(1.0164744854), tensor(1.2131074667), tensor(0.7358251810), tensor(0.7357573509), tensor(1.4181730747), tensor(1.0065896511), tensor(1.1324534416), tensor(0.9260897040), tensor(0.9037923813), tensor(0.8527607918), tensor(1.6444879770), tensor(1.1088998318), tensor(1.4817186594), tensor(1.6114679575), tensor(1.4350539446), tensor(1.0558791161), tensor(0.8807014823), tensor(1.0838912725)]\n",
            "b:  [tensor(1.3939502239), tensor(0.7499175072), tensor(1.2948325872), tensor(1.2058972120), tensor(0.9586429000), tensor(1.7337404490), tensor(1.1925371885), tensor(1.3064808846), tensor(1.1503373384), tensor(0.9511311054), tensor(1.2653521299), tensor(1.1954845190), tensor(0.7529478669), tensor(1.1788216829), tensor(1.2066010237), tensor(0.9339417815), tensor(0.9407355189), tensor(1.2290902138), tensor(1.3266136646), tensor(1.3607826233)]\n",
            "c:  [tensor(-0.2891660631), tensor(0.5844794512), tensor(0.3085795939), tensor(-0.5398899913), tensor(0.0223282818), tensor(-0.0083818026), tensor(0.2057055533), tensor(0.0742577687), tensor(0.9382879734), tensor(-0.0431240797), tensor(-0.0085110590), tensor(-0.2891202569), tensor(-0.0809802786), tensor(0.6076671481), tensor(-0.0223639160), tensor(0.0346668735), tensor(-0.1823955923), tensor(-0.0829754993)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([11.2217512131,  5.2333641052,  8.5408210754,  5.7017650604,\n",
            "         9.7275142670, 11.7211284637,  5.5930485725,  7.3388357162,\n",
            "         6.7668271065,  8.2306795120,  8.7409334183,  6.9439001083,\n",
            "         5.0986027718,  7.7466015816,  5.7735199928,  4.8258047104,\n",
            "         5.3841524124,  8.9628343582, 10.2004747391,  8.6264638901])\n",
            "btensor.grad: tensor([ 8.1113138199, 10.9639053345,  8.7505960464, 10.4410314560,\n",
            "        10.8502693176,  8.0317668915,  9.0266437531,  9.0791015625,\n",
            "         9.4173860550, 10.5903148651, 10.0012044907,  9.1534194946,\n",
            "        10.7220344543, 10.4914321899, 11.7982959747, 10.0690317154,\n",
            "        10.7539253235,  9.2056531906,  9.8797369003,  8.3985910416])\n",
            "ctensor.grad: tensor([-57.7754669189,  50.3462829590,  41.4240341187, -12.1134366989,\n",
            "         -0.7542317510, -57.2078628540, -28.5939483643, -59.5286827087,\n",
            "         22.2855758667,   1.5103842020, 111.6172561646,  54.9859848022,\n",
            "        119.0168304443,  18.8459281921,   1.1535683870,  83.6894073486,\n",
            "         39.8025970459,  91.2323150635])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(686.0775756836, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7951436639), tensor(1.6104159355), tensor(1.0242592096), tensor(1.2136347294), tensor(0.7341541648), tensor(0.7402183414), tensor(1.4195433855), tensor(1.0109786987), tensor(1.1320084333), tensor(0.9304839373), tensor(0.9092673659), tensor(0.8528680205), tensor(1.6461558342), tensor(1.1137287617), tensor(1.4831711054), tensor(1.6132732630), tensor(1.4359743595), tensor(1.0627623796), tensor(0.8885294795), tensor(1.0940070152)]\n",
            "b:  [tensor(1.3993791342), tensor(0.7630121112), tensor(1.3016592264), tensor(1.2148461342), tensor(0.9724393487), tensor(1.7377629280), tensor(1.2009570599), tensor(1.3157359362), tensor(1.1584447622), tensor(0.9614235163), tensor(1.2753335238), tensor(1.2046620846), tensor(0.7658013701), tensor(1.1915531158), tensor(1.2217396498), tensor(0.9470736384), tensor(0.9512725472), tensor(1.2363834381), tensor(1.3378014565), tensor(1.3667303324)]\n",
            "c:  [tensor(-0.3062011600), tensor(0.6131299138), tensor(0.3322172165), tensor(-0.5399301052), tensor(0.0229266137), tensor(0.0127076041), tensor(0.2115710825), tensor(0.0861570686), tensor(0.9390199184), tensor(-0.0440619104), tensor(-0.0355618931), tensor(-0.2950149179), tensor(-0.0938327089), tensor(0.6123174429), tensor(-0.0229551271), tensor(0.0250911899), tensor(-0.1842463464), tensor(-0.0843860134)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.1085314751, -0.5865302682, -1.5569412708, -0.1054558754,\n",
            "         0.3341998458, -0.8921931982, -0.2740698457, -0.8778033853,\n",
            "         0.0890082568, -0.8788484335, -1.0949947834, -0.0214494467,\n",
            "        -0.3335624039, -0.9657882452, -0.2905009091, -0.3610631227,\n",
            "        -0.1840844750, -1.3766429424, -1.5655970573, -2.0231549740])\n",
            "btensor.grad: tensor([-1.0857787132, -2.6189198494, -1.3653337955, -1.7897871733,\n",
            "        -2.7592866421, -0.8044965863, -1.6839785576, -1.8510136604,\n",
            "        -1.6214869022, -2.0584762096, -1.9962822199, -1.8355181217,\n",
            "        -2.5706961155, -2.5462753773, -3.0277152061, -2.6263711452,\n",
            "        -2.1074056625, -1.4586551189, -2.2375643253, -1.1895432472])\n",
            "ctensor.grad: tensor([ 17.0350894928, -28.6504669189, -23.6376056671,   0.0400849283,\n",
            "         -0.5983325839, -21.0894050598,  -5.8655333519, -11.8992996216,\n",
            "         -0.7319676280,   0.9378296137,  27.0508327484,   5.8946576118,\n",
            "         12.8524293900,  -4.6502795219,   0.5912100673,   9.5756826401,\n",
            "          1.8507579565,   1.4105124474])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(683.6721191406, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8149736524), tensor(1.6160079241), tensor(1.0415811539), tensor(1.2164117098), tensor(0.7449700236), tensor(0.7600018978), tensor(1.4247087240), tensor(1.0224133730), tensor(1.1365101337), tensor(0.9430100322), tensor(0.9239048958), tensor(0.8585304618), tensor(1.6504461765), tensor(1.1253376007), tensor(1.4888592958), tensor(1.6174614429), tensor(1.4400893450), tensor(1.0795193911), tensor(0.9083598852), tensor(1.1137456894)]\n",
            "b:  [tensor(1.4088251591), tensor(0.7817821503), tensor(1.3139896393), tensor(1.2308748960), tensor(0.9928344488), tensor(1.7466133833), tensor(1.2141038179), tensor(1.3310611248), tensor(1.1718685627), tensor(0.9789923429), tensor(1.2913156748), tensor(1.2185816765), tensor(0.7832661271), tensor(1.2104048729), tensor(1.2435587645), tensor(0.9648400545), tensor(0.9680646062), tensor(1.2492561340), tensor(1.3557400703), tensor(1.3781716824)]\n",
            "c:  [tensor(-0.3273276687), tensor(0.6361557841), tensor(0.3510982096), tensor(-0.5476325154), tensor(0.0235025324), tensor(0.0104142185), tensor(0.2053272873), tensor(0.0736512840), tensor(0.9563606977), tensor(-0.0447406210), tensor(-0.0095391888), tensor(-0.2774032354), tensor(-0.0588362403), tensor(0.6256675720), tensor(-0.0234553423), tensor(0.0428220928), tensor(-0.1730872840), tensor(-0.0601729006)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-3.9660003185, -1.1183872223, -3.4643890858, -0.5553977489,\n",
            "        -2.1631741524, -3.9567134380, -1.0330750942, -2.2869348526,\n",
            "        -0.9003406763, -2.5052161217, -2.9275119305, -1.1324875355,\n",
            "        -0.8580777049, -2.3217630386, -1.1376353502, -0.8376376629,\n",
            "        -0.8229892254, -3.3514134884, -3.9660818577, -3.9477365017])\n",
            "btensor.grad: tensor([-1.8892126083, -3.7540082932, -2.4660897255, -3.2057464123,\n",
            "        -4.0790257454, -1.7700831890, -2.6293408871, -3.0650274754,\n",
            "        -2.6847579479, -3.5137670040, -3.1964297295, -2.7839224339,\n",
            "        -3.4929542542, -3.7703452110, -4.3638134003, -3.5532774925,\n",
            "        -3.3584089279, -2.5745317936, -3.5877189636, -2.2882771492])\n",
            "ctensor.grad: tensor([ 21.1265010834, -23.0258502960, -18.8810024261,   7.7024188042,\n",
            "         -0.5759190917,   2.2933850288,   6.2437915802,  12.5057802200,\n",
            "        -17.3408012390,   0.6787101626, -26.0227031708, -17.6116733551,\n",
            "        -34.9964675903, -13.3501443863,   0.5002155304, -17.7308998108,\n",
            "        -11.1590671539, -24.2131137848])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(684.9735107422, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8031201959), tensor(1.6101126671), tensor(1.0356260538), tensor(1.2065299749), tensor(0.7285116315), tensor(0.7472265959), tensor(1.4159702063), tensor(1.0144935846), tensor(1.1237355471), tensor(0.9339626431), tensor(0.9139426947), tensor(0.8461026549), tensor(1.6434159279), tensor(1.1165133715), tensor(1.4802265167), tensor(1.6108938456), tensor(1.4313435555), tensor(1.0704115629), tensor(0.8995711207), tensor(1.1102908850)]\n",
            "b:  [tensor(1.4002751112), tensor(0.7800922990), tensor(1.3071554899), tensor(1.2246731520), tensor(0.9911063910), tensor(1.7382079363), tensor(1.2091814280), tensor(1.3276841640), tensor(1.1658856869), tensor(0.9729334116), tensor(1.2873381376), tensor(1.2141834497), tensor(0.7809948325), tensor(1.2082463503), tensor(1.2437837124), tensor(0.9655270576), tensor(0.9632931948), tensor(1.2424174547), tensor(1.3526841402), tensor(1.3715153933)]\n",
            "c:  [tensor(-0.3314733207), tensor(0.6546817422), tensor(0.3660181761), tensor(-0.5382065773), tensor(0.0243943799), tensor(0.0647102147), tensor(0.2257965654), tensor(0.1161228940), tensor(0.9366165400), tensor(-0.0461862721), tensor(-0.1022589952), tensor(-0.3111005127), tensor(-0.1338058859), tensor(0.6156625152), tensor(-0.0244395826), tensor(-0.0117926970), tensor(-0.1931457371), tensor(-0.1044916734)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([2.3706879616, 1.1790529490, 1.1910226345, 1.9763516188, 3.2916796207,\n",
            "        2.5550580025, 1.7477003336, 1.5839643478, 2.5549082756, 1.8094828129,\n",
            "        1.9924390316, 2.4855649471, 1.4060500860, 1.7648476362, 1.7265517712,\n",
            "        1.3135186434, 1.7491664886, 1.8215644360, 1.7577583790, 0.6909607649])\n",
            "btensor.grad: tensor([ 1.7100005150,  0.3379719853,  1.3668186665,  1.2403473854,\n",
            "         0.3456059694,  1.6810989380,  0.9844831228,  0.6753824949,\n",
            "         1.1965842247,  1.2117908001,  0.7955103517,  0.8796411753,\n",
            "         0.4542608261,  0.4317038655, -0.0449873731, -0.1374041438,\n",
            "         0.9542802572,  1.3677443266,  0.6111905575,  1.3312550783])\n",
            "ctensor.grad: tensor([  4.1456394196, -18.5259609222, -14.9199724197,  -9.4259157181,\n",
            "         -0.8918474913, -54.2959899902, -20.4692802429, -42.4716072083,\n",
            "         19.7441711426,   1.4456516504,  92.7198028564,  33.6972770691,\n",
            "         74.9696426392,  10.0050611496,   0.9842408895,  54.6147880554,\n",
            "         20.0584526062,  44.3187713623])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(710.4082641602, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.9010292292), tensor(1.6349540949), tensor(1.0986183882), tensor(1.2334640026), tensor(0.8421172500), tensor(0.8573566675), tensor(1.4471656084), tensor(1.0697691441), tensor(1.1667118073), tensor(1.0004132986), tensor(0.9834594727), tensor(0.8992844820), tensor(1.6675306559), tensor(1.1673476696), tensor(1.5158598423), tensor(1.6329391003), tensor(1.4606868029), tensor(1.1382507086), tensor(0.9792908430), tensor(1.1738333702)]\n",
            "b:  [tensor(1.4345872402), tensor(0.8211925626), tensor(1.3491485119), tensor(1.2702785730), tensor(1.0353063345), tensor(1.7752100229), tensor(1.2463475466), tensor(1.3709063530), tensor(1.2070417404), tensor(1.0224138498), tensor(1.3322696686), tensor(1.2506123781), tensor(0.8214347959), tensor(1.2526777983), tensor(1.2928233147), tensor(1.0016971827), tensor(1.0066092014), tensor(1.2859315872), tensor(1.3989382982), tensor(1.4123411179)]\n",
            "c:  [tensor(-0.3379318714), tensor(0.6167631745), tensor(0.3476428986), tensor(-0.6104590297), tensor(0.0242075827), tensor(-0.1286296248), tensor(0.1393038332), tensor(-0.0630992576), tensor(1.0449842215), tensor(-0.0454571061), tensor(0.1704418510), tensor(-0.2006943226), tensor(0.1054005176), tensor(0.6919991970), tensor(-0.0240898617), tensor(0.1880813539), tensor(-0.1080977172), tensor(0.0721861199)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-19.5818099976,  -4.9682822227, -12.5984659195,  -5.3868160248,\n",
            "        -22.7211227417, -22.0260200500,  -6.2390871048, -11.0551042557,\n",
            "         -8.5952644348, -13.2901306152, -13.9033622742, -10.6363620758,\n",
            "         -4.8229498863, -10.1668529510,  -7.1266736984,  -4.4090557098,\n",
            "         -5.8686599731, -13.5678234100, -15.9439487457, -12.7084875107])\n",
            "btensor.grad: tensor([-6.8624205589, -8.2200489044, -8.3986082077, -9.1210927963,\n",
            "        -8.8399887085, -7.4004182816, -7.4332323074, -8.6444330215,\n",
            "        -8.2312049866, -9.8960771561, -8.9863033295, -7.2857775688,\n",
            "        -8.0879917145, -8.8862829208, -9.8079223633, -7.2340340614,\n",
            "        -8.6631984711, -8.7028179169, -9.2508306503, -8.1651506424])\n",
            "ctensor.grad: tensor([ 6.4585595131e+00,  3.7918560028e+01,  1.8375265121e+01,\n",
            "         7.2252426147e+01,  1.8679681420e-01,  1.9333982849e+02,\n",
            "         8.6492729187e+01,  1.7922213745e+02, -1.0836766815e+02,\n",
            "        -7.2916686535e-01, -2.7270083618e+02, -1.1040618134e+02,\n",
            "        -2.3920639038e+02, -7.6336677551e+01, -3.4972155094e-01,\n",
            "        -1.9987405396e+02, -8.5048019409e+01, -1.7667778015e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(780.5709838867, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8352755904), tensor(1.6056524515), tensor(1.0484415293), tensor(1.2026346922), tensor(0.7855679393), tensor(0.7879524231), tensor(1.4157881737), tensor(1.0259829760), tensor(1.1299755573), tensor(0.9516814351), tensor(0.9313520193), tensor(0.8605576754), tensor(1.6391748190), tensor(1.1227591038), tensor(1.4833388329), tensor(1.6065778732), tensor(1.4312307835), tensor(1.0855559111), tensor(0.9190381765), tensor(1.1200091839)]\n",
            "b:  [tensor(1.3887451887), tensor(0.7416344881), tensor(1.2968069315), tensor(1.2039996386), tensor(0.9656275511), tensor(1.7297687531), tensor(1.1873025894), tensor(1.3095091581), tensor(1.1472642422), tensor(0.9575483203), tensor(1.2672799826), tensor(1.1934056282), tensor(0.7466721535), tensor(1.1857271194), tensor(1.2168180943), tensor(0.9261656404), tensor(0.9370103478), tensor(1.2296543121), tensor(1.3362213373), tensor(1.3612396717)]\n",
            "c:  [tensor(-0.2540222406), tensor(0.5371822119), tensor(0.2710200548), tensor(-0.6079695821), tensor(0.0244487338), tensor(-0.1164247394), tensor(0.1457252949), tensor(-0.0488905162), tensor(1.0385062695), tensor(-0.0462928414), tensor(0.1335693151), tensor(-0.2206233144), tensor(0.0611046888), tensor(0.6861141920), tensor(-0.0246873535), tensor(0.1602392495), tensor(-0.1221566647), tensor(0.0369105153)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([13.1507282257,  5.8603320122, 10.0353822708,  6.1658525467,\n",
            "        11.3098602295, 13.8808431625,  6.2754840851,  8.7572269440,\n",
            "         7.3472418785,  9.7463750839, 10.4214963913,  7.7453660965,\n",
            "         5.6711788177,  8.9177036285,  6.5042119026,  5.2722358704,\n",
            "         5.8911962509, 10.5389547348, 12.0505332947, 10.7648315430])\n",
            "btensor.grad: tensor([ 9.1684055328, 15.9116210938, 10.4683132172, 13.2557868958,\n",
            "        13.9357547760,  9.0882511139, 11.8089809418, 12.2794322968,\n",
            "        11.9555034637, 12.9731054306, 12.9979343414, 11.4413566589,\n",
            "        14.9525232315, 13.3901424408, 15.2010374069, 15.1063051224,\n",
            "        13.9197759628, 11.2554454803, 12.5433940887, 10.2202863693])\n",
            "ctensor.grad: tensor([-83.9096374512,  79.5809783936,  76.6228408813,  -2.4894182682,\n",
            "         -0.2411517352, -12.2048816681,  -6.4214582443, -14.2087402344,\n",
            "          6.4779295921,   0.8357349038,  36.8725318909,  19.9289894104,\n",
            "         44.2958259583,   5.8850307465,   0.5974917412,  27.8421077728,\n",
            "         14.0589427948,  35.2756042480])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(739.8750610352, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7899580002), tensor(1.5933115482), tensor(1.0170791149), tensor(1.1910707951), tensor(0.7496116161), tensor(0.7385337353), tensor(1.4014148712), tensor(1.0017243624), tensor(1.1124311686), tensor(0.9239999652), tensor(0.9000164866), tensor(0.8420783877), tensor(1.6276842356), tensor(1.0976778269), tensor(1.4682232141), tensor(1.5963459015), tensor(1.4186553955), tensor(1.0525586605), tensor(0.8781268001), tensor(1.0854145288)]\n",
            "b:  [tensor(1.3699698448), tensor(0.7012225986), tensor(1.2718117237), tensor(1.1688562632), tensor(0.9284479022), tensor(1.7090758085), tensor(1.1582982540), tensor(1.2775548697), tensor(1.1188030243), tensor(0.9255985022), tensor(1.2332143784), tensor(1.1652816534), tensor(0.7104433179), tensor(1.1501092911), tensor(1.1726512909), tensor(0.8853265643), tensor(0.9000196457), tensor(1.2030965090), tensor(1.3021308184), tensor(1.3372850418)]\n",
            "c:  [tensor(-0.2082688361), tensor(0.5012371540), tensor(0.2368940115), tensor(-0.6061158776), tensor(0.0246440675), tensor(-0.1065427214), tensor(0.1509126723), tensor(-0.0375737511), tensor(1.0293285847), tensor(-0.0472372286), tensor(0.0814126134), tensor(-0.2475831211), tensor(0.0014795475), tensor(0.6801189780), tensor(-0.0252568983), tensor(0.1301961243), tensor(-0.1370612085), tensor(0.0006276779)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([9.0635128021, 2.4681863785, 6.2724766731, 2.3127841949, 7.1912679672,\n",
            "        9.8837404251, 2.8746583462, 4.8517279625, 3.5088713169, 5.5362930298,\n",
            "        6.2671046257, 3.6958622932, 2.2981238365, 5.0162572861, 3.0231337547,\n",
            "        2.0463950634, 2.5150809288, 6.5994520187, 8.1822786331, 6.9189357758])\n",
            "btensor.grad: tensor([3.7550573349, 8.0823793411, 4.9990525246, 7.0286822319, 7.4359254837,\n",
            "        4.1385784149, 5.8008756638, 6.3908486366, 5.6922383308, 6.3899617195,\n",
            "        6.8131232262, 5.6248016357, 7.2457675934, 7.1235599518, 8.8333520889,\n",
            "        8.1678142548, 7.3981404305, 5.3115496635, 6.8181076050, 4.7909345627])\n",
            "ctensor.grad: tensor([-45.7534027100,  35.9450263977,  34.1260414124,  -1.8536782265,\n",
            "         -0.1953328401,  -9.8820199966,  -5.1873831749, -11.3167657852,\n",
            "          9.1776905060,   0.9443858862,  52.1567039490,  26.9598083496,\n",
            "         59.6251373291,   5.9952335358,   0.5695452094,  30.0431194305,\n",
            "         14.9045391083,  36.2828369141])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(719.7274780273, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7609503269), tensor(1.5909967422), tensor(0.9990711212), tensor(1.1905807257), tensor(0.7278966308), tensor(0.7060866952), tensor(1.3971898556), tensor(0.9906873703), tensor(1.1061440706), tensor(0.9107216001), tensor(0.8835313320), tensor(0.8358896375), tensor(1.6260823011), tensor(1.0856152773), tensor(1.4634795189), tensor(1.5951751471), tensor(1.4157496691), tensor(1.0336220264), tensor(0.8523555994), tensor(1.0658349991)]\n",
            "b:  [tensor(1.3660626411), tensor(0.6887503266), tensor(1.2633090019), tensor(1.1544510126), tensor(0.9136132002), tensor(1.7025010586), tensor(1.1490278244), tensor(1.2656595707), tensor(1.1103245020), tensor(0.9140459895), tensor(1.2202033997), tensor(1.1558275223), tensor(0.7006976604), tensor(1.1356983185), tensor(1.1520512104), tensor(0.8708783388), tensor(0.8856289983), tensor(1.1946638823), tensor(1.2871710062), tensor(1.3300174475)]\n",
            "c:  [tensor(-0.1879361719), tensor(0.5038625002), tensor(0.2339957505), tensor(-0.6047356129), tensor(0.0248097442), tensor(-0.0983632579), tensor(0.1551178694), tensor(-0.0284827799), tensor(1.0134979486), tensor(-0.0482915863), tensor(-0.0027954504), tensor(-0.2873629928), tensor(-0.0836729407), tensor(0.6737477183), tensor(-0.0258201212), tensor(0.0960690081), tensor(-0.1532498896), tensor(-0.0372346938)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([5.8015375137, 0.4629618227, 3.6016030312, 0.0980231762, 4.3429937363,\n",
            "        6.4894051552, 0.8450064659, 2.2073926926, 1.2574279308, 2.6556725502,\n",
            "        3.2970304489, 1.2377519608, 0.3203987181, 2.4125137329, 0.9487369657,\n",
            "        0.2341434211, 0.5811449289, 3.7873237133, 5.1542425156, 3.9159090519])\n",
            "btensor.grad: tensor([0.7814356089, 2.4944534302, 1.7005410194, 2.8810498714, 2.9669384956,\n",
            "        1.3149427176, 1.8540744781, 2.3790559769, 1.6957037449, 2.3104994297,\n",
            "        2.6021845341, 1.8908233643, 1.9491297007, 2.8821976185, 4.1200127602,\n",
            "        2.8896472454, 2.8781349659, 1.6865153313, 2.9919738770, 1.4535119534])\n",
            "ctensor.grad: tensor([-20.3326644897,  -2.6253235340,   2.8982605934,  -1.3802851439,\n",
            "         -0.1656764895,  -8.1794633865,  -4.2052011490,  -9.0909700394,\n",
            "         15.8306827545,   1.0543589592,  84.2080612183,  39.7798690796,\n",
            "         85.1524810791,   6.3712882996,   0.5632232428,  34.1271095276,\n",
            "         16.1886863708,  37.8623695374])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(700.3308105469, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7559678555), tensor(1.5979446173), tensor(0.9985167980), tensor(1.1987698078), tensor(0.7219121456), tensor(0.6996414661), tensor(1.4025969505), tensor(0.9938592315), tensor(1.1105268002), tensor(0.9130868316), tensor(0.8862777352), tensor(0.8406389356), tensor(1.6329396963), tensor(1.0891320705), tensor(1.4684883356), tensor(1.6019961834), tensor(1.4214514494), tensor(1.0353460312), tensor(0.8497582674), tensor(1.0661889315)]\n",
            "b:  [tensor(1.3762514591), tensor(0.7029735446), tensor(1.2719538212), tensor(1.1631860733), tensor(0.9253666401), tensor(1.7101534605), tensor(1.1588746309), tensor(1.2734961510), tensor(1.1204018593), tensor(0.9251893759), tensor(1.2289353609), tensor(1.1663891077), tensor(0.7156529427), tensor(1.1461073160), tensor(1.1609107256), tensor(0.8831482530), tensor(0.8962143064), tensor(1.2044416666), tensor(1.2949122190), tensor(1.3389976025)]\n",
            "c:  [tensor(-0.1960863918), tensor(0.5473176241), tensor(0.2597506344), tensor(-0.6041156650), tensor(0.0249508582), tensor(-0.0927742422), tensor(0.1577874571), tensor(-0.0227302313), tensor(1.0068378448), tensor(-0.0491755567), tensor(-0.0529314950), tensor(-0.3078519702), tensor(-0.1225548014), tensor(0.6706949472), tensor(-0.0263282955), tensor(0.0694914758), tensor(-0.1645269096), tensor(-0.0616017468)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.9964905977, -1.3895684481,  0.1108599007, -1.6378049850,\n",
            "         1.1969003677,  1.2890429497, -1.0814086199, -0.6343781352,\n",
            "        -0.8765525222, -0.4730431139, -0.5492843390, -0.9498560429,\n",
            "        -1.3714804649, -0.7033501267, -1.0017528534, -1.3642175198,\n",
            "        -1.1403654814, -0.3447916508,  0.5194630623, -0.0707795769])\n",
            "btensor.grad: tensor([-2.0377702713, -2.8446400166, -1.7289586067, -1.7470045090,\n",
            "        -2.3506917953, -1.5304847956, -1.9693582058, -1.5673060417,\n",
            "        -2.0154623985, -2.2286782265, -1.7463979721, -2.1123232841,\n",
            "        -2.9910554886, -2.0818066597, -1.7718969584, -2.4539797306,\n",
            "        -2.1170644760, -1.9555562735, -1.5482357740, -1.7960277796])\n",
            "ctensor.grad: tensor([  8.1502227783, -43.4551162720, -25.7548866272,  -0.6199446917,\n",
            "         -0.1411140263,  -5.5890192986,  -2.6695830822,  -5.7525486946,\n",
            "          6.6601347923,   0.8839691877,  50.1360435486,  20.4889869690,\n",
            "         38.8818588257,   3.0527822971,   0.5081745386,  26.5775279999,\n",
            "         11.2770128250,  24.3670520782])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(695.1882324219, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7674914002), tensor(1.6074713469), tensor(1.0087006092), tensor(1.2091653347), tensor(0.7315514088), tensor(0.7122991085), tensor(1.4134513140), tensor(1.0059094429), tensor(1.1219043732), tensor(0.9247139096), tensor(0.9022871256), tensor(0.8527008295), tensor(1.6425584555), tensor(1.1016979218), tensor(1.4791404009), tensor(1.6109633446), tensor(1.4312366247), tensor(1.0516543388), tensor(0.8631608486), tensor(1.0786750317)]\n",
            "b:  [tensor(1.3928345442), tensor(0.7272692919), tensor(1.2891647816), tensor(1.1843183041), tensor(0.9481466413), tensor(1.7249546051), tensor(1.1769692898), tensor(1.2912279367), tensor(1.1388244629), tensor(0.9477154613), tensor(1.2475779057), tensor(1.1850205660), tensor(0.7384162545), tensor(1.1667070389), tensor(1.1813155413), tensor(0.9044343829), tensor(0.9178233147), tensor(1.2229635715), tensor(1.3141822815), tensor(1.3561952114)]\n",
            "c:  [tensor(-0.2218124866), tensor(0.5874306560), tensor(0.2962712049), tensor(-0.6040543318), tensor(0.0250937343), tensor(-0.0885393098), tensor(0.1596265882), tensor(-0.0187818930), tensor(1.0295175314), tensor(-0.0495563410), tensor(-0.0132497735), tensor(-0.2903198302), tensor(-0.0808183551), tensor(0.6747128367), tensor(-0.0267699119), tensor(0.0615841001), tensor(-0.1668340862), tensor(-0.0637843236)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-2.3047065735, -1.9053521156, -2.0367569923, -2.0791082382,\n",
            "        -1.9278585911, -2.5315306187, -2.1708781719, -2.4100394249,\n",
            "        -2.2755122185, -2.3254199028, -3.2018837929, -2.4123764038,\n",
            "        -1.9237467051, -2.5131640434, -2.1304202080, -1.7934314013,\n",
            "        -1.9570440054, -3.2616636753, -2.6805157661, -2.4972121716])\n",
            "btensor.grad: tensor([-3.3166155815, -4.8591527939, -3.4421942234, -4.2264471054,\n",
            "        -4.5560059547, -2.9602179527, -3.6189358234, -3.5463612080,\n",
            "        -3.6845326424, -4.5052213669, -3.7285017967, -3.7262802124,\n",
            "        -4.5526595116, -4.1199531555, -4.0809669495, -4.2572278976,\n",
            "        -4.3218078613, -3.7043862343, -3.8540036678, -3.4395124912])\n",
            "ctensor.grad: tensor([ 25.7260856628, -40.1130561829, -36.5205574036,  -0.0613179542,\n",
            "         -0.1428760141,  -4.2349305153,  -1.8391268253,  -3.9483389854,\n",
            "        -22.6797351837,   0.3807835281, -39.6817207336, -17.5321254730,\n",
            "        -41.7364463806,  -4.0179028511,   0.4416170716,   7.9073758125,\n",
            "          2.3071720600,   2.1825752258])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(692.1972045898, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7593355179), tensor(1.6068624258), tensor(1.0034945011), tensor(1.2073415518), tensor(0.7185928822), tensor(0.7039403915), tensor(1.4112737179), tensor(1.0020282269), tensor(1.1170703173), tensor(0.9195550680), tensor(0.8980503678), tensor(0.8471719623), tensor(1.6417123079), tensor(1.0983126163), tensor(1.4764771461), tensor(1.6100184917), tensor(1.4287930727), tensor(1.0477075577), tensor(0.8570500016), tensor(1.0759156942)]\n",
            "b:  [tensor(1.3918458223), tensor(0.7336953282), tensor(1.2887432575), tensor(1.1859139204), tensor(0.9522035122), tensor(1.7232816219), tensor(1.1789932251), tensor(1.2928187847), tensor(1.1397019625), tensor(0.9483315349), tensor(1.2490338087), tensor(1.1874703169), tensor(0.7437284589), tensor(1.1698828936), tensor(1.1854754686), tensor(0.9118565917), tensor(0.9211022258), tensor(1.2232292891), tensor(1.3157641888), tensor(1.3561608791)]\n",
            "c:  [tensor(-0.2174475193), tensor(0.6200277209), tensor(0.3181324303), tensor(-0.6030063033), tensor(0.0252908841), tensor(-0.0801854283), tensor(0.1634045541), tensor(-0.0105691189), tensor(1.0158866644), tensor(-0.0507155359), tensor(-0.0860467702), tensor(-0.3190995455), tensor(-0.1380666792), tensor(0.6685935259), tensor(-0.0275109336), tensor(0.0200525708), tensor(-0.1838396341), tensor(-0.0982882231)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([1.6311749220, 0.1217935979, 1.0412306786, 0.3647547960, 2.5917088985,\n",
            "        1.6717455387, 0.4355223775, 0.7762323618, 0.9668132663, 1.0317673683,\n",
            "        0.8473482132, 1.1057720184, 0.1692354381, 0.6770606041, 0.5326551199,\n",
            "        0.1889815778, 0.4886996746, 0.7893471718, 1.2221684456, 0.5518577099])\n",
            "btensor.grad: tensor([ 0.1977346390, -1.2852100134,  0.0843004137, -0.3191210926,\n",
            "        -0.8113769293,  0.3346084356, -0.4047799110, -0.3181765676,\n",
            "        -0.1754931211, -0.1232179403, -0.2911879420, -0.4899432063,\n",
            "        -1.0624381304, -0.6351636648, -0.8319962621, -1.4844441414,\n",
            "        -0.6557868719, -0.0531479716, -0.3163878322,  0.0068653226])\n",
            "ctensor.grad: tensor([ -4.3649682999, -32.5970802307, -21.8612251282,  -1.0479991436,\n",
            "         -0.1971502751,  -8.3538827896,  -3.7779641151,  -8.2127733231,\n",
            "         13.6308984756,   1.1591947079,  72.7969894409,  28.7797107697,\n",
            "         57.2483253479,   6.1192893982,   0.7410219312,  41.5315284729,\n",
            "         17.0055484772,  34.5038986206])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(693.0644531250, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7906587124), tensor(1.6178051233), tensor(1.0260376930), tensor(1.2187434435), tensor(0.7500383258), tensor(0.7398660779), tensor(1.4262559414), tensor(1.0231145620), tensor(1.1351938248), tensor(0.9420221448), tensor(0.9273685217), tensor(0.8668619990), tensor(1.6525624990), tensor(1.1196596622), tensor(1.4921535254), tensor(1.6198270321), tensor(1.4418659210), tensor(1.0780663490), tensor(0.8878482580), tensor(1.1011751890)]\n",
            "b:  [tensor(1.4119303226), tensor(0.7634531856), tensor(1.3124970198), tensor(1.2156007290), tensor(0.9811609983), tensor(1.7435694933), tensor(1.2025960684), tensor(1.3184460402), tensor(1.1642373800), tensor(0.9783075452), tensor(1.2756041288), tensor(1.2112022638), tensor(0.7707396746), tensor(1.1972165108), tensor(1.2150382996), tensor(0.9383003116), tensor(0.9498822093), tensor(1.2484484911), tensor(1.3438954353), tensor(1.3794230223)]\n",
            "c:  [tensor(-0.2613869905), tensor(0.6407186985), tensor(0.3470518291), tensor(-0.6040434837), tensor(0.0254524630), tensor(-0.0782174394), tensor(0.1636817753), tensor(-0.0098632053), tensor(1.0665758848), tensor(-0.0506971478), tensor(0.0305315703), tensor(-0.2711512446), tensor(-0.0287358984), tensor(0.6939723492), tensor(-0.0277266614), tensor(0.0719366670), tensor(-0.1611581892), tensor(-0.0442778766)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-6.2646408081, -2.1885414124, -4.5086364746, -2.2803688049,\n",
            "        -6.2890849113, -7.1851320267, -2.9964361191, -4.2172703743,\n",
            "        -3.6247003078, -4.4934201241, -5.8636322021, -3.9380044937,\n",
            "        -2.1700434685, -4.2694106102, -3.1352832317, -1.9616996050,\n",
            "        -2.6145579815, -6.0717678070, -6.1596550941, -5.0518879890])\n",
            "btensor.grad: tensor([-4.0168881416, -5.9515700340, -4.7507553101, -5.9373712540,\n",
            "        -5.7915019989, -4.0575776100, -4.7205638885, -5.1254596710,\n",
            "        -4.9070930481, -5.9952030182, -5.3140649796, -4.7463927269,\n",
            "        -5.4022479057, -5.4667282104, -5.9125618935, -5.2887449265,\n",
            "        -5.7559938431, -5.0438370705, -5.6262454987, -4.6524186134])\n",
            "ctensor.grad: tensor([ 4.3939472198e+01, -2.0690994263e+01, -2.8919410706e+01,\n",
            "         1.0371605158e+00, -1.6157850623e-01, -1.9679914713e+00,\n",
            "        -2.7722290158e-01, -7.0591348410e-01, -5.0689262390e+01,\n",
            "        -1.8387440592e-02, -1.1657833862e+02, -4.7948291779e+01,\n",
            "        -1.0933077240e+02, -2.5378807068e+01,  2.1572804451e-01,\n",
            "        -5.1884090424e+01, -2.2681442261e+01, -5.4010345459e+01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(708.8280029297, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7561965585), tensor(1.6033785343), tensor(1.0003212690), tensor(1.2022254467), tensor(0.7167592049), tensor(0.7040455341), tensor(1.4095472097), tensor(1.0010111332), tensor(1.1136379242), tensor(0.9170020223), tensor(0.8999268413), tensor(0.8442751765), tensor(1.6385358572), tensor(1.0963933468), tensor(1.4747601748), tensor(1.6058833599), tensor(1.4255095720), tensor(1.0497211218), tensor(0.8564633727), tensor(1.0771182775)]\n",
            "b:  [tensor(1.3886686563), tensor(0.7415843010), tensor(1.2887592316), tensor(1.1897841692), tensor(0.9551618695), tensor(1.7208049297), tensor(1.1817671061), tensor(1.2975504398), tensor(1.1413962841), tensor(0.9492893219), tensor(1.2520881891), tensor(1.1891329288), tensor(0.7486724257), tensor(1.1722238064), tensor(1.1896048784), tensor(0.9202374220), tensor(0.9249572158), tensor(1.2242207527), tensor(1.3191652298), tensor(1.3574514389)]\n",
            "c:  [tensor(-0.2230578363), tensor(0.6382611394), tensor(0.3461768925), tensor(-0.6004870534), tensor(0.0257751048), tensor(-0.0589244887), tensor(0.1729664505), tensor(0.0100204572), tensor(1.0331428051), tensor(-0.0523150563), tensor(-0.1227466464), tensor(-0.3397430480), tensor(-0.1700015664), tensor(0.6735478640), tensor(-0.0288803820), tensor(-0.0197467431), tensor(-0.2017814815), tensor(-0.1322886944)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([6.8924365044, 2.8853216171, 5.1432867050, 3.3035936356, 6.6558208466,\n",
            "        7.1641068459, 3.3417406082, 4.4206790924, 4.3111710548, 5.0040287971,\n",
            "        5.4883365631, 4.5173625946, 2.8053350449, 4.6532568932, 3.4786660671,\n",
            "        2.7887361050, 3.2712616920, 5.6690397263, 6.2769765854, 4.8113722801])\n",
            "btensor.grad: tensor([4.6523318291, 4.3737754822, 4.7475686073, 5.1633057594, 5.1998252869,\n",
            "        4.5529026985, 4.1657872200, 4.1791229248, 4.5682277679, 5.8036508560,\n",
            "        4.7031807899, 4.4138722420, 4.4134511948, 4.9985466003, 5.0866951942,\n",
            "        3.6125776768, 4.9850039482, 4.8455524445, 4.9460396767, 4.3943243027])\n",
            "ctensor.grad: tensor([-38.3291435242,   2.4575684071,   0.8749461174,  -3.5564253330,\n",
            "         -0.3226424158, -19.2929496765,  -9.2846708298, -19.8836612701,\n",
            "         33.4330291748,   1.6179071665, 153.2782135010,  68.5917968750,\n",
            "        141.2656555176,  20.4245128632,   1.1537196636,  91.6834030151,\n",
            "         40.6232986450,  88.0108032227])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(711.9833984375, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8240490556), tensor(1.6249785423), tensor(1.0476257801), tensor(1.2279945612), tensor(0.8033859134), tensor(0.7822374105), tensor(1.4382746220), tensor(1.0445649624), tensor(1.1550667286), tensor(0.9693582654), tensor(0.9576594830), tensor(0.8909681439), tensor(1.6599974632), tensor(1.1394349337), tensor(1.5067240000), tensor(1.6255691051), tensor(1.4535129070), tensor(1.1060730219), tensor(0.9181431532), tensor(1.1245553493)]\n",
            "b:  [tensor(1.4236838818), tensor(0.7832280993), tensor(1.3297848701), tensor(1.2355873585), tensor(0.9971088767), tensor(1.7574954033), tensor(1.2192293406), tensor(1.3391561508), tensor(1.1822141409), tensor(0.9965497851), tensor(1.2962151766), tensor(1.2261883020), tensor(0.7890111208), tensor(1.2141252756), tensor(1.2356491089), tensor(0.9569864869), tensor(0.9687827826), tensor(1.2668802738), tensor(1.3633761406), tensor(1.3971514702)]\n",
            "c:  [tensor(-0.3107632995), tensor(0.6198049188), tensor(0.3450033069), tensor(-0.6053158045), tensor(0.0259139538), tensor(-0.0667507350), tensor(0.1678076982), tensor(-0.0009465935), tensor(1.1320260763), tensor(-0.0515161566), tensor(0.1126958579), tensor(-0.2503042817), tensor(0.0343998522), tensor(0.7404882312), tensor(-0.0284931585), tensor(0.1437728405), tensor(-0.1374151260), tensor(0.0105349123)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-13.5705041885,  -4.3200049400,  -9.4608993530,  -5.1538319588,\n",
            "        -17.3253421783, -15.6383771896,  -5.7454833984,  -8.7107696533,\n",
            "         -8.2857532501, -10.4712438583, -11.5465250015,  -9.3385982513,\n",
            "         -4.2923183441,  -8.6083154678,  -6.3927674294,  -3.9371540546,\n",
            "         -5.6006698608, -11.2703771591, -12.3359508514,  -9.4874124527])\n",
            "btensor.grad: tensor([-7.0030379295, -8.3287611008, -8.2051343918, -9.1606273651,\n",
            "        -8.3893995285, -7.3380923271, -7.4924526215, -8.3211507797,\n",
            "        -8.1635646820, -9.4520931244, -8.8253993988, -7.4110794067,\n",
            "        -8.0677347183, -8.3803024292, -9.2088451385, -7.3498120308,\n",
            "        -8.7651185989, -8.5318927765, -8.8421831131, -7.9400019646])\n",
            "ctensor.grad: tensor([ 8.7705474854e+01,  1.8456211090e+01,  1.1735864878e+00,\n",
            "         4.8287544250e+00, -1.3884866238e-01,  7.8262472153e+00,\n",
            "         5.1587448120e+00,  1.0967050552e+01, -9.8883277893e+01,\n",
            "        -7.9889869690e-01, -2.3544248962e+02, -8.9438766479e+01,\n",
            "        -2.0440141296e+02, -6.6940368652e+01, -3.8722431660e-01,\n",
            "        -1.6351956177e+02, -6.4366355896e+01, -1.4282359314e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(748.6845703125, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7705749869), tensor(1.6017225981), tensor(1.0074717999), tensor(1.2032552958), tensor(0.7558427453), tensor(0.7252460122), tensor(1.4130619764), tensor(1.0096291304), tensor(1.1246620417), tensor(0.9299930930), tensor(0.9145227671), tensor(0.8584752083), tensor(1.6376934052), tensor(1.1034084558), tensor(1.4804399014), tensor(1.6044744253), tensor(1.4295095205), tensor(1.0622191429), tensor(0.8686814904), tensor(1.0824475288)]\n",
            "b:  [tensor(1.3859707117), tensor(0.7298231721), tensor(1.2876055241), tensor(1.1856489182), tensor(0.9442859292), tensor(1.7204178572), tensor(1.1762999296), tensor(1.2947616577), tensor(1.1377040148), tensor(0.9449799657), tensor(1.2476125956), tensor(1.1827002764), tensor(0.7371035814), tensor(1.1634424925), tensor(1.1789124012), tensor(0.9065672755), tensor(0.9174771309), tensor(1.2228823900), tensor(1.3151388168), tensor(1.3567057848)]\n",
            "c:  [tensor(-0.2526059151), tensor(0.5691225529), tensor(0.2969408631), tensor(-0.5976456404), tensor(0.0264489688), tensor(-0.0288695209), tensor(0.1869721711), tensor(0.0391034819), tensor(1.1162718534), tensor(-0.0528054908), tensor(0.0279832184), tensor(-0.2926994860), tensor(-0.0594135448), tensor(0.7288109064), tensor(-0.0293955486), tensor(0.0886660665), tensor(-0.1640915275), tensor(-0.0539637282)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([10.6948108673,  4.6511869431,  8.0307931900,  4.9478640556,\n",
            "         9.5086288452, 11.3982753754,  5.0425257683,  6.9871773720,\n",
            "         6.0809388161,  7.8730378151,  8.6273450851,  6.4985918999,\n",
            "         4.4608082771,  7.2052888870,  5.2568306923,  4.2189388275,\n",
            "         4.8006820679,  8.7707815170,  9.8923339844,  8.4215593338])\n",
            "btensor.grad: tensor([ 7.5426292419, 10.6809835434,  8.4358673096,  9.9876985550,\n",
            "        10.5645875931,  7.4155106544,  8.5858888626,  8.8789091110,\n",
            "         8.9020338058, 10.3139638901,  9.7205152512,  8.6976156235,\n",
            "        10.3815050125, 10.1365547180, 11.3473329544, 10.0838441849,\n",
            "        10.2611331940,  8.7995748520,  9.6474771500,  8.0891361237])\n",
            "ctensor.grad: tensor([-58.1573867798,  50.6823883057,  48.0624275208,  -7.6701674461,\n",
            "         -0.5350155830, -37.8812141418, -19.1644706726, -40.0500717163,\n",
            "         15.7542362213,   1.2893338203,  84.7126388550,  42.3952026367,\n",
            "         93.8133926392,  11.6772956848,   0.9023897052,  55.1067733765,\n",
            "         26.6764068604,  64.4986343384])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(700.4584350586, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7503008246), tensor(1.5967473984), tensor(0.9938865900), tensor(1.1972835064), tensor(0.7322170734), tensor(0.7027839422), tensor(1.4055079222), tensor(0.9982622862), tensor(1.1129611731), tensor(0.9162154198), tensor(0.8981333375), tensor(0.8456920385), tensor(1.6329553127), tensor(1.0918167830), tensor(1.4722347260), tensor(1.5993170738), tensor(1.4221538305), tensor(1.0451967716), tensor(0.8497769237), tensor(1.0702540874)]\n",
            "b:  [tensor(1.3765050173), tensor(0.7242697477), tensor(1.2770633698), tensor(1.1742533445), tensor(0.9350057840), tensor(1.7099912167), tensor(1.1693607569), tensor(1.2865312099), tensor(1.1294519901), tensor(0.9325149655), tensor(1.2382431030), tensor(1.1749434471), tensor(0.7323666215), tensor(1.1543682814), tensor(1.1706806421), tensor(0.9031636119), tensor(0.9084848762), tensor(1.2127933502), tensor(1.3044555187), tensor(1.3474334478)]\n",
            "c:  [tensor(-0.2446634173), tensor(0.5848280191), tensor(0.3045929968), tensor(-0.5910037160), tensor(0.0269579887), tensor(0.0085398182), tensor(0.2037718445), tensor(0.0727795735), tensor(1.0926132202), tensor(-0.0540789180), tensor(-0.0830393434), tensor(-0.3405067623), tensor(-0.1566552222), tensor(0.7176863551), tensor(-0.0302092470), tensor(0.0326310880), tensor(-0.1881002933), tensor(-0.1069478542)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([4.0548310280, 0.9950436354, 2.7170362473, 1.1943564415, 4.7251343727,\n",
            "        4.4924173355, 1.5108206272, 2.2733628750, 2.3401827812, 2.7555303574,\n",
            "        3.2778890133, 2.5566337109, 0.9476146102, 2.3183312416, 1.6410408020,\n",
            "        1.0314755440, 1.4711490870, 3.4044752121, 3.7809088230, 2.4386937618])\n",
            "btensor.grad: tensor([1.8931469917, 1.1106848717, 2.1084294319, 2.2791140079, 1.8560323715,\n",
            "        2.0853321552, 1.3878426552, 1.6460970640, 1.6504094601, 2.4930002689,\n",
            "        1.8739045858, 1.5513582230, 0.9473910332, 1.8148443699, 1.6463462114,\n",
            "        0.6807309389, 1.7984485626, 2.0178155899, 2.1366634369, 1.8544600010])\n",
            "ctensor.grad: tensor([ -7.9425001144, -15.7054843903,  -7.6521410942,  -6.6419377327,\n",
            "         -0.5090200901, -37.4093360901, -16.7996788025, -33.6760902405,\n",
            "         23.6585731506,   1.2734262943, 111.0225601196,  47.8072776794,\n",
            "         97.2416763306,  11.1245765686,   0.8136991858,  56.0349769592,\n",
            "         24.0087604523,  52.9841232300])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(693.5677490234, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7944269776), tensor(1.6108489037), tensor(1.0250538588), tensor(1.2117640972), tensor(0.7630386353), tensor(0.7500420213), tensor(1.4228065014), tensor(1.0230863094), tensor(1.1325541735), tensor(0.9423723817), tensor(0.9299830794), tensor(0.8652748466), tensor(1.6469035149), tensor(1.1181422472), tensor(1.4896385670), tensor(1.6116487980), tensor(1.4369759560), tensor(1.0794045925), tensor(0.8898405433), tensor(1.1032452583)]\n",
            "b:  [tensor(1.3987671137), tensor(0.7590231299), tensor(1.3024221659), tensor(1.2069000006), tensor(0.9693090320), tensor(1.7314907312), tensor(1.1965187788), tensor(1.3147003651), tensor(1.1570029259), tensor(0.9658859968), tensor(1.2674779892), tensor(1.2021398544), tensor(0.7647490501), tensor(1.1861732006), tensor(1.2061408758), tensor(0.9342992902), tensor(0.9412575960), tensor(1.2400643826), tensor(1.3357067108), tensor(1.3721480370)]\n",
            "c:  [tensor(-0.2867899537), tensor(0.5999074578), tensor(0.3323732316), tensor(-0.6025551558), tensor(0.0272346977), tensor(-0.0121817663), tensor(0.1906838864), tensor(0.0435221121), tensor(1.1377713680), tensor(-0.0540044084), tensor(0.0226145610), tensor(-0.2958541811), tensor(-0.0535802022), tensor(0.7406402826), tensor(-0.0303864703), tensor(0.0826769471), tensor(-0.1642919928), tensor(-0.0511610173)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-8.8252267838, -2.8203084469, -6.2334556580, -2.8961062431,\n",
            "        -6.1643166542, -9.4516105652, -3.4597246647, -4.9647951126,\n",
            "        -3.9186084270, -5.2313880920, -6.3699464798, -3.9165604115,\n",
            "        -2.7896413803, -5.2650918961, -3.4807622433, -2.4663479328,\n",
            "        -2.9644215107, -6.8415746689, -8.0127248764, -6.5982365608])\n",
            "btensor.grad: tensor([-4.4524297714, -6.9506797791, -5.0717611313, -6.5293345451,\n",
            "        -6.8606443405, -4.2998981476, -5.4316072464, -5.6338257790,\n",
            "        -5.5101795197, -6.6742062569, -5.8469753265, -5.4392700195,\n",
            "        -6.4764847755, -6.3609962463, -7.0920362473, -6.2271394730,\n",
            "        -6.5545444489, -5.4542098045, -6.2502403259, -4.9429106712])\n",
            "ctensor.grad: tensor([ 4.2126537323e+01, -1.5079463959e+01, -2.7780241013e+01,\n",
            "         1.1551447868e+01, -2.7670818567e-01,  2.0721584320e+01,\n",
            "         1.3087960243e+01,  2.9257457733e+01, -4.5158187866e+01,\n",
            "        -7.4509307742e-02, -1.0565390015e+02, -4.4652576447e+01,\n",
            "        -1.0307501221e+02, -2.2953901291e+01,  1.7722283304e-01,\n",
            "        -5.0045852661e+01, -2.3808300018e+01, -5.5786834717e+01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(701.6953735352, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7663499117), tensor(1.6003819704), tensor(1.0053867102), tensor(1.1991175413), tensor(0.7330613732), tensor(0.7199538350), tensor(1.4094446898), tensor(1.0054388046), tensor(1.1142067909), tensor(0.9219467044), tensor(0.9065638185), tensor(0.8457906842), tensor(1.6366297007), tensor(1.0997525454), tensor(1.4756822586), tensor(1.6011810303), tensor(1.4239214659), tensor(1.0555267334), tensor(0.8640163541), tensor(1.0852724314)]\n",
            "b:  [tensor(1.3808586597), tensor(0.7439198494), tensor(1.2840692997), tensor(1.1869798899), tensor(0.9511489272), tensor(1.7136898041), tensor(1.1815732718), tensor(1.2993927002), tensor(1.1402624846), tensor(0.9438919425), tensor(1.2502752542), tensor(1.1862487793), tensor(0.7499845624), tensor(1.1688176394), tensor(1.1898798943), tensor(0.9228710532), tensor(0.9232303500), tensor(1.2215325832), tensor(1.3174973726), tensor(1.3551669121)]\n",
            "c:  [tensor(-0.2718901038), tensor(0.6062253118), tensor(0.3315137029), tensor(-0.5916432142), tensor(0.0279197581), tensor(0.0434471406), tensor(0.2155798078), tensor(0.0932533666), tensor(1.1087179184), tensor(-0.0554356240), tensor(-0.1080444083), tensor(-0.3525055945), tensor(-0.1702923030), tensor(0.7251224518), tensor(-0.0313752927), tensor(0.0105067864), tensor(-0.1952651590), tensor(-0.1204602718)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([5.6154141426, 2.0933864117, 3.9334185123, 2.5293216705, 5.9954528809,\n",
            "        6.0176358223, 2.6723730564, 3.5294904709, 3.6694703102, 4.0851411819,\n",
            "        4.6838479042, 3.8968358040, 2.0547554493, 3.6779446602, 2.7912545204,\n",
            "        2.0935571194, 2.6109013557, 4.7755751610, 5.1648411751, 3.5945680141])\n",
            "btensor.grad: tensor([3.5816833973, 3.0206570625, 3.6705844402, 3.9840238094, 3.6320219040,\n",
            "        3.5601959229, 2.9891104698, 3.0615434647, 3.3480918407, 4.3988089561,\n",
            "        3.4405450821, 3.1782138348, 2.9528930187, 3.4711043835, 3.2522017956,\n",
            "        2.2856485844, 3.6054549217, 3.7063484192, 3.6418726444, 3.3962371349])\n",
            "ctensor.grad: tensor([-14.8998422623,  -6.3178682327,   0.8595155478, -10.9119691849,\n",
            "         -0.6850594878, -55.6289024353, -24.8959197998, -49.7312507629,\n",
            "         29.0534610748,   1.4312145710, 130.6589660645,  56.6514053345,\n",
            "        116.7120971680,  15.5178594589,   0.9888233542,  72.1701583862,\n",
            "         30.9731712341,  69.2992553711])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(699.5651245117, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8357330561), tensor(1.6192245483), tensor(1.0523037910), tensor(1.2189553976), tensor(0.7926912904), tensor(0.7947854400), tensor(1.4333676100), tensor(1.0426363945), tensor(1.1442824602), tensor(0.9640028477), tensor(0.9543507695), tensor(0.8776381612), tensor(1.6551249027), tensor(1.1377125978), tensor(1.5009824038), tensor(1.6178219318), tensor(1.4451726675), tensor(1.1054555178), tensor(0.9241793156), tensor(1.1327370405)]\n",
            "b:  [tensor(1.4088797569), tensor(0.7835264802), tensor(1.3173036575), tensor(1.2274968624), tensor(0.9918774962), tensor(1.7426809072), tensor(1.2146445513), tensor(1.3353912830), tensor(1.1751070023), tensor(0.9858643413), tensor(1.2875907421), tensor(1.2191630602), tensor(0.7872784734), tensor(1.2077409029), tensor(1.2336034775), tensor(0.9582045078), tensor(0.9628497362), tensor(1.2569926977), tensor(1.3571506739), tensor(1.3873898983)]\n",
            "c:  [tensor(-0.3097502291), tensor(0.5961580873), tensor(0.3455166519), tensor(-0.6229262352), tensor(0.0280404277), tensor(-0.0358110853), tensor(0.1764045358), tensor(0.0092291310), tensor(1.1753417253), tensor(-0.0550326928), tensor(0.0544073060), tensor(-0.2864705622), tensor(-0.0207835585), tensor(0.7678011656), tensor(-0.0312996656), tensor(0.1185895130), tensor(-0.1472425610), tensor(-0.0147548839)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-13.8766307831,  -3.7685143948,  -9.3834142685,  -3.9675710201,\n",
            "        -11.9259805679, -14.9663181305,  -4.7845911980,  -7.4395303726,\n",
            "         -6.0151448250,  -8.4112243652,  -9.5573892593,  -6.3694915771,\n",
            "         -3.6990299225,  -7.5920062065,  -5.0600261688,  -3.3281836510,\n",
            "         -4.2502398491,  -9.9857511520, -12.0325927734,  -9.4929141998])\n",
            "btensor.grad: tensor([-5.6042308807, -7.9213223457, -6.6468753815, -8.1033830643,\n",
            "        -8.1457138062, -5.7982177734, -6.6142449379, -7.1997146606,\n",
            "        -6.9688982964, -8.3944759369, -7.4630918503, -6.5828609467,\n",
            "        -7.4587831497, -7.7846450806, -8.7447052002, -7.0666966438,\n",
            "        -7.9238715172, -7.0920124054, -7.9306683540, -6.4445986748])\n",
            "ctensor.grad: tensor([ 3.7860111237e+01,  1.0067234993e+01, -1.4002959251e+01,\n",
            "         3.1283004761e+01, -1.2066879123e-01,  7.9258224487e+01,\n",
            "         3.9175266266e+01,  8.4024230957e+01, -6.6623840332e+01,\n",
            "        -4.0292930603e-01, -1.6245170593e+02, -6.6035034180e+01,\n",
            "        -1.4950874329e+02, -4.2678718567e+01, -7.5627371669e-02,\n",
            "        -1.0808271790e+02, -4.8022590637e+01, -1.0570538330e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(727.4500122070, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7885335088), tensor(1.6003124714), tensor(1.0177394152), tensor(1.1983360052), tensor(0.7502791286), tensor(0.7447549701), tensor(1.4119038582), tensor(1.0130970478), tensor(1.1175969839), tensor(0.9306147695), tensor(0.9171677828), tensor(0.8496018648), tensor(1.6369383335), tensor(1.1068071127), tensor(1.4787344933), tensor(1.6003096104), tensor(1.4248167276), tensor(1.0672227144), tensor(0.8809834123), tensor(1.0981836319)]\n",
            "b:  [tensor(1.3783917427), tensor(0.7442357540), tensor(1.2838267088), tensor(1.1879209280), tensor(0.9511669874), tensor(1.7125169039), tensor(1.1820546389), tensor(1.3022295237), tensor(1.1409939528), tensor(0.9443364739), tensor(1.2509503365), tensor(1.1854267120), tensor(0.7490911484), tensor(1.1689337492), tensor(1.1911112070), tensor(0.9226577282), tensor(0.9231085777), tensor(1.2219808102), tensor(1.3195055723), tensor(1.3556102514)]\n",
            "c:  [tensor(-0.2657638788), tensor(0.5749191046), tensor(0.3137172163), tensor(-0.6130504012), tensor(0.0286548175), tensor(0.0134962611), tensor(0.2003809214), tensor(0.0578729250), tensor(1.1461322308), tensor(-0.0564870089), tensor(-0.0837303028), tensor(-0.3507797122), tensor(-0.1567942649), tensor(0.7534422278), tensor(-0.0322759226), tensor(0.0515969098), tensor(-0.1782326251), tensor(-0.0886353552)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 9.4399070740,  3.7824163437,  6.9128675461,  4.1238884926,\n",
            "         8.4824275970, 10.0060920715,  4.2927474976,  5.9078617096,\n",
            "         5.3371009827,  6.6776132584,  7.4365992546,  5.6072587967,\n",
            "         3.6373085976,  6.1810960770,  4.4495706558,  3.5024549961,\n",
            "         4.0711879730,  7.6465587616,  8.6391782761,  6.9106717110])\n",
            "btensor.grad: tensor([6.0976033211, 7.8581500053, 6.6953911781, 7.9151763916, 8.1421022415,\n",
            "        6.0327987671, 6.5179738998, 6.6323523521, 6.8225989342, 8.3055715561,\n",
            "        7.3280730247, 6.7472734451, 7.6374664307, 7.7614312172, 8.4984636307,\n",
            "        7.1093568802, 7.9482274055, 7.0023889542, 7.5290169716, 6.3559236526])\n",
            "ctensor.grad: tensor([-43.9863624573,  21.2389678955,  31.7994327545,  -9.8758573532,\n",
            "         -0.6143891215, -49.3073425293, -23.9763870239, -48.6437911987,\n",
            "         29.2094573975,   1.4543164968, 138.1376037598,  64.3091583252,\n",
            "        136.0106964111,  14.3589582443,   0.9762554765,  66.9925994873,\n",
            "         30.9900684357,  73.8804702759])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(686.5109863281, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8053769469), tensor(1.6080918312), tensor(1.0324044228), tensor(1.2055892944), tensor(0.7610921860), tensor(0.7621489763), tensor(1.4212561846), tensor(1.0256067514), tensor(1.1265347004), tensor(0.9426302910), tensor(0.9327512383), tensor(0.8582466841), tensor(1.6447033882), tensor(1.1200693846), tensor(1.4879142046), tensor(1.6069062948), tensor(1.4324327707), tensor(1.0847860575), tensor(0.8989250064), tensor(1.1150410175)]\n",
            "b:  [tensor(1.3921598196), tensor(0.7660964727), tensor(1.2993792295), tensor(1.2084765434), tensor(0.9737339020), tensor(1.7254210711), tensor(1.1988391876), tensor(1.3195909262), tensor(1.1574391127), tensor(0.9656772614), tensor(1.2687894106), tensor(1.2024850845), tensor(0.7691864967), tensor(1.1894698143), tensor(1.2136486769), tensor(0.9428719878), tensor(0.9437057376), tensor(1.2386624813), tensor(1.3394505978), tensor(1.3709315062)]\n",
            "c:  [tensor(-0.2947013378), tensor(0.6020122170), tensor(0.3438512087), tensor(-0.6166246533), tensor(0.0290855318), tensor(0.0198319424), tensor(0.2001481652), tensor(0.0561334677), tensor(1.1688233614), tensor(-0.0567805506), tensor(-0.0375556722), tensor(-0.3295193315), tensor(-0.1084780023), tensor(0.7606399655), tensor(-0.0327552781), tensor(0.0548304655), tensor(-0.1737956256), tensor(-0.0770836249)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-3.3686897755, -1.5558651686, -2.9330091476, -1.4506462812,\n",
            "        -2.1626100540, -3.4788050652, -1.8704638481, -2.5019440651,\n",
            "        -1.7875398397, -2.4030983448, -3.1166875362, -1.7289592028,\n",
            "        -1.5530160666, -2.6524646282, -1.8359333277, -1.3193265200,\n",
            "        -1.5232048035, -3.5126757622, -3.5883171558, -3.3714673519])\n",
            "btensor.grad: tensor([-2.7536225319, -4.3721380234, -3.1104950905, -4.1111345291,\n",
            "        -4.5133891106, -2.5808296204, -3.3569021225, -3.4722883701,\n",
            "        -3.2890362740, -4.2681579590, -3.5678238869, -3.4116659164,\n",
            "        -4.0190687180, -4.1072111130, -4.5075049400, -4.0428481102,\n",
            "        -4.1194310188, -3.3363339901, -3.9889974594, -3.0642454624])\n",
            "ctensor.grad: tensor([ 28.9374523163, -27.0931282043, -30.1339988708,   3.5742340088,\n",
            "         -0.4307138324,  -6.3356814384,   0.2327515781,   1.7394561768,\n",
            "        -22.6910915375,   0.2935434580, -46.1746292114, -21.2603702545,\n",
            "        -48.3162612915,  -7.1977667809,   0.4793553948,  -3.2335550785,\n",
            "         -4.4369935989, -11.5517272949])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(684.5415039062, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.7981354594), tensor(1.6054388285), tensor(1.0286506414), tensor(1.2000167370), tensor(0.7443764210), tensor(0.7536130548), tensor(1.4159144163), tensor(1.0198597908), tensor(1.1170868874), tensor(0.9354135990), tensor(0.9250580668), tensor(0.8474608660), tensor(1.6415742636), tensor(1.1148365736), tensor(1.4821077585), tensor(1.6034766436), tensor(1.4266668558), tensor(1.0786175728), tensor(0.8928267956), tensor(1.1139385700)]\n",
            "b:  [tensor(1.3868726492), tensor(0.7688399553), tensor(1.2953978777), tensor(1.2067788839), tensor(0.9766558409), tensor(1.7201241255), tensor(1.1975588799), tensor(1.3186098337), tensor(1.1544792652), tensor(0.9629758596), tensor(1.2673547268), tensor(1.2019538879), tensor(0.7708287835), tensor(1.1912628412), tensor(1.2179145813), tensor(0.9478850961), tensor(0.9440421462), tensor(1.2350242138), tensor(1.3393206596), tensor(1.3669834137)]\n",
            "c:  [tensor(-0.2998443246), tensor(0.6272801161), tensor(0.3577476740), tensor(-0.6102159619), tensor(0.0297639128), tensor(0.0602484047), tensor(0.2151891738), tensor(0.0858415514), tensor(1.1540089846), tensor(-0.0579102561), tensor(-0.1034356877), tensor(-0.3533925712), tensor(-0.1594638675), tensor(0.7527355552), tensor(-0.0336172171), tensor(0.0105666257), tensor(-0.1896755397), tensor(-0.1126199663)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([1.4482982159, 0.5306039453, 0.7507487535, 1.1145029068, 3.3431475163,\n",
            "        1.7071795464, 1.0683445930, 1.1493899822, 1.8895691633, 1.4433352947,\n",
            "        1.5386372805, 2.1571602821, 0.6258314848, 1.0465553999, 1.1612857580,\n",
            "        0.6859284043, 1.1531821489, 1.2337014675, 1.2196378708, 0.2204857022])\n",
            "btensor.grad: tensor([ 1.0574231148, -0.5486921668,  0.7962687016,  0.3395417333,\n",
            "        -0.5843887329,  1.0593888760,  0.2560728788,  0.1962212324,\n",
            "         0.5919731259,  0.5402748585,  0.2869452834,  0.1062296629,\n",
            "        -0.3284593225, -0.3585990071, -0.8531763554, -1.0026252270,\n",
            "        -0.0672845840,  0.7276508808,  0.0259966254,  0.7896164060])\n",
            "ctensor.grad: tensor([  5.1429867744, -25.2679157257, -13.8964500427,  -6.4087147713,\n",
            "         -0.6783809662, -40.4164619446, -15.0410108566, -29.7080802917,\n",
            "         14.8144035339,   1.1297039986,  65.8800125122,  23.8732471466,\n",
            "         50.9858589172,   7.9044351578,   0.8619390726,  44.2638359070,\n",
            "         15.8799114227,  35.5363388062])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(687.3133544922, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8467333317), tensor(1.6180912256), tensor(1.0629587173), tensor(1.2115610838), tensor(0.7830750346), tensor(0.8050711155), tensor(1.4317330122), tensor(1.0462045670), tensor(1.1352096796), tensor(0.9643791318), tensor(0.9583952427), tensor(0.8667763472), tensor(1.6538294554), tensor(1.1409621239), tensor(1.4987144470), tensor(1.6142007113), tensor(1.4398037195), tensor(1.1143244505), tensor(0.9354462624), tensor(1.1494488716)]\n",
            "b:  [tensor(1.4055662155), tensor(0.7986802459), tensor(1.3188506365), tensor(1.2370125055), tensor(1.0081126690), tensor(1.7398895025), tensor(1.2212431431), tensor(1.3452270031), tensor(1.1789550781), tensor(0.9942759871), tensor(1.2942122221), tensor(1.2257707119), tensor(0.7980142236), tensor(1.2208029032), tensor(1.2512936592), tensor(0.9748806357), tensor(0.9732413292), tensor(1.2600568533), tensor(1.3694647551), tensor(1.3901511431)]\n",
            "c:  [tensor(-0.3261825442), tensor(0.6288087964), tensor(0.3734281361), tensor(-0.6338375211), tensor(0.0300821569), tensor(0.0032091253), tensor(0.1846561581), tensor(0.0223489776), tensor(1.1976295710), tensor(-0.0579100996), tensor(0.0037519783), tensor(-0.3065937757), tensor(-0.0565925017), tensor(0.7817955613), tensor(-0.0338295475), tensor(0.0827664286), tensor(-0.1546536535), tensor(-0.0381176099)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ -9.7195711136,  -2.5304882526,  -6.8616175652,  -2.3088755608,\n",
            "         -7.7397193909, -10.2916135788,  -3.1637134552,  -5.2689657211,\n",
            "         -3.6245632172,  -5.7931017876,  -6.6674327850,  -3.8630981445,\n",
            "         -2.4510388374,  -5.2251129150,  -3.3213338852,  -2.1448082924,\n",
            "         -2.6273717880,  -7.1413736343,  -8.5238943100,  -7.1020698547])\n",
            "btensor.grad: tensor([-3.7387177944, -5.9680538177, -4.6905565262, -6.0467300415,\n",
            "        -6.2913703918, -3.9530820847, -4.7368493080, -5.3234252930,\n",
            "        -4.8951559067, -6.2600264549, -5.3715052605, -4.7633695602,\n",
            "        -5.4370923042, -5.9080224037, -6.6758131981, -5.3991093636,\n",
            "        -5.8398361206, -5.0065369606, -6.0288114548, -4.6335396767])\n",
            "ctensor.grad: tensor([ 2.6338226318e+01, -1.5286777020e+00, -1.5680448532e+01,\n",
            "         2.3621583939e+01, -3.1824359298e-01,  5.7039276123e+01,\n",
            "         3.0533018112e+01,  6.3492572784e+01, -4.3620635986e+01,\n",
            "        -1.5712250024e-04, -1.0718766022e+02, -4.6798793793e+01,\n",
            "        -1.0287136078e+02, -2.9060028076e+01,  2.1232908964e-01,\n",
            "        -7.2199798584e+01, -3.5021881104e+01, -7.4502349854e+01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(708.9663696289, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8052557707), tensor(1.6008917093), tensor(1.0328760147), tensor(1.1913350821), tensor(0.7430559397), tensor(0.7618610263), tensor(1.4110146761), tensor(1.0193475485), tensor(1.1088428497), tensor(0.9342914820), tensor(0.9249542952), tensor(0.8394913673), tensor(1.6367552280), tensor(1.1129541397), tensor(1.4774571657), tensor(1.5976243019), tensor(1.4199764729), tensor(1.0802016258), tensor(0.8978589177), tensor(1.1210042238)]\n",
            "b:  [tensor(1.3776874542), tensor(0.7689658999), tensor(1.2901545763), tensor(1.2039757967), tensor(0.9764855504), tensor(1.7127931118), tensor(1.1946560144), tensor(1.3186269999), tensor(1.1503505707), tensor(0.9590663910), tensor(1.2650133371), tensor(1.1984549761), tensor(0.7690957189), tensor(1.1907426119), tensor(1.2208982706), tensor(0.9499150515), tensor(0.9413867593), tensor(1.2300398350), tensor(1.3393361568), tensor(1.3628219366)]\n",
            "c:  [tensor(-0.2946381867), tensor(0.6279442310), tensor(0.3553411067), tensor(-0.6194407344), tensor(0.0308707692), tensor(0.0730820745), tensor(0.2166320384), tensor(0.0856781006), tensor(1.1591454744), tensor(-0.0595761575), tensor(-0.1584457904), tensor(-0.3780892491), tensor(-0.2054027915), tensor(0.7623329163), tensor(-0.0349905938), tensor(-0.0041099936), tensor(-0.1926343441), tensor(-0.1262837052)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([8.2955064774, 3.4398930073, 6.0165410042, 4.0451903343, 8.0038251877,\n",
            "        8.6420135498, 4.1436700821, 5.3714003563, 5.2733712196, 6.0175261497,\n",
            "        6.6881957054, 5.4569969177, 3.4148480892, 5.6015992165, 4.2514486313,\n",
            "        3.3152816296, 3.9654409885, 6.8245735168, 7.5174651146, 5.6889181137])\n",
            "btensor.grad: tensor([5.5757412910, 5.9428672791, 5.7392225266, 6.6073403358, 6.3254213333,\n",
            "        5.4192810059, 5.3174333572, 5.3199973106, 5.7209067345, 7.0419163704,\n",
            "        5.8397717476, 5.4631414413, 5.7837004662, 6.0120515823, 6.0790867805,\n",
            "        4.9931139946, 6.3709087372, 6.0033993721, 6.0257234573, 5.4658527374])\n",
            "ctensor.grad: tensor([-31.5443687439,   0.8645620346,  18.0870208740, -14.3967876434,\n",
            "         -0.7886125445, -69.8729400635, -31.9758796692, -63.3291168213,\n",
            "         38.4841461182,   1.6660566330, 162.1977539062,  71.4954681396,\n",
            "        148.8102722168,  19.4626274109,   1.1610445976,  86.8764190674,\n",
            "         37.9806938171,  88.1660919189])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(707.6412963867, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8823277950), tensor(1.6253430843), tensor(1.0883526802), tensor(1.2197812796), tensor(0.8348642588), tensor(0.8446515203), tensor(1.4411102533), tensor(1.0666956902), tensor(1.1527049541), tensor(0.9934906960), tensor(0.9856070876), tensor(0.8889093995), tensor(1.6607421637), tensor(1.1600133181), tensor(1.5109553337), tensor(1.6199445724), tensor(1.4497643709), tensor(1.1398067474), tensor(0.9654308558), tensor(1.1736245155)]\n",
            "b:  [tensor(1.4133343697), tensor(0.8096055984), tensor(1.3319735527), tensor(1.2495952845), tensor(1.0189112425), tensor(1.7506290674), tensor(1.2320384979), tensor(1.3607997894), tensor(1.1913323402), tensor(1.0069032907), tensor(1.3099508286), tensor(1.2357666492), tensor(0.8092774153), tensor(1.2339982986), tensor(1.2690414190), tensor(0.9858679175), tensor(0.9851769209), tensor(1.2735632658), tensor(1.3848139048), tensor(1.4028539658)]\n",
            "c:  [tensor(-0.3360657394), tensor(0.5866432786), tensor(0.3696679473), tensor(-0.6674194336), tensor(0.0308265798), tensor(-0.0550879091), tensor(0.1573617458), tensor(-0.0372517630), tensor(1.2389998436), tensor(-0.0589701682), tensor(0.0292758942), tensor(-0.3070560694), tensor(-0.0451802909), tensor(0.8226814866), tensor(-0.0346800312), tensor(0.1543708146), tensor(-0.1246928275), tensor(0.0204917639)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-15.4144058228,  -4.8902678490, -11.0953350067,  -5.6892380714,\n",
            "        -18.3616619110, -16.5580940247,  -6.0191144943,  -9.4696168900,\n",
            "         -8.7724180222, -11.8398427963, -12.1305541992,  -9.8836078644,\n",
            "         -4.7973890305,  -9.4118471146,  -6.6996273994,  -4.4640645981,\n",
            "         -5.9575743675, -11.9210319519, -13.5143833160, -10.5240631104])\n",
            "btensor.grad: tensor([-7.1293783188, -8.1279411316, -8.3638048172, -9.1238870621,\n",
            "        -8.4851350784, -7.5671887398, -7.4764924049, -8.4345560074,\n",
            "        -8.1963663101, -9.5673875809, -8.9875040054, -7.4623250961,\n",
            "        -8.0363340378, -8.6511363983, -9.6286411285, -7.1905789375,\n",
            "        -8.7580308914, -8.7046766281, -9.0955524445, -8.0064163208])\n",
            "ctensor.grad: tensor([ 4.1427562714e+01,  4.1300941467e+01, -1.4326845169e+01,\n",
            "         4.7978675842e+01,  4.4189468026e-02,  1.2816998291e+02,\n",
            "         5.9270294189e+01,  1.2292985535e+02, -7.9854400635e+01,\n",
            "        -6.0598862171e-01, -1.8772167969e+02, -7.1033172607e+01,\n",
            "        -1.6022248840e+02, -6.0348548889e+01, -3.1056436896e-01,\n",
            "        -1.5848080444e+02, -6.7941513062e+01, -1.4677546692e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(738.7219238281, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8268497586), tensor(1.6024559736), tensor(1.0468145609), tensor(1.1947976351), tensor(0.7844285369), tensor(0.7862474918), tensor(1.4151012897), tensor(1.0304973125), tensor(1.1210323572), tensor(0.9529894590), tensor(0.9414396882), tensor(0.8555827737), tensor(1.6383962631), tensor(1.1231507063), tensor(1.4840786457), tensor(1.5989320278), tensor(1.4253883362), tensor(1.0949318409), tensor(0.9149844646), tensor(1.1312630177)]\n",
            "b:  [tensor(1.3767752647), tensor(0.7577137947), tensor(1.2913954258), tensor(1.2002806664), tensor(0.9688542485), tensor(1.7146104574), tensor(1.1905236244), tensor(1.3181980848), tensor(1.1483708620), tensor(0.9563770294), tensor(1.2638980150), tensor(1.1942009926), tensor(0.7597734928), tensor(1.1861263514), tensor(1.2166652679), tensor(0.9385720491), tensor(0.9352440238), tensor(1.2302516699), tensor(1.3383299112), tensor(1.3637697697)]\n",
            "c:  [tensor(-0.2714755237), tensor(0.5693919659), tensor(0.3132723868), tensor(-0.6621015668), tensor(0.0312382057), tensor(-0.0274493415), tensor(0.1712622792), tensor(-0.0087816883), tensor(1.2009031773), tensor(-0.0605870336), tensor(-0.1380276084), tensor(-0.3847609460), tensor(-0.2079061121), tensor(0.8141678572), tensor(-0.0354810767), tensor(0.1122275963), tensor(-0.1449182630), tensor(-0.0308077931)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([11.0956048965,  4.5774121284,  8.3076334000,  4.9967346191,\n",
            "        10.0871400833, 11.6808013916,  5.2018041611,  7.2396669388,\n",
            "         6.3345270157,  8.1002483368,  8.8334846497,  6.6653261185,\n",
            "         4.4691848755,  7.3725233078,  5.3753356934,  4.2025146484,\n",
            "         4.8752164841,  8.9749927521, 10.0892829895,  8.4722948074])\n",
            "btensor.grad: tensor([ 7.3118238449, 10.3783664703,  8.1156148911,  9.8629226685,\n",
            "        10.0114040375,  7.2037310600,  8.3029870987,  8.5203504562,\n",
            "         8.5922861099, 10.1052474976,  9.2105731964,  8.3131265640,\n",
            "         9.9007902145,  9.5743999481, 10.4752273560,  9.4591798782,\n",
            "         9.9865779877,  8.6623201370,  9.2968091965,  7.8168501854])\n",
            "ctensor.grad: tensor([-64.5902175903,  17.2513027191,  56.3955612183,  -5.3178882599,\n",
            "         -0.4116266072, -27.6385669708, -13.9005336761, -28.4700737000,\n",
            "         38.0966758728,   1.6168656349, 167.3034973145,  77.7048721313,\n",
            "        162.7258148193,   8.5136241913,   0.8010454178,  42.1432151794,\n",
            "         20.2254390717,  51.2995529175])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(694.5008544922, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8219396472), tensor(1.6071432829), tensor(1.0483112335), tensor(1.2015352249), tensor(0.7942597866), tensor(0.7808741331), tensor(1.4223964214), tensor(1.0360606909), tensor(1.1314398050), tensor(0.9596961737), tensor(0.9474309087), tensor(0.8662551045), tensor(1.6435790062), tensor(1.1291319132), tensor(1.4929915667), tensor(1.6040951014), tensor(1.4336128235), tensor(1.1009674072), tensor(0.9143396616), tensor(1.1320374012)]\n",
            "b:  [tensor(1.3909367323), tensor(0.7669218779), tensor(1.3058094978), tensor(1.2139223814), tensor(0.9790167809), tensor(1.7291662693), tensor(1.2015967369), tensor(1.3301091194), tensor(1.1612955332), tensor(0.9723631144), tensor(1.2765461206), tensor(1.2052382231), tensor(0.7694683671), tensor(1.1967332363), tensor(1.2256729603), tensor(0.9456700683), tensor(0.9472063780), tensor(1.2456818819), tensor(1.3509861231), tensor(1.3778892756)]\n",
            "c:  [tensor(-0.2892577946), tensor(0.6048511863), tensor(0.3404312134), tensor(-0.6602264643), tensor(0.0315759219), tensor(-0.0089799371), tensor(0.1800440848), tensor(0.0086148363), tensor(1.2362300158), tensor(-0.0606990755), tensor(-0.0619754344), tensor(-0.3553190529), tensor(-0.1454088986), tensor(0.8109507561), tensor(-0.0360918529), tensor(0.0830939561), tensor(-0.1575169265), tensor(-0.0603587106)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.9820255041, -0.9374689460, -0.2993416488, -1.3475105762,\n",
            "        -1.9662508965,  1.0746694803, -1.4590190649, -1.1126790047,\n",
            "        -2.0814867020, -1.3413437605, -1.1982400417, -2.1344695091,\n",
            "        -1.0365498066, -1.1962492466, -1.7825796604, -1.0326230526,\n",
            "        -1.6449087858, -1.2071169615,  0.1289579272, -0.1548855007])\n",
            "btensor.grad: tensor([-2.8322856426, -1.8416190147, -2.8828041553, -2.7283511162,\n",
            "        -2.0325067043, -2.9111647606, -2.2146213055, -2.3822076321,\n",
            "        -2.5849347115, -3.1972203255, -2.5296094418, -2.2074344158,\n",
            "        -1.9389722347, -2.1213657856, -1.8015358448, -1.4196007252,\n",
            "        -2.3924760818, -3.0860402584, -2.5312495232, -2.8238923550])\n",
            "ctensor.grad: tensor([ 17.7822837830, -35.4592208862, -27.1588134766,  -1.8751060963,\n",
            "         -0.3377153873, -18.4694042206,  -8.7818126678, -17.3965244293,\n",
            "        -35.3268089294,   0.1120404154, -76.0521697998, -29.4419021606,\n",
            "        -62.4972114563,   3.2171065807,   0.6107743979,  29.1336345673,\n",
            "         12.5986690521,  29.5509185791])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(687.7520751953, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8048911095), tensor(1.6017763615), tensor(1.0361452103), tensor(1.1942083836), tensor(0.7714453936), tensor(0.7628701329), tensor(1.4161100388), tensor(1.0261650085), tensor(1.1206563711), tensor(0.9460349083), tensor(0.9357386827), tensor(0.8535394669), tensor(1.6386895180), tensor(1.1193356514), tensor(1.4856590033), tensor(1.5986899137), tensor(1.4265033007), tensor(1.0904819965), tensor(0.9003987908), tensor(1.1230809689)]\n",
            "b:  [tensor(1.3843710423), tensor(0.7651748061), tensor(1.2988616228), tensor(1.2091633081), tensor(0.9771543145), tensor(1.7217240334), tensor(1.1968548298), tensor(1.3245273829), tensor(1.1543507576), tensor(0.9662290812), tensor(1.2695493698), tensor(1.2009433508), tensor(0.7660932541), tensor(1.1929372549), tensor(1.2207551003), tensor(0.9451505542), tensor(0.9432053566), tensor(1.2384960651), tensor(1.3458787203), tensor(1.3714838028)]\n",
            "c:  [tensor(-0.2801194489), tensor(0.6401159763), tensor(0.3459993303), tensor(-0.6552444100), tensor(0.0320520289), tensor(0.0228711385), tensor(0.1940806508), tensor(0.0362356007), tensor(1.2207109928), tensor(-0.0617562979), tensor(-0.1254099309), tensor(-0.3789893389), tensor(-0.1964024156), tensor(0.8018549085), tensor(-0.0369418934), tensor(0.0333271436), tensor(-0.1777584106), tensor(-0.1069124788)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([3.4097073078, 1.0733913183, 2.4332025051, 1.4653781652, 4.5628805161,\n",
            "        3.6008026600, 1.2572773695, 1.9791311026, 2.1566781998, 2.7322590351,\n",
            "        2.3384459019, 2.5431218147, 0.9778997898, 1.9592421055, 1.4665200710,\n",
            "        1.0810375214, 1.4219021797, 2.0970883369, 2.7881717682, 1.7912817001])\n",
            "btensor.grad: tensor([1.3131462336, 0.3494092822, 1.3895694017, 0.9518111944, 0.3724912405,\n",
            "        1.4884560108, 0.9483910799, 1.1163454056, 1.3889486790, 1.2268104553,\n",
            "        1.3993586302, 0.8589723706, 0.6750208139, 0.7591951489, 0.9835706949,\n",
            "        0.1039019227, 0.8002041578, 1.4371615648, 1.0214825869, 1.2810951471])\n",
            "ctensor.grad: tensor([ -9.1383504868, -35.2647895813,  -5.5681176186,  -4.9820299149,\n",
            "         -0.4761067629, -31.8510723114, -14.0365686417, -27.6207637787,\n",
            "         15.5189857483,   1.0572230816,  63.4344978333,  23.6702785492,\n",
            "         50.9935150146,   9.0958528519,   0.8500390053,  49.7668113708,\n",
            "         20.2414875031,  46.5537643433])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(685.0661621094, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8285005093), tensor(1.6096820831), tensor(1.0549248457), tensor(1.2026076317), tensor(0.7938484550), tensor(0.7900410295), tensor(1.4278076887), tensor(1.0424505472), tensor(1.1341972351), tensor(0.9629930258), tensor(0.9570194483), tensor(0.8671107292), tensor(1.6467036009), tensor(1.1363521814), tensor(1.4977097511), tensor(1.6053251028), tensor(1.4362363815), tensor(1.1132708788), tensor(0.9243978858), tensor(1.1433813572)]\n",
            "b:  [tensor(1.3999681473), tensor(0.7891911864), tensor(1.3175662756), tensor(1.2330429554), tensor(0.9998731017), tensor(1.7377655506), tensor(1.2160995007), tensor(1.3452383280), tensor(1.1740264893), tensor(0.9898427725), tensor(1.2906539440), tensor(1.2198352814), tensor(0.7881490588), tensor(1.2144136429), tensor(1.2454822063), tensor(0.9665768147), tensor(0.9663849473), tensor(1.2591345310), tensor(1.3690609932), tensor(1.3898820877)]\n",
            "c:  [tensor(-0.3152531981), tensor(0.6537473798), tensor(0.3768756688), tensor(-0.6599545479), tensor(0.0324380100), tensor(0.0244245604), tensor(0.1915387511), tensor(0.0299711693), tensor(1.2581762075), tensor(-0.0618068427), tensor(-0.0406483263), tensor(-0.3438864648), tensor(-0.1169249043), tensor(0.8158339858), tensor(-0.0373444930), tensor(0.0565960109), tensor(-0.1650384218), tensor(-0.0751107484)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-4.7218804359, -1.5811421871, -3.7559196949, -1.6798424721,\n",
            "        -4.4806160927, -5.4341816902, -2.3395211697, -3.2571151257,\n",
            "        -2.7081620693, -3.3916249275, -4.2561488152, -2.7142572403,\n",
            "        -1.6028277874, -3.4032983780, -2.4101562500, -1.3270478249,\n",
            "        -1.9466227293, -4.5577764511, -4.7998194695, -4.0600733757])\n",
            "btensor.grad: tensor([-3.1194155216, -4.8032765388, -3.7409327030, -4.7759175301,\n",
            "        -4.5437560081, -3.2083101273, -3.8489422798, -4.1421818733,\n",
            "        -3.9351546764, -4.7227411270, -4.2209076881, -3.7783944607,\n",
            "        -4.4111566544, -4.2952761650, -4.9454240799, -4.2852501869,\n",
            "        -4.6359195709, -4.1276879311, -4.6364464760, -3.6796545982])\n",
            "ctensor.grad: tensor([ 3.5133758545e+01, -1.3631402969e+01, -3.0876342773e+01,\n",
            "         4.7101473808e+00, -3.8597983122e-01, -1.5534207821e+00,\n",
            "         2.5419025421e+00,  6.2644309998e+00, -3.7465171814e+01,\n",
            "         5.0545748323e-02, -8.4761604309e+01, -3.5102878571e+01,\n",
            "        -7.9477508545e+01, -1.3979062080e+01,  4.0259978175e-01,\n",
            "        -2.3268863678e+01, -1.2719994545e+01, -3.1801733017e+01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(687.4435424805, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8077052236), tensor(1.6000266075), tensor(1.0395205021), tensor(1.1893106699), tensor(0.7633843422), tensor(0.7682235837), tensor(1.4147483110), tensor(1.0267020464), tensor(1.1152038574), tensor(0.9441912174), tensor(0.9375007749), tensor(0.8463772535), tensor(1.6368435621), tensor(1.1206698418), tensor(1.4837714434), tensor(1.5952639580), tensor(1.4228347540), tensor(1.0948063135), tensor(0.9050016999), tensor(1.1314021349)]\n",
            "b:  [tensor(1.3833550215), tensor(0.7804375887), tensor(1.3017218113), tensor(1.2182669640), tensor(0.9900096655), tensor(1.7213783264), tensor(1.2038792372), tensor(1.3327834606), tensor(1.1591593027), tensor(0.9727209806), tensor(1.2766400576), tensor(1.2081207037), tensor(0.7782511115), tensor(1.2034480572), tensor(1.2362830639), tensor(0.9612094760), tensor(0.9541342854), tensor(1.2430802584), tensor(1.3561908007), tensor(1.3745739460)]\n",
            "c:  [tensor(-0.3023450375), tensor(0.6730979085), tensor(0.3783102632), tensor(-0.6497661471), tensor(0.0331471823), tensor(0.0778798312), tensor(0.2134641558), tensor(0.0728860721), tensor(1.2293047905), tensor(-0.0632713214), tensor(-0.1503576934), tensor(-0.3873463571), tensor(-0.2092168927), tensor(0.8005988598), tensor(-0.0384284332), tensor(-0.0123347938), tensor(-0.1920787096), tensor(-0.1368397921)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([4.1590552330, 1.9310910702, 3.0808613300, 2.6594021320, 6.0928215981,\n",
            "        4.3634896278, 2.6118764877, 3.1497082710, 3.7986731529, 3.7603619099,\n",
            "        3.9037353992, 4.1467013359, 1.9720017910, 3.1364631653, 2.7876725197,\n",
            "        2.0122215748, 2.6803171635, 3.6929228306, 3.8792324066, 2.3958539963])\n",
            "btensor.grad: tensor([3.3226273060, 1.7507213354, 3.1688916683, 2.9552075863, 1.9726912975,\n",
            "        3.2774469852, 2.4440529346, 2.4909739494, 2.9734311104, 3.4243569374,\n",
            "        2.8027758598, 2.3429057598, 1.9795867205, 2.1931066513, 1.8398336172,\n",
            "        1.0734703541, 2.4501309395, 3.2108488083, 2.5740334988, 3.0616183281])\n",
            "ctensor.grad: tensor([-12.9081478119, -19.3505229950,  -1.4346035719, -10.1884078979,\n",
            "         -0.7091738582, -53.4552688599, -21.9253997803, -42.9148979187,\n",
            "         28.8714618683,   1.4644817114, 109.7093658447,  43.4598846436,\n",
            "         92.2919845581,  15.2351522446,   1.0839405060,  68.9308013916,\n",
            "         27.0402889252,  61.7290420532])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(698.0773925781, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8830696940), tensor(1.6196264029), tensor(1.0908899307), tensor(1.2109687328), tensor(0.8382143378), tensor(0.8501127958), tensor(1.4403486252), tensor(1.0684860945), tensor(1.1501749754), tensor(0.9935399890), tensor(0.9906907082), tensor(0.8853401542), tensor(1.6559854746), tensor(1.1613888741), tensor(1.5114916563), tensor(1.6127709150), tensor(1.4463428259), tensor(1.1478871107), tensor(0.9694504142), tensor(1.1807670593)]\n",
            "b:  [tensor(1.4114747047), tensor(0.8179221749), tensor(1.3359961510), tensor(1.2585585117), tensor(1.0282419920), tensor(1.7519465685), tensor(1.2363243103), tensor(1.3695216179), tensor(1.1943651438), tensor(1.0143917799), tensor(1.3146075010), tensor(1.2403932810), tensor(0.8139997721), tensor(1.2409861088), tensor(1.2790766954), tensor(0.9941778779), tensor(0.9926311374), tensor(1.2797882557), tensor(1.3962981701), tensor(1.4080569744)]\n",
            "c:  [tensor(-0.3417487741), tensor(0.6401818991), tensor(0.3835935593), tensor(-0.6886616349), tensor(0.0332308859), tensor(-0.0290859267), tensor(0.1609292477), tensor(-0.0348188132), tensor(1.2988948822), tensor(-0.0628127903), tensor(0.0180255473), tensor(-0.3207972050), tensor(-0.0597486645), tensor(0.8544603586), tensor(-0.0382418707), tensor(0.1314981431), tensor(-0.1292479336), tensor(-0.0022372901)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-15.0728940964,  -3.9199607372, -10.2738809586,  -4.3316106796,\n",
            "        -14.9660043716, -16.3778381348,  -5.1200666428,  -8.3567991257,\n",
            "         -6.9942264557,  -9.8697500229, -10.6379842758,  -7.7925815582,\n",
            "         -3.8283822536,  -8.1438016891,  -5.5440397263,  -3.5013844967,\n",
            "         -4.7016158104, -10.6161499023, -12.8897380829,  -9.8729782104])\n",
            "btensor.grad: tensor([-5.6239466667, -7.4969186783, -6.8548750877, -8.0583209991,\n",
            "        -7.6464757919, -6.1136403084, -6.4890222549, -7.3476347923,\n",
            "        -7.0411648750, -8.3341579437, -7.5934834480, -6.4545130730,\n",
            "        -7.1497373581, -7.5076045990, -8.5587215424, -6.5936846733,\n",
            "        -7.6993651390, -7.3416061401, -8.0214729309, -6.6966009140])\n",
            "ctensor.grad: tensor([ 3.9403732300e+01,  3.2916004181e+01, -5.2833065987e+00,\n",
            "         3.8895500183e+01, -8.3702549338e-02,  1.0696575165e+02,\n",
            "         5.2534900665e+01,  1.0770487976e+02, -6.9590103149e+01,\n",
            "        -4.5852750540e-01, -1.6838323975e+02, -6.6549140930e+01,\n",
            "        -1.4946821594e+02, -5.3861488342e+01, -1.8656428158e-01,\n",
            "        -1.4383293152e+02, -6.2830780029e+01, -1.3460249329e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(735.8653564453, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8270176649), tensor(1.5953927040), tensor(1.0483587980), tensor(1.1841123104), tensor(0.7855882645), tensor(0.7913777232), tensor(1.4125372171), tensor(1.0308198929), tensor(1.1160771847), tensor(0.9514623880), tensor(0.9449167848), tensor(0.8496677876), tensor(1.6322473288), tensor(1.1231069565), tensor(1.4827169180), tensor(1.5902206898), tensor(1.4200147390), tensor(1.1013329029), tensor(0.9180250168), tensor(1.1382507086)]\n",
            "b:  [tensor(1.3721947670), tensor(0.7670874000), tensor(1.2930177450), tensor(1.2073348761), tensor(0.9770852923), tensor(1.7130427361), tensor(1.1939859390), tensor(1.3259921074), tensor(1.1500830650), tensor(0.9611513019), tensor(1.2673348188), tensor(1.1975251436), tensor(0.7653113604), tensor(1.1922233105), tensor(1.2267321348), tensor(0.9482743144), tensor(0.9418225884), tensor(1.2340562344), tensor(1.3481881618), tensor(1.3667466640)]\n",
            "c:  [tensor(-0.2765368223), tensor(0.6241298914), tensor(0.3299459815), tensor(-0.6816505194), tensor(0.0337133743), tensor(0.0072107166), tensor(0.1788551956), tensor(0.0007874668), tensor(1.2555444241), tensor(-0.0645826906), tensor(-0.1671807319), tensor(-0.4058847725), tensor(-0.2376635969), tensor(0.8425670266), tensor(-0.0392041616), tensor(0.0742764473), tensor(-0.1559886634), tensor(-0.0693534687)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([11.2104053497,  4.8467326164,  8.5062341690,  5.3712835312,\n",
            "        10.5252122879, 11.7470140457,  5.5622820854,  7.5332522392,\n",
            "         6.8195624352,  8.4155244827,  9.1547861099,  7.1344780922,\n",
            "         4.7476196289,  7.6563901901,  5.7549390793,  4.5100336075,\n",
            "         5.2656197548,  9.3108463287, 10.2850837708,  8.5032653809])\n",
            "btensor.grad: tensor([ 7.8559861183, 10.1669578552,  8.5956850052, 10.2447214127,\n",
            "        10.2313404083,  7.7807602882,  8.4676828384,  8.7059001923,\n",
            "         8.8564186096, 10.6480903625,  9.4545335770,  8.5736188889,\n",
            "         9.7376785278,  9.7525644302, 10.4689197540,  9.1807088852,\n",
            "        10.1617097855,  9.1464080811,  9.6220140457,  8.2620534897])\n",
            "ctensor.grad: tensor([-65.2119598389,  16.0520248413,  53.6475868225,  -7.0110917091,\n",
            "         -0.4824897349, -36.2966423035, -17.9259433746, -35.6062774658,\n",
            "         43.3504447937,   1.7698975801, 185.2062683105,  85.0875701904,\n",
            "        177.9149169922,  11.8933029175,   0.9622892141,  57.2216911316,\n",
            "         26.7407360077,  67.1161727905])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(692.6362915039, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8355957270), tensor(1.6044989824), tensor(1.0592182875), tensor(1.1966556311), tensor(0.8092916012), tensor(0.8004592657), tensor(1.4242275953), tensor(1.0440394878), tensor(1.1343454123), tensor(0.9695154428), tensor(0.9609879851), tensor(0.8685030937), tensor(1.6418509483), tensor(1.1373592615), tensor(1.4967062473), tensor(1.5990768671), tensor(1.4334102869), tensor(1.1167272329), tensor(0.9283305407), tensor(1.1483268738)]\n",
            "b:  [tensor(1.3926353455), tensor(0.7846477032), tensor(1.3149461746), tensor(1.2287564278), tensor(0.9938977957), tensor(1.7339060307), tensor(1.2122772932), tensor(1.3461509943), tensor(1.1706011295), tensor(0.9840465188), tensor(1.2894345522), tensor(1.2152781487), tensor(0.7837606072), tensor(1.2105574608), tensor(1.2458525896), tensor(0.9633880854), tensor(0.9622247219), tensor(1.2571657896), tensor(1.3688399792), tensor(1.3878158331)]\n",
            "c:  [tensor(-0.3113002777), tensor(0.6415657997), tensor(0.3729991317), tensor(-0.6811875701), tensor(0.0340756029), tensor(0.0247961376), tensor(0.1864138395), tensor(0.0148317199), tensor(1.3045897484), tensor(-0.0644843355), tensor(-0.0584200546), tensor(-0.3653483987), tensor(-0.1496027708), tensor(0.8439050913), tensor(-0.0397703499), tensor(0.0557760745), tensor(-0.1628119349), tensor(-0.0822544917)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.7156183720, -1.8212651014, -2.1718978882, -2.5086538792,\n",
            "        -4.7406735420, -1.8163028955, -2.3380682468, -2.6439242363,\n",
            "        -3.6536560059, -3.6106104851, -3.2142426968, -3.7670555115,\n",
            "        -1.9207134247, -2.8504538536, -2.7978718281, -1.7712469101,\n",
            "        -2.6791024208, -3.0788674355, -2.0611057281, -2.0152399540])\n",
            "btensor.grad: tensor([-4.0881166458, -3.5120642185, -4.3856797218, -4.2843046188,\n",
            "        -3.3624997139, -4.1726469994, -3.6582748890, -4.0317821503,\n",
            "        -4.1036176682, -4.5790448189, -4.4199566841, -3.5506052971,\n",
            "        -3.6898479462, -3.6668336391, -3.8240845203, -3.0227499008,\n",
            "        -4.0804247856, -4.6219215393, -4.1303534508, -4.2138299942])\n",
            "ctensor.grad: tensor([ 3.4763454437e+01, -1.7435888290e+01, -4.3053150177e+01,\n",
            "        -4.6295350790e-01, -3.6222872138e-01, -1.7585420609e+01,\n",
            "        -7.5586409569e+00, -1.4044252396e+01, -4.9045303345e+01,\n",
            "        -9.8357051611e-02, -1.0876067352e+02, -4.0536384583e+01,\n",
            "        -8.8060829163e+01, -1.3380589485e+00,  5.6618821621e-01,\n",
            "         1.8500371933e+01,  6.8232727051e+00,  1.2901021004e+01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(684.6538696289, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8180143833), tensor(1.5972015858), tensor(1.0461428165), tensor(1.1863467693), tensor(0.7814788818), tensor(0.7820011377), tensor(1.4147968292), tensor(1.0315374136), tensor(1.1190826893), tensor(0.9529262185), tensor(0.9460768700), tensor(0.8509604335), tensor(1.6347980499), tensor(1.1251496077), tensor(1.4859608412), tensor(1.5913505554), tensor(1.4229441881), tensor(1.1034020185), tensor(0.9130499363), tensor(1.1392083168)]\n",
            "b:  [tensor(1.3811141253), tensor(0.7807762027), tensor(1.3035645485), tensor(1.2199627161), tensor(0.9896937013), tensor(1.7215728760), tensor(1.2043119669), tensor(1.3372712135), tensor(1.1596676111), tensor(0.9729868770), tensor(1.2789499760), tensor(1.2078340054), tensor(0.7780506015), tensor(1.2040544748), tensor(1.2395929098), tensor(0.9615337253), tensor(0.9549536109), tensor(1.2454237938), tensor(1.3604555130), tensor(1.3767746687)]\n",
            "c:  [tensor(-0.3009335697), tensor(0.6681951880), tensor(0.3782038689), tensor(-0.6737297773), tensor(0.0346795581), tensor(0.0681511089), tensor(0.2043628246), tensor(0.0493179411), tensor(1.2825009823), tensor(-0.0656986833), tensor(-0.1405774206), tensor(-0.3965669274), tensor(-0.2162056565), tensor(0.8316519260), tensor(-0.0407694839), tensor(-0.0033776760), tensor(-0.1857925653), tensor(-0.1341845393)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([3.5162715912, 1.4594770670, 2.6151008606, 2.0617768764, 5.5625438690,\n",
            "        3.6916265488, 1.8861548901, 2.5004143715, 3.0525343418, 3.3178422451,\n",
            "        2.9822273254, 3.5085268021, 1.4105746746, 2.4419248104, 2.1490921974,\n",
            "        1.5452535152, 2.0932266712, 2.6650481224, 3.0561249256, 1.8237075806])\n",
            "btensor.grad: tensor([2.3042416573, 0.7742986679, 2.2763142586, 1.7587316036, 0.8408190012,\n",
            "        2.4666254520, 1.5930765867, 1.7759504318, 2.1867039204, 2.2119312286,\n",
            "        2.0969052315, 1.4888345003, 1.1419978142, 1.3006068468, 1.2519383430,\n",
            "        0.3708686829, 1.4542272091, 2.3484010696, 1.6768836975, 2.2082238197])\n",
            "ctensor.grad: tensor([-10.3667087555, -26.6294040680,  -5.2047467232,  -7.4578018188,\n",
            "         -0.6039537191, -43.3549690247, -17.9489822388, -34.4862174988,\n",
            "         22.0887794495,   1.2143511772,  82.1573638916,  31.2185134888,\n",
            "         66.6028747559,  12.2531890869,   0.9991350174,  59.1537475586,\n",
            "         22.9806251526,  51.9300384521])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(687.2274169922, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8638517261), tensor(1.6103962660), tensor(1.0810332298), tensor(1.2002712488), tensor(0.8233728409), tensor(0.8319936395), tensor(1.4327523708), tensor(1.0593010187), tensor(1.1415748596), tensor(0.9832947254), tensor(0.9814996719), tensor(0.8745866418), tensor(1.6477413177), tensor(1.1528728008), tensor(1.5046548843), tensor(1.6029781103), tensor(1.4383735657), tensor(1.1401371956), tensor(0.9561456442), tensor(1.1736527681)]\n",
            "b:  [tensor(1.4017291069), tensor(0.8111501336), tensor(1.3285766840), tensor(1.2513549328), tensor(1.0202713013), tensor(1.7433786392), tensor(1.2294886112), tensor(1.3649471998), tensor(1.1863167286), tensor(1.0051498413), tensor(1.3070461750), tensor(1.2329343557), tensor(0.8062087893), tensor(1.2328472137), tensor(1.2726441622), tensor(0.9880492687), tensor(0.9848256111), tensor(1.2726393938), tensor(1.3914884329), tensor(1.4014128447)]\n",
            "c:  [tensor(-0.3416494727), tensor(0.6590840220), tensor(0.3954151273), tensor(-0.6924759150), tensor(0.0349918716), tensor(0.0232041702), tensor(0.1787692457), tensor(-0.0020447001), tensor(1.3309568167), tensor(-0.0655391887), tensor(-0.0248440579), tensor(-0.3492421806), tensor(-0.1096323729), tensor(0.8651218414), tensor(-0.0408817604), tensor(0.0815526322), tensor(-0.1470247805), tensor(-0.0486685559)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-9.1674661636, -2.6389393806, -6.9780826569, -2.7848892212,\n",
            "        -8.3787946701, -9.9985017776, -3.5911066532, -5.5527291298,\n",
            "        -4.4984445572, -6.0737071037, -7.0845656395, -4.7252464294,\n",
            "        -2.5886542797, -5.5446310043, -3.7388195992, -2.3255085945,\n",
            "        -3.0858874321, -7.3470392227, -8.6191415787, -6.8888940811])\n",
            "btensor.grad: tensor([-4.1229982376, -6.0747909546, -5.0024170876, -6.2784433365,\n",
            "        -6.1155300140, -4.3611526489, -5.0353264809, -5.5351986885,\n",
            "        -5.3298316002, -6.4325847626, -5.6192297935, -5.0200738907,\n",
            "        -5.6316370964, -5.7585420609, -6.6102399826, -5.3031044006,\n",
            "        -5.9743957520, -5.4431304932, -6.2065877914, -4.9276461601])\n",
            "ctensor.grad: tensor([ 4.0715900421e+01,  9.1111497879e+00, -1.7211252213e+01,\n",
            "         1.8746147156e+01, -3.1231427193e-01,  4.4946937561e+01,\n",
            "         2.5593584061e+01,  5.1362640381e+01, -4.8455844879e+01,\n",
            "        -1.5949277580e-01, -1.1573336029e+02, -4.7324733734e+01,\n",
            "        -1.0657328033e+02, -3.3469890594e+01,  1.1227702349e-01,\n",
            "        -8.4930305481e+01, -3.8767780304e+01, -8.5515975952e+01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(704.6527099609, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8224394321), tensor(1.5926964283), tensor(1.0497031212), tensor(1.1789424419), tensor(0.7785009742), tensor(0.7887871265), tensor(1.4109408855), tensor(1.0308636427), tensor(1.1128437519), tensor(0.9505986571), tensor(0.9466634393), tensor(0.8442500234), tensor(1.6300902367), tensor(1.1241071224), tensor(1.4819288254), tensor(1.5859094858), tensor(1.4171581268), tensor(1.1053802967), tensor(0.9179185033), tensor(1.1450737715)]\n",
            "b:  [tensor(1.3724410534), tensor(0.7823172808), tensor(1.2981259823), tensor(1.2174147367), tensor(0.9902488589), tensor(1.7143980265), tensor(1.2019991875), tensor(1.3363546133), tensor(1.1560280323), tensor(0.9691795707), tensor(1.2758067846), tensor(1.2053872347), tensor(0.7777277231), tensor(1.2033013105), tensor(1.2423239946), tensor(0.9640954733), tensor(0.9533695579), tensor(1.2407960892), tensor(1.3603935242), tensor(1.3720574379)]\n",
            "c:  [tensor(-0.3037685156), tensor(0.6692568660), tensor(0.3717071414), tensor(-0.6796983480), tensor(0.0357119739), tensor(0.0873814672), tensor(0.2080197930), tensor(0.0541074052), tensor(1.2883569002), tensor(-0.0673158541), tensor(-0.1867522895), tensor(-0.4186368883), tensor(-0.2551209033), tensor(0.8468571901), tensor(-0.0420541652), tensor(-0.0007636324), tensor(-0.1824188083), tensor(-0.1333543956)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([8.2824592590, 3.5399684906, 6.2660140991, 4.2657570839, 8.9743690491,\n",
            "        8.6412973404, 4.3622989655, 5.6874690056, 5.7462182045, 6.5392136574,\n",
            "        6.9672431946, 6.0673265457, 3.5302245617, 5.7531299591, 4.5452022552,\n",
            "        3.4137232304, 4.2430768013, 6.9513826370, 7.6454339027, 5.7157979012])\n",
            "btensor.grad: tensor([5.8576059341, 5.7665648460, 6.0901308060, 6.7880501747, 6.0044922829,\n",
            "        5.7961311340, 5.4978852272, 5.7185254097, 6.0577497482, 7.1940507889,\n",
            "        6.2478847504, 5.5094146729, 5.6962146759, 5.9091901779, 6.0640382767,\n",
            "        4.7907638550, 6.2912120819, 6.3686561584, 6.2189855576, 5.8710794449])\n",
            "ctensor.grad: tensor([-37.8809700012, -10.1728162766,  23.7079792023, -12.7775611877,\n",
            "         -0.7201007605, -64.1772918701, -29.2505378723, -56.1521034241,\n",
            "         42.5998802185,   1.7766643763, 161.9082183838,  69.3947143555,\n",
            "        145.4885253906,  18.2646293640,   1.1724059582,  82.3162612915,\n",
            "         35.3940238953,  84.6858291626])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(699.8002929688, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8848540783), tensor(1.6146656275), tensor(1.0970407724), tensor(1.2056412697), tensor(0.8482286334), tensor(0.8544160128), tensor(1.4365965128), tensor(1.0706679821), tensor(1.1519670486), tensor(1.0016901493), tensor(0.9971220493), tensor(0.8870530128), tensor(1.6518642902), tensor(1.1644730568), tensor(1.5106242895), tensor(1.6062788963), tensor(1.4438682795), tensor(1.1543109417), tensor(0.9725112319), tensor(1.1883794069)]\n",
            "b:  [tensor(1.4053659439), tensor(0.8185119033), tensor(1.3359820843), tensor(1.2579823732), tensor(1.0270409584), tensor(1.7486704588), tensor(1.2356019020), tensor(1.3742129803), tensor(1.1929488182), tensor(1.0114049911), tensor(1.3169068098), tensor(1.2391498089), tensor(0.8139839172), tensor(1.2413018942), tensor(1.2851686478), tensor(0.9957249165), tensor(0.9923459291), tensor(1.2799566984), tensor(1.4007735252), tensor(1.4082684517)]\n",
            "c:  [tensor(-0.3567905426), tensor(0.6316506267), tensor(0.4008401930), tensor(-0.7122367024), tensor(0.0358540863), tensor(0.0023046881), tensor(0.1661486626), tensor(-0.0300545916), tensor(1.3552017212), tensor(-0.0668726265), tensor(-0.0341975242), tensor(-0.3625116348), tensor(-0.1287645251), tensor(0.8936567307), tensor(-0.0419019125), tensor(0.1209322140), tensor(-0.1291067898), tensor(-0.0143406317)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-12.4829349518,  -4.3938436508,  -9.4675407410,  -5.3397746086,\n",
            "        -13.9455327988, -13.1257829666,  -5.1311302185,  -7.9608707428,\n",
            "         -7.8246555328, -10.2182941437, -10.0917186737,  -8.5605945587,\n",
            "         -4.3548045158,  -8.0731935501,  -5.7390880585,  -4.0738735199,\n",
            "         -5.3420228958,  -9.7861175537, -10.9185514450,  -8.6611270905])\n",
            "btensor.grad: tensor([-6.5849709511, -7.2389211655, -7.5712237358, -8.1135225296,\n",
            "        -7.3584156036, -6.8544821739, -6.7205548286, -7.5716738701,\n",
            "        -7.3841662407, -8.4450912476, -8.2199945450, -6.7525143623,\n",
            "        -7.2512440681, -7.6001243591, -8.5689268112, -6.3258924484,\n",
            "        -7.7952694893, -7.8321175575, -8.0760126114, -7.2422094345])\n",
            "ctensor.grad: tensor([ 5.3022026062e+01,  3.7606250763e+01, -2.9133062363e+01,\n",
            "         3.2538337708e+01, -1.4211085439e-01,  8.5076774597e+01,\n",
            "         4.1871120453e+01,  8.4161994934e+01, -6.6844772339e+01,\n",
            "        -4.4322738051e-01, -1.5255476379e+02, -5.6125247955e+01,\n",
            "        -1.2635636902e+02, -4.6799526215e+01, -1.5225256979e-01,\n",
            "        -1.2169583893e+02, -5.3312019348e+01, -1.1901375580e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(713.9064941406, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8365080357), tensor(1.5944715738), tensor(1.0603191853), tensor(1.1820210218), tensor(0.7988053560), tensor(0.8035110235), tensor(1.4128473997), tensor(1.0379147530), tensor(1.1212829351), tensor(0.9638453722), tensor(0.9580590725), tensor(0.8541117907), tensor(1.6318562031), tensor(1.1317850351), tensor(1.4857857227), tensor(1.5875313282), tensor(1.4210101366), tensor(1.1158747673), tensor(0.9290815592), tensor(1.1532579660)]\n",
            "b:  [tensor(1.3735820055), tensor(0.7812127471), tensor(1.3016823530), tensor(1.2190136909), tensor(0.9914094806), tensor(1.7172187567), tensor(1.2024232149), tensor(1.3393359184), tensor(1.1570113897), tensor(0.9711957574), tensor(1.2791272402), tensor(1.2066743374), tensor(0.7771559358), tensor(1.2058808804), tensor(1.2462300062), tensor(0.9632226825), tensor(0.9546074271), tensor(1.2435325384), tensor(1.3641599417), tensor(1.3747795820)]\n",
            "c:  [tensor(-0.3044376075), tensor(0.6499642730), tensor(0.3573628366), tensor(-0.7034030557), tensor(0.0364322364), tensor(0.0492323376), tensor(0.1887035519), tensor(0.0133934990), tensor(1.3104547262), tensor(-0.0686541945), tensor(-0.1972571313), tensor(-0.4323146939), tensor(-0.2768303752), tensor(0.8820542693), tensor(-0.0428914428), tensor(0.0633216500), tensor(-0.1553491205), tensor(-0.0804458112)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 9.6692056656,  4.0388169289,  7.3443222046,  4.7240419388,\n",
            "         9.8846588135, 10.1809988022,  4.7498226166,  6.5506496429,\n",
            "         6.1368198395,  7.5689568520,  7.8125925064,  6.5882396698,\n",
            "         4.0016255379,  6.5376114845,  4.9677047729,  3.7495217323,\n",
            "         4.5716309547,  7.6872429848,  8.6859340668,  7.0242867470])\n",
            "btensor.grad: tensor([6.3567919731, 7.4598307610, 6.8599495888, 7.7937326431, 7.1262903214,\n",
            "        6.2903466225, 6.6357350349, 6.9754147530, 7.1874914169, 8.0418472290,\n",
            "        7.5559105873, 6.4951019287, 7.3655972481, 7.0842142105, 7.7877349854,\n",
            "        6.5004501343, 7.5476994514, 7.2848258018, 7.3227128983, 6.6977849007])\n",
            "ctensor.grad: tensor([-52.3529434204, -18.3136634827,  43.4773674011,  -8.8336734772,\n",
            "         -0.5781509280, -46.9276466370, -22.5548820496, -43.4480895996,\n",
            "         44.7469711304,   1.7815693617, 163.0596008301,  69.8030548096,\n",
            "        148.0658416748,  11.6024742126,   0.9895289540,  57.6105575562,\n",
            "         26.2423286438,  66.1051788330])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(692.4396972656, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8514184356), tensor(1.6059725285), tensor(1.0756233931), tensor(1.1980118752), tensor(0.8271193504), tensor(0.8185929060), tensor(1.4254542589), tensor(1.0544581413), tensor(1.1432754993), tensor(0.9875904322), tensor(0.9778540134), tensor(0.8766599298), tensor(1.6441657543), tensor(1.1493910551), tensor(1.5015236139), tensor(1.5985856056), tensor(1.4369612932), tensor(1.1337667704), tensor(0.9428337216), tensor(1.1669168472)]\n",
            "b:  [tensor(1.3971551657), tensor(0.8005735874), tensor(1.3270443678), tensor(1.2428305149), tensor(1.0096250772), tensor(1.7407845259), tensor(1.2230714560), tensor(1.3628016710), tensor(1.1803853512), tensor(0.9961405396), tensor(1.3055866957), tensor(1.2266213894), tensor(0.7979108691), tensor(1.2267621756), tensor(1.2691498995), tensor(0.9798154831), tensor(0.9772801399), tensor(1.2689689398), tensor(1.3874762058), tensor(1.3990616798)]\n",
            "c:  [tensor(-0.3478848636), tensor(0.6538852453), tensor(0.4051728845), tensor(-0.7052296996), tensor(0.0368817188), tensor(0.0653094724), tensor(0.1947065592), tensor(0.0238293521), tensor(1.3629742861), tensor(-0.0684911162), tensor(-0.0821653381), tensor(-0.3917065561), tensor(-0.1876953244), tensor(0.8855360150), tensor(-0.0434596166), tensor(0.0507289767), tensor(-0.1590507925), tensor(-0.0857707337)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-2.9820816517, -2.3001866341, -3.0608422756, -3.1981742382,\n",
            "        -5.6628022194, -3.0163760185, -2.5213608742, -3.3086800575,\n",
            "        -4.3985166550, -4.7490134239, -3.9589872360, -4.5096268654,\n",
            "        -2.4619095325, -3.5212025642, -3.1475813389, -2.2108528614,\n",
            "        -3.1902327538, -3.5784053802, -2.7504343987, -2.7317714691])\n",
            "btensor.grad: tensor([-4.7146239281, -3.8721661568, -5.0724110603, -4.7633528709,\n",
            "        -3.6431150436, -4.7131619453, -4.1296396255, -4.6931400299,\n",
            "        -4.6747903824, -4.9889516830, -5.2918891907, -3.9894061089,\n",
            "        -4.1509881020, -4.1762704849, -4.5839748383, -3.3185617924,\n",
            "        -4.5345373154, -5.0872893333, -4.6632490158, -4.8564162254])\n",
            "ctensor.grad: tensor([  43.4472579956,   -3.9209647179,  -47.8100318909,    1.8266577721,\n",
            "          -0.4494840205,  -16.0771331787,   -6.0030040741,  -10.4358520508,\n",
            "         -52.5195426941,   -0.1630782783, -115.0917892456,  -40.6081466675,\n",
            "         -89.1350402832,   -3.4817543030,    0.5681722760,   12.5926704407,\n",
            "           3.7016742229,    5.3249211311])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(679.8043823242, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8371766806), tensor(1.5985175371), tensor(1.0653108358), tensor(1.1867191792), tensor(0.8021419048), tensor(0.8049036860), tensor(1.4172568321), tensor(1.0440514088), tensor(1.1284066439), tensor(0.9714989066), tensor(0.9651038051), tensor(0.8594051600), tensor(1.6372941732), tensor(1.1385817528), tensor(1.4917485714), tensor(1.5905605555), tensor(1.4264748096), tensor(1.1233203411), tensor(0.9315656424), tensor(1.1610797644)]\n",
            "b:  [tensor(1.3861426115), tensor(0.7992162108), tensor(1.3166934252), tensor(1.2372900248), tensor(1.0081551075), tensor(1.7291646004), tensor(1.2168407440), tensor(1.3561416864), tensor(1.1711418629), tensor(0.9884012938), tensor(1.2961912155), tensor(1.2202863693), tensor(0.7936106324), tensor(1.2219043970), tensor(1.2644900084), tensor(0.9792254567), tensor(0.9716381431), tensor(1.2583464384), tensor(1.3816213608), tensor(1.3898537159)]\n",
            "c:  [tensor(-0.3450081944), tensor(0.6803013086), tensor(0.4090721309), tensor(-0.6957061887), tensor(0.0376646519), tensor(0.1183919758), tensor(0.2151860297), tensor(0.0629549176), tensor(1.3455985785), tensor(-0.0695105270), tensor(-0.1437990814), tensor(-0.4132367671), tensor(-0.2347061932), tensor(0.8750581741), tensor(-0.0444864780), tensor(-0.0022804737), tensor(-0.1783756316), tensor(-0.1310084313)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([2.8483524323, 1.4909955263, 2.0625023842, 2.2585380077, 4.9954843521,\n",
            "        2.7378394604, 1.6394829750, 2.0813460350, 2.9737660885, 3.2183020115,\n",
            "        2.5500447750, 3.4509513378, 1.3743270636, 2.1618542671, 1.9550132751,\n",
            "        1.6050056219, 2.0972986221, 2.0892744064, 2.2536134720, 1.1674077511])\n",
            "btensor.grad: tensor([2.2025189400, 0.2714797854, 2.0701911449, 1.1081020832, 0.2940030098,\n",
            "        2.3239862919, 1.2461426258, 1.3320060968, 1.8487077951, 1.5478522778,\n",
            "        1.8791003227, 1.2670129538, 0.8600479364, 0.9715439081, 0.9319688678,\n",
            "        0.1180087924, 1.1283948421, 2.1244902611, 1.1709740162, 1.8415875435])\n",
            "ctensor.grad: tensor([ -2.8766648769, -26.4160423279,  -3.8992507458,  -9.5234937668,\n",
            "         -0.7829313278, -53.0825042725, -20.4794673920, -39.1255683899,\n",
            "         17.3756771088,   1.0194083452,  61.6337394714,  21.5301971436,\n",
            "         47.0108680725,  10.4778680801,   1.0268598795,  53.0094490051,\n",
            "         19.3248405457,  45.2376976013])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(684.0986938477, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8905999660), tensor(1.6114513874), tensor(1.1020274162), tensor(1.1993731260), tensor(0.8445628881), tensor(0.8629890680), tensor(1.4346888065), tensor(1.0735510588), tensor(1.1482536793), tensor(1.0022901297), tensor(1.0003701448), tensor(0.8813079000), tensor(1.6500571966), tensor(1.1663135290), tensor(1.5099340677), tensor(1.6015715599), tensor(1.4403988123), tensor(1.1603240967), tensor(0.9775950909), tensor(1.1979387999)]\n",
            "b:  [tensor(1.4035888910), tensor(0.8280716538), tensor(1.3390955925), tensor(1.2667059898), tensor(1.0376449823), tensor(1.7487542629), tensor(1.2399436235), tensor(1.3822976351), tensor(1.1956242323), tensor(1.0192172527), tensor(1.3214710951), tensor(1.2430890799), tensor(0.8199673295), tensor(1.2490253448), tensor(1.2961246967), tensor(1.0043315887), tensor(0.9993750453), tensor(1.2837003469), tensor(1.4110360146), tensor(1.4129039049)]\n",
            "c:  [tensor(-0.3670333922), tensor(0.6619351506), tensor(0.4234939814), tensor(-0.7270852327), tensor(0.0379693955), tensor(0.0327654183), tensor(0.1714849770), tensor(-0.0253150612), tensor(1.3868576288), tensor(-0.0694749951), tensor(-0.0429633707), tensor(-0.3709575236), tensor(-0.1427312493), tensor(0.9083831906), tensor(-0.0446929410), tensor(0.0891217589), tensor(-0.1342245489), tensor(-0.0378161222)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-10.6846551895,  -2.5867681503,  -7.3433170319,  -2.5307986736,\n",
            "         -8.4842014313, -11.6170768738,  -3.4863903522,  -5.8999261856,\n",
            "         -3.9694151878,  -6.1582431793,  -7.0532598495,  -4.3805484772,\n",
            "         -2.5525972843,  -5.5463476181,  -3.6370928288,  -2.2021946907,\n",
            "         -2.7848017216,  -7.4007439613,  -9.2058849335,  -7.3718042374])\n",
            "btensor.grad: tensor([-3.4892590046, -5.7710876465, -4.4804320335, -5.8831868172,\n",
            "        -5.8979730606, -3.9179284573, -4.6205711365, -5.2311840057,\n",
            "        -4.8964681625, -6.1632027626, -5.0559859276, -4.5605397224,\n",
            "        -5.2713370323, -5.4241886139, -6.3269405365, -5.0212159157,\n",
            "        -5.5473833084, -5.0707912445, -5.8829307556, -4.6100316048])\n",
            "ctensor.grad: tensor([ 2.2025188446e+01,  1.8366167068e+01, -1.4421849251e+01,\n",
            "         3.1379062653e+01, -3.0474242568e-01,  8.5626556396e+01,\n",
            "         4.3701053619e+01,  8.8269973755e+01, -4.1259063721e+01,\n",
            "        -3.5533875227e-02, -1.0083570862e+02, -4.2279251099e+01,\n",
            "        -9.1974945068e+01, -3.3325000763e+01,  2.0646357536e-01,\n",
            "        -9.1402229309e+01, -4.4151081085e+01, -9.3192306519e+01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(707.4023437500, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8440911770), tensor(1.5911116600), tensor(1.0662606955), tensor(1.1750947237), tensor(0.7954749465), tensor(0.8145519495), tensor(1.4108061790), tensor(1.0414460897), tensor(1.1168235540), tensor(0.9648510814), tensor(0.9623442292), tensor(0.8477648497), tensor(1.6299450397), tensor(1.1340528727), tensor(1.4847759008), tensor(1.5823186636), tensor(1.4168891907), tensor(1.1229516268), tensor(0.9357008934), tensor(1.1650990248)]\n",
            "b:  [tensor(1.3714976311), tensor(0.7946594954), tensor(1.3051909208), tensor(1.2293928862), tensor(1.0042837858), tensor(1.7168264389), tensor(1.2083849907), tensor(1.3491718769), tensor(1.1607921124), tensor(0.9796025157), tensor(1.2852964401), tensor(1.2118800879), tensor(0.7863413095), tensor(1.2155101299), tensor(1.2598297596), tensor(0.9757577181), tensor(0.9639396071), tensor(1.2479870319), tensor(1.3760778904), tensor(1.3797142506)]\n",
            "c:  [tensor(-0.3199300766), tensor(0.6803905368), tensor(0.3887506425), tensor(-0.7149757743), tensor(0.0386635214), tensor(0.0954468772), tensor(0.2006978542), tensor(0.0294322073), tensor(1.3411726952), tensor(-0.0712824538), tensor(-0.2046733499), tensor(-0.4390927553), tensor(-0.2878614664), tensor(0.8916780949), tensor(-0.0458763540), tensor(0.0107411593), tensor(-0.1686231941), tensor(-0.1222044602)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([9.3017597198, 4.0679359436, 7.1533451080, 4.8556804657, 9.8175935745,\n",
            "        9.6874294281, 4.7765364647, 6.4209952354, 6.2860302925, 7.4878063202,\n",
            "        7.6051874161, 6.7086153030, 4.0224332809, 6.4521298409, 5.0316314697,\n",
            "        3.8505737782, 4.7019176483, 7.4744863510, 8.3788356781, 6.5679621696])\n",
            "btensor.grad: tensor([6.4182596207, 6.6824283600, 6.7809348106, 7.4626274109, 6.6722335815,\n",
            "        6.3855743408, 6.3117289543, 6.6251573563, 6.9664278030, 7.9229431152,\n",
            "        7.2349352837, 6.2417883873, 6.7252016068, 6.7030405998, 7.2589936256,\n",
            "        5.7147731781, 7.0870881081, 7.1426582336, 6.9916267395, 6.6379375458])\n",
            "ctensor.grad: tensor([-47.1032981873, -18.4554042816,  34.7433471680, -12.1094532013,\n",
            "         -0.6941254139, -62.6814575195, -29.2128734589, -54.7472648621,\n",
            "         45.6849594116,   1.8074588776, 161.7099761963,  68.1352462769,\n",
            "        145.1302032471,  16.7051143646,   1.1834136248,  78.3805923462,\n",
            "         34.3986434937,  84.3883361816])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(692.8822021484, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8845061064), tensor(1.6093890667), tensor(1.1007045507), tensor(1.1984170675), tensor(0.8456423879), tensor(0.8565541506), tensor(1.4305765629), tensor(1.0714877844), tensor(1.1491205692), tensor(1.0050711632), tensor(0.9999287724), tensor(0.8825390935), tensor(1.6483955383), tensor(1.1652311087), tensor(1.5077384710), tensor(1.5994572639), tensor(1.4393504858), tensor(1.1583482027), tensor(0.9720395207), tensor(1.1958545446)]\n",
            "b:  [tensor(1.4012091160), tensor(0.8239352107), tensor(1.3385301828), tensor(1.2629872561), tensor(1.0332738161), tensor(1.7468167543), tensor(1.2368187904), tensor(1.3814436197), tensor(1.1924828291), tensor(1.0144402981), tensor(1.3213890791), tensor(1.2404129505), tensor(0.8166305423), tensor(1.2467283010), tensor(1.2955918312), tensor(1.0012181997), tensor(0.9962995648), tensor(1.2816572189), tensor(1.4097718000), tensor(1.4113972187)]\n",
            "c:  [tensor(-0.3734475374), tensor(0.6555067301), tensor(0.4319675863), tensor(-0.7340909243), tensor(0.0389937460), tensor(0.0534628071), tensor(0.1781978756), tensor(-0.0139701962), tensor(1.3983473778), tensor(-0.0710032061), tensor(-0.0776609182), tensor(-0.3940276504), tensor(-0.1874476373), tensor(0.9206848741), tensor(-0.0460359156), tensor(0.0793359131), tensor(-0.1369689852), tensor(-0.0480360240)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ -8.0829858780,  -3.6554737091,  -6.8887686729,  -4.6644630432,\n",
            "        -10.0334901810,  -8.4004373550,  -3.9540696144,  -6.0083413124,\n",
            "         -6.4594049454,  -8.0440149307,  -7.5169053078,  -6.9548473358,\n",
            "         -3.6901030540,  -6.2356462479,  -4.5925064087,  -3.4277193546,\n",
            "         -4.4922680855,  -7.0793251991,  -7.2677297592,  -6.1511011124])\n",
            "btensor.grad: tensor([-5.9422965050, -5.8551421165, -6.6678500175, -6.7188630104,\n",
            "        -5.7979955673, -5.9980645180, -5.6867704391, -6.4543576241,\n",
            "        -6.3381404877, -6.9675621986, -7.2185287476, -5.7065801620,\n",
            "        -6.0578474998, -6.2436294556, -7.1524124146, -5.0920886993,\n",
            "        -6.4719896317, -6.7340364456, -6.7387742996, -6.3365964890])\n",
            "ctensor.grad: tensor([  53.5174674988,   24.8838024139,  -43.2169418335,   19.1151504517,\n",
            "          -0.3302234709,   41.9840698242,   22.4999771118,   43.4024009705,\n",
            "         -57.1746292114,   -0.2792511880, -127.0124206543,  -45.0651130676,\n",
            "        -100.4138259888,  -29.0068054199,    0.1595621705,  -68.5947494507,\n",
            "         -31.6542034149,  -74.1684341431])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(692.9345092773, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8471788168), tensor(1.5930536985), tensor(1.0725889206), tensor(1.1780602932), tensor(0.8052824736), tensor(0.8183227777), tensor(1.4129365683), tensor(1.0468661785), tensor(1.1240458488), tensor(0.9739336371), tensor(0.9708839059), tensor(0.8549465537), tensor(1.6328198910), tensor(1.1399120092), tensor(1.4885407686), tensor(1.5838588476), tensor(1.4206459522), tensor(1.1308299303), tensor(0.9402536750), tensor(1.1715517044)]\n",
            "b:  [tensor(1.3782268763), tensor(0.8031942248), tensor(1.3142869473), tensor(1.2397016287), tensor(1.0129669905), tensor(1.7234269381), tensor(1.2154778242), tensor(1.3589568138), tensor(1.1677408218), tensor(0.9887380004), tensor(1.2953002453), tensor(1.2189427614), tensor(0.7938358188), tensor(1.2242910862), tensor(1.2697649002), tensor(0.9828453660), tensor(0.9725356102), tensor(1.2559834719), tensor(1.3866138458), tensor(1.3883223534)]\n",
            "c:  [tensor(-0.3433413804), tensor(0.6890351772), tensor(0.4104040563), tensor(-0.7208140492), tensor(0.0397709273), tensor(0.1230857819), tensor(0.2096862197), tensor(0.0448966064), tensor(1.3643822670), tensor(-0.0723768473), tensor(-0.1892625540), tensor(-0.4371841848), tensor(-0.2826411426), tensor(0.9054381847), tensor(-0.0471927412), tensor(0.0053096041), tensor(-0.1686441749), tensor(-0.1250470728)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([7.4654641151, 3.2670750618, 5.6231245995, 4.0713481903, 8.0719776154,\n",
            "        7.6462802887, 3.5280036926, 4.9243106842, 5.0149388313, 6.2275071144,\n",
            "        5.8089733124, 5.5185103416, 3.1151411533, 5.0638298988, 3.8395378590,\n",
            "        3.1196939945, 3.7409067154, 5.5036544800, 6.3571739197, 4.8605756760])\n",
            "btensor.grad: tensor([4.5964546204, 4.1481957436, 4.8486409187, 4.6571249962, 4.0613660812,\n",
            "        4.6779661179, 4.2681841850, 4.4973726273, 4.9483971596, 5.1404557228,\n",
            "        5.2177610397, 4.2940382957, 4.5589504242, 4.4874463081, 5.1653823853,\n",
            "        3.6745681763, 4.7527966499, 5.1347532272, 4.6315879822, 4.6149826050])\n",
            "ctensor.grad: tensor([-30.1061458588, -33.5284500122,  21.5635375977, -13.2768802643,\n",
            "         -0.7771821022, -69.6229705811, -31.4883518219, -58.8667984009,\n",
            "         33.9651260376,   1.3736411333, 111.6016311646,  43.1565399170,\n",
            "         95.1935043335,  15.2466983795,   1.1568253040,  74.0263061523,\n",
            "         31.6751899719,  77.0110473633])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(688.6704711914, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8950973153), tensor(1.6099777222), tensor(1.1097131968), tensor(1.1979126930), tensor(0.8564931750), tensor(0.8699432611), tensor(1.4325484037), tensor(1.0782525539), tensor(1.1527260542), tensor(1.0128862858), tensor(1.0086261034), tensor(0.8866942525), tensor(1.6495509148), tensor(1.1710371971), tensor(1.5108840466), tensor(1.5992647409), tensor(1.4406675100), tensor(1.1679402590), tensor(0.9821048379), tensor(1.2060046196)]\n",
            "b:  [tensor(1.4032933712), tensor(0.8326910734), tensor(1.3441581726), tensor(1.2720978260), tensor(1.0423491001), tensor(1.7505491972), tensor(1.2422984838), tensor(1.3900886774), tensor(1.1976510286), tensor(1.0228445530), tensor(1.3284903765), tensor(1.2458528280), tensor(0.8234747648), tensor(1.2544221878), tensor(1.3053588867), tensor(1.0085290670), tensor(1.0038944483), tensor(1.2881236076), tensor(1.4194421768), tensor(1.4176323414)]\n",
            "c:  [tensor(-0.3821951747), tensor(0.6617621183), tensor(0.4442028403), tensor(-0.7520122528), tensor(0.0400553122), tensor(0.0415844545), tensor(0.1692862362), tensor(-0.0336802863), tensor(1.4155395031), tensor(-0.0721801892), tensor(-0.0726827011), tensor(-0.3935424387), tensor(-0.1870700717), tensor(0.9380648136), tensor(-0.0473671071), tensor(0.0899795964), tensor(-0.1284942627), tensor(-0.0360394791)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ -9.5837020874,  -3.3847968578,  -7.4248499870,  -3.9704916477,\n",
            "        -10.2421360016, -10.3240976334,  -3.9223561287,  -6.2772679329,\n",
            "         -5.7360310555,  -7.7905216217,  -7.5484347343,  -6.3495430946,\n",
            "         -3.3462100029,  -6.2250490189,  -4.4686503410,  -3.0811798573,\n",
            "         -4.0043191910,  -7.4220571518,  -8.3702354431,  -6.8905863762])\n",
            "btensor.grad: tensor([-5.0132980347, -5.8993678093, -5.9742350578, -6.4792480469,\n",
            "        -5.8764286041, -5.4244575500, -5.3641276360, -6.2263803482,\n",
            "        -5.9820489883, -6.8213143349, -6.6380348206, -5.3820238113,\n",
            "        -5.9277901649, -6.0262160301, -7.1188006401, -5.1367368698,\n",
            "        -6.2717728615, -6.4280285835, -6.5656700134, -5.8619918823])\n",
            "ctensor.grad: tensor([  38.8537826538,   27.2730731964,  -33.7987899780,   31.1981868744,\n",
            "          -0.2843837738,   81.5013198853,   40.3999786377,   78.5768890381,\n",
            "         -51.1572227478,   -0.1966578662, -116.5798492432,  -43.6417465210,\n",
            "         -95.5710678101,  -32.6266517639,    0.1743660569,  -84.6699905396,\n",
            "         -40.1499137878,  -89.0075912476])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(700.8878784180, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8509760499), tensor(1.5902767181), tensor(1.0757669210), tensor(1.1742445230), tensor(0.8104578853), tensor(0.8243117332), tensor(1.4112920761), tensor(1.0483562946), tensor(1.1237324476), tensor(0.9762968421), tensor(0.9738460183), tensor(0.8548796177), tensor(1.6306412220), tensor(1.1408355236), tensor(1.4879071712), tensor(1.5807012320), tensor(1.4187194109), tensor(1.1346215010), tensor(0.9439395070), tensor(1.1753393412)]\n",
            "b:  [tensor(1.3751852512), tensor(0.8040883541), tensor(1.3140279055), tensor(1.2414551973), tensor(1.0144319534), tensor(1.7220128775), tensor(1.2146360874), tensor(1.3606863022), tensor(1.1662883759), tensor(0.9893732667), tensor(1.2952336073), tensor(1.2182201147), tensor(0.7931842804), tensor(1.2249249220), tensor(1.2713872194), tensor(0.9831017852), tensor(0.9729728699), tensor(1.2560292482), tensor(1.3891807795), tensor(1.3884341717)]\n",
            "c:  [tensor(-0.3381431997), tensor(0.6951947212), tensor(0.4109925032), tensor(-0.7406650186), tensor(0.0407386310), tensor(0.1026436388), tensor(0.1978733838), tensor(0.0192281604), tensor(1.3752287626), tensor(-0.0737065449), tensor(-0.2045518160), tensor(-0.4458086193), tensor(-0.3013909757), tensor(0.9230186343), tensor(-0.0485405438), tensor(0.0160648376), tensor(-0.1611290425), tensor(-0.1165074632)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([8.8242492676, 3.9402031898, 6.7892498970, 4.7336359024, 9.2070579529,\n",
            "        9.1263113022, 4.2512626648, 5.9792408943, 5.7987146378, 7.3178858757,\n",
            "        6.9560165405, 6.3629231453, 3.7819490433, 6.0403318405, 4.5953769684,\n",
            "        3.7127027512, 4.3896183968, 6.6637558937, 7.6330680847, 6.1330661774])\n",
            "btensor.grad: tensor([5.6216259003, 5.7205419540, 6.0260472298, 6.1285142899, 5.5834255219,\n",
            "        5.7072639465, 5.5324854851, 5.8804745674, 6.2725224495, 6.6942529678,\n",
            "        6.6513590813, 5.5265474319, 6.0580940247, 5.8994536400, 6.7943267822,\n",
            "        5.0854516029, 6.1843147278, 6.4188809395, 6.0522794724, 5.8396272659])\n",
            "ctensor.grad: tensor([-44.0519790649, -33.4326095581,  33.2103424072, -11.3472127914,\n",
            "         -0.6833200455, -61.0591812134, -28.5871391296, -52.9084434509,\n",
            "         40.3106956482,   1.5263539553, 131.8690948486,  52.2661743164,\n",
            "        114.3208999634,  15.0462045670,   1.1734359264,  73.9147567749,\n",
            "         32.6347808838,  80.4679794312])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(687.0093994141, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8811933994), tensor(1.6044127941), tensor(1.1022443771), tensor(1.1924060583), tensor(0.8478054404), tensor(0.8565218449), tensor(1.4265791178), tensor(1.0716186762), tensor(1.1489226818), tensor(1.0072280169), tensor(1.0022659302), tensor(0.8813879490), tensor(1.6450484991), tensor(1.1651242971), tensor(1.5060695410), tensor(1.5938116312), tensor(1.4363441467), tensor(1.1613693237), tensor(0.9709486365), tensor(1.1993380785)]\n",
            "b:  [tensor(1.3994392157), tensor(0.8286498785), tensor(1.3417141438), tensor(1.2691714764), tensor(1.0378526449), tensor(1.7467858791), tensor(1.2383902073), tensor(1.3880543709), tensor(1.1931011677), tensor(1.0180137157), tensor(1.3257987499), tensor(1.2419097424), tensor(0.8188076615), tensor(1.2503463030), tensor(1.3017359972), tensor(1.0044475794), tensor(1.0000361204), tensor(1.2844487429), tensor(1.4172565937), tensor(1.4149646759)]\n",
            "c:  [tensor(-0.3850278258), tensor(0.6805635095), tensor(0.4534813464), tensor(-0.7537233829), tensor(0.0411760472), tensor(0.0804114118), tensor(0.1841933131), tensor(-0.0066041797), tensor(1.4249277115), tensor(-0.0735434219), tensor(-0.0946477950), tensor(-0.4065503776), tensor(-0.2146420181), tensor(0.9424918294), tensor(-0.0489213131), tensor(0.0560409166), tensor(-0.1410324425), tensor(-0.0678823143)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-6.0434713364, -2.8272187710, -5.2954936028, -3.6322996616,\n",
            "        -7.4695148468, -6.4420166016, -3.0574030876, -4.6524820328,\n",
            "        -5.0380487442, -6.1862411499, -5.6839790344, -5.3016667366,\n",
            "        -2.8814456463, -4.8577508926, -3.6324803829, -2.6220872402,\n",
            "        -3.5249547958, -5.3495564461, -5.4018316269, -4.7997422218])\n",
            "btensor.grad: tensor([-4.8508019447, -4.9123077393, -5.5372567177, -5.5432648659,\n",
            "        -4.6841354370, -4.9546051025, -4.7508316040, -5.4736170769,\n",
            "        -5.3625669479, -5.7280883789, -6.1130380630, -4.7379341125,\n",
            "        -5.1246757507, -5.0842733383, -6.0697531700, -4.2691669464,\n",
            "        -5.4126410484, -5.6839008331, -5.6151676178, -5.3060932159])\n",
            "ctensor.grad: tensor([  46.8846397400,   14.6312170029,  -42.4888381958,   13.0583610535,\n",
            "          -0.4374152422,   22.2322273254,   13.6800775528,   25.8323383331,\n",
            "         -49.6989097595,   -0.1631212085, -109.9040145874,  -39.2582321167,\n",
            "         -86.7489624023,  -19.4732189178,    0.3807678223,  -39.9760780334,\n",
            "         -20.0966053009,  -48.6251411438])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(683.9705200195, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8515302539), tensor(1.5903789997), tensor(1.0800908804), tensor(1.1740731001), tensor(0.8137141466), tensor(0.8274621367), tensor(1.4123898745), tensor(1.0522471666), tensor(1.1269856691), tensor(0.9805940390), tensor(0.9789975882), tensor(0.8569988012), tensor(1.6318882704), tensor(1.1446151733), tensor(1.4901071787), tensor(1.5799871683), tensor(1.4198986292), tensor(1.1399507523), tensor(0.9466040134), tensor(1.1820403337)]\n",
            "b:  [tensor(1.3803807497), tensor(0.8160188198), tensor(1.3222939968), tensor(1.2530400753), tensor(1.0246391296), tensor(1.7272067070), tensor(1.2232624292), tensor(1.3719890118), tensor(1.1747038364), tensor(0.9995376468), tensor(1.3056739569), tensor(1.2259569168), tensor(0.8033612370), tensor(1.2341201305), tensor(1.2835913897), tensor(0.9929948449), tensor(0.9830941558), tensor(1.2641600370), tensor(1.4009819031), tensor(1.3972975016)]\n",
            "c:  [tensor(-0.3667149544), tensor(0.7132422924), tensor(0.4429563582), tensor(-0.7397010922), tensor(0.0420317017), tensor(0.1531491280), tensor(0.2154415101), tensor(0.0519273281), tensor(1.3977503777), tensor(-0.0747121647), tensor(-0.1820022166), tensor(-0.4384236932), tensor(-0.2848475575), tensor(0.9268466830), tensor(-0.0501382127), tensor(-0.0190522335), tensor(-0.1716074049), tensor(-0.1408184320)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([5.9326338768, 2.8067572117, 4.4306912422, 3.6665830612, 6.8182606697,\n",
            "        5.8119435310, 2.8378567696, 3.8742978573, 4.3874030113, 5.3267965317,\n",
            "        4.6536726952, 4.8778324127, 2.6320464611, 4.1018171310, 3.1924674511,\n",
            "        2.7648878098, 3.2890932560, 4.2837090492, 4.8689193726, 3.4595427513])\n",
            "btensor.grad: tensor([3.8117017746, 2.5262119770, 3.8840394020, 3.2262732983, 2.6427106857,\n",
            "        3.9158318043, 3.0255489349, 3.2130749226, 3.6794641018, 3.6952123642,\n",
            "        4.0249586105, 3.1905670166, 3.0892829895, 3.2452275753, 3.6289200783,\n",
            "        2.2905492783, 3.3883886337, 4.0577378273, 3.2549443245, 3.5334393978])\n",
            "ctensor.grad: tensor([-18.3128604889, -32.6787567139,  10.5250005722, -14.0222749710,\n",
            "         -0.8556536436, -72.7377090454, -31.2482013702, -58.5315055847,\n",
            "         27.1772918701,   1.1687455177,  87.3544082642,  31.8733177185,\n",
            "         70.2055435181,  15.6451196671,   1.2169009447,  75.0931472778,\n",
            "         30.5749626160,  72.9361114502])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(691.2330932617, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.9245861769), tensor(1.6101324558), tensor(1.1292583942), tensor(1.1964848042), tensor(0.8822925687), tensor(0.9054340720), tensor(1.4364893436), tensor(1.0936007500), tensor(1.1595746279), tensor(1.0292190313), tensor(1.0280970335), tensor(0.8957179189), tensor(1.6510289907), tensor(1.1828911304), tensor(1.5166473389), tensor(1.5976300240), tensor(1.4423525333), tensor(1.1880255938), tensor(1.0059969425), tensor(1.2277505398)]\n",
            "b:  [tensor(1.4052733183), tensor(0.8490699530), tensor(1.3532167673), tensor(1.2885947227), tensor(1.0580724478), tensor(1.7554228306), tensor(1.2521165609), tensor(1.4057084322), tensor(1.2066955566), tensor(1.0371468067), tensor(1.3400321007), tensor(1.2549418211), tensor(0.8356357813), tensor(1.2672091722), tensor(1.3226215839), tensor(1.0216858387), tensor(1.0172294378), tensor(1.2985750437), tensor(1.4371014833), tensor(1.4284477234)]\n",
            "c:  [tensor(-0.3896465302), tensor(0.6662386656), tensor(0.4578698874), tensor(-0.7894598842), tensor(0.0421279594), tensor(0.0091265589), tensor(0.1472453475), tensor(-0.0840268135), tensor(1.4496921301), tensor(-0.0744958222), tensor(-0.0588327050), tensor(-0.3907012045), tensor(-0.1815794110), tensor(0.9781783223), tensor(-0.0500836000), tensor(0.1282238960), tensor(-0.1046620980), tensor(0.0011033863)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-14.6111793518,  -3.9506824017,  -9.8334980011,  -4.4823303223,\n",
            "        -13.7156829834, -15.5943851471,  -4.8199019432,  -8.2707290649,\n",
            "         -6.5177969933,  -9.7249946594,  -9.8198947906,  -7.7438278198,\n",
            "         -3.8281555176,  -7.6551990509,  -5.3080239296,  -3.5285604000,\n",
            "         -4.4907832146,  -9.6149587631, -11.8785810471,  -9.1420402527])\n",
            "btensor.grad: tensor([-4.9785127640, -6.6102237701, -6.1845455170, -7.1109247208,\n",
            "        -6.6866731644, -5.6432247162, -5.7708301544, -6.7438836098,\n",
            "        -6.3983530998, -7.5218248367, -6.8716282845, -5.7969789505,\n",
            "        -6.4549045563, -6.6178083420, -7.8060350418, -5.7381916046,\n",
            "        -6.8270478249, -6.8829994202, -7.2239232063, -6.2300448418])\n",
            "ctensor.grad: tensor([ 2.2931562424e+01,  4.7003654480e+01, -1.4913516998e+01,\n",
            "         4.9758789062e+01, -9.6256911755e-02,  1.4402256775e+02,\n",
            "         6.8196166992e+01,  1.3595413208e+02, -5.1941761017e+01,\n",
            "        -2.1634459496e-01, -1.2316950226e+02, -4.7722496033e+01,\n",
            "        -1.0326815033e+02, -5.1331638336e+01, -5.4612167180e-02,\n",
            "        -1.4727612305e+02, -6.6945304871e+01, -1.4192181396e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(721.0149536133, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8687475324), tensor(1.5852541924), tensor(1.0860257149), tensor(1.1677932739), tensor(0.8266647458), tensor(0.8466407657), tensor(1.4090666771), tensor(1.0545210838), tensor(1.1242079735), tensor(0.9837069511), tensor(0.9831358194), tensor(0.8570534587), tensor(1.6266621351), tensor(1.1444802284), tensor(1.4872908592), tensor(1.5746871233), tensor(1.4153028727), tensor(1.1447143555), tensor(0.9570525885), tensor(1.1857043505)]\n",
            "b:  [tensor(1.3684697151), tensor(0.8031989336), tensor(1.3125848770), tensor(1.2431892157), tensor(1.0156657696), tensor(1.7182837725), tensor(1.2117924690), tensor(1.3625613451), tensor(1.1628807783), tensor(0.9894733429), tensor(1.2935349941), tensor(1.2158391476), tensor(0.7899555564), tensor(1.2246131897), tensor(1.2742018700), tensor(0.9809409380), tensor(0.9722272158), tensor(1.2547581196), tensor(1.3933662176), tensor(1.3879169226)]\n",
            "c:  [tensor(-0.3201661706), tensor(0.6955917478), tensor(0.3982190490), tensor(-0.7841055989), tensor(0.0425298586), tensor(0.0397359505), tensor(0.1623727083), tensor(-0.0561232790), tensor(1.3994503021), tensor(-0.0763051733), tensor(-0.2258716524), tensor(-0.4598343372), tensor(-0.3305975795), tensor(0.9683941603), tensor(-0.0510851555), tensor(0.0765962005), tensor(-0.1288200021), tensor(-0.0615432933)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([11.1677331924,  4.9756426811,  8.6465253830,  5.7383079529,\n",
            "        11.1255607605, 11.7586622238,  5.4845304489,  7.8159213066,\n",
            "         7.0733237267,  9.1024131775,  8.9922475815,  7.7328939438,\n",
            "         4.8733730316,  7.6821794510,  5.8712954521,  4.5885787010,\n",
            "         5.4099235535,  8.6622486115,  9.7888717651,  8.4092426300])\n",
            "btensor.grad: tensor([7.3607215881, 9.1742076874, 8.1263895035, 9.0811052322, 8.4813270569,\n",
            "        7.4278216362, 8.0648241043, 8.6294097900, 8.7629566193, 9.5346889496,\n",
            "        9.2994222641, 7.8205227852, 9.1360425949, 8.5191965103, 9.6839313507,\n",
            "        8.1489744186, 9.0004396439, 8.7633743286, 8.7470502853, 8.1061706543])\n",
            "ctensor.grad: tensor([-69.4803466797, -29.3530654907,  59.6508369446,  -5.3543033600,\n",
            "         -0.4018980265, -30.6093921661, -15.1273632050, -27.9035320282,\n",
            "         50.2418632507,   1.8093529940, 167.0389404297,  69.1331253052,\n",
            "        149.0181427002,   9.7841501236,   1.0015548468,  51.6276969910,\n",
            "         24.1579074860,  62.6466751099])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(695.6014404297, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8669547439), tensor(1.5930541754), tensor(1.0890034437), tensor(1.1820725203), tensor(0.8423789740), tensor(0.8416031599), tensor(1.4164297581), tensor(1.0620943308), tensor(1.1426048279), tensor(0.9984197617), tensor(0.9920402765), tensor(0.8745197654), tensor(1.6358959675), tensor(1.1543279886), tensor(1.4983692169), tensor(1.5828859806), tensor(1.4287562370), tensor(1.1500492096), tensor(0.9549331069), tensor(1.1858130693)]\n",
            "b:  [tensor(1.3897893429), tensor(0.8113142848), tensor(1.3329741955), tensor(1.2578135729), tensor(1.0221880674), tensor(1.7376700640), tensor(1.2254389524), tensor(1.3779410124), tensor(1.1798752546), tensor(1.0049488544), tensor(1.3125379086), tensor(1.2286437750), tensor(0.8009765744), tensor(1.2360558510), tensor(1.2851181030), tensor(0.9870667458), tensor(0.9857130051), tensor(1.2730945349), tensor(1.4073555470), tensor(1.4069612026)]\n",
            "c:  [tensor(-0.3450718820), tensor(0.7089796066), tensor(0.4363537133), tensor(-0.7812929749), tensor(0.0428880043), tensor(0.0648761168), tensor(0.1744411141), tensor(-0.0345983282), tensor(1.4486136436), tensor(-0.0762044415), tensor(-0.1201452166), tensor(-0.4247021079), tensor(-0.2528652251), tensor(0.9634132385), tensor(-0.0518823452), tensor(0.0350484625), tensor(-0.1468657553), tensor(-0.1023447812)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.3585518599, -1.5600037575, -0.5955458283, -2.8558511734,\n",
            "        -3.1428489685,  1.0075156689, -1.4726110697, -1.5146601200,\n",
            "        -3.6793694496, -2.9425668716, -1.7808866501, -3.4932661057,\n",
            "        -1.8467714787, -1.9695520401, -2.2156705856, -1.6397793293,\n",
            "        -2.6906657219, -1.0669751167,  0.4238978624, -0.0217433274])\n",
            "btensor.grad: tensor([-4.2639346123, -1.6230697632, -4.0778713226, -2.9248745441,\n",
            "        -1.3044679165, -3.8772521019, -2.7292983532, -3.0759294033,\n",
            "        -3.3989005089, -3.0951137543, -3.8005766869, -2.5609347820,\n",
            "        -2.2042014599, -2.2885434628, -2.1832349300, -1.2251641750,\n",
            "        -2.6971588135, -3.6672763824, -2.7978775501, -3.8088548183])\n",
            "ctensor.grad: tensor([ 2.4905696869e+01, -1.3387874603e+01, -3.8134674072e+01,\n",
            "        -2.8126490116e+00, -3.5814410448e-01, -2.5140163422e+01,\n",
            "        -1.2068404198e+01, -2.1524950027e+01, -4.9163352966e+01,\n",
            "        -1.0072986037e-01, -1.0572643280e+02, -3.5132213593e+01,\n",
            "        -7.7732353210e+01,  4.9809093475e+00,  7.9719066620e-01,\n",
            "         4.1547737122e+01,  1.8045753479e+01,  4.0801490784e+01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(677.5889282227, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8526824713), tensor(1.5856457949), tensor(1.0785683393), tensor(1.1727489233), tensor(0.8256483674), tensor(0.8301668763), tensor(1.4123179913), tensor(1.0542920828), tensor(1.1326732635), tensor(0.9836495519), tensor(0.9831597209), tensor(0.8617542386), tensor(1.6295351982), tensor(1.1468578577), tensor(1.4920724630), tensor(1.5750073195), tensor(1.4209789038), tensor(1.1434105635), tensor(0.9462513924), tensor(1.1803587675)]\n",
            "b:  [tensor(1.3831349611), tensor(0.8132896423), tensor(1.3265072107), tensor(1.2566449642), tensor(1.0213630199), tensor(1.7299799919), tensor(1.2239801884), tensor(1.3749470711), tensor(1.1760149002), tensor(1.0016233921), tensor(1.3060889244), tensor(1.2255035639), tensor(0.8000652790), tensor(1.2321491241), tensor(1.2815513611), tensor(0.9884448051), tensor(0.9841580987), tensor(1.2673546076), tensor(1.4052312374), tensor(1.4020243883)]\n",
            "c:  [tensor(-0.3391531110), tensor(0.7391836047), tensor(0.4466234148), tensor(-0.7757505178), tensor(0.0434108861), tensor(0.1027640700), tensor(0.1907884181), tensor(-0.0056841336), tensor(1.4431629181), tensor(-0.0769162551), tensor(-0.1455897093), tensor(-0.4314168692), tensor(-0.2649025321), tensor(0.9546102285), tensor(-0.0529033393), tensor(-0.0158230364), tensor(-0.1665330976), tensor(-0.1436248720)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([2.8544499874, 1.4816716909, 2.0870101452, 1.8647303581, 3.3461236954,\n",
            "        2.2872562408, 0.8223484755, 1.5604463816, 1.9863246679, 2.9540445805,\n",
            "        1.7761142254, 2.5531024933, 1.2721481323, 1.4940377474, 1.2593511343,\n",
            "        1.5757340193, 1.5554580688, 1.3277189732, 1.7363377810, 1.0908501148])\n",
            "btensor.grad: tensor([ 1.3308719397, -0.3950713873,  1.2934074402,  0.2337324917,\n",
            "         0.1650122404,  1.5380223989,  0.2917477489,  0.5987892151,\n",
            "         0.7720782757,  0.6650896072,  1.2898087502,  0.6280437708,\n",
            "         0.1822553277,  0.7813463211,  0.7133534551, -0.2756155133,\n",
            "         0.3109789491,  1.1479879618,  0.4248690605,  0.9873592257])\n",
            "ctensor.grad: tensor([ -5.9187822342, -30.2039890289, -10.2697105408,  -5.5424618721,\n",
            "         -0.5228815675, -37.8879508972, -16.3473072052, -28.9141941071,\n",
            "          5.4507756233,   0.7118120193,  25.4444980621,   6.7147703171,\n",
            "         12.0373115540,   8.8030204773,   1.0209956169,  50.8714981079,\n",
            "         19.6673412323,  41.2800941467])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(675.6551513672, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8748446107), tensor(1.5905293226), tensor(1.0976852179), tensor(1.1768943071), tensor(0.8419308662), tensor(0.8569939733), tensor(1.4215619564), tensor(1.0684612989), tensor(1.1411631107), tensor(0.9952697158), tensor(1.0011036396), tensor(0.8695048690), tensor(1.6342923641), tensor(1.1603654623), tensor(1.5002019405), tensor(1.5787334442), tensor(1.4261404276), tensor(1.1633026600), tensor(0.9700775146), tensor(1.2009828091)]\n",
            "b:  [tensor(1.3912140131), tensor(0.8333976269), tensor(1.3378173113), tensor(1.2749490738), tensor(1.0400792360), tensor(1.7387280464), tensor(1.2386646271), tensor(1.3903664351), tensor(1.1907453537), tensor(1.0195331573), tensor(1.3200165033), tensor(1.2398617268), tensor(0.8174837232), tensor(1.2476165295), tensor(1.3010452986), tensor(1.0057475567), tensor(1.0015332699), tensor(1.2811416388), tensor(1.4234704971), tensor(1.4140104055)]\n",
            "c:  [tensor(-0.3672841787), tensor(0.7389137745), tensor(0.4627350271), tensor(-0.7817074060), tensor(0.0438894443), tensor(0.0970647633), tensor(0.1831434965), tensor(-0.0195633173), tensor(1.4659868479), tensor(-0.0771502629), tensor(-0.0941308737), tensor(-0.4082654715), tensor(-0.2109625638), tensor(0.9725582600), tensor(-0.0533674732), tensor(0.0262097195), tensor(-0.1451578438), tensor(-0.0933724493)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-4.4324259758, -0.9767116904, -3.8233830929, -0.8290873766,\n",
            "        -3.2564978600, -5.3654222488, -1.8488004208, -2.8338420391,\n",
            "        -1.6979805231, -2.3240339756, -3.5887775421, -1.5501236916,\n",
            "        -0.9514409900, -2.7015254498, -1.6258944273, -0.7452224493,\n",
            "        -1.0322990417, -3.9784309864, -4.7652244568, -4.1248016357])\n",
            "btensor.grad: tensor([-1.6158109903, -4.0216026306, -2.2620208263, -3.6608185768,\n",
            "        -3.7432422638, -1.7496068478, -2.9368937016, -3.0838687420,\n",
            "        -2.9460813999, -3.5819597244, -2.7855226994, -2.8716349602,\n",
            "        -3.4836833477, -3.0934810638, -3.8987932205, -3.4605507851,\n",
            "        -3.4750337601, -2.7574031353, -3.6478505135, -2.3971948624])\n",
            "ctensor.grad: tensor([ 28.1310520172,   0.2698016167, -16.1116008759,   5.9568920135,\n",
            "         -0.4785595238,   5.6993093491,   7.6449217796,  13.8791818619,\n",
            "        -22.8239498138,   0.2340062112, -51.4588317871, -23.1514091492,\n",
            "        -53.9399719238, -17.9480514526,   0.4641350210, -42.0327529907,\n",
            "        -21.3752479553, -50.2524185181])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(679.3267211914, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8522692919), tensor(1.5790531635), tensor(1.0801872015), tensor(1.1606742144), tensor(0.8093116879), tensor(0.8352958560), tensor(1.4086363316), tensor(1.0521680117), tensor(1.1197440624), tensor(0.9725325108), tensor(0.9814970493), tensor(0.8459861875), tensor(1.6233122349), tensor(1.1429610252), tensor(1.4851740599), tensor(1.5666724443), tensor(1.4105056524), tensor(1.1455764771), tensor(0.9505616426), tensor(1.1891766787)]\n",
            "b:  [tensor(1.3731615543), tensor(0.8252715468), tensor(1.3201283216), tensor(1.2610967159), tensor(1.0313673019), tensor(1.7197721004), tensor(1.2256515026), tensor(1.3764514923), tensor(1.1739599705), tensor(1.0028772354), tensor(1.3028459549), tensor(1.2267646790), tensor(0.8066315055), tensor(1.2353790998), tensor(1.2879936695), tensor(0.9992504716), tensor(0.9880408049), tensor(1.2628375292), tensor(1.4096249342), tensor(1.3975468874)]\n",
            "c:  [tensor(-0.3510744870), tensor(0.7620164752), tensor(0.4589673877), tensor(-0.7707902789), tensor(0.0446305983), tensor(0.1548577249), tensor(0.2064652890), tensor(0.0234747007), tensor(1.4371584654), tensor(-0.0783942118), tensor(-0.1861770153), tensor(-0.4418442249), tensor(-0.2842217684), tensor(0.9570990801), tensor(-0.0546121858), tensor(-0.0429201946), tensor(-0.1711360365), tensor(-0.1546432674)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([4.5150671005, 2.2952382565, 3.4996023178, 3.2440166473, 6.5238413811,\n",
            "        4.3396210670, 2.5851223469, 3.2586548328, 4.2838139534, 4.5474462509,\n",
            "        3.9213163853, 4.7037315369, 2.1960172653, 3.4808967113, 3.0055708885,\n",
            "        2.4121923447, 3.1269664764, 3.5452351570, 3.9031727314, 2.3612153530])\n",
            "btensor.grad: tensor([3.6105036736, 1.6252195835, 3.5377945900, 2.7704668045, 1.7423917055,\n",
            "        3.7911837101, 2.6026198864, 2.7829849720, 3.3570694923, 3.3311963081,\n",
            "        3.4341077805, 2.6194176674, 2.1704487801, 2.4474909306, 2.6103193760,\n",
            "        1.2994190454, 2.6984877586, 3.6608259678, 2.7691097260, 3.2927010059])\n",
            "ctensor.grad: tensor([-16.2097034454, -23.1026821136,   3.7676370144, -10.9171037674,\n",
            "         -0.7411537766, -57.7929649353, -23.3217868805, -43.0380172729,\n",
            "         28.8283557892,   1.2439477444,  92.0461425781,  33.5787353516,\n",
            "         73.2591934204,  15.4592018127,   1.2447142601,  69.1299133301,\n",
            "         25.9781932831,  61.2708129883])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(691.0372314453, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.9255940318), tensor(1.5994927883), tensor(1.1326066256), tensor(1.1835715771), tensor(0.8821233511), tensor(0.9129990935), tensor(1.4333586693), tensor(1.0955584049), tensor(1.1538803577), tensor(1.0246143341), tensor(1.0327752829), tensor(0.8889802694), tensor(1.6425076723), tensor(1.1816693544), tensor(1.5120553970), tensor(1.5855205059), tensor(1.4334986210), tensor(1.1946171522), tensor(1.0125151873), tensor(1.2364649773)]\n",
            "b:  [tensor(1.3977724314), tensor(0.8582555056), tensor(1.3505629301), tensor(1.2962549925), tensor(1.0652024746), tensor(1.7478029728), tensor(1.2543969154), tensor(1.4100513458), tensor(1.2061676979), tensor(1.0409679413), tensor(1.3371973038), tensor(1.2560737133), tensor(0.8389421701), tensor(1.2684190273), tensor(1.3267314434), tensor(1.0278507471), tensor(1.0217694044), tensor(1.2970706224), tensor(1.4458984137), tensor(1.4285334349)]\n",
            "c:  [tensor(-0.3872553110), tensor(0.7115226388), tensor(0.4614117444), tensor(-0.8135419488), tensor(0.0447877012), tensor(0.0238780677), tensor(0.1416512132), tensor(-0.0998580158), tensor(1.4912568331), tensor(-0.0781450868), tensor(-0.0557261854), tensor(-0.3906621933), tensor(-0.1723426282), tensor(1.0152349472), tensor(-0.0544350669), tensor(0.1250639856), tensor(-0.0970783159), tensor(0.0001363158)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-14.6649446487,  -4.0879244804, -10.4838790894,  -4.5794801712,\n",
            "        -14.5623369217, -15.5406513214,  -4.9444704056,  -8.6780681610,\n",
            "         -6.8272695541, -10.4163761139, -10.2556428909,  -8.5988140106,\n",
            "         -3.8390984535,  -7.7416639328,  -5.3762555122,  -3.7696194649,\n",
            "         -4.5985989571,  -9.8081436157, -12.3907022476,  -9.4576683044])\n",
            "btensor.grad: tensor([-4.9221735001, -6.5967969894, -6.0869216919, -7.0316486359,\n",
            "        -6.7670269012, -5.6061701775, -5.7490897179, -6.7199683189,\n",
            "        -6.4415464401, -7.6181426048, -6.8702588081, -5.8618178368,\n",
            "        -6.4621329308, -6.6079735756, -7.7475509644, -5.7200593948,\n",
            "        -6.7457151413, -6.8466210365, -7.2546858788, -6.1973094940])\n",
            "ctensor.grad: tensor([ 3.6180809021e+01,  5.0493835449e+01, -2.4443564415e+00,\n",
            "         4.2751689911e+01, -1.5710417926e-01,  1.3097964478e+02,\n",
            "         6.4814079285e+01,  1.2333271027e+02, -5.4098365784e+01,\n",
            "        -2.4912802875e-01, -1.3045082092e+02, -5.1182018280e+01,\n",
            "        -1.1187913513e+02, -5.8135868073e+01, -1.7712034285e-01,\n",
            "        -1.6798416138e+02, -7.4057716370e+01, -1.5477957153e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(724.9622802734, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8675602078), tensor(1.5736969709), tensor(1.0871118307), tensor(1.1537104845), tensor(0.8235221505), tensor(0.8517046571), tensor(1.4038184881), tensor(1.0540711880), tensor(1.1159951687), tensor(0.9772531390), tensor(0.9849250317), tensor(0.8480900526), tensor(1.6168671846), tensor(1.1410971880), tensor(1.4807316065), tensor(1.5616850853), tensor(1.4048717022), tensor(1.1481972933), tensor(0.9606158733), tensor(1.1921298504)]\n",
            "b:  [tensor(1.3579503298), tensor(0.8083325624), tensor(1.3067190647), tensor(1.2455341816), tensor(1.0187768936), tensor(1.7078425884), tensor(1.2105528116), tensor(1.3633369207), tensor(1.1590735912), tensor(0.9885945916), tensor(1.2877600193), tensor(1.2137727737), tensor(0.7902591228), tensor(1.2226785421), tensor(1.2754899263), tensor(0.9841186404), tensor(0.9728549123), tensor(1.2500218153), tensor(1.3978745937), tensor(1.3845379353)]\n",
            "c:  [tensor(-0.3131658733), tensor(0.7331424952), tensor(0.3971036971), tensor(-0.8084098101), tensor(0.0451597758), tensor(0.0534244329), tensor(0.1561826319), tensor(-0.0737900510), tensor(1.4356179237), tensor(-0.0801684558), tensor(-0.2443578839), tensor(-0.4702083170), tensor(-0.3429580927), tensor(1.0057201385), tensor(-0.0554266423), tensor(0.0745843127), tensor(-0.1205871627), tensor(-0.0615917966)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([11.6067600250,  5.1591567993,  9.0989522934,  5.9722113609,\n",
            "        11.7202405930, 12.2588920593,  5.9080266953,  8.2974338531,\n",
            "         7.5770311356,  9.4722414017,  9.5700445175,  8.1780471802,\n",
            "         5.1280951500,  8.1144266129,  6.2647514343,  4.7670898438,\n",
            "         5.7253856659,  9.2839775085, 10.3798608780,  8.8670377731])\n",
            "btensor.grad: tensor([ 7.9644312859,  9.9845867157,  8.7687807083, 10.1441726685,\n",
            "         9.2851085663,  7.9920821190,  8.7688293457,  9.3428754807,\n",
            "         9.4188289642, 10.4746646881,  9.8874511719,  8.4601793289,\n",
            "         9.7366075516,  9.1480913162, 10.2482957840,  8.7464237213,\n",
            "         9.7828960419,  9.4097537994,  9.6047525406,  8.7990894318])\n",
            "ctensor.grad: tensor([-74.0894241333, -21.6198787689,  64.3080520630,  -5.1321201324,\n",
            "         -0.3720733523, -29.5463619232, -14.5314159393, -26.0679626465,\n",
            "         55.6389541626,   2.0233681202, 188.6316833496,  79.5461273193,\n",
            "        170.6154479980,   9.5148134232,   0.9915757179,  50.4796714783,\n",
            "         23.5088481903,  61.7281112671])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(697.8900756836, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8694767356), tensor(1.5848859549), tensor(1.0926816463), tensor(1.1729761362), tensor(0.8444381952), tensor(0.8488943577), tensor(1.4133903980), tensor(1.0648598671), tensor(1.1390691996), tensor(0.9975275397), tensor(0.9973508716), tensor(0.8709157705), tensor(1.6294609308), tensor(1.1545201540), tensor(1.4948035479), tensor(1.5732671022), tensor(1.4222809076), tensor(1.1559406519), tensor(0.9603577256), tensor(1.1938364506)]\n",
            "b:  [tensor(1.3843874931), tensor(0.8180584908), tensor(1.3313648701), tensor(1.2627135515), tensor(1.0273150206), tensor(1.7313542366), tensor(1.2268750668), tensor(1.3814990520), tensor(1.1794514656), tensor(1.0073181391), tensor(1.3108639717), tensor(1.2293775082), tensor(0.8037921786), tensor(1.2373695374), tensor(1.2890790701), tensor(0.9917923212), tensor(0.9888720512), tensor(1.2718323469), tensor(1.4144252539), tensor(1.4074257612)]\n",
            "c:  [tensor(-0.3442157507), tensor(0.7394692302), tensor(0.4408548176), tensor(-0.8060157895), tensor(0.0454749987), tensor(0.0760275126), tensor(0.1670841724), tensor(-0.0548201241), tensor(1.4905531406), tensor(-0.0800073743), tensor(-0.1261310279), tensor(-0.4316044152), tensor(-0.2572996616), tensor(1.0014154911), tensor(-0.0561917499), tensor(0.0362373516), tensor(-0.1372146010), tensor(-0.0995555222)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.3833051324, -2.2377963066, -1.1139652729, -3.8531320095,\n",
            "        -4.1832108498,  0.5620602965, -1.9143848419, -2.1577401161,\n",
            "        -4.6148071289, -4.0548796654, -2.4851648808, -4.5651392937,\n",
            "        -2.5187578201, -2.6845970154, -2.8143930435, -2.3163964748,\n",
            "        -3.4818522930, -1.5486832857,  0.0516240001, -0.3413315117])\n",
            "btensor.grad: tensor([-5.2874226570, -1.9451878071, -4.9291715622, -3.4358625412,\n",
            "        -1.7076188326, -4.7023301125, -3.2644455433, -3.6324374676,\n",
            "        -4.0755863190, -3.7447080612, -4.6207966805, -3.1209421158,\n",
            "        -2.7066068649, -2.9381928444, -2.7178208828, -1.5347316265,\n",
            "        -3.2034249306, -4.3621034622, -3.3101339340, -4.5775752068])\n",
            "ctensor.grad: tensor([  31.0498790741,   -6.3267159462,  -43.7511291504,   -2.3940491676,\n",
            "          -0.3152221441,  -22.6030807495,  -10.9015388489,  -18.9699268341,\n",
            "         -54.9351654053,   -0.1610852331, -118.2268600464,  -38.6039009094,\n",
            "         -85.6584167480,    4.3046035767,    0.7651057243,   38.3469581604,\n",
            "          16.6274356842,   37.9637184143])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(677.7514648438, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8521671891), tensor(1.5766113997), tensor(1.0793771744), tensor(1.1625661850), tensor(0.8252866864), tensor(0.8341401219), tensor(1.4082062244), tensor(1.0550851822), tensor(1.1274335384), tensor(0.9805462360), tensor(0.9858834147), tensor(0.8564758897), tensor(1.6222827435), tensor(1.1450378895), tensor(1.4874283075), tensor(1.5646228790), tensor(1.4135005474), tensor(1.1466211081), tensor(0.9484196901), tensor(1.1857087612)]\n",
            "b:  [tensor(1.3764264584), tensor(0.8175895810), tensor(1.3231623173), tensor(1.2591632605), tensor(1.0242209435), tensor(1.7223545313), tensor(1.2235019207), tensor(1.3765107393), tensor(1.1736768484), tensor(1.0019534826), tensor(1.3022537231), tensor(1.2242538929), tensor(0.8007007837), tensor(1.2314052582), tensor(1.2825037241), tensor(0.9910267591), tensor(0.9849460125), tensor(1.2643254995), tensor(1.4097987413), tensor(1.4009495974)]\n",
            "c:  [tensor(-0.3337526619), tensor(0.7707794905), tensor(0.4476164877), tensor(-0.8003914952), tensor(0.0459568985), tensor(0.1134707779), tensor(0.1836666018), tensor(-0.0261035580), tensor(1.4819796085), tensor(-0.0807809904), tensor(-0.1594786346), tensor(-0.4411906302), tensor(-0.2765905261), tensor(0.9914641380), tensor(-0.0572391227), tensor(-0.0187045224), tensor(-0.1589082778), tensor(-0.1467734575)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([3.4619073868, 1.6549127102, 2.6609039307, 2.0819859505, 3.8303031921,\n",
            "        2.9508492947, 1.0368282795, 1.9549452066, 2.3271372318, 3.3962590694,\n",
            "        2.2934944630, 2.8879802227, 1.4356424809, 1.8964595795, 1.4750531912,\n",
            "        1.7288537025, 1.7560758591, 1.8639153242, 2.3876061440, 1.6255269051])\n",
            "btensor.grad: tensor([1.5922094584, 0.0937794447, 1.6405122280, 0.7100533247, 0.6188262701,\n",
            "        1.7999404669, 0.6746364236, 0.9976592064, 1.1549170017, 1.0729414225,\n",
            "        1.7220575809, 1.0247175694, 0.6182754636, 1.1928480864, 1.3150613308,\n",
            "        0.1531115174, 0.7852125168, 1.5013715029, 0.9253045321, 1.2952445745])\n",
            "ctensor.grad: tensor([-10.4630985260, -31.3102416992,  -6.7616586685,  -5.6242923737,\n",
            "         -0.4819000363, -37.4432678223, -16.5824317932, -28.7165641785,\n",
            "          8.5735616684,   0.7736172080,  33.3476066589,   9.5862007141,\n",
            "         19.2908668518,   9.9513692856,   1.0473722219,  54.9418716431,\n",
            "         21.6936740875,  47.2179260254])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(675.6387939453, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8744872808), tensor(1.5823465586), tensor(1.0982065201), tensor(1.1682088375), tensor(0.8442395926), tensor(0.8612586260), tensor(1.4184106588), tensor(1.0699301958), tensor(1.1375494003), tensor(0.9936707616), tensor(1.0046213865), tensor(0.8662615418), tensor(1.6277555227), tensor(1.1593511105), tensor(1.4967931509), tensor(1.5692266226), tensor(1.4199353456), tensor(1.1669700146), tensor(0.9716165662), tensor(1.2059265375)]\n",
            "b:  [tensor(1.3859452009), tensor(0.8378965855), tensor(1.3359110355), tensor(1.2779592276), tensor(1.0427904129), tensor(1.7327820063), tensor(1.2389594316), tensor(1.3928757906), tensor(1.1896727085), tensor(1.0207335949), tensor(1.3176101446), tensor(1.2394806147), tensor(0.8189365268), tensor(1.2472729683), tensor(1.3025412560), tensor(1.0086307526), tensor(1.0030993223), tensor(1.2801234722), tensor(1.4285837412), tensor(1.4141815901)]\n",
            "c:  [tensor(-0.3646543026), tensor(0.7689095140), tensor(0.4661662281), tensor(-0.8051946163), tensor(0.0463994890), tensor(0.1109673753), tensor(0.1783597320), tensor(-0.0353804491), tensor(1.5078997612), tensor(-0.0809772313), tensor(-0.1001510918), tensor(-0.4152170420), tensor(-0.2172704935), tensor(1.0098719597), tensor(-0.0576792099), tensor(0.0251205638), tensor(-0.1371457577), tensor(-0.0945183635)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-4.4640173912, -1.1470428705, -3.7658743858, -1.1285234690,\n",
            "        -3.7905843258, -5.4236950874, -2.0408971310, -2.9689941406,\n",
            "        -2.0231685638, -2.6249086857, -3.7475914955, -1.9571312666,\n",
            "        -1.0945444107, -2.8626389503, -1.8729755878, -0.9207452536,\n",
            "        -1.2869567871, -4.0697808266, -4.6393756866, -4.0435600281])\n",
            "btensor.grad: tensor([-1.9037510157, -4.0614047050, -2.5497381687, -3.7591922283,\n",
            "        -3.7138898373, -2.0855009556, -3.0914928913, -3.2730083466,\n",
            "        -3.1991755962, -3.7560346127, -3.0712869167, -3.0453548431,\n",
            "        -3.6471529007, -3.1735489368, -4.0074996948, -3.5207905769,\n",
            "        -3.6306531429, -3.1595928669, -3.7570023537, -2.6463932991])\n",
            "ctensor.grad: tensor([ 30.9016399384,   1.8699532747, -18.5497436523,   4.8031024933,\n",
            "         -0.4425914288,   2.5034036636,   5.3068633080,   9.2768898010,\n",
            "        -25.9201107025,   0.1962377429, -59.3275413513, -25.9735813141,\n",
            "        -59.3200378418, -18.4078483582,   0.4400874078, -43.8250846863,\n",
            "        -21.7625141144, -52.2550888062])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(679.3571166992, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8505583405), tensor(1.5706361532), tensor(1.0792325735), tensor(1.1515334845), tensor(0.8101039529), tensor(0.8382684588), tensor(1.4049603939), tensor(1.0527759790), tensor(1.1151791811), tensor(0.9697960019), tensor(0.9837960005), tensor(0.8418140411), tensor(1.6166069508), tensor(1.1409131289), tensor(1.4812616110), tensor(1.5569934845), tensor(1.4037737846), tensor(1.1479400396), tensor(0.9504932165), tensor(1.1930423975)]\n",
            "b:  [tensor(1.3670988083), tensor(0.8286477327), tensor(1.3172398806), tensor(1.2628329992), tensor(1.0331891775), tensor(1.7130626440), tensor(1.2249232531), tensor(1.3778562546), tensor(1.1717731953), tensor(1.0030026436), tensor(1.2992619276), tensor(1.2253640890), tensor(0.8070857525), tensor(1.2340230942), tensor(1.2878359556), tensor(1.0010565519), tensor(0.9883015752), tensor(1.2607833147), tensor(1.4132190943), tensor(1.3968303204)]\n",
            "c:  [tensor(-0.3462283313), tensor(0.7917190194), tensor(0.4598881304), tensor(-0.7944166064), tensor(0.0471029133), tensor(0.1680111289), tensor(0.2017096728), tensor(0.0069445446), tensor(1.4769004583), tensor(-0.0822644457), tensor(-0.1977556050), tensor(-0.4509706199), tensor(-0.2957339585), tensor(0.9946671724), tensor(-0.0589174703), tensor(-0.0432575643), tensor(-0.1629767716), tensor(-0.1563711464)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([4.7857904434, 2.3420813084, 3.7947850227, 3.3350603580, 6.8271331787,\n",
            "        4.5980377197, 2.6900563240, 3.4308452606, 4.4740548134, 4.7749528885,\n",
            "        4.1650772095, 4.8894996643, 2.2297046185, 3.6876075268, 3.1063158512,\n",
            "        2.4466395378, 3.2323224545, 3.8059861660, 4.2246680260, 2.5768210888])\n",
            "btensor.grad: tensor([3.7692673206, 1.8497730494, 3.7342398167, 3.0252513885, 1.9202507734,\n",
            "        3.9438753128, 2.8072352409, 3.0038990974, 3.5799012184, 3.5461993217,\n",
            "        3.6696381569, 2.8233001232, 2.3701524734, 2.6499662399, 2.9410490990,\n",
            "        1.5148417950, 2.9595441818, 3.8680236340, 3.0729281902, 3.4702563286])\n",
            "ctensor.grad: tensor([-18.4259624481, -22.8095245361,   6.2780957222, -10.7779989243,\n",
            "         -0.7034223676, -57.0437431335, -23.3499412537, -42.3249931335,\n",
            "         30.9993000031,   1.2872112989,  97.6044998169,  35.7535705566,\n",
            "         78.4634704590,  15.2047843933,   1.2382606268,  68.3781280518,\n",
            "         25.8310108185,  61.8527755737])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(690.1408691406, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.9214315414), tensor(1.5916182995), tensor(1.1311129332), tensor(1.1752805710), tensor(0.8807063699), tensor(0.9138013721), tensor(1.4292095900), tensor(1.0952943563), tensor(1.1493502855), tensor(1.0223381519), tensor(1.0338505507), tensor(0.8855215311), tensor(1.6361318827), tensor(1.1790807247), tensor(1.5079765320), tensor(1.5765281916), tensor(1.4269672632), tensor(1.1955109835), tensor(1.0099462271), tensor(1.2388461828)]\n",
            "b:  [tensor(1.3921408653), tensor(0.8612409830), tensor(1.3479344845), tensor(1.2974696159), tensor(1.0663369894), tensor(1.7415910959), tensor(1.2534997463), tensor(1.4113755226), tensor(1.2039511204), tensor(1.0407211781), tensor(1.3340984583), tensor(1.2547757626), tensor(0.8394785523), tensor(1.2668097019), tensor(1.3264089823), tensor(1.0293266773), tensor(1.0217523575), tensor(1.2954658270), tensor(1.4490147829), tensor(1.4279021025)]\n",
            "c:  [tensor(-0.3865493536), tensor(0.7409194708), tensor(0.4680529237), tensor(-0.8335820436), tensor(0.0472827889), tensor(0.0462565050), tensor(0.1409834325), tensor(-0.1062740907), tensor(1.5307593346), tensor(-0.0820219964), tensor(-0.0687012523), tensor(-0.4006802142), tensor(-0.1861730963), tensor(1.0496538877), tensor(-0.0587669089), tensor(0.1177361310), tensor(-0.0916865841), tensor(-0.0060498118)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-14.1746463776,  -4.1964392662, -10.3760633469,  -4.7494149208,\n",
            "        -14.1204833984, -15.1065855026,  -4.8498315811,  -8.5036678314,\n",
            "         -6.8342323303, -10.5084228516, -10.0109176636,  -8.7414970398,\n",
            "         -3.9049837589,  -7.6335139275,  -5.3429899216,  -3.9069464207,\n",
            "         -4.6386971474,  -9.5141849518, -11.8906116486,  -9.1607503891])\n",
            "btensor.grad: tensor([-5.0084080696, -6.5186500549, -6.1389250755, -6.9273123741,\n",
            "        -6.6295609474, -5.7056913376, -5.7153029442, -6.7038602829,\n",
            "        -6.4355864525, -7.5437145233, -6.9673099518, -5.8823423386,\n",
            "        -6.4785580635, -6.5573306084, -7.7145996094, -5.6540222168,\n",
            "        -6.6901559830, -6.9364986420, -7.1591343880, -6.2143645287])\n",
            "ctensor.grad: tensor([ 4.0321022034e+01,  5.0799560547e+01, -8.1647872925e+00,\n",
            "         3.9165447235e+01, -1.7987480760e-01,  1.2175461578e+02,\n",
            "         6.0726230621e+01,  1.1321862793e+02, -5.3858921051e+01,\n",
            "        -2.4244867265e-01, -1.2905435181e+02, -5.0290409088e+01,\n",
            "        -1.0956085968e+02, -5.4986663818e+01, -1.5056224167e-01,\n",
            "        -1.6099368286e+02, -7.1290184021e+01, -1.5032133484e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(720.0692749023, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8649076819), tensor(1.5666298866), tensor(1.0866965055), tensor(1.1459506750), tensor(0.8229454756), tensor(0.8539349437), tensor(1.4005444050), tensor(1.0547398329), tensor(1.1121094227), tensor(0.9757048488), tensor(0.9872413278), tensor(0.8450269103), tensor(1.6113729477), tensor(1.1394733191), tensor(1.4774888754), tensor(1.5534255505), tensor(1.3990211487), tensor(1.1506172419), tensor(0.9597091079), tensor(1.1959528923)]\n",
            "b:  [tensor(1.3537681103), tensor(0.8141052127), tensor(1.3057256937), tensor(1.2493336201), tensor(1.0228573084), tensor(1.7030711174), tensor(1.2114552259), tensor(1.3665134907), tensor(1.1584560871), tensor(0.9907519817), tensor(1.2865536213), tensor(1.2142810822), tensor(0.7931112647), tensor(1.2235190868), tensor(1.2771974802), tensor(0.9879983664), tensor(0.9750269651), tensor(1.2500658035), tensor(1.4029045105), tensor(1.3854095936)]\n",
            "c:  [tensor(-0.3153232634), tensor(0.7658638358), tensor(0.4060328901), tensor(-0.8278128505), tensor(0.0476718768), tensor(0.0797862858), tensor(0.1572998315), tensor(-0.0778977871), tensor(1.4751142263), tensor(-0.0840105563), tensor(-0.2526229322), tensor(-0.4770015478), tensor(-0.3514473140), tensor(1.0401017666), tensor(-0.0597747415), tensor(0.0664237738), tensor(-0.1153971925), tensor(-0.0686033741)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([11.3047742844,  4.9976773262,  8.8832836151,  5.8659901619,\n",
            "        11.5521850586, 11.9732875824,  5.7330389023,  8.1109075546,\n",
            "         7.4481787682,  9.3266572952,  9.3218498230,  8.0989265442,\n",
            "         4.9517784119,  7.9214782715,  6.0975394249,  4.6205220222,\n",
            "         5.5892243385,  8.9787464142, 10.0474224091,  8.5786533356])\n",
            "btensor.grad: tensor([7.6745562553, 9.4271526337, 8.4417572021, 9.6272096634, 8.6959314346,\n",
            "        7.7040038109, 8.4088973999, 8.9723987579, 9.0990076065, 9.9938335419,\n",
            "        9.5089731216, 8.0989341736, 9.2734622955, 8.6581201553, 9.8422899246,\n",
            "        8.2656621933, 9.3450775146, 9.0800027847, 9.2220554352, 8.4984979630])\n",
            "ctensor.grad: tensor([-71.2260818481, -24.9443454742,  62.0200271606,  -5.7691998482,\n",
            "         -0.3890884221, -33.5297737122, -16.3163948059, -28.3763008118,\n",
            "         55.6450805664,   1.9885636568, 183.9216766357,  76.3213119507,\n",
            "        165.2742156982,   9.5520668030,   1.0078308582,  51.3123588562,\n",
            "         23.7106094360,  62.5535583496])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(696.3104248047, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8696145415), tensor(1.5787975788), tensor(1.0940638781), tensor(1.1662827730), tensor(0.8464009166), tensor(0.8537766337), tensor(1.4108713865), tensor(1.0668199062), tensor(1.1365907192), tensor(0.9980901480), tensor(1.0012558699), tensor(0.8693655729), tensor(1.6248899698), tensor(1.1543878317), tensor(1.4926817417), tensor(1.5659731627), tensor(1.4175164700), tensor(1.1598261595), tensor(0.9614935517), tensor(1.1993844509)]\n",
            "b:  [tensor(1.3812493086), tensor(0.8254111409), tensor(1.3317147493), tensor(1.2677726746), tensor(1.0326402187), tensor(1.7278479338), tensor(1.2290629148), tensor(1.3863356113), tensor(1.1803553104), tensor(1.0108263493), tensor(1.3117681742), tensor(1.2311424017), tensor(0.8083055019), tensor(1.2397307158), tensor(1.2928243876), tensor(0.9971299767), tensor(0.9925502539), tensor(1.2734116316), tensor(1.4207865000), tensor(1.4095087051)]\n",
            "c:  [tensor(-0.3506486118), tensor(0.7686431408), tensor(0.4524139762), tensor(-0.8252510428), tensor(0.0480079316), tensor(0.1050795019), tensor(0.1693018526), tensor(-0.0574989729), tensor(1.5316891670), tensor(-0.0838233978), tensor(-0.1302984804), tensor(-0.4368458688), tensor(-0.2626695335), tensor(1.0363287926), tensor(-0.0605369285), tensor(0.0299712010), tensor(-0.1309156865), tensor(-0.1037852764)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.9413661361, -2.4335429668, -1.4734630585, -4.0664205551,\n",
            "        -4.6910867691,  0.0316665694, -2.0653886795, -2.4160084724,\n",
            "        -4.8962473869, -4.4770636559, -2.8029062748, -4.8677272797,\n",
            "        -2.7033941746, -2.9829118252, -3.0385832787, -2.5095140934,\n",
            "        -3.6990737915, -1.8417946100, -0.3568831086, -0.6863142848])\n",
            "btensor.grad: tensor([-5.4962325096, -2.2611894608, -5.1978025436, -3.6878180504,\n",
            "        -1.9565833807, -4.9553675652, -3.5215382576, -3.9644165039,\n",
            "        -4.3798465729, -4.0148825645, -5.0429143906, -3.3722538948,\n",
            "        -3.0388438702, -3.2423148155, -3.1253850460, -1.8263183832,\n",
            "        -3.5046553612, -4.6691589355, -3.5763955116, -4.8198313713])\n",
            "ctensor.grad: tensor([  35.3253440857,   -2.7793154716,  -46.3810691833,   -2.5617921352,\n",
            "          -0.3360536695,  -25.2932128906,  -12.0020227432,  -20.3988132477,\n",
            "         -56.5749702454,   -0.1871592999, -122.3244476318,  -40.1556854248,\n",
            "         -88.7777786255,    3.7729423046,    0.7621869445,   36.4525718689,\n",
            "          15.5184907913,   35.1819038391])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(675.9167480469, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8528308272), tensor(1.5705481768), tensor(1.0810641050), tensor(1.1551837921), tensor(0.8261524439), tensor(0.8399204612), tensor(1.4052178860), tensor(1.0571279526), tensor(1.1237390041), tensor(0.9806102514), tensor(0.9893752337), tensor(0.8537363410), tensor(1.6176435947), tensor(1.1444412470), tensor(1.4847602844), tensor(1.5572614670), tensor(1.4079926014), tensor(1.1501162052), tensor(0.9497103095), tensor(1.1921440363)]\n",
            "b:  [tensor(1.3721072674), tensor(0.8248831630), tensor(1.3225483894), tensor(1.2635713816), tensor(1.0297912359), tensor(1.7178199291), tensor(1.2251379490), tensor(1.3809168339), tensor(1.1739463806), tensor(1.0050657988), tensor(1.3024988174), tensor(1.2255227566), tensor(0.8050171733), tensor(1.2335650921), tensor(1.2861053944), tensor(0.9962670803), tensor(0.9878836274), tensor(1.2648820877), tensor(1.4155948162), tensor(1.4023208618)]\n",
            "c:  [tensor(-0.3418542743), tensor(0.7970919013), tensor(0.4571325779), tensor(-0.8186171055), tensor(0.0485449694), tensor(0.1472908258), tensor(0.1874379814), tensor(-0.0263208672), tensor(1.5202386379), tensor(-0.0846457630), tensor(-0.1704946756), tensor(-0.4488911629), tensor(-0.2877115607), tensor(1.0266990662), tensor(-0.0615988448), tensor(-0.0224127322), tensor(-0.1510097384), tensor(-0.1486264169)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([3.3567438126, 1.6498856544, 2.5999557972, 2.2198040485, 4.0496926308,\n",
            "        2.7712314129, 1.1306936741, 1.9383915663, 2.5703351498, 3.4959812164,\n",
            "        2.3761327267, 3.1258509159, 1.4492845535, 1.9893136024, 1.5842816830,\n",
            "        1.7423332930, 1.9047660828, 1.9419895411, 2.3566431999, 1.4480800629])\n",
            "btensor.grad: tensor([1.8283973932, 0.1056013107, 1.8332625628, 0.8402664661, 0.5698082447,\n",
            "        2.0055937767, 0.7849962115, 1.0837538242, 1.2817837000, 1.1521040201,\n",
            "        1.8538609743, 1.1239266396, 0.6576645374, 1.2331287861, 1.3438055515,\n",
            "        0.1725783348, 0.9333200455, 1.7059131861, 1.0383439064, 1.4375585318])\n",
            "ctensor.grad: tensor([ -8.7943410873, -28.4487400055,  -4.7185873985,  -6.6339612007,\n",
            "         -0.5370396376, -42.2113265991, -18.1361198425, -31.1781044006,\n",
            "         11.4505262375,   0.8223627210,  40.1961936951,  12.0453014374,\n",
            "         25.0420341492,   9.6297435760,   1.0619163513,  52.3839302063,\n",
            "         20.0940475464,  44.8411407471])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(675.3435668945, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8810883164), tensor(1.5784482956), tensor(1.1050575972), tensor(1.1627085209), tensor(0.8497502804), tensor(0.8738797903), tensor(1.4167970419), tensor(1.0757037401), tensor(1.1357315779), tensor(0.9983894825), tensor(1.0112410784), tensor(0.8668479323), tensor(1.6249444485), tensor(1.1615455151), tensor(1.4960108995), tensor(1.5639580488), tensor(1.4159690142), tensor(1.1732144356), tensor(0.9772385955), tensor(1.2162905931)]\n",
            "b:  [tensor(1.3827674389), tensor(0.8465099931), tensor(1.3368405104), tensor(1.2835773230), tensor(1.0502043962), tensor(1.7300602198), tensor(1.2417891026), tensor(1.3991420269), tensor(1.1917071342), tensor(1.0262446404), tensor(1.3197749853), tensor(1.2422049046), tensor(0.8249583244), tensor(1.2512152195), tensor(1.3086432219), tensor(1.0149856806), tensor(1.0073750019), tensor(1.2828489542), tensor(1.4361428022), tensor(1.4174704552)]\n",
            "c:  [tensor(-0.3740315437), tensor(0.7876399159), tensor(0.4745206535), tensor(-0.8281131387), tensor(0.0489929318), tensor(0.1261047721), tensor(0.1724605858), tensor(-0.0524929017), tensor(1.5479981899), tensor(-0.0848261267), tensor(-0.1052040309), tensor(-0.4206255674), tensor(-0.2251677066), tensor(1.0480141640), tensor(-0.0620178208), tensor(0.0343694501), tensor(-0.1228580475), tensor(-0.0852603838)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-5.6514978409, -1.5800256729, -4.7986893654, -1.5049407482,\n",
            "        -4.7195653915, -6.7918648720, -2.3158226013, -3.7151601315,\n",
            "        -2.3985099792, -3.5558481216, -4.3731651306, -2.6223170757,\n",
            "        -1.4601666927, -3.4208657742, -2.2501266003, -1.3393110037,\n",
            "        -1.5952932835, -4.6196479797, -5.5056548119, -4.8293099403])\n",
            "btensor.grad: tensor([-2.1320455074, -4.3253698349, -2.8584187031, -4.0011844635,\n",
            "        -4.0826277733, -2.4480650425, -3.3302326202, -3.6450402737,\n",
            "        -3.5521531105, -4.2357659340, -3.4552276134, -3.3364248276,\n",
            "        -3.9882283211, -3.5300166607, -4.5075621605, -3.7437090874,\n",
            "        -3.8982734680, -3.5933790207, -4.1095881462, -3.0299301147])\n",
            "ctensor.grad: tensor([ 32.1772804260,   9.4519596100, -17.3880748749,   9.4960212708,\n",
            "         -0.4479634464,  21.1860466003,  14.9773988724,  26.1720352173,\n",
            "        -27.7595825195,   0.1803638786, -65.2906417847, -28.2655944824,\n",
            "        -62.5438499451, -21.3150444031,   0.4189743698, -56.7821807861,\n",
            "        -28.1516933441, -63.3660278320])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(682.1710815430, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8506243229), tensor(1.5643908978), tensor(1.0808892250), tensor(1.1434068680), tensor(0.8114281297), tensor(0.8438929915), tensor(1.4009239674), tensor(1.0546622276), tensor(1.1106142998), tensor(0.9699293375), tensor(0.9858184457), tensor(0.8393985629), tensor(1.6116483212), tensor(1.1391084194), tensor(1.4781655073), tensor(1.5498785973), tensor(1.3976787329), tensor(1.1494837999), tensor(0.9505751729), tensor(1.1983482838)]\n",
            "b:  [tensor(1.3608744144), tensor(0.8322534561), tensor(1.3145359755), tensor(1.2639254332), tensor(1.0359189510), tensor(1.7074784040), tensor(1.2238903046), tensor(1.3800579309), tensor(1.1698822975), tensor(1.0041041374), tensor(1.2969239950), tensor(1.2240517139), tensor(0.8082317114), tensor(1.2334938049), tensor(1.2880868912), tensor(1.0026265383), tensor(0.9877526760), tensor(1.2594673634), tensor(1.4161946774), tensor(1.3966504335)]\n",
            "c:  [tensor(-0.3495182991), tensor(0.8131901026), tensor(0.4604350626), tensor(-0.8156646490), tensor(0.0497104041), tensor(0.1906425357), tensor(0.1999607682), tensor(-0.0035111979), tensor(1.5121431351), tensor(-0.0862049758), tensor(-0.2164281607), tensor(-0.4620275199), tensor(-0.3167960048), tensor(1.0321261883), tensor(-0.0632736236), tensor(-0.0390878879), tensor(-0.1519418359), tensor(-0.1564124525)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([6.0927968025, 2.8114757538, 4.8336734772, 3.8603191376, 7.6644248962,\n",
            "        5.9973545074, 3.1746129990, 4.2083139420, 5.0234603882, 5.6920275688,\n",
            "        5.0845255852, 5.4898710251, 2.6592204571, 4.4874105453, 3.5690739155,\n",
            "        2.8158893585, 3.6580562592, 4.7461247444, 5.3326845169, 3.5884616375])\n",
            "btensor.grad: tensor([4.3786120415, 2.8513026237, 4.4608988762, 3.9303851128, 2.8570799828,\n",
            "        4.5163731575, 3.5797498226, 3.8168239594, 4.3649568558, 4.4280948639,\n",
            "        4.5702075958, 3.6306498051, 3.3453261852, 3.5442731380, 4.1112656593,\n",
            "        2.4718332291, 3.9244697094, 4.6763229370, 3.9896295071, 4.1640152931])\n",
            "ctensor.grad: tensor([-24.5132427216, -25.5501594543,  14.0856037140, -12.4485092163,\n",
            "         -0.7174714804, -64.5377578735, -27.5001792908, -48.9817008972,\n",
            "         35.8549919128,   1.3788493872, 111.2241210938,  41.4019508362,\n",
            "         91.6283035278,  15.8879756927,   1.2558007240,  73.4573364258,\n",
            "         29.0837898254,  71.1520614624])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(691.7566528320, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.9237496257), tensor(1.5877783298), tensor(1.1340205669), tensor(1.1708147526), tensor(0.8852716088), tensor(0.9213827848), tensor(1.4260293245), tensor(1.0989484787), tensor(1.1479144096), tensor(1.0270677805), tensor(1.0378979445), tensor(0.8876846433), tensor(1.6335517168), tensor(1.1795974970), tensor(1.5067064762), tensor(1.5716830492), tensor(1.4232646227), tensor(1.1981546879), tensor(1.0100468397), tensor(1.2441732883)]\n",
            "b:  [tensor(1.3888213634), tensor(0.8654739261), tensor(1.3481630087), tensor(1.2997834682), tensor(1.0693719387), tensor(1.7388417721), tensor(1.2538045645), tensor(1.4154793024), tensor(1.2037383318), tensor(1.0430563688), tensor(1.3347964287), tensor(1.2550566196), tensor(0.8421278596), tensor(1.2678606510), tensor(1.3285933733), tensor(1.0314476490), tensor(1.0227543116), tensor(1.2967325449), tensor(1.4532010555), tensor(1.4301877022)]\n",
            "c:  [tensor(-0.3903283179), tensor(0.7565203905), tensor(0.4784120917), tensor(-0.8581628799), tensor(0.0498528965), tensor(0.0580393076), tensor(0.1354184449), tensor(-0.1229487136), tensor(1.5680329800), tensor(-0.0859255493), tensor(-0.0848517865), tensor(-0.4121553898), tensor(-0.2092011273), tensor(1.0854703188), tensor(-0.0631365404), tensor(0.1197792888), tensor(-0.0811484605), tensor(-0.0053868741)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-14.6250591278,  -4.6774759293, -10.6262569427,  -5.4815707207,\n",
            "        -14.7686996460, -15.4979543686,  -5.0210771561,  -8.8572549820,\n",
            "         -7.4600319862, -11.4276952744, -10.4158964157,  -9.6572208405,\n",
            "         -4.3806762695,  -8.0978221893,  -5.7081928253,  -4.3608818054,\n",
            "         -5.1171760559,  -9.7341718674, -11.8943328857,  -9.1649913788])\n",
            "btensor.grad: tensor([-5.5893907547, -6.6440892220, -6.7254033089, -7.1715979576,\n",
            "        -6.6906042099, -6.2726740837, -5.9828548431, -7.0842700005,\n",
            "        -6.7712087631, -7.7904539108, -7.5744872093, -6.2009778023,\n",
            "        -6.7792258263, -6.8733720779, -8.1012859344, -5.7642126083,\n",
            "        -7.0003228188, -7.4530405998, -7.4012799263, -6.7074494362])\n",
            "ctensor.grad: tensor([ 4.0810009003e+01,  5.6669712067e+01, -1.7977016449e+01,\n",
            "         4.2498237610e+01, -1.4249388874e-01,  1.3260322571e+02,\n",
            "         6.4542320251e+01,  1.1943750763e+02, -5.5889801025e+01,\n",
            "        -2.7942395210e-01, -1.3157637024e+02, -4.9872142792e+01,\n",
            "        -1.0759487152e+02, -5.3344085693e+01, -1.3708370924e-01,\n",
            "        -1.5886717224e+02, -7.0793373108e+01, -1.5102557373e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(716.7072143555, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8680350184), tensor(1.5631349087), tensor(1.0904111862), tensor(1.1417840719), tensor(0.8288549185), tensor(0.8621950746), tensor(1.3985804319), tensor(1.0591018200), tensor(1.1117951870), tensor(0.9805653691), tensor(0.9924575686), tensor(0.8476378322), tensor(1.6094008684), tensor(1.1408405304), tensor(1.4771555662), tensor(1.5489268303), tensor(1.3960821629), tensor(1.1550086737), tensor(0.9615466595), tensor(1.2019896507)]\n",
            "b:  [tensor(1.3523335457), tensor(0.8201127052), tensor(1.3077259064), tensor(1.2548148632), tensor(1.0283471346), tensor(1.7019623518), tensor(1.2134321928), tensor(1.3721141815), tensor(1.1596364975), tensor(0.9957354069), tensor(1.2884912491), tensor(1.2161358595), tensor(0.7968748808), tensor(1.2265002728), tensor(1.2805105448), tensor(0.9913490415), tensor(0.9779680967), tensor(1.2527107000), tensor(1.4091782570), tensor(1.3894240856)]\n",
            "c:  [tensor(-0.3199813962), tensor(0.7879871130), tensor(0.4165446758), tensor(-0.8529539108), tensor(0.0502072163), tensor(0.0891595483), tensor(0.1505704671), tensor(-0.0973264277), tensor(1.5140167475), tensor(-0.0877811015), tensor(-0.2574546635), tensor(-0.4819204509), tensor(-0.3616914749), tensor(1.0769038200), tensor(-0.0641143546), tensor(0.0722706094), tensor(-0.1031480059), tensor(-0.0641913414)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([11.1429185867,  4.9286832809,  8.7218666077,  5.8061447144,\n",
            "        11.2833433151, 11.8375368118,  5.4897880554,  7.9693427086,\n",
            "         7.2238488197,  9.3004808426,  9.0880794525,  8.0093679428,\n",
            "         4.8301630020,  7.7513971329,  5.9101753235,  4.5512390137,\n",
            "         5.4364938736,  8.6292085648,  9.7000341415,  8.4367227554])\n",
            "btensor.grad: tensor([7.2975678444, 9.0722475052, 8.0874128342, 8.9937238693, 8.2049560547,\n",
            "        7.3758873940, 8.0744743347, 8.6730213165, 8.8203783035, 9.4641981125,\n",
            "        9.2610416412, 7.7841572762, 9.0505914688, 8.2720727921, 9.6165752411,\n",
            "        8.0197172165, 8.9572381973, 8.8043804169, 8.8045492172, 8.1527166367])\n",
            "ctensor.grad: tensor([-70.3469085693, -31.4667205811,  61.8674201965,  -5.2089562416,\n",
            "         -0.3543204665, -31.1202392578, -15.1520280838, -25.6222839355,\n",
            "         54.0162544250,   1.8555507660, 172.6028747559,  69.7650604248,\n",
            "        152.4903411865,   8.5665025711,   0.9778158665,  47.5086784363,\n",
            "         21.9995460510,  58.8044624329])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(695.9084472656, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8696402311), tensor(1.5738369226), tensor(1.0956736803), tensor(1.1604111195), tensor(0.8498061299), tensor(0.8582174182), tensor(1.4076151848), tensor(1.0684638023), tensor(1.1349201202), tensor(1.0000704527), tensor(1.0035946369), tensor(0.8696347475), tensor(1.6214342117), tensor(1.1538268328), tensor(1.4911731482), tensor(1.5602992773), tensor(1.4134923220), tensor(1.1618459225), tensor(0.9610109925), tensor(1.2027312517)]\n",
            "b:  [tensor(1.3781210184), tensor(0.8288996220), tensor(1.3319073915), tensor(1.2710819244), tensor(1.0355490446), tensor(1.7254619598), tensor(1.2290794849), tensor(1.3899477720), tensor(1.1797450781), tensor(1.0135275126), tensor(1.3118087053), tensor(1.2311834097), tensor(0.8096147180), tensor(1.2405436039), tensor(1.2938909531), tensor(0.9981812239), tensor(0.9934533834), tensor(1.2743188143), tensor(1.4249044657), tensor(1.4115481377)]\n",
            "c:  [tensor(-0.3505807519), tensor(0.7939825654), tensor(0.4582870305), tensor(-0.8501387239), tensor(0.0505196974), tensor(0.1144838482), tensor(0.1627173275), tensor(-0.0771803707), tensor(1.5693030357), tensor(-0.0876037851), tensor(-0.1375413835), tensor(-0.4423217177), tensor(-0.2745560110), tensor(1.0721906424), tensor(-0.0649122968), tensor(0.0333893150), tensor(-0.1200036407), tensor(-0.1039089710)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-0.3210427165, -2.1404051781, -1.0525010824, -3.7254133224,\n",
            "        -4.1902437210,  0.7955287695, -1.8069508076, -1.8724037409,\n",
            "        -4.6249985695, -3.9010274410, -2.2274098396, -4.3993797302,\n",
            "        -2.4066715240, -2.5972509384, -2.8035171032, -2.2744789124,\n",
            "        -3.4820318222, -1.3674552441,  0.1071339250, -0.1483204365])\n",
            "btensor.grad: tensor([-5.1574964523, -1.7573804855, -4.8362922668, -3.2534153461,\n",
            "        -1.4403927326, -4.6999311447, -3.1294474602, -3.5667111874,\n",
            "        -4.0217108727, -3.5584235191, -4.6634831429, -3.0095098019,\n",
            "        -2.5479726791, -2.8086712360, -2.6760773659, -1.3664360046,\n",
            "        -3.0970592499, -4.3216257095, -3.1452476978, -4.4247989655])\n",
            "ctensor.grad: tensor([  30.5993499756,   -5.9954304695,  -41.7423515320,   -2.8151745796,\n",
            "          -0.3124805093,  -25.3243007660,  -12.1468620300,  -20.1460590363,\n",
            "         -55.2863273621,   -0.1773187369, -119.9132843018,  -39.5987472534,\n",
            "         -87.1354522705,    4.7131733894,    0.7979406118,   38.8812942505,\n",
            "          16.8556365967,   39.7176284790])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(676.1985473633, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8511879444), tensor(1.5647584200), tensor(1.0809621811), tensor(1.1486158371), tensor(0.8289674520), tensor(0.8426592946), tensor(1.4016855955), tensor(1.0577185154), tensor(1.1215687990), tensor(0.9809206128), tensor(0.9904844165), tensor(0.8530216813), tensor(1.6135114431), tensor(1.1431165934), tensor(1.4828073978), tensor(1.5508716106), tensor(1.4035285711), tensor(1.1508951187), tensor(0.9479171634), tensor(1.1939876080)]\n",
            "b:  [tensor(1.3682787418), tensor(0.8273155093), tensor(1.3217408657), tensor(1.2658133507), tensor(1.0311951637), tensor(1.7147638798), tensor(1.2245095968), tensor(1.3835709095), tensor(1.1727467775), tensor(1.0066618919), tensor(1.3011856079), tensor(1.2246180773), tensor(0.8052396774), tensor(1.2330152988), tensor(1.2855372429), tensor(0.9963471293), tensor(0.9879043102), tensor(1.2648656368), tensor(1.4186269045), tensor(1.4035522938)]\n",
            "c:  [tensor(-0.3388981521), tensor(0.8234636784), tensor(0.4607166052), tensor(-0.8436449766), tensor(0.0510101356), tensor(0.1558471173), tensor(0.1809661537), tensor(-0.0467331111), tensor(1.5572812557), tensor(-0.0884363204), tensor(-0.1789294034), tensor(-0.4547522664), tensor(-0.3003479242), tensor(1.0622608662), tensor(-0.0659811050), tensor(-0.0209033191), tensor(-0.1413413584), tensor(-0.1519981921)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([3.6904635429, 1.8156977892, 2.9422912598, 2.3590602875, 4.1677412987,\n",
            "        3.1116290092, 1.1859073639, 2.1490597725, 2.6702718735, 3.8299725056,\n",
            "        2.6220393181, 3.3226153851, 1.5845472813, 2.1420440674, 1.6731531620,\n",
            "        1.8855384588, 1.9927461147, 2.1901662350, 2.6187601089, 1.7487342358])\n",
            "btensor.grad: tensor([1.9684582949, 0.3168283105, 2.0333120823, 1.0537115335, 0.8707865477,\n",
            "        2.1396262646, 0.9139713049, 1.2753734589, 1.3996558189, 1.3731198311,\n",
            "        2.1246242523, 1.3130663633, 0.8750066757, 1.5056679249, 1.6707351208,\n",
            "        0.3668144345, 1.1098177433, 1.8906347752, 1.2555224895, 1.5991721153])\n",
            "ctensor.grad: tensor([-11.6826105118, -29.4810886383,  -2.4295706749,  -6.4937748909,\n",
            "         -0.4904392660, -41.3632621765, -18.2488193512, -30.4472599030,\n",
            "         12.0218200684,   0.8325324059,  41.3880157471,  12.4305629730,\n",
            "         25.7919101715,   9.9297828674,   1.0688056946,  54.2926330566,\n",
            "         21.3377227783,  48.0892105103])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(674.6611328125, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8769491911), tensor(1.5719481707), tensor(1.1024299860), tensor(1.1559039354), tensor(0.8512130976), tensor(0.8743020892), tensor(1.4129406214), tensor(1.0750267506), tensor(1.1331570148), tensor(0.9967828393), tensor(1.0109957457), tensor(0.8650444150), tensor(1.6201714277), tensor(1.1593685150), tensor(1.4935077429), tensor(1.5567725897), tensor(1.4110776186), tensor(1.1725273132), tensor(0.9729793072), tensor(1.2163876295)]\n",
            "b:  [tensor(1.3785490990), tensor(0.8483169675), tensor(1.3354780674), tensor(1.2848999500), tensor(1.0501958132), tensor(1.7264509201), tensor(1.2408187389), tensor(1.4011530876), tensor(1.1901488304), tensor(1.0266404152), tensor(1.3178443909), tensor(1.2408083677), tensor(0.8247830272), tensor(1.2494626045), tensor(1.3072845936), tensor(1.0146864653), tensor(1.0069983006), tensor(1.2825301886), tensor(1.4382729530), tensor(1.4180406332)]\n",
            "c:  [tensor(-0.3718789816), tensor(0.8153499365), tensor(0.4804553986), tensor(-0.8502691388), tensor(0.0514439195), tensor(0.1445278823), tensor(0.1714365035), tensor(-0.0631372109), tensor(1.5849341154), tensor(-0.0886269137), tensor(-0.1142982095), tensor(-0.4268918335), tensor(-0.2386102527), tensor(1.0812097788), tensor(-0.0664338320), tensor(0.0281330831), tensor(-0.1168181300), tensor(-0.0942560285)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-5.1522498131, -1.4379515648, -4.2935628891, -1.4576213360,\n",
            "        -4.4491262436, -6.3285555840, -2.2510035038, -3.4616460800,\n",
            "        -2.3176488876, -3.1724431515, -4.1022753716, -2.4045479298,\n",
            "        -1.3319879770, -3.2503757477, -2.1400716305, -1.1802052259,\n",
            "        -1.5098133087, -4.3264298439, -5.0124301910, -4.4799985886])\n",
            "btensor.grad: tensor([-2.0540719032, -4.2002887726, -2.7474389076, -3.8173155785,\n",
            "        -3.8001277447, -2.3374009132, -3.2618322372, -3.5164406300,\n",
            "        -3.4804067612, -3.9957022667, -3.3317594528, -3.2380611897,\n",
            "        -3.9086747169, -3.2894506454, -4.3494801521, -3.6678621769,\n",
            "        -3.8188061714, -3.5329024792, -3.9292051792, -2.8976752758])\n",
            "ctensor.grad: tensor([ 32.9808311462,   8.1137142181, -19.7387847900,   6.6241436005,\n",
            "         -0.4337832034,  11.3192300797,   9.5296459198,  16.4040985107,\n",
            "        -27.6528892517,   0.1905968487, -64.6311874390, -27.8604373932,\n",
            "        -61.7376632690, -18.9489059448,   0.4527275860, -49.0363998413,\n",
            "        -24.5232295990, -57.7421646118])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(679.3909912109, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8495903611), tensor(1.5590425730), tensor(1.0805011988), tensor(1.1376383305), tensor(0.8150404692), tensor(0.8479987979), tensor(1.3986029625), tensor(1.0562305450), tensor(1.1092764139), tensor(0.9699467421), tensor(0.9879193306), tensor(0.8387433887), tensor(1.6081298590), tensor(1.1388850212), tensor(1.4770215750), tensor(1.5436856747), tensor(1.3937494755), tensor(1.1512078047), tensor(0.9492106438), tensor(1.2012678385)]\n",
            "b:  [tensor(1.3580836058), tensor(0.8368554711), tensor(1.3148214817), tensor(1.2677985430), tensor(1.0386189222), tensor(1.7052284479), tensor(1.2250754833), tensor(1.3841171265), tensor(1.1704045534), tensor(1.0071353912), tensor(1.2967935801), tensor(1.2246165276), tensor(0.8105425239), tensor(1.2339465618), tensor(1.2891016006), tensor(1.0046628714), tensor(0.9897101521), tensor(1.2608798742), tensor(1.4206087589), tensor(1.3991479874)]\n",
            "c:  [tensor(-0.3506193757), tensor(0.8393791914), tensor(0.4683838785), tensor(-0.8385881782), tensor(0.0521361530), tensor(0.2051440626), tensor(0.1968133897), tensor(-0.0183600038), tensor(1.5510773659), tensor(-0.0899382457), tensor(-0.2180161178), tensor(-0.4648441672), tensor(-0.3223465979), tensor(1.0668063164), tensor(-0.0676648021), tensor(-0.0390378125), tensor(-0.1427684575), tensor(-0.1582384706)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([5.4717607498, 2.5811092854, 4.3857531548, 3.6531300545, 7.2345218658,\n",
            "        5.2606616020, 2.8675222397, 3.7592322826, 4.7761240005, 5.3672199249,\n",
            "        4.6152882576, 5.2602105141, 2.4083254337, 4.0966911316, 3.2972433567,\n",
            "        2.6173837185, 3.4656279087, 4.2639040947, 4.7537336349, 3.0239689350])\n",
            "btensor.grad: tensor([4.0930929184, 2.2923023701, 4.1313076019, 3.4202780724, 2.3153810501,\n",
            "        4.2444834709, 3.1486535072, 3.4071862698, 3.9488625526, 3.9010088444,\n",
            "        4.2101688385, 3.2383666039, 2.8481063843, 3.1032168865, 3.6365897655,\n",
            "        2.0047078133, 3.4576301575, 4.3300704956, 3.5328502655, 3.7785251141])\n",
            "ctensor.grad: tensor([-21.2595996857, -24.0292549133,  12.0715303421, -11.6809310913,\n",
            "         -0.6922321320, -60.6161727905, -25.3768825531, -44.7772064209,\n",
            "         33.8566894531,   1.3113352060, 103.7179031372,  37.9523391724,\n",
            "         83.7363510132,  14.4034452438,   1.2309716940,  67.1708908081,\n",
            "         25.9503326416,  63.9824371338])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(688.4771728516, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.9181489944), tensor(1.5809332132), tensor(1.1311244965), tensor(1.1628478765), tensor(0.8824562430), tensor(0.9221032262), tensor(1.4219516516), tensor(1.0982294083), tensor(1.1432191133), tensor(1.0234165192), tensor(1.0365130901), tensor(0.8837252259), tensor(1.6283211708), tensor(1.1767654419), tensor(1.5034964085), tensor(1.5638499260), tensor(1.4170272350), tensor(1.1968011856), tensor(1.0054019690), tensor(1.2449489832)]\n",
            "b:  [tensor(1.3835464716), tensor(0.8686015606), tensor(1.3458282948), tensor(1.3012496233), tensor(1.0702275038), tensor(1.7342411280), tensor(1.2531609535), tensor(1.4174416065), tensor(1.2021718025), tensor(1.0437698364), tensor(1.3320913315), tensor(1.2538287640), tensor(0.8428965807), tensor(1.2660704851), tensor(1.3277069330), tensor(1.0322299004), tensor(1.0226908922), tensor(1.2961641550), tensor(1.4554816484), tensor(1.4303766489)]\n",
            "c:  [tensor(-0.3903669715), tensor(0.7866435051), tensor(0.4879101813), tensor(-0.8771371245), tensor(0.0523219779), tensor(0.0826513022), tensor(0.1364512742), tensor(-0.1283828318), tensor(1.6036007404), tensor(-0.0897282213), tensor(-0.0931333452), tensor(-0.4167293310), tensor(-0.2196341604), tensor(1.1149237156), tensor(-0.0676318333), tensor(0.1073212475), tensor(-0.0765203610), tensor(-0.0167010427)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-13.7117261887,  -4.3781208992, -10.1246614456,  -5.0419044495,\n",
            "        -13.4831514359, -14.8208827972,  -4.6697411537,  -8.3997802734,\n",
            "         -6.7885398865, -10.6939649582,  -9.7187442780,  -8.9963645935,\n",
            "         -4.0382566452,  -7.5760765076,  -5.2949552536,  -4.0328621864,\n",
            "         -4.6555633545,  -9.1186704636, -11.2382736206,  -8.7362222672])\n",
            "btensor.grad: tensor([-5.0925636292, -6.3492164612, -6.2013740540, -6.6902060509,\n",
            "        -6.3217086792, -5.8025450706, -5.6170935631, -6.6649031639,\n",
            "        -6.3534398079, -7.3268952370, -7.0595583916, -5.8424453735,\n",
            "        -6.4708170891, -6.4247822762, -7.7210750580, -5.5134000778,\n",
            "        -6.5961565971, -7.0568451881, -6.9745736122, -6.2457361221])\n",
            "ctensor.grad: tensor([ 3.9747577667e+01,  5.2735652924e+01, -1.9526309967e+01,\n",
            "         3.8548927307e+01, -1.8582393229e-01,  1.2249275208e+02,\n",
            "         6.0362110138e+01,  1.1002282715e+02, -5.2523380280e+01,\n",
            "        -2.1002106369e-01, -1.2488276672e+02, -4.8114826202e+01,\n",
            "        -1.0271243286e+02, -4.8117378235e+01, -3.2971903682e-02,\n",
            "        -1.4635905457e+02, -6.6248092651e+01, -1.4153741455e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(712.8056640625, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8637597561), tensor(1.5567277670), tensor(1.0883727074), tensor(1.1340380907), tensor(0.8267171383), tensor(0.8642717004), tensor(1.3950326443), tensor(1.0590940714), tensor(1.1073399782), tensor(0.9774272442), tensor(0.9920778871), tensor(0.8437571526), tensor(1.6046776772), tensor(1.1387683153), tensor(1.4744015932), tensor(1.5414273739), tensor(1.3901100159), tensor(1.1547328234), tensor(0.9582498074), tensor(1.2041299343)]\n",
            "b:  [tensor(1.3476482630), tensor(0.8257941604), tensor(1.3062595129), tensor(1.2580113411), tensor(1.0311430693), tensor(1.6978496313), tensor(1.2142199278), tensor(1.3754204512), tensor(1.1592106819), tensor(0.9977200627), tensor(1.2870237827), tensor(1.2161071301), tensor(0.7996870279), tensor(1.2263668776), tensor(1.2811284065), tensor(0.9944211245), tensor(0.9794732332), tensor(1.2529587746), tensor(1.4127753973), tensor(1.3904668093)]\n",
            "c:  [tensor(-0.3227679729), tensor(0.8181477785), tensor(0.4290259480), tensor(-0.8709233403), tensor(0.0527039990), tensor(0.1196748465), tensor(0.1542482227), tensor(-0.0992497280), tensor(1.5492070913), tensor(-0.0915695354), tensor(-0.2649391890), tensor(-0.4855949283), tensor(-0.3702045679), tensor(1.1054943800), tensor(-0.0686716512), tensor(0.0552381687), tensor(-0.1003512964), tensor(-0.0802855566)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([10.8778467178,  4.8410792351,  8.5503492355,  5.7619562149,\n",
            "        11.1478176117, 11.5663042068,  5.3838071823,  7.8270769119,\n",
            "         7.1758174896,  9.1978530884,  8.8870449066,  7.9936103821,\n",
            "         4.7287020683,  7.5994286537,  5.8189611435,  4.4845061302,\n",
            "         5.3834323883,  8.4136753082,  9.4304380417,  8.1638212204])\n",
            "btensor.grad: tensor([7.1796531677, 8.5614833832, 7.9137663841, 8.6476478577, 7.8168869019,\n",
            "        7.2782893181, 7.7882080078, 8.4042310715, 8.5922193527, 9.2099533081,\n",
            "        9.0135078430, 7.5443334579, 8.6419067383, 7.9407143593, 9.3157024384,\n",
            "        7.5617518425, 8.6435375214, 8.6410722733, 8.5412502289, 7.9819602966])\n",
            "ctensor.grad: tensor([-67.5989913940, -31.5042514801,  58.8842468262,  -6.2138056755,\n",
            "         -0.3820225298, -37.0235404968, -17.7969474792, -29.1331005096,\n",
            "         54.3936042786,   1.8413145542, 171.8058166504,  68.8655853271,\n",
            "        150.5704193115,   9.4293375015,   1.0398204327,  52.0830764771,\n",
            "         23.8309364319,  63.5845108032])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(693.3173828125, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8701595664), tensor(1.5688310862), tensor(1.0966173410), tensor(1.1541765928), tensor(0.8511614203), tensor(0.8651782274), tensor(1.4053934813), tensor(1.0709555149), tensor(1.1322966814), tensor(1.0000506639), tensor(1.0064496994), tensor(0.8678262830), tensor(1.6180611849), tensor(1.1542559862), tensor(1.4899283648), tensor(1.5540492535), tensor(1.4088382721), tensor(1.1644800901), tensor(0.9614150524), tensor(1.2083283663)]\n",
            "b:  [tensor(1.3748154640), tensor(0.8376936913), tensor(1.3323552608), tensor(1.2765555382), tensor(1.0409411192), tensor(1.7227684259), tensor(1.2320590019), tensor(1.3958454132), tensor(1.1816766262), tensor(1.0176739693), tensor(1.3133361340), tensor(1.2333171368), tensor(0.8154152632), tensor(1.2429293394), tensor(1.2979667187), tensor(1.0042494535), tensor(0.9977015853), tensor(1.2767546177), tensor(1.4309202433), tensor(1.4143896103)]\n",
            "c:  [tensor(-0.3598885238), tensor(0.8185648322), tensor(0.4759285152), tensor(-0.8681388497), tensor(0.0530441739), tensor(0.1470836699), tensor(0.1671251506), tensor(-0.0781815872), tensor(1.6059594154), tensor(-0.0913615823), tensor(-0.1413170993), tensor(-0.4446043968), tensor(-0.2800509334), tensor(1.1018333435), tensor(-0.0694652423), tensor(0.0192912519), tensor(-0.1154047251), tensor(-0.1143060923)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.2799609900, -2.4206588268, -1.6489157677, -4.0276951790,\n",
            "        -4.8888568878, -0.1813104600, -2.0721654892, -2.3722829819,\n",
            "        -4.9913377762, -4.5246925354, -2.8743519783, -4.8138246536,\n",
            "        -2.6767079830, -3.0975306034, -3.1053552628, -2.5243666172,\n",
            "        -3.7456514835, -1.9494541883, -0.6330474019, -0.8396806717])\n",
            "btensor.grad: tensor([-5.4334506989, -2.3799047470, -5.2191615105, -3.7088279724,\n",
            "        -1.9596179724, -4.9837484360, -3.5678057671, -4.0849866867,\n",
            "        -4.4931812286, -3.9907875061, -5.2624721527, -3.4420130253,\n",
            "        -3.1456470490, -3.3124976158, -3.3676707745, -1.9656596184,\n",
            "        -3.6456706524, -4.7591710091, -3.6289684772, -4.7845664024])\n",
            "ctensor.grad: tensor([  37.1205596924,   -0.4170745611,  -46.9025764465,   -2.7844822407,\n",
            "          -0.3401762843,  -27.4088249207,  -12.8769321442,  -21.0681400299,\n",
            "         -56.7522773743,   -0.2079551369, -123.6220779419,  -40.9905357361,\n",
            "         -90.1536483765,    3.6609890461,    0.7935886383,   35.9469146729,\n",
            "          15.0534315109,   34.0205345154])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(673.6092529297, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8541580439), tensor(1.5604264736), tensor(1.0838416815), tensor(1.1422969103), tensor(0.8302639127), tensor(0.8525628448), tensor(1.3995455503), tensor(1.0616408587), tensor(1.1183204651), tensor(0.9816758037), tensor(0.9944756031), tensor(0.8507783413), tensor(1.6106699705), tensor(1.1441159248), tensor(1.4814692736), tensor(1.5450996161), tensor(1.3984832764), tensor(1.1546934843), tensor(0.9501743913), tensor(1.2023333311)]\n",
            "b:  [tensor(1.3642365932), tensor(0.8371838331), tensor(1.3219538927), tensor(1.2716450691), tensor(1.0382725000), tensor(1.7114020586), tensor(1.2276574373), tensor(1.3898270130), tensor(1.1746790409), tensor(1.0114278793), tensor(1.3029186726), tensor(1.2271734476), tensor(0.8118620515), tensor(1.2362943888), tensor(1.2910224199), tensor(1.0033673048), tensor(0.9924436808), tensor(1.2669513226), tensor(1.4252713919), tensor(1.4063445330)]\n",
            "c:  [tensor(-0.3520103395), tensor(0.8430540562), tensor(0.4782389700), tensor(-0.8609087467), tensor(0.0536028519), tensor(0.1908421516), tensor(0.1854646802), tensor(-0.0471906699), tensor(1.5915564299), tensor(-0.0922266245), tensor(-0.1879659891), tensor(-0.4589700699), tensor(-0.3100063503), tensor(1.0928660631), tensor(-0.0705546513), tensor(-0.0291739814), tensor(-0.1333658099), tensor(-0.1552614123)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([3.2003002167, 1.6809335947, 2.5551326275, 2.3759353161, 4.1794991493,\n",
            "        2.5230727196, 1.1695975065, 1.8629381657, 2.7952497005, 3.6749699116,\n",
            "        2.3948218822, 3.4095897675, 1.4782325029, 2.0280098915, 1.6918278933,\n",
            "        1.7899172306, 2.0710051060, 1.9573124647, 2.2481377125, 1.1990082264])\n",
            "btensor.grad: tensor([2.1157710552, 0.1019728184, 2.0802683830, 0.9820925593, 0.5337275267,\n",
            "        2.2732770443, 0.8803119659, 1.2036783695, 1.3995190859, 1.2492260933,\n",
            "        2.0834884644, 1.2287334204, 0.7106368542, 1.3269996643, 1.3888622522,\n",
            "        0.1764265895, 1.0515767336, 1.9606505632, 1.1297757626, 1.6090176105])\n",
            "ctensor.grad: tensor([ -7.8781714439, -24.4892101288,  -2.3104510307,  -7.2300753593,\n",
            "         -0.5586791039, -43.7584724426, -18.3395290375, -30.9909152985,\n",
            "         14.4030408859,   0.8650393486,  46.6488838196,  14.3656806946,\n",
            "         29.9554100037,   8.9672517776,   1.0894055367,  48.4652328491,\n",
            "         17.9610862732,  40.9553222656])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(674.5625610352, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8862660527), tensor(1.5698870420), tensor(1.1109551191), tensor(1.1514122486), tensor(0.8574498296), tensor(0.8912010193), tensor(1.4120947123), tensor(1.0835263729), tensor(1.1318147182), tensor(1.0029100180), tensor(1.0187145472), tensor(0.8670233488), tensor(1.6192350388), tensor(1.1631755829), tensor(1.4940093756), tensor(1.5531007051), tensor(1.4074692726), tensor(1.1795682907), tensor(0.9802435637), tensor(1.2290245295)]\n",
            "b:  [tensor(1.3753571510), tensor(0.8591832519), tensor(1.3369594812), tensor(1.2917684317), tensor(1.0591441393), tensor(1.7246500254), tensor(1.2448089123), tensor(1.4089984894), tensor(1.1932684183), tensor(1.0337270498), tensor(1.3209851980), tensor(1.2445634604), tensor(0.8326585889), tensor(1.2544770241), tensor(1.3150008917), tensor(1.0224145651), tensor(1.0125524998), tensor(1.2864049673), tensor(1.4466898441), tensor(1.4226642847)]\n",
            "c:  [tensor(-0.3841824234), tensor(0.8262671232), tensor(0.4955213368), tensor(-0.8738190532), tensor(0.0540358014), tensor(0.1544341594), tensor(0.1633643806), tensor(-0.0852106884), tensor(1.6198728085), tensor(-0.0924175158), tensor(-0.1198546290), tensor(-0.4297637939), tensor(-0.2472921312), tensor(1.1161476374), tensor(-0.0709833354), tensor(0.0384487398), tensor(-0.1000220776), tensor(-0.0819700733)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-6.4216012955, -1.8921138048, -5.4226818085, -1.8230667114,\n",
            "        -5.4371848106, -7.7276315689, -2.5098314285, -4.3770985603,\n",
            "        -2.6988446712, -4.2468433380, -4.8477926254, -3.2489984035,\n",
            "        -1.7130179405, -3.8119201660, -2.5080258846, -1.6002253294,\n",
            "        -1.7972104549, -4.9749641418, -6.0138373375, -5.3382320404])\n",
            "btensor.grad: tensor([-2.2241172791, -4.3998823166, -3.0011060238, -4.0246801376,\n",
            "        -4.1743316650, -2.6496043205, -3.4303011894, -3.8342897892,\n",
            "        -3.7178676128, -4.4598441124, -3.6132955551, -3.4779999256,\n",
            "        -4.1593127251, -3.6365211010, -4.7956957817, -3.8094444275,\n",
            "        -4.0217733383, -3.8907241821, -4.2836904526, -3.2639474869])\n",
            "ctensor.grad: tensor([ 32.1720771790,  16.7869014740, -17.2823791504,  12.9103116989,\n",
            "         -0.4329476655,  36.4079856873,  22.1002960205,  38.0200157166,\n",
            "        -28.3163814545,   0.1908893287, -68.1113586426, -29.2062664032,\n",
            "        -62.7142257690, -23.2815856934,   0.4286850095, -67.6227188110,\n",
            "        -33.3437347412, -73.2913360596])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(683.7749633789, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8510187864), tensor(1.5538800955), tensor(1.0830855370), tensor(1.1299815178), tensor(0.8167319894), tensor(0.8560152650), tensor(1.3948465586), tensor(1.0596116781), tensor(1.1049524546), tensor(0.9705793858), tensor(0.9901685119), tensor(0.8372008801), tensor(1.6042175293), tensor(1.1380563974), tensor(1.4746799469), tensor(1.5376218557), tensor(1.3877038956), tensor(1.1528337002), tensor(0.9501404166), tensor(1.2073388100)]\n",
            "b:  [tensor(1.3514673710), tensor(0.8412756324), tensor(1.3120576143), tensor(1.2692973614), tensor(1.0415153503), tensor(1.7000963688), tensor(1.2243322134), tensor(1.3868089914), tensor(1.1687549353), tensor(1.0087635517), tensor(1.2944654226), tensor(1.2235162258), tensor(0.8120916486), tensor(1.2334344387), tensor(1.2896001339), tensor(1.0063016415), tensor(0.9893988967), tensor(1.2598408461), tensor(1.4236472845), tensor(1.3994787931)]\n",
            "c:  [tensor(-0.3540274501), tensor(0.8546665311), tensor(0.4740976691), tensor(-0.8609749079), tensor(0.0547158942), tensor(0.2214659452), tensor(0.1927165836), tensor(-0.0348860361), tensor(1.5809729099), tensor(-0.0938135311), tensor(-0.2378063202), tensor(-0.4735580981), tensor(-0.3443052471), tensor(1.1009353399), tensor(-0.0722466782), tensor(-0.0348922201), tensor(-0.1299995184), tensor(-0.1570737511)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([7.0494570732, 3.2013967037, 5.5739259720, 4.2861528397, 8.1435670853,\n",
            "        7.0371479988, 3.4496312141, 4.7829332352, 5.3724446297, 6.4661273956,\n",
            "        5.7092084885, 5.9644908905, 3.0034987926, 5.0238318443, 3.8658802509,\n",
            "        3.0957751274, 3.9530711174, 5.3469123840, 6.0206251144, 4.3371505737])\n",
            "btensor.grad: tensor([4.7779445648, 3.5815184116, 4.9803814888, 4.4942164421, 3.5257689953,\n",
            "        4.9107332230, 4.0953330994, 4.4378995895, 4.9026985168, 4.9926986694,\n",
            "        5.3039555550, 4.2094440460, 4.1133852005, 4.2085113525, 5.0801520348,\n",
            "        3.2225852013, 4.6307206154, 5.3128204346, 4.6085114479, 4.6370868683])\n",
            "ctensor.grad: tensor([-30.1549797058, -28.3994197845,  21.4236583710, -12.8441524506,\n",
            "         -0.6800929308, -67.0317916870, -29.3521976471, -50.3246498108,\n",
            "         38.8998756409,   1.3960123062, 117.9516906738,  43.7942962646,\n",
            "         97.0131072998,  15.2122745514,   1.2633396387,  73.3409576416,\n",
            "         29.9774322510,  75.1036758423])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(688.4541625977, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.9138674140), tensor(1.5769239664), tensor(1.1307189465), tensor(1.1575336456), tensor(0.8816193938), tensor(0.9230036736), tensor(1.4176688194), tensor(1.1004303694), tensor(1.1406354904), tensor(1.0245156288), tensor(1.0373147726), tensor(0.8835558891), tensor(1.6258078814), tensor(1.1756615639), tensor(1.5015691519), tensor(1.5589932203), tensor(1.4123772383), tensor(1.1961588860), tensor(1.0009076595), tensor(1.2479323149)]\n",
            "b:  [tensor(1.3795465231), tensor(0.8722672462), tensor(1.3453111649), tensor(1.3027414083), tensor(1.0721113682), tensor(1.7310307026), tensor(1.2528425455), tensor(1.4209305048), tensor(1.2012668848), tensor(1.0452706814), tensor(1.3320146799), tensor(1.2533391714), tensor(0.8446882963), tensor(1.2659621239), tensor(1.3287516832), tensor(1.0331960917), tensor(1.0228261948), tensor(1.2963829041), tensor(1.4585011005), tensor(1.4322730303)]\n",
            "c:  [tensor(-0.3984811306), tensor(0.8025797606), tensor(0.5050122142), tensor(-0.8973975182), tensor(0.0549142212), tensor(0.1067811251), tensor(0.1367834508), tensor(-0.1338384897), tensor(1.6350326538), tensor(-0.0935672000), tensor(-0.1121878475), tensor(-0.4267944992), tensor(-0.2449078858), tensor(1.1436367035), tensor(-0.0723003298), tensor(0.0949936956), tensor(-0.0706885681), tensor(-0.0279560089)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-12.5697288513,  -4.6087841988,  -9.5266885757,  -5.5104303360,\n",
            "        -12.9774799347, -13.3976783752,  -4.5644516945,  -8.1637334824,\n",
            "         -7.1365957260, -10.7872581482,  -9.4292411804,  -9.2710037231,\n",
            "         -4.3180818558,  -7.5210456848,  -5.3778343201,  -4.2742776871,\n",
            "         -4.9346609116,  -8.6650371552, -10.1534404755,  -8.1186914444])\n",
            "btensor.grad: tensor([-5.6158270836, -6.1983246803, -6.6507024765, -6.6888089180,\n",
            "        -6.1191997528, -6.1868658066, -5.7020554543, -6.8243055344,\n",
            "        -6.5023818016, -7.3014264107, -7.5098547935, -5.9645872116,\n",
            "        -6.5193271637, -6.5055255890, -7.8303084373, -5.3788890839,\n",
            "        -6.6854586601, -7.3084015846, -6.9707665443, -6.5588560104])\n",
            "ctensor.grad: tensor([ 4.4453674316e+01,  5.2086799622e+01, -3.0914543152e+01,\n",
            "         3.6422592163e+01, -1.9832870364e-01,  1.1468481445e+02,\n",
            "         5.5933128357e+01,  9.8952445984e+01, -5.4059791565e+01,\n",
            "        -2.4633055925e-01, -1.2561846161e+02, -4.6763584137e+01,\n",
            "        -9.9397346497e+01, -4.2701313019e+01,  5.3650975227e-02,\n",
            "        -1.2988591003e+02, -5.9310947418e+01, -1.2911773682e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(706.3044433594, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8619090319), tensor(1.5534905195), tensor(1.0900633335), tensor(1.1295140982), tensor(0.8294889331), tensor(0.8681327105), tensor(1.3929487467), tensor(1.0634921789), tensor(1.1068640947), tensor(0.9799942970), tensor(0.9955072403), tensor(0.8452115059), tensor(1.6032133102), tensor(1.1398204565), tensor(1.4744560719), tensor(1.5372655392), tensor(1.3868814707), tensor(1.1570299864), tensor(0.9570259452), tensor(1.2095659971)]\n",
            "b:  [tensor(1.3465783596), tensor(0.8340754509), tensor(1.3088299036), tensor(1.2646610737), tensor(1.0368700027), tensor(1.6973121166), tensor(1.2178641558), tensor(1.3827702999), tensor(1.1621212959), tensor(1.0040657520), tensor(1.2899801731), tensor(1.2187070847), tensor(0.8051081896), tensor(1.2296162844), tensor(1.2850381136), tensor(0.9989185333), tensor(0.9834355116), tensor(1.2562346458), tensor(1.4199756384), tensor(1.3961230516)]\n",
            "c:  [tensor(-0.3363828957), tensor(0.8395708799), tensor(0.4517284632), tensor(-0.8900835514), tensor(0.0553296134), tensor(0.1504329145), tensor(0.1575496048), tensor(-0.1007276326), tensor(1.5849286318), tensor(-0.0952063501), tensor(-0.2658289075), tensor(-0.4862295687), tensor(-0.3755364418), tensor(1.1333310604), tensor(-0.0734120384), tensor(0.0379558206), tensor(-0.0965599865), tensor(-0.0966728181)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([10.3916759491,  4.6866879463,  8.1311340332,  5.6039118767,\n",
            "        10.4260950089, 10.9741878510,  4.9440116882,  7.3876399994,\n",
            "         6.7542753220,  8.9042634964,  8.3615064621,  7.6688814163,\n",
            "         4.5189242363,  7.1682157516,  5.4226174355,  4.3455286026,\n",
            "         5.0991601944,  7.8257799149,  8.7763404846,  7.6732749939])\n",
            "btensor.grad: tensor([6.5936355591, 7.6383595467, 7.2962470055, 7.6160569191, 7.0482835770,\n",
            "        6.7437071800, 6.9956769943, 7.6320347786, 7.8291139603, 8.2409896851,\n",
            "        8.4068946838, 6.9264159203, 7.9160270691, 7.2691645622, 8.7427091599,\n",
            "        6.8555068970, 7.8781328201, 8.0296602249, 7.7050876617, 7.2299966812])\n",
            "ctensor.grad: tensor([-62.0982360840, -36.9911117554,  53.2837409973,  -7.3139820099,\n",
            "         -0.4153926373, -43.6517868042, -20.7661495209, -33.1108512878,\n",
            "         50.1040267944,   1.6391525269, 153.6410522461,  59.4350547791,\n",
            "        130.6285705566,  10.3056602478,   1.1117085218,  57.0378723145,\n",
            "         25.8714199066,  68.7168045044])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(688.2670288086, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8700364828), tensor(1.5646228790), tensor(1.0988631248), tensor(1.1476186514), tensor(0.8531181812), tensor(0.8718416095), tensor(1.4028643370), tensor(1.0749595165), tensor(1.1299910545), tensor(1.0012696981), tensor(1.0096992254), tensor(0.8670700192), tensor(1.6154571772), tensor(1.1548159122), tensor(1.4892048836), tensor(1.5488356352), tensor(1.4040261507), tensor(1.1672413349), tensor(0.9616678953), tensor(1.2153384686)]\n",
            "b:  [tensor(1.3714354038), tensor(0.8470135331), tensor(1.3335914612), tensor(1.2828526497), tensor(1.0471976995), tensor(1.7207920551), tensor(1.2353752851), tensor(1.4033212662), tensor(1.1841661930), tensor(1.0233898163), tensor(1.3161329031), tensor(1.2357434034), tensor(0.8214889765), tensor(1.2459900379), tensor(1.3029837608), tensor(1.0098733902), tensor(1.0020632744), tensor(1.2797243595), tensor(1.4380862713), tensor(1.4187585115)]\n",
            "c:  [tensor(-0.3743298650), tensor(0.8392195106), tensor(0.4978337586), tensor(-0.8874710798), tensor(0.0557156801), tensor(0.1788217127), tensor(0.1705650389), tensor(-0.0791537315), tensor(1.6384090185), tensor(-0.0950240120), tensor(-0.1485294402), tensor(-0.4465869367), tensor(-0.2890254557), tensor(1.1306324005), tensor(-0.0742319524), tensor(0.0050085224), tensor(-0.1098167226), tensor(-0.1250587702)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.6254916191, -2.2264673710, -1.7599544525, -3.6209039688,\n",
            "        -4.7258462906, -0.7417795658, -1.9831132889, -2.2934768200,\n",
            "        -4.6253871918, -4.2550764084, -2.8383913040, -4.3716979027,\n",
            "        -2.4487764835, -2.9990909100, -2.9497566223, -2.3140251637,\n",
            "        -3.4289321899, -2.0422782898, -0.9283959866, -1.1544889212])\n",
            "btensor.grad: tensor([-4.9714126587, -2.5876190662, -4.9523105621, -3.6383047104,\n",
            "        -2.0655322075, -4.6959791183, -3.5022301674, -4.1101870537,\n",
            "        -4.4089875221, -3.8648171425, -5.2305545807, -3.4072675705,\n",
            "        -3.2761616707, -3.2747449875, -3.5891323090, -2.1909632683,\n",
            "        -3.7255499363, -4.6979393959, -3.6221234798, -4.5270862579])\n",
            "ctensor.grad: tensor([  37.9469642639,    0.3513899744,  -46.1053047180,   -2.6124925613,\n",
            "          -0.3860668540,  -28.3888015747,  -13.0154266357,  -21.5739002228,\n",
            "         -53.4803428650,   -0.1823416650, -117.2994613647,  -39.6426353455,\n",
            "         -86.5109710693,    2.6986823082,    0.8199163079,   32.9472961426,\n",
            "          13.2567348480,   28.3859539032])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(671.1326904297, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8577511907), tensor(1.5573354959), tensor(1.0891922712), tensor(1.1362885237), tensor(0.8338562250), tensor(0.8637532592), tensor(1.3977259398), tensor(1.0682158470), tensor(1.1163929701), tensor(0.9848455191), tensor(0.9998790622), tensor(0.8508246541), tensor(1.6090459824), tensor(1.1461906433), tensor(1.4813961983), tensor(1.5407687426), tensor(1.3939427137), tensor(1.1596051455), tensor(0.9533949494), tensor(1.2129108906)]\n",
            "b:  [tensor(1.3608875275), tensor(0.8481224775), tensor(1.3237490654), tensor(1.2789728642), tensor(1.0467165709), tensor(1.7097085714), tensor(1.2317903042), tensor(1.3984025717), tensor(1.1780035496), tensor(1.0187597275), tensor(1.3065972328), tensor(1.2307256460), tensor(0.8194293976), tensor(1.2408237457), tensor(1.2983572483), tensor(1.0103440285), tensor(0.9979097247), tensor(1.2707149982), tensor(1.4339922667), tensor(1.4115726948)]\n",
            "c:  [tensor(-0.3708351254), tensor(0.8581156731), tensor(0.5003899932), tensor(-0.8803528547), tensor(0.0563411042), tensor(0.2200932056), tensor(0.1863974184), tensor(-0.0515310392), tensor(1.6235980988), tensor(-0.0958897769), tensor(-0.1946285665), tensor(-0.4606651962), tensor(-0.3184938431), tensor(1.1235470772), tensor(-0.0753363371), tensor(-0.0337571986), tensor(-0.1226855889), tensor(-0.1554816365)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([2.4570555687, 1.4574749470, 1.9341642857, 2.2660155296, 3.8523859978,\n",
            "        1.6176748276, 1.0276845694, 1.3487339020, 2.7196266651, 3.2848362923,\n",
            "        1.9640291929, 3.2490782738, 1.2822431326, 1.7250549793, 1.5617480278,\n",
            "        1.6133744717, 2.0166771412, 1.5272357464, 1.6545896530, 0.4855204225])\n",
            "btensor.grad: tensor([ 2.1095867157, -0.2217943966,  1.9684888124,  0.7759544253,\n",
            "         0.0962165594,  2.2166945934,  0.7169964910,  0.9837309718,\n",
            "         1.2325295210,  0.9260083437,  1.9071259499,  1.0035576820,\n",
            "         0.4119186997,  1.0332552195,  0.9252930880, -0.0941262245,\n",
            "         0.8307058215,  1.8018763065,  0.8188040853,  1.4371664524])\n",
            "ctensor.grad: tensor([ -3.4947283268, -18.8961620331,  -2.5562267303,  -7.1182279587,\n",
            "         -0.6254233122, -41.2714958191, -15.8323726654, -27.6226882935,\n",
            "         14.8109769821,   0.8657674193,  46.0991325378,  14.0782594681,\n",
            "         29.4683837891,   7.0853209496,   1.1043825150,  38.7657203674,\n",
            "         12.8688650131,  30.4228591919])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(673.4149780273, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8910910487), tensor(1.5672314167), tensor(1.1170709133), tensor(1.1452605724), tensor(0.8611723781), tensor(0.9044309855), tensor(1.4097563028), tensor(1.0915615559), tensor(1.1291029453), tensor(1.0074415207), tensor(1.0241291523), tensor(0.8682830334), tensor(1.6178679466), tensor(1.1652530432), tensor(1.4937629700), tensor(1.5488824844), tensor(1.4024834633), tensor(1.1842396259), tensor(0.9839467406), tensor(1.2400231361)]\n",
            "b:  [tensor(1.3709799051), tensor(0.8691209555), tensor(1.3378689289), tensor(1.2977919579), tensor(1.0669654608), tensor(1.7223908901), tensor(1.2478553057), tensor(1.4169273376), tensor(1.1955132484), tensor(1.0404735804), tensor(1.3235077858), tensor(1.2471994162), tensor(0.8393789530), tensor(1.2583473921), tensor(1.3218808174), tensor(1.0283473730), tensor(1.0168914795), tensor(1.2896804810), tensor(1.4547522068), tensor(1.4275695086)]\n",
            "c:  [tensor(-0.3979727030), tensor(0.8376052976), tensor(0.5158830285), tensor(-0.8973495364), tensor(0.0567937233), tensor(0.1670315862), tensor(0.1563228965), tensor(-0.1031800434), tensor(1.6490460634), tensor(-0.0961427689), tensor(-0.1320068836), tensor(-0.4334821999), tensor(-0.2624047995), tensor(1.1474767923), tensor(-0.0758313462), tensor(0.0404202081), tensor(-0.0856335461), tensor(-0.0773167387)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-6.6679663658, -1.9791734219, -5.5757327080, -1.7944118977,\n",
            "        -5.4632306099, -8.1355466843, -2.4060647488, -4.6691527367,\n",
            "        -2.5419847965, -4.5191979408, -4.8500237465, -3.4916701317,\n",
            "        -1.7643933296, -3.8124904633, -2.4733595848, -1.6227414608,\n",
            "        -1.7081476450, -4.9268894196, -6.1103572845, -5.4224524498])\n",
            "btensor.grad: tensor([-2.0184707642, -4.1996965408, -2.8239760399, -3.7638170719,\n",
            "        -4.0497708321, -2.5364668369, -3.2129988670, -3.7049579620,\n",
            "        -3.5019483566, -4.3427729607, -3.3821043968, -3.2947528362,\n",
            "        -3.9899137020, -3.5047254562, -4.7047042847, -3.6006686687,\n",
            "        -3.7963614464, -3.7931029797, -4.1519885063, -3.1993696690])\n",
            "ctensor.grad: tensor([ 27.1375846863,  20.5104007721, -15.4930086136,  16.9966907501,\n",
            "         -0.4526198506,  53.0616226196,  30.0745220184,  51.6490020752,\n",
            "        -25.4480056763,   0.2529927790, -62.6216812134, -27.1829929352,\n",
            "        -56.0890541077, -23.9297180176,   0.4950104654, -74.1774063110,\n",
            "        -37.0520439148, -78.1648941040])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(685.1510620117, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8525822163), tensor(1.5496635437), tensor(1.0868531466), tensor(1.1224629879), tensor(0.8200340271), tensor(0.8655993342), tensor(1.3917956352), tensor(1.0656011105), tensor(1.1016609669), tensor(0.9727788568), tensor(0.9936357141), tensor(0.8373870850), tensor(1.6013624668), tensor(1.1385735273), tensor(1.4736646414), tensor(1.5322703123), tensor(1.3820511103), tensor(1.1556977034), tensor(0.9517560005), tensor(1.2153890133)]\n",
            "b:  [tensor(1.3463782072), tensor(0.8485592604), tensor(1.3117218018), tensor(1.2737398148), tensor(1.0466799736), tensor(1.6970822811), tensor(1.2259495258), tensor(1.3929687738), tensor(1.1697927713), tensor(1.0140645504), tensor(1.2948946953), tensor(1.2244241238), tensor(0.8160683513), tensor(1.2350094318), tensor(1.2933377028), tensor(1.0094676018), tensor(0.9916101098), tensor(1.2615120411), tensor(1.4301340580), tensor(1.4032980204)]\n",
            "c:  [tensor(-0.3639803529), tensor(0.8697046041), tensor(0.4902625978), tensor(-0.8842769265), tensor(0.0574582927), tensor(0.2362049520), tensor(0.1871307343), tensor(-0.0515269004), tensor(1.6097179651), tensor(-0.0975080952), tensor(-0.2493805587), tensor(-0.4765796363), tensor(-0.3581401408), tensor(1.1322907209), tensor(-0.0771293044), tensor(-0.0348055325), tensor(-0.1171284467), tensor(-0.1569707394)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([7.7017726898, 3.5135726929, 6.0435614586, 4.5595240593, 8.2276754379,\n",
            "        7.7663254738, 3.5921406746, 5.1920900345, 5.4883971214, 6.9325284958,\n",
            "        6.0986881256, 6.1791925430, 3.3010883331, 5.3358998299, 4.0196547508,\n",
            "        3.3224358559, 4.0864686966, 5.7083740234, 6.4381422997, 4.9268350601])\n",
            "btensor.grad: tensor([4.9203367233, 4.1123332977, 5.2294154167, 4.8104386330, 4.0570964813,\n",
            "        5.0617289543, 4.3811626434, 4.7917242050, 5.1441044807, 5.2818160057,\n",
            "        5.7226061821, 4.5550494194, 4.6621189117, 4.6675896645, 5.7086281776,\n",
            "        3.7759494781, 5.0562748909, 5.6336956024, 4.9236183167, 4.8542938232])\n",
            "ctensor.grad: tensor([-33.9923439026, -32.0993041992,  25.6204414368, -13.0726156235,\n",
            "         -0.6645709872, -69.1733703613, -30.8078422546, -51.6531410217,\n",
            "         39.3280715942,   1.3653287888, 117.3736724854,  43.0974273682,\n",
            "         95.7353286743,  15.1861076355,   1.2979606390,  75.2257385254,\n",
            "         31.4949035645,  79.6539916992])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(685.9533081055, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.9084221125), tensor(1.5718926191), tensor(1.1299622059), tensor(1.1494809389), tensor(0.8787326217), tensor(0.9243034720), tensor(1.4128317833), tensor(1.1034469604), tensor(1.1359109879), tensor(1.0232572556), tensor(1.0370633602), tensor(0.8814481497), tensor(1.6223222017), tensor(1.1736041307), tensor(1.4990464449), tensor(1.5528798103), tensor(1.4057626724), tensor(1.1950687170), tensor(0.9961746931), tensor(1.2520550489)]\n",
            "b:  [tensor(1.3741647005), tensor(0.8775954247), tensor(1.3442754745), tensor(1.3052531481), tensor(1.0750708580), tensor(1.7271661758), tensor(1.2530678511), tensor(1.4256700277), tensor(1.2009015083), tensor(1.0483708382), tensor(1.3315750360), tensor(1.2529989481), tensor(0.8471423984), tensor(1.2659162283), tensor(1.3308696747), tensor(1.0346553326), tensor(1.0235463381), tensor(1.2968258858), tensor(1.4631490707), tensor(1.4350678921)]\n",
            "c:  [tensor(-0.4094812572), tensor(0.8218485713), tensor(0.5256370306), tensor(-0.9170286655), tensor(0.0577007458), tensor(0.1331763417), tensor(0.1367837638), tensor(-0.1380182803), tensor(1.6618100405), tensor(-0.0972917899), tensor(-0.1292511821), tensor(-0.4324610233), tensor(-0.2648261487), tensor(1.1696552038), tensor(-0.0773055702), tensor(0.0794157833), tensor(-0.0643683150), tensor(-0.0410722792)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-11.1679840088,  -4.4458098412,  -8.6218023300,  -5.4035902023,\n",
            "        -11.7397212982, -11.7408266068,  -4.2072343826,  -7.5691661835,\n",
            "         -6.8500099182, -10.0956773758,  -8.6855382919,  -8.8122072220,\n",
            "         -4.1919536591,  -7.0061302185,  -5.0763607025,  -4.1218953133,\n",
            "         -4.7423028946,  -7.8742094040,  -8.8837394714,  -7.3332147598])\n",
            "btensor.grad: tensor([-5.5572896004, -5.8072295189, -6.5107297897, -6.3026642799,\n",
            "        -5.6781702042, -6.0167880058, -5.4236741066, -6.5402455330,\n",
            "        -6.2217559814, -6.8612580299, -7.3360729218, -5.7149720192,\n",
            "        -6.2148060799, -6.1813483238, -7.5063929558, -5.0375490189,\n",
            "        -6.3872351646, -7.0627751350, -6.6030058861, -6.3539767265])\n",
            "ctensor.grad: tensor([  45.5009117126,   47.8560180664,  -35.3744049072,   32.7517662048,\n",
            "          -0.2424517423,  103.0286026001,   50.3469696045,   86.4913711548,\n",
            "         -52.0921134949,   -0.2163031697, -120.1293640137,  -44.1186218262,\n",
            "         -93.3139801025,  -37.3644943237,    0.1762633622, -114.2213058472,\n",
            "         -52.7601280212, -115.8984527588])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(700.7239379883, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8586388230), tensor(1.5490148067), tensor(1.0910640955), tensor(1.1220827103), tensor(0.8300130367), tensor(0.8721871972), tensor(1.3898568153), tensor(1.0683420897), tensor(1.1038316488), tensor(0.9801213145), tensor(0.9974314570), tensor(0.8445026875), tensor(1.6004008055), tensor(1.1396746635), tensor(1.4735743999), tensor(1.5316933393), tensor(1.3814363480), tensor(1.1581859589), tensor(0.9549403191), tensor(1.2158507109)]\n",
            "b:  [tensor(1.3434216976), tensor(0.8432776332), tensor(1.3101894855), tensor(1.2708817720), tensor(1.0426127911), tensor(1.6955527067), tensor(1.2214095592), tensor(1.3907552958), tensor(1.1652649641), tensor(1.0109494925), tensor(1.2922024727), tensor(1.2209208012), tensor(0.8107841015), tensor(1.2321046591), tensor(1.2897064686), tensor(1.0034586191), tensor(0.9873084426), tensor(1.2592711449), tensor(1.4280128479), tensor(1.4019298553)]\n",
            "c:  [tensor(-0.3528348804), tensor(0.8615969419), tensor(0.4779939651), tensor(-0.9081484675), tensor(0.0581648238), tensor(0.1855309308), tensor(0.1613953561), tensor(-0.0994510278), tensor(1.6153867245), tensor(-0.0987918228), tensor(-0.2684609294), tensor(-0.4847808480), tensor(-0.3801623583), tensor(1.1579426527), tensor(-0.0785118788), tensor(0.0153214410), tensor(-0.0931013376), tensor(-0.1168281212)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 9.9566564560,  4.5755720139,  7.7796144485,  5.4796400070,\n",
            "         9.7439193726, 10.4232540131,  4.5949873924,  7.0209665298,\n",
            "         6.4158577919,  8.6271915436,  7.9263768196,  7.3890962601,\n",
            "         4.3842692375,  6.7858929634,  5.0944113731,  4.2372856140,\n",
            "         4.8652596474,  7.3765568733,  8.2468776703,  7.2408709526])\n",
            "btensor.grad: tensor([6.1486034393, 6.8635601997, 6.8172087669, 6.8742713928, 6.4916172028,\n",
            "        6.3226914406, 6.3316669464, 6.9829430580, 7.1272997856, 7.4842615128,\n",
            "        7.8745050430, 6.4156217575, 7.2716588974, 6.7623066902, 8.2326383591,\n",
            "        6.2393541336, 7.2475800514, 7.5109572411, 7.0272464752, 6.6276030540])\n",
            "ctensor.grad: tensor([-56.6463737488, -39.7483940125,  47.6430473328,  -8.8801803589,\n",
            "         -0.4640780985, -52.3545799255, -24.6115951538, -38.5672492981,\n",
            "         46.4233055115,   1.5000303984, 139.2097473145,  52.3198356628,\n",
            "        115.3361892700,  11.7125930786,   1.2063094378,  64.0943374634,\n",
            "         28.7330207825,  75.7558364868])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(683.3768310547, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8720437884), tensor(1.5607577562), tensor(1.1028901339), tensor(1.1400109529), tensor(0.8553415537), tensor(0.8823432326), tensor(1.4005125761), tensor(1.0820455551), tensor(1.1267427206), tensor(1.0028336048), tensor(1.0142649412), tensor(0.8663793206), tensor(1.6130033731), tensor(1.1562104225), tensor(1.4887048006), tensor(1.5435601473), tensor(1.3982021809), tensor(1.1712880135), tensor(0.9636775851), tensor(1.2257466316)]\n",
            "b:  [tensor(1.3674829006), tensor(0.8588389158), tensor(1.3351503611), tensor(1.2903032303), tensor(1.0555326939), tensor(1.7187662125), tensor(1.2398476601), tensor(1.4127343893), tensor(1.1880413294), tensor(1.0314266682), tensor(1.3196811676), tensor(1.2392711639), tensor(0.8294790983), tensor(1.2501286268), tensor(1.3108367920), tensor(1.0169616938), tensor(1.0078613758), tensor(1.2838400602), tensor(1.4477183819), tensor(1.4247840643)]\n",
            "c:  [tensor(-0.3944808245), tensor(0.8559548259), tensor(0.5245441198), tensor(-0.9076464772), tensor(0.0585943051), tensor(0.2061605304), tensor(0.1701538414), tensor(-0.0837776363), tensor(1.6661953926), tensor(-0.0986315683), tensor(-0.1562205553), tensor(-0.4462436438), tensor(-0.2965547144), tensor(1.1589171886), tensor(-0.0793144181), tensor(-0.0038365964), tensor(-0.0996818691), tensor(-0.1278431863)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-2.6809887886, -2.3485829830, -2.3652081490, -3.5856466293,\n",
            "        -5.0657019615, -2.0312075615, -2.1311593056, -2.7407045364,\n",
            "        -4.5822176933, -4.5424613953, -3.3666934967, -4.3753290176,\n",
            "        -2.5205216408, -3.3071572781, -3.0260701180, -2.3733541965,\n",
            "        -3.3531780243, -2.6204018593, -1.7474582195, -1.9791959524])\n",
            "btensor.grad: tensor([-4.8122448921, -3.1122543812, -4.9921841621, -3.8842906952,\n",
            "        -2.5839848518, -4.6426982880, -3.6876111031, -4.3958115578,\n",
            "        -4.5552787781, -4.0954437256, -5.4957365990, -3.6700634956,\n",
            "        -3.7390029430, -3.6047947407, -4.2260622978, -2.7006053925,\n",
            "        -4.1105866432, -4.9137735367, -3.9411005974, -4.5708479881])\n",
            "ctensor.grad: tensor([  41.6459465027,    5.6421289444,  -46.5501441956,   -0.5020005107,\n",
            "          -0.4294805229,  -20.6296005249,   -8.7584867477,  -15.6733865738,\n",
            "         -50.8086357117,   -0.1602529436, -112.2403793335,  -38.5372009277,\n",
            "         -83.6076431274,   -0.9744771719,    0.8025381565,   19.1580371857,\n",
            "           6.5805320740,   11.0150709152])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(669.8415527344, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8595782518), tensor(1.5532968044), tensor(1.0933141708), tensor(1.1279041767), tensor(0.8354997635), tensor(0.8744287491), tensor(1.3946770430), tensor(1.0756812096), tensor(1.1121948957), tensor(0.9862368703), tensor(1.0039557219), tensor(0.8496870399), tensor(1.6064260006), tensor(1.1468839645), tensor(1.4803636074), tensor(1.5352768898), tensor(1.3873993158), tensor(1.1630736589), tensor(0.9550045729), tensor(1.2236953974)]\n",
            "b:  [tensor(1.3557363749), tensor(0.8590854406), tensor(1.3242552280), tensor(1.2852209806), tensor(1.0547341108), tensor(1.7068148851), tensor(1.2351832390), tensor(1.4070093632), tensor(1.1807463169), tensor(1.0261914730), tensor(1.3089796305), tensor(1.2334080935), tensor(0.8265415430), tensor(1.2442966700), tensor(1.3056021929), tensor(1.0164544582), tensor(1.0025429726), tensor(1.2739262581), tensor(1.4429737329), tensor(1.4169211388)]\n",
            "c:  [tensor(-0.3911389709), tensor(0.8723828793), tensor(0.5250749588), tensor(-0.9000046849), tensor(0.0592898056), tensor(0.2474928796), tensor(0.1850109845), tensor(-0.0568445586), tensor(1.6489913464), tensor(-0.0995417461), tensor(-0.2071976662), tensor(-0.4622203708), tensor(-0.3310833275), tensor(1.1519246101), tensor(-0.0804839134), tensor(-0.0404010490), tensor(-0.1111281216), tensor(-0.1569937170)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([2.4931075573, 1.4921818972, 1.9151962996, 2.4213528633, 3.9683558941,\n",
            "        1.5828981400, 1.1671147346, 1.2728644609, 2.9095637798, 3.3193471432,\n",
            "        2.0618467331, 3.3384540081, 1.3154721260, 1.8652868271, 1.6682406664,\n",
            "        1.6566464901, 2.1605846882, 1.6428731680, 1.7345983982, 0.4102529287])\n",
            "btensor.grad: tensor([ 2.3493075371, -0.0493103862,  2.1790328026,  1.0164449215,\n",
            "         0.1597171426,  2.3902540207,  0.9328877330,  1.1450064182,\n",
            "         1.4590014219,  1.0470390320,  2.1403076649,  1.1726140976,\n",
            "         0.5875096321,  1.1663978100,  1.0469080210,  0.1014444828,\n",
            "         1.0636737347,  1.9827699661,  0.9489286542,  1.5725877285])\n",
            "ctensor.grad: tensor([ -3.3418431282, -16.4280586243,  -0.5308302641,  -7.6418113708,\n",
            "         -0.6955014467, -41.3323478699, -14.8571414948, -26.9330768585,\n",
            "         17.2040290833,   0.9101799726,  50.9771003723,  15.9767198563,\n",
            "         34.5286140442,   6.9925508499,   1.1694953442,  36.5644493103,\n",
            "         11.4462528229,  29.1505260468])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(673.6340332031, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8972507119), tensor(1.5649884939), tensor(1.1241146326), tensor(1.1388638020), tensor(0.8674988747), tensor(0.9203454852), tensor(1.4074680805), tensor(1.1021463871), tensor(1.1269412041), tensor(1.0136203766), tensor(1.0308331251), tensor(0.8721358776), tensor(1.6167174578), tensor(1.1680328846), tensor(1.4942791462), tensor(1.5447849035), tensor(1.3973189592), tensor(1.1897879839), tensor(0.9883874059), tensor(1.2523360252)]\n",
            "b:  [tensor(1.3668067455), tensor(0.8802722692), tensor(1.3397341967), tensor(1.3044810295), tensor(1.0753068924), tensor(1.7210628986), tensor(1.2516436577), tensor(1.4267246723), tensor(1.1989580393), tensor(1.0486681461), tensor(1.3271399736), tensor(1.2505966425), tensor(0.8471618295), tensor(1.2627491951), tensor(1.3304344416), tensor(1.0344678164), tensor(1.0221992731), tensor(1.2947007418), tensor(1.4646637440), tensor(1.4343378544)]\n",
            "c:  [tensor(-0.4151776731), tensor(0.8450646996), tensor(0.5403626561), tensor(-0.9230661392), tensor(0.0597306266), tensor(0.1712247133), tensor(0.1445904076), tensor(-0.1265039146), tensor(1.6753792763), tensor(-0.0997982919), tensor(-0.1411046833), tensor(-0.4339978099), tensor(-0.2751180232), tensor(1.1792054176), tensor(-0.0809957981), tensor(0.0489793122), tensor(-0.0670355186), tensor(-0.0659892783)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-7.5344915390, -2.3383307457, -6.1600985527, -2.1919131279,\n",
            "        -6.3998184204, -9.1833448410, -2.5581972599, -5.2930412292,\n",
            "        -2.9492628574, -5.4767117500, -5.3754701614, -4.4897627831,\n",
            "        -2.0582845211, -4.2297811508, -2.7831149101, -1.9016134739,\n",
            "        -1.9839341640, -5.3428540230, -6.6765627861, -5.7281174660])\n",
            "btensor.grad: tensor([-2.2140717506, -4.2373671532, -3.0957920551, -3.8520042896,\n",
            "        -4.1145658493, -2.8496036530, -3.2920863628, -3.9430577755,\n",
            "        -3.6423449516, -4.4953441620, -3.6320793629, -3.4377050400,\n",
            "        -4.1240572929, -3.6905002594, -4.9664397240, -3.6026768684,\n",
            "        -3.9312496185, -4.1548953056, -4.3380045891, -3.4833486080])\n",
            "ctensor.grad: tensor([ 24.0386981964,  27.3181800842, -15.2876691818,  23.0614280701,\n",
            "         -0.4408206940,  76.2681732178,  40.4205703735,  69.6593551636,\n",
            "        -26.3879222870,   0.2565459013, -66.0929794312, -28.2225742340,\n",
            "        -55.9653015137, -27.2808456421,   0.5118880868, -89.3803558350,\n",
            "        -44.0926017761, -91.0044326782])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(690.3323364258, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8531641960), tensor(1.5445746183), tensor(1.0896128416), tensor(1.1136029959), tensor(0.8237460256), tensor(0.8749849796), tensor(1.3873646259), tensor(1.0716656446), tensor(1.0975601673), tensor(0.9746797681), tensor(0.9961107373), tensor(0.8383784890), tensor(1.5973515511), tensor(1.1380523443), tensor(1.4718798399), tensor(1.5258899927), tensor(1.3751506805), tensor(1.1573494673), tensor(0.9520272613), tensor(1.2221014500)]\n",
            "b:  [tensor(1.3397239447), tensor(0.8539121151), tensor(1.3101931810), tensor(1.2761361599), tensor(1.0494244099), tensor(1.6931343079), tensor(1.2258161306), tensor(1.3981423378), tensor(1.1694544554), tensor(1.0176932812), tensor(1.2938181162), tensor(1.2238022089), tensor(0.8181242943), tensor(1.2345979214), tensor(1.2958292961), tensor(1.0101863146), tensor(0.9921315908), tensor(1.2624152899), tensor(1.4356664419), tensor(1.4063900709)]\n",
            "c:  [tensor(-0.3719758391), tensor(0.8820797205), tensor(0.5056976676), tensor(-0.9105387330), tensor(0.0603368953), tensor(0.2399393320), tensor(0.1759445518), tensor(-0.0759927630), tensor(1.6332677603), tensor(-0.1011912003), tensor(-0.2654099762), tensor(-0.4796411395), tensor(-0.3762076199), tensor(1.1644370556), tensor(-0.0823295414), tensor(-0.0271788910), tensor(-0.0999838561), tensor(-0.1507600546)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([8.8173046112, 4.0827827454, 6.9003477097, 5.0521621704, 8.7505655289,\n",
            "        9.0721063614, 4.0206937790, 6.0961513519, 5.8761959076, 7.7881231308,\n",
            "        6.9444813728, 6.7514781952, 3.8731772900, 5.9961147308, 4.4798669815,\n",
            "        3.7789907455, 4.4336471558, 6.4877038002, 7.2720298767, 6.0469169617])\n",
            "btensor.grad: tensor([5.4165506363, 5.2720274925, 5.9081964493, 5.6689653397, 5.1765022278,\n",
            "        5.5857133865, 5.1655020714, 5.7164707184, 5.9007220268, 6.1949691772,\n",
            "        6.6643695831, 5.3588843346, 5.8075098991, 5.6302628517, 6.9210295677,\n",
            "        4.8562932014, 6.0135383606, 6.4570879936, 5.7994623184, 5.5895543098])\n",
            "ctensor.grad: tensor([-43.2018203735, -37.0150299072,  34.6649665833, -12.5274333954,\n",
            "         -0.6062683463, -68.7146148682, -31.3541450500, -50.5111503601,\n",
            "         42.1114730835,   1.3929055929, 124.3052902222,  45.6433143616,\n",
            "        101.0895843506,  14.7683897018,   1.3337403536,  76.1582031250,\n",
            "         32.9483337402,  84.7707748413])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(682.1859130859, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8932500482), tensor(1.5638630390), tensor(1.1213744879), tensor(1.1383351088), tensor(0.8686604500), tensor(0.9148945212), tensor(1.4046221972), tensor(1.1015748978), tensor(1.1281712055), tensor(1.0152394772), tensor(1.0305213928), tensor(0.8742990494), tensor(1.6162437201), tensor(1.1667089462), tensor(1.4936532974), tensor(1.5440429449), tensor(1.3966437578), tensor(1.1874319315), tensor(0.9824961424), tensor(1.2498601675)]\n",
            "b:  [tensor(1.3671007156), tensor(0.8789333105), tensor(1.3410193920), tensor(1.3038542271), tensor(1.0732381344), tensor(1.7211869955), tensor(1.2502843142), tensor(1.4276037216), tensor(1.1979070902), tensor(1.0475590229), tensor(1.3284252882), tensor(1.2495830059), tensor(0.8457899690), tensor(1.2618817091), tensor(1.3290642500), tensor(1.0319545269), tensor(1.0208553076), tensor(1.2945319414), tensor(1.4645593166), tensor(1.4357082844)]\n",
            "c:  [tensor(-0.4211358130), tensor(0.8476795554), tensor(0.5489921570), tensor(-0.9307677150), tensor(0.0606861226), tensor(0.1812932044), tensor(0.1463746130), tensor(-0.1233110428), tensor(1.6839052439), tensor(-0.1010001153), tensor(-0.1508530676), tensor(-0.4389866889), tensor(-0.2894079089), tensor(1.1887320280), tensor(-0.0827595666), tensor(0.0419427529), tensor(-0.0668561906), tensor(-0.0746416450)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-8.0171718597, -3.8576886654, -6.3523206711, -4.9464111328,\n",
            "        -8.9828910828, -7.9819045067, -3.4515132904, -5.9818582535,\n",
            "        -6.1222152710, -8.1119422913, -6.8821363449, -7.1841101646,\n",
            "        -3.7784323692, -5.7313175201, -4.3546843529, -3.6305882931,\n",
            "        -4.2986049652, -6.0164999962, -6.0937776566, -5.5517411232])\n",
            "btensor.grad: tensor([-5.4753484726, -5.0042352676, -6.1652307510, -5.5436077118,\n",
            "        -4.7627491951, -5.6105480194, -4.8936281204, -5.8922853470,\n",
            "        -5.6905288696, -5.9731388092, -6.9214386940, -5.1561503410,\n",
            "        -5.5331397057, -5.4567518234, -6.6469850540, -4.3536372185,\n",
            "        -5.7447462082, -6.4233403206, -5.7785844803, -5.8636374474])\n",
            "ctensor.grad: tensor([  49.1599617004,   34.4001388550,  -43.2944602966,   20.2289924622,\n",
            "          -0.3492266238,   58.6461296082,   29.5699443817,   47.3182754517,\n",
            "         -50.6374931335,   -0.1910880357, -114.5569000244,  -40.6544494629,\n",
            "         -86.7997207642,  -24.2949256897,    0.4300214648,  -69.1216430664,\n",
            "         -33.1276626587,  -76.1184082031])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(686.2276000977, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8521225452), tensor(1.5445710421), tensor(1.0895187855), tensor(1.1142711639), tensor(0.8286437392), tensor(0.8734924793), tensor(1.3865991831), tensor(1.0738159418), tensor(1.1009539366), tensor(0.9784875512), tensor(0.9984273911), tensor(0.8426250815), tensor(1.5980180502), tensor(1.1392976046), tensor(1.4733397961), tensor(1.5261597633), tensor(1.3760862350), tensor(1.1577150822), tensor(0.9493733644), tensor(1.2226437330)]\n",
            "b:  [tensor(1.3422390223), tensor(0.8563706875), tensor(1.3140115738), tensor(1.2789350748), tensor(1.0504324436), tensor(1.6958169937), tensor(1.2278981209), tensor(1.4025939703), tensor(1.1723611355), tensor(1.0207495689), tensor(1.2981877327), tensor(1.2257567644), tensor(0.8203882575), tensor(1.2363898754), tensor(1.2981888056), tensor(1.0108091831), tensor(0.9943593144), tensor(1.2657008171), tensor(1.4392780066), tensor(1.4108462334)]\n",
            "c:  [tensor(-0.3837615848), tensor(0.8852922916), tensor(0.5198396444), tensor(-0.9176938534), tensor(0.0613297746), tensor(0.2522756159), tensor(0.1785195172), tensor(-0.0709166005), tensor(1.6468346119), tensor(-0.1022784039), tensor(-0.2590880990), tensor(-0.4777604342), tensor(-0.3751549125), tensor(1.1736068726), tensor(-0.0841186345), tensor(-0.0355466753), tensor(-0.1000899673), tensor(-0.1594179869)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([8.2254991531, 3.8584086895, 6.3711371422, 4.8127832413, 8.0033369064,\n",
            "        8.2804059982, 3.6045937538, 5.5517845154, 5.4434623718, 7.3503904343,\n",
            "        6.4187946320, 6.3347883224, 3.6451241970, 5.4822597504, 4.0626916885,\n",
            "        3.5766384602, 4.1115045547, 5.9433770180, 6.6245522499, 5.4432806969])\n",
            "btensor.grad: tensor([4.9723391533, 4.5125308037, 5.4015593529, 4.9838242531, 4.5611338615,\n",
            "        5.0740122795, 4.4772315025, 5.0019464493, 5.1091814041, 5.3618884087,\n",
            "        6.0475049019, 4.7652420998, 5.0803403854, 5.0983605385, 6.1750826836,\n",
            "        4.2290663719, 5.2992024422, 5.7662286758, 5.0562710762, 4.9724149704])\n",
            "ctensor.grad: tensor([-37.3742103577, -37.6127357483,  29.1524906158, -13.0738754272,\n",
            "         -0.6436501741, -70.9824066162, -32.1449089050, -52.3944396973,\n",
            "         37.0706596375,   1.2782851458, 108.2350387573,  38.7737388611,\n",
            "         85.7470092773,  15.1251792908,   1.3590673208,  77.4894256592,\n",
            "         33.2337760925,  84.7763290405])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(681.4697875977, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8988936543), tensor(1.5642733574), tensor(1.1262181997), tensor(1.1384648085), tensor(0.8761013746), tensor(0.9232168198), tensor(1.4046674967), tensor(1.1067190170), tensor(1.1309968233), tensor(1.0210121870), tensor(1.0354936123), tensor(0.8797689080), tensor(1.6168549061), tensor(1.1697396040), tensor(1.4954830408), tensor(1.5442193747), tensor(1.3968628645), tensor(1.1912460327), tensor(0.9860141873), tensor(1.2545152903)]\n",
            "b:  [tensor(1.3674707413), tensor(0.8826395869), tensor(1.3435566425), tensor(1.3070712090), tensor(1.0755915642), tensor(1.7227547169), tensor(1.2523015738), tensor(1.4321399927), tensor(1.2003988028), tensor(1.0510386229), tensor(1.3317122459), tensor(1.2516850233), tensor(0.8487768769), tensor(1.2639508247), tensor(1.3324776888), tensor(1.0335687399), tensor(1.0234596729), tensor(1.2977839708), tensor(1.4687464237), tensor(1.4394630194)]\n",
            "c:  [tensor(-0.4281944633), tensor(0.8450625539), tensor(0.5561236739), tensor(-0.9443719983), tensor(0.0616493970), tensor(0.1686857045), tensor(0.1371574551), tensor(-0.1400515288), tensor(1.6939369440), tensor(-0.1021371037), tensor(-0.1511137486), tensor(-0.4384595454), tensor(-0.2921637595), tensor(1.2041548491), tensor(-0.0844736770), tensor(0.0579919741), tensor(-0.0561359935), tensor(-0.0612545460)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-9.3542251587, -3.9404544830, -7.3398718834, -4.8387317657,\n",
            "        -9.4915218353, -9.9448642731, -3.6136620045, -6.5806088448,\n",
            "        -6.0085844994, -8.5049257278, -7.4132423401, -7.4287610054,\n",
            "        -3.7673695087, -6.0884027481, -4.4286379814, -3.6119143963,\n",
            "        -4.1553158760, -6.7061848640, -7.3281688690, -6.3743047714])\n",
            "btensor.grad: tensor([-5.0463347435, -5.2537817955, -5.9090089798, -5.6272268295,\n",
            "        -5.0318193436, -5.3875427246, -4.8806920052, -5.9091939926,\n",
            "        -5.6075363159, -6.0578088760, -6.7048935890, -5.1856427193,\n",
            "        -5.6777291298, -5.5121860504, -6.8577861786, -4.5519180298,\n",
            "        -5.8200745583, -6.4166264534, -5.8936777115, -5.7233514786])\n",
            "ctensor.grad: tensor([  44.4328804016,   40.2297401428,  -36.2840499878,   26.6781291962,\n",
            "          -0.3196213841,   83.5899047852,   41.3620605469,   69.1349258423,\n",
            "         -47.1023635864,   -0.1412973106, -107.9743347168,  -39.3008842468,\n",
            "         -82.9911499023,  -30.5479831696,    0.3550454676,  -93.5386428833,\n",
            "         -43.9539718628,  -98.1634368896])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(692.8887329102, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8528905511), tensor(1.5425435305), tensor(1.0904942751), tensor(1.1122874022), tensor(0.8326619267), tensor(0.8759315610), tensor(1.3844101429), tensor(1.0747127533), tensor(1.1015889645), tensor(0.9804558158), tensor(0.9992864728), tensor(0.8451834321), tensor(1.5961196423), tensor(1.1391197443), tensor(1.4726891518), tensor(1.5241895914), tensor(1.3745236397), tensor(1.1578254700), tensor(0.9490075111), tensor(1.2221376896)]\n",
            "b:  [tensor(1.3398051262), tensor(0.8541864753), tensor(1.3129103184), tensor(1.2776445150), tensor(1.0474438667), tensor(1.6944128275), tensor(1.2256371975), tensor(1.4021865129), tensor(1.1704357862), tensor(1.0192706585), tensor(1.2966065407), tensor(1.2237071991), tensor(0.8176941276), tensor(1.2338871956), tensor(1.2959772348), tensor(1.0072453022), tensor(0.9921661019), tensor(1.2645988464), tensor(1.4387341738), tensor(1.4105298519)]\n",
            "c:  [tensor(-0.3806348443), tensor(0.8865541220), tensor(0.5174275041), tensor(-0.9330784678), tensor(0.0621997043), tensor(0.2332273424), tensor(0.1670275480), tensor(-0.0932074040), tensor(1.6536222696), tensor(-0.1034724861), tensor(-0.2688480616), tensor(-0.4810759425), tensor(-0.3859753311), tensor(1.1903591156), tensor(-0.0858087540), tensor(-0.0156733021), tensor(-0.0885770768), tensor(-0.1456951201)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([9.2006196976, 4.3459658623, 7.1447949409, 5.2354922295, 8.6878890991,\n",
            "        9.4570465088, 4.0514807701, 6.4012470245, 5.8815822601, 8.1112737656,\n",
            "        7.2414240837, 6.9170908928, 4.1470618248, 6.1239662170, 4.5587816238,\n",
            "        4.0059571266, 4.4678568840, 6.6841011047, 7.4013352394, 6.4755177498])\n",
            "btensor.grad: tensor([5.5331177711, 5.6906223297, 6.1292700768, 5.8853344917, 5.6295299530,\n",
            "        5.6683864594, 5.3328790665, 5.9907035828, 5.9926004410, 6.3535871506,\n",
            "        7.0211405754, 5.5955562592, 6.2165536880, 6.0127220154, 7.3000802994,\n",
            "        5.2646856308, 6.2587175369, 6.6370224953, 6.0024495125, 5.7866353989])\n",
            "ctensor.grad: tensor([-47.5596275330, -41.4915618896,  38.6961593628, -11.2935056686,\n",
            "         -0.5503085256, -64.5416259766, -29.8700885773, -46.8441238403,\n",
            "         40.3146972656,   1.3353801966, 117.7343139648,  42.6163825989,\n",
            "         93.8115615845,  13.7956762314,   1.3350752592,  73.6652755737,\n",
            "         32.4410820007,  84.4405670166])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(678.5508422852, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8791612983), tensor(1.5569233894), tensor(1.1113555431), tensor(1.1315958500), tensor(0.8637231588), tensor(0.9017047882), tensor(1.3975594044), tensor(1.0957130194), tensor(1.1256681681), tensor(1.0087815523), tensor(1.0234483480), tensor(0.8701394200), tensor(1.6107870340), tensor(1.1604189873), tensor(1.4897112846), tensor(1.5377968550), tensor(1.3916975260), tensor(1.1786714792), tensor(0.9682894349), tensor(1.2416452169)]\n",
            "b:  [tensor(1.3631762266), tensor(0.8747135997), tensor(1.3388204575), tensor(1.3002517223), tensor(1.0659446716), tensor(1.7179152966), tensor(1.2461501360), tensor(1.4268617630), tensor(1.1946270466), tensor(1.0432428122), tensor(1.3261326551), tensor(1.2450178862), tensor(0.8407868147), tensor(1.2556993961), tensor(1.3231613636), tensor(1.0252002478), tensor(1.0163514614), tensor(1.2916644812), tensor(1.4620863199), tensor(1.4347972870)]\n",
            "c:  [tensor(-0.4258642495), tensor(0.8673030734), tensor(0.5604462028), tensor(-0.9417400360), tensor(0.0626403838), tensor(0.2171232998), tensor(0.1574415267), tensor(-0.1066860706), tensor(1.7000859976), tensor(-0.1033524945), tensor(-0.1646670401), tensor(-0.4443193674), tensor(-0.3070892692), tensor(1.2028527260), tensor(-0.0864768922), tensor(0.0105831269), tensor(-0.0744043961), tensor(-0.1092502326)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-5.2541551590, -2.8759787083, -4.1722621918, -3.8616943359,\n",
            "        -6.2122440338, -5.1546397209, -2.6298422813, -4.2000536919,\n",
            "        -4.8158421516, -5.6651492119, -4.8323769569, -4.9911952019,\n",
            "        -2.9334888458, -4.2598595619, -3.4044303894, -2.7214548588,\n",
            "        -3.4347832203, -4.1691975594, -3.8563809395, -3.9015030861])\n",
            "btensor.grad: tensor([-4.6742162704, -4.1054277420, -5.1820249557, -4.5214514732,\n",
            "        -3.7001686096, -4.7005038261, -4.1025896072, -4.9350504875,\n",
            "        -4.8382587433, -4.7944250107, -5.9052248001, -4.2621297836,\n",
            "        -4.6185340881, -4.3624439240, -5.4368314743, -3.5909857750,\n",
            "        -4.8370623589, -5.4131278992, -4.6704258919, -4.8534784317])\n",
            "ctensor.grad: tensor([  45.2294158936,   19.2510280609,  -43.0186920166,    8.6615486145,\n",
            "          -0.4406825900,   16.1040401459,    9.5860137939,   13.4786691666,\n",
            "         -46.4636840820,   -0.1199937463, -104.1810150146,  -36.7565650940,\n",
            "         -78.8860397339,  -12.4936494827,    0.6681418419,  -26.2564277649,\n",
            "         -14.1726818085,  -36.4448852539])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "probability after training of team 2 landing 5 goals against 3: tensor(0.0185559411)\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "*************************************************\n",
            "\n",
            " Validation:\n",
            "\n",
            "test unseen validation set using only earlier traning\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(10.0121421814, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8791612983), tensor(1.5569233894), tensor(1.1113555431), tensor(1.1315958500), tensor(0.8637231588), tensor(0.9017047882), tensor(1.3975594044), tensor(1.0957130194), tensor(1.1256681681), tensor(1.0087815523), tensor(1.0234483480), tensor(0.8701394200), tensor(1.6107870340), tensor(1.1604189873), tensor(1.4897112846), tensor(1.5377968550), tensor(1.3916975260), tensor(1.1786714792), tensor(0.9682894349), tensor(1.2416452169)]\n",
            "b:  [tensor(1.3631762266), tensor(0.8747135997), tensor(1.3388204575), tensor(1.3002517223), tensor(1.0659446716), tensor(1.7179152966), tensor(1.2461501360), tensor(1.4268617630), tensor(1.1946270466), tensor(1.0432428122), tensor(1.3261326551), tensor(1.2450178862), tensor(0.8407868147), tensor(1.2556993961), tensor(1.3231613636), tensor(1.0252002478), tensor(1.0163514614), tensor(1.2916644812), tensor(1.4620863199), tensor(1.4347972870)]\n",
            "c:  [tensor(-0.4258642495), tensor(0.8673030734), tensor(0.5604462028), tensor(-0.9417400360), tensor(0.0626403838), tensor(0.2171232998), tensor(0.1574415267), tensor(-0.1066860706), tensor(1.7000859976), tensor(-0.1033524945), tensor(-0.1646670401), tensor(-0.4443193674), tensor(-0.3070892692), tensor(1.2028527260), tensor(-0.0864768922), tensor(0.0105831269), tensor(-0.0744043961), tensor(-0.1092502326)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.2450178862,  1.4620863199, -1.1347991228,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000, -0.4510509968,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6548663974,  0.0000000000,  1.1759940386,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -0.2789373100,  1.2631853819,  0.8887639046,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  1.7481921911,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -2.5952205658,  0.0000000000,  0.3763084412,  0.0000000000])\n",
            "ctensor.grad: tensor([-1.2532918453, -0.1352090240,  0.3345161676, -0.1723933220,\n",
            "         0.0000000000, -0.8791330457, -0.4692613184, -1.8496425152,\n",
            "         1.4358645678,  0.0000000000,  3.6292548180,  1.1877791882,\n",
            "         2.9181907177,  0.0044743791,  0.0000000000,  0.2380073667,\n",
            "         0.2113931477,  1.2395199537])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(10.0121421814, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8791612983), tensor(1.5569233894), tensor(1.1113555431), tensor(1.1315958500), tensor(0.8624781370), tensor(0.9002426863), tensor(1.3986941576), tensor(1.0957130194), tensor(1.1256681681), tensor(1.0087815523), tensor(1.0234483480), tensor(0.8705904484), tensor(1.6107870340), tensor(1.1604189873), tensor(1.4897112846), tensor(1.5377968550), tensor(1.3910427094), tensor(1.1786714792), tensor(0.9671134353), tensor(1.2416452169)]\n",
            "b:  [tensor(1.3631762266), tensor(0.8747135997), tensor(1.3388204575), tensor(1.3002517223), tensor(1.0662236214), tensor(1.7166521549), tensor(1.2452614307), tensor(1.4268617630), tensor(1.1946270466), tensor(1.0432428122), tensor(1.3261326551), tensor(1.2432696819), tensor(0.8407868147), tensor(1.2556993961), tensor(1.3231613636), tensor(1.0252002478), tensor(1.0189466476), tensor(1.2916644812), tensor(1.4617099762), tensor(1.4347972870)]\n",
            "c:  [tensor(-0.4258642495), tensor(0.8673030734), tensor(0.5604462028), tensor(-0.9417400360), tensor(0.0626403838), tensor(0.2171232998), tensor(0.1574415267), tensor(-0.1066860706), tensor(1.7000859976), tensor(-0.1033524945), tensor(-0.1646670401), tensor(-0.4443193674), tensor(-0.3070892692), tensor(1.2028527260), tensor(-0.0864768922), tensor(0.0105831269), tensor(-0.0744043961), tensor(-0.1092502326)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.2450178862,  1.4620863199, -1.1347991228,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000, -0.4510509968,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6548663974,  0.0000000000,  1.1759940386,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -0.2789373100,  1.2631853819,  0.8887639046,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  1.7481921911,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -2.5952205658,  0.0000000000,  0.3763084412,  0.0000000000])\n",
            "ctensor.grad: tensor([-1.2532918453, -0.1352090240,  0.3345161676, -0.1723933220,\n",
            "         0.0000000000, -0.8791330457, -0.4692613184, -1.8496425152,\n",
            "         1.4358645678,  0.0000000000,  3.6292548180,  1.1877791882,\n",
            "         2.9181907177,  0.0044743791,  0.0000000000,  0.2380073667,\n",
            "         0.2113931477,  1.2395199537])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.9927816391, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8791612983), tensor(1.5569233894), tensor(1.1113555431), tensor(1.1315958500), tensor(0.8612348437), tensor(0.8987810016), tensor(1.3998253345), tensor(1.0957130194), tensor(1.1256681681), tensor(1.0087815523), tensor(1.0234483480), tensor(0.8710401654), tensor(1.6107870340), tensor(1.1604189873), tensor(1.4897112846), tensor(1.5377968550), tensor(1.3903889656), tensor(1.1786714792), tensor(0.9659390450), tensor(1.2416452169)]\n",
            "b:  [tensor(1.3631762266), tensor(0.8747135997), tensor(1.3388204575), tensor(1.3002517223), tensor(1.0665018559), tensor(1.7153905630), tensor(1.2443739176), tensor(1.4268617630), tensor(1.1946270466), tensor(1.0432428122), tensor(1.3261326551), tensor(1.2415227890), tensor(0.8407868147), tensor(1.2556993961), tensor(1.3231613636), tensor(1.0252002478), tensor(1.0215282440), tensor(1.2916644812), tensor(1.4613351822), tensor(1.4347972870)]\n",
            "c:  [tensor(-0.4258642495), tensor(0.8673030734), tensor(0.5604462028), tensor(-0.9417400360), tensor(0.0626403838), tensor(0.2171232998), tensor(0.1574415267), tensor(-0.1066860706), tensor(1.7000859976), tensor(-0.1033524945), tensor(-0.1646670401), tensor(-0.4443193674), tensor(-0.3070892692), tensor(1.2028527260), tensor(-0.0864768922), tensor(0.0105831269), tensor(-0.0744043961), tensor(-0.1092502326)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.2432696819,  1.4617099762, -1.1311539412,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000, -0.4497348070,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6537486911,  0.0000000000,  1.1743850708,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -0.2782408297,  1.2615808249,  0.8875364661,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  1.7469471693,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -2.5815556049,  0.0000000000,  0.3748463392,  0.0000000000])\n",
            "ctensor.grad: tensor([-1.2531211376, -0.1350696683,  0.3344414234, -0.1723829210,\n",
            "         0.0000000000, -0.8793591261, -0.4694215655, -1.8494983912,\n",
            "         1.4337151051,  0.0000000000,  3.6239371300,  1.1860804558,\n",
            "         2.9137165546,  0.0047310814,  0.0000000000,  0.2392061353,\n",
            "         0.2119181454,  1.2399923801])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.9735231400, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8791612983), tensor(1.5569233894), tensor(1.1113555431), tensor(1.1315958500), tensor(0.8599933386), tensor(0.8973196745), tensor(1.4009528160), tensor(1.0957130194), tensor(1.1256681681), tensor(1.0087815523), tensor(1.0234483480), tensor(0.8714885712), tensor(1.6107870340), tensor(1.1604189873), tensor(1.4897112846), tensor(1.5377968550), tensor(1.3897362947), tensor(1.1786714792), tensor(0.9647662640), tensor(1.2416452169)]\n",
            "b:  [tensor(1.3631762266), tensor(0.8747135997), tensor(1.3388204575), tensor(1.3002517223), tensor(1.0667793751), tensor(1.7141306400), tensor(1.2434875965), tensor(1.4268617630), tensor(1.1946270466), tensor(1.0432428122), tensor(1.3261326551), tensor(1.2397770882), tensor(0.8407868147), tensor(1.2556993961), tensor(1.3231613636), tensor(1.0252002478), tensor(1.0240962505), tensor(1.2916644812), tensor(1.4609618187), tensor(1.4347972870)]\n",
            "c:  [tensor(-0.4258642495), tensor(0.8673030734), tensor(0.5604462028), tensor(-0.9417400360), tensor(0.0626403838), tensor(0.2171232998), tensor(0.1574415267), tensor(-0.1066860706), tensor(1.7000859976), tensor(-0.1033524945), tensor(-0.1646670401), tensor(-0.4443193674), tensor(-0.3070892692), tensor(1.2028527260), tensor(-0.0864768922), tensor(0.0105831269), tensor(-0.0744043961), tensor(-0.1092502326)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.2415227890,  1.4613351822, -1.1275271177,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000, -0.4484238923,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6526324749,  0.0000000000,  1.1727780104,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -0.2775465250,  1.2599780560,  0.8863101006,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  1.7457039356,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -2.5680236816,  0.0000000000,  0.3733846545,  0.0000000000])\n",
            "ctensor.grad: tensor([-1.2529430389, -0.1349367499,  0.3343584538, -0.1723719388,\n",
            "         0.0000000000, -0.8795826435, -0.4695805311, -1.8493539095,\n",
            "         1.4315705299,  0.0000000000,  3.6186323166,  1.1843849421,\n",
            "         2.9092509747,  0.0049845800,  0.0000000000,  0.2403966784,\n",
            "         0.2124396861,  1.2404605150])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.9543657303, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8791612983), tensor(1.5569233894), tensor(1.1113555431), tensor(1.1315958500), tensor(0.8587535620), tensor(0.8958587050), tensor(1.4020767212), tensor(1.0957130194), tensor(1.1256681681), tensor(1.0087815523), tensor(1.0234483480), tensor(0.8719356656), tensor(1.6107870340), tensor(1.1604189873), tensor(1.4897112846), tensor(1.5377968550), tensor(1.3890848160), tensor(1.1786714792), tensor(0.9635950923), tensor(1.2416452169)]\n",
            "b:  [tensor(1.3631762266), tensor(0.8747135997), tensor(1.3388204575), tensor(1.3002517223), tensor(1.0670561790), tensor(1.7128722668), tensor(1.2426024675), tensor(1.4268617630), tensor(1.1946270466), tensor(1.0432428122), tensor(1.3261326551), tensor(1.2380325794), tensor(0.8407868147), tensor(1.2556993961), tensor(1.3231613636), tensor(1.0252002478), tensor(1.0266509056), tensor(1.2916644812), tensor(1.4605898857), tensor(1.4347972870)]\n",
            "c:  [tensor(-0.4258642495), tensor(0.8673030734), tensor(0.5604462028), tensor(-0.9417400360), tensor(0.0626403838), tensor(0.2171232998), tensor(0.1574415267), tensor(-0.1066860706), tensor(1.7000859976), tensor(-0.1033524945), tensor(-0.1646670401), tensor(-0.4443193674), tensor(-0.3070892692), tensor(1.2028527260), tensor(-0.0864768922), tensor(0.0105831269), tensor(-0.0744043961), tensor(-0.1092502326)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.2397770882,  1.4609618187, -1.1239181757,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000, -0.4471179247,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6515174508,  0.0000000000,  1.1711724997,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -0.2768541574,  1.2583765984,  0.8850845098,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  1.7444623709,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -2.5546224117,  0.0000000000,  0.3719233274,  0.0000000000])\n",
            "ctensor.grad: tensor([-1.2527569532, -0.1348104477,  0.3342673182, -0.1723604053,\n",
            "         0.0000000000, -0.8798035979, -0.4697385430, -1.8492090702,\n",
            "         1.4294282198,  0.0000000000,  3.6133308411,  1.1826907396,\n",
            "         2.9047889709,  0.0052406490,  0.0000000000,  0.2415875196,\n",
            "         0.2129611075,  1.2409301996])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.9353094101, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8791612983), tensor(1.5569233894), tensor(1.1113555431), tensor(1.1315958500), tensor(0.8575155139), tensor(0.8943980932), tensor(1.4031970501), tensor(1.0957130194), tensor(1.1256681681), tensor(1.0087815523), tensor(1.0234483480), tensor(0.8723815084), tensor(1.6107870340), tensor(1.1604189873), tensor(1.4897112846), tensor(1.5377968550), tensor(1.3884344101), tensor(1.1786714792), tensor(0.9624255300), tensor(1.2416452169)]\n",
            "b:  [tensor(1.3631762266), tensor(0.8747135997), tensor(1.3388204575), tensor(1.3002517223), tensor(1.0673323870), tensor(1.7116154432), tensor(1.2417186499), tensor(1.4268617630), tensor(1.1946270466), tensor(1.0432428122), tensor(1.3261326551), tensor(1.2362893820), tensor(0.8407868147), tensor(1.2556993961), tensor(1.3231613636), tensor(1.0252002478), tensor(1.0291922092), tensor(1.2916644812), tensor(1.4602193832), tensor(1.4347972870)]\n",
            "c:  [tensor(-0.4258642495), tensor(0.8673030734), tensor(0.5604462028), tensor(-0.9417400360), tensor(0.0626403838), tensor(0.2171232998), tensor(0.1574415267), tensor(-0.1066860706), tensor(1.7000859976), tensor(-0.1033524945), tensor(-0.1646670401), tensor(-0.4443193674), tensor(-0.3070892692), tensor(1.2028527260), tensor(-0.0864768922), tensor(0.0105831269), tensor(-0.0744043961), tensor(-0.1092502326)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.2380325794,  1.4605898857, -1.1203271151,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000, -0.4458171725,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6504038572,  0.0000000000,  1.1695686579,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -0.2761639059,  1.2567769289,  0.8838601112,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  1.7432225943,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -2.5413501263,  0.0000000000,  0.3704623580,  0.0000000000])\n",
            "ctensor.grad: tensor([-1.2525633574, -0.1346904039,  0.3341681063, -0.1723482758,\n",
            "         0.0000000000, -0.8800220490, -0.4698954225, -1.8490637541,\n",
            "         1.4272880554,  0.0000000000,  3.6080334187,  1.1809980869,\n",
            "         2.9003312588,  0.0054942966,  0.0000000000,  0.2427724004,\n",
            "         0.2134799063,  1.2413964272])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.9163513184, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8791612983), tensor(1.5569233894), tensor(1.1113555431), tensor(1.1315958500), tensor(0.8562792540), tensor(0.8929378986), tensor(1.4043138027), tensor(1.0957130194), tensor(1.1256681681), tensor(1.0087815523), tensor(1.0234483480), tensor(0.8728260398), tensor(1.6107870340), tensor(1.1604189873), tensor(1.4897112846), tensor(1.5377968550), tensor(1.3877850771), tensor(1.1786714792), tensor(0.9612575769), tensor(1.2416452169)]\n",
            "b:  [tensor(1.3631762266), tensor(0.8747135997), tensor(1.3388204575), tensor(1.3002517223), tensor(1.0676078796), tensor(1.7103602886), tensor(1.2408360243), tensor(1.4268617630), tensor(1.1946270466), tensor(1.0432428122), tensor(1.3261326551), tensor(1.2345473766), tensor(0.8407868147), tensor(1.2556993961), tensor(1.3231613636), tensor(1.0252002478), tensor(1.0317203999), tensor(1.2916644812), tensor(1.4598504305), tensor(1.4347972870)]\n",
            "c:  [tensor(-0.4258642495), tensor(0.8673030734), tensor(0.5604462028), tensor(-0.9417400360), tensor(0.0626403838), tensor(0.2171232998), tensor(0.1574415267), tensor(-0.1066860706), tensor(1.7000859976), tensor(-0.1033524945), tensor(-0.1646670401), tensor(-0.4443193674), tensor(-0.3070892692), tensor(1.2028527260), tensor(-0.0864768922), tensor(0.0105831269), tensor(-0.0744043961), tensor(-0.1092502326)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.2362893820,  1.4602193832, -1.1167531013,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000, -0.4445211291,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6492918730,  0.0000000000,  1.1679666042,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -0.2754755020,  1.2551789284,  0.8826369047,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  1.7419846058,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -2.5282034874,  0.0000000000,  0.3690017462,  0.0000000000])\n",
            "ctensor.grad: tensor([-1.2523629665, -0.1345764995,  0.3340614736, -0.1723356545,\n",
            "         0.0000000000, -0.8802382350, -0.4700513184, -1.8489177227,\n",
            "         1.4251468182,  0.0000000000,  3.6027348042,  1.1793045998,\n",
            "         2.8958747387,  0.0057446659,  0.0000000000,  0.2439467907,\n",
            "         0.2139946222,  1.2418572903])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.8974924088, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8791612983), tensor(1.5569233894), tensor(1.1113555431), tensor(1.1315958500), tensor(0.8550447226), tensor(0.8914780617), tensor(1.4054269791), tensor(1.0957130194), tensor(1.1256681681), tensor(1.0087815523), tensor(1.0234483480), tensor(0.8732692599), tensor(1.6107870340), tensor(1.1604189873), tensor(1.4897112846), tensor(1.5377968550), tensor(1.3871369362), tensor(1.1786714792), tensor(0.9600912333), tensor(1.2416452169)]\n",
            "b:  [tensor(1.3631762266), tensor(0.8747135997), tensor(1.3388204575), tensor(1.3002517223), tensor(1.0678826571), tensor(1.7091066837), tensor(1.2399545908), tensor(1.4268617630), tensor(1.1946270466), tensor(1.0432428122), tensor(1.3261326551), tensor(1.2328066826), tensor(0.8407868147), tensor(1.2556993961), tensor(1.3231613636), tensor(1.0252002478), tensor(1.0342355967), tensor(1.2916644812), tensor(1.4594829082), tensor(1.4347972870)]\n",
            "c:  [tensor(-0.4258642495), tensor(0.8673030734), tensor(0.5604462028), tensor(-0.9417400360), tensor(0.0626403838), tensor(0.2171232998), tensor(0.1574415267), tensor(-0.1066860706), tensor(1.7000859976), tensor(-0.1033524945), tensor(-0.1646670401), tensor(-0.4443193674), tensor(-0.3070892692), tensor(1.2028527260), tensor(-0.0864768922), tensor(0.0105831269), tensor(-0.0744043961), tensor(-0.1092502326)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.2345473766,  1.4598504305, -1.1131967306,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000, -0.4432303011,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6481811404,  0.0000000000,  1.1663657427,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -0.2747892737,  1.2535820007,  0.8814145923,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  1.7407482862,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -2.5151817799,  0.0000000000,  0.3675415516,  0.0000000000])\n",
            "ctensor.grad: tensor([-1.2521548271, -0.1344690323,  0.3339466155, -0.1723223925,\n",
            "         0.0000000000, -0.8804517388, -0.4702060223, -1.8487714529,\n",
            "         1.4230086803,  0.0000000000,  3.5974433422,  1.1776119471,\n",
            "         2.8914229870,  0.0059945509,  0.0000000000,  0.2451176643,\n",
            "         0.2145079374,  1.2423170805])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.8787288666, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8791612983), tensor(1.5569233894), tensor(1.1113555431), tensor(1.1315958500), tensor(0.8538119197), tensor(0.8900185823), tensor(1.4065365791), tensor(1.0957130194), tensor(1.1256681681), tensor(1.0087815523), tensor(1.0234483480), tensor(0.8737112284), tensor(1.6107870340), tensor(1.1604189873), tensor(1.4897112846), tensor(1.5377968550), tensor(1.3864898682), tensor(1.1786714792), tensor(0.9589264393), tensor(1.2416452169)]\n",
            "b:  [tensor(1.3631762266), tensor(0.8747135997), tensor(1.3388204575), tensor(1.3002517223), tensor(1.0681567192), tensor(1.7078547478), tensor(1.2390743494), tensor(1.4268617630), tensor(1.1946270466), tensor(1.0432428122), tensor(1.3261326551), tensor(1.2310671806), tensor(0.8407868147), tensor(1.2556993961), tensor(1.3231613636), tensor(1.0252002478), tensor(1.0367379189), tensor(1.2916644812), tensor(1.4591168165), tensor(1.4347972870)]\n",
            "c:  [tensor(-0.4258642495), tensor(0.8673030734), tensor(0.5604462028), tensor(-0.9417400360), tensor(0.0626403838), tensor(0.2171232998), tensor(0.1574415267), tensor(-0.1066860706), tensor(1.7000859976), tensor(-0.1033524945), tensor(-0.1646670401), tensor(-0.4443193674), tensor(-0.3070892692), tensor(1.2028527260), tensor(-0.0864768922), tensor(0.0105831269), tensor(-0.0744043961), tensor(-0.1092502326)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.2328066826,  1.4594829082, -1.1096578836,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000, -0.4419445097,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6470721960,  0.0000000000,  1.1647669077,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -0.2741050124,  1.2519868612,  0.8801938295,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  1.7395137548,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -2.5022830963,  0.0000000000,  0.3660817146,  0.0000000000])\n",
            "ctensor.grad: tensor([-1.2519396544, -0.1343677640,  0.3338243067, -0.1723086834,\n",
            "         0.0000000000, -0.8806627989, -0.4703598619, -1.8486251831,\n",
            "         1.4208741188,  0.0000000000,  3.5921576023,  1.1759216785,\n",
            "         2.8869779110,  0.0062453300,  0.0000000000,  0.2462885380,\n",
            "         0.2150208652,  1.2427774668])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.8600635529, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8791612983), tensor(1.5569233894), tensor(1.1113555431), tensor(1.1315958500), tensor(0.8525808454), tensor(0.8885594606), tensor(1.4076427221), tensor(1.0957130194), tensor(1.1256681681), tensor(1.0087815523), tensor(1.0234483480), tensor(0.8741518855), tensor(1.6107870340), tensor(1.1604189873), tensor(1.4897112846), tensor(1.5377968550), tensor(1.3858438730), tensor(1.1786714792), tensor(0.9577632546), tensor(1.2416452169)]\n",
            "b:  [tensor(1.3631762266), tensor(0.8747135997), tensor(1.3388204575), tensor(1.3002517223), tensor(1.0684301853), tensor(1.7066043615), tensor(1.2381954193), tensor(1.4268617630), tensor(1.1946270466), tensor(1.0432428122), tensor(1.3261326551), tensor(1.2293288708), tensor(0.8407868147), tensor(1.2556993961), tensor(1.3231613636), tensor(1.0252002478), tensor(1.0392273664), tensor(1.2916644812), tensor(1.4587521553), tensor(1.4347972870)]\n",
            "c:  [tensor(-0.4258642495), tensor(0.8673030734), tensor(0.5604462028), tensor(-0.9417400360), tensor(0.0626403838), tensor(0.2171232998), tensor(0.1574415267), tensor(-0.1066860706), tensor(1.7000859976), tensor(-0.1033524945), tensor(-0.1646670401), tensor(-0.4443193674), tensor(-0.3070892692), tensor(1.2028527260), tensor(-0.0864768922), tensor(0.0105831269), tensor(-0.0744043961), tensor(-0.1092502326)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.2310670614,  1.4591166973, -1.1061360836,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000, -0.4406636953,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6459643245,  0.0000000000,  1.1631696224,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -0.2734228373,  1.2503931522,  0.8789737821,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  1.7382807732,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -2.4895045757,  0.0000000000,  0.3646222353,  0.0000000000])\n",
            "ctensor.grad: tensor([-1.2517170906, -0.1342726350,  0.3336941004, -0.1722943485,\n",
            "         0.0000000000, -0.8808712959, -0.4705124497, -1.8484779596,\n",
            "         1.4187374115,  0.0000000000,  3.5868699551,  1.1742300987,\n",
            "         2.8825318813,  0.0064932704,  0.0000000000,  0.2474505305,\n",
            "         0.2155301273,  1.2432329655])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(9.8414907455, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(0.8791612983), tensor(1.5569233894), tensor(1.1113555431), tensor(1.1315958500), tensor(0.8513514996), tensor(0.8871006966), tensor(1.4087454081), tensor(1.0957130194), tensor(1.1256681681), tensor(1.0087815523), tensor(1.0234483480), tensor(0.8745912910), tensor(1.6107870340), tensor(1.1604189873), tensor(1.4897112846), tensor(1.5377968550), tensor(1.3851990700), tensor(1.1786714792), tensor(0.9566016793), tensor(1.2416452169)]\n",
            "b:  [tensor(1.3631762266), tensor(0.8747135997), tensor(1.3388204575), tensor(1.3002517223), tensor(1.0687029362), tensor(1.7053555250), tensor(1.2373176813), tensor(1.4268617630), tensor(1.1946270466), tensor(1.0432428122), tensor(1.3261326551), tensor(1.2275918722), tensor(0.8407868147), tensor(1.2556993961), tensor(1.3231613636), tensor(1.0252002478), tensor(1.0417041779), tensor(1.2916644812), tensor(1.4583890438), tensor(1.4347972870)]\n",
            "c:  [tensor(-0.4258642495), tensor(0.8673030734), tensor(0.5604462028), tensor(-0.9417400360), tensor(0.0626403838), tensor(0.2171232998), tensor(0.1574415267), tensor(-0.1066860706), tensor(1.7000859976), tensor(-0.1033524945), tensor(-0.1646670401), tensor(-0.4443193674), tensor(-0.3070892692), tensor(1.2028527260), tensor(-0.0864768922), tensor(0.0105831269), tensor(-0.0744043961), tensor(-0.1092502326)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         1.2293288708,  1.4587521553, -1.1026312113,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000, -0.4393874407,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "         0.6448580027,  0.0000000000,  1.1615740061,  0.0000000000])\n",
            "btensor.grad: tensor([ 0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -0.2727423906,  1.2488009930,  0.8777548075,  0.0000000000,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  1.7370498180,\n",
            "         0.0000000000,  0.0000000000,  0.0000000000,  0.0000000000,\n",
            "        -2.4768455029,  0.0000000000,  0.3631631136,  0.0000000000])\n",
            "ctensor.grad: tensor([-1.2514877319, -0.1341834664,  0.3335565329, -0.1722795665,\n",
            "         0.0000000000, -0.8810777068, -0.4706642032, -1.8483308554,\n",
            "         1.4166101217,  0.0000000000,  3.5815992355,  1.1725445986,\n",
            "         2.8780980110,  0.0067402869,  0.0000000000,  0.2486077547,\n",
            "         0.2160377800,  1.2436870337])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "=============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "Historic Bookies Estimate:\n",
        "==========================\n",
        "\n",
        "The historic bookies estimate for goals landed by team i against team j is\n",
        "\n",
        "a_i b_j\n",
        "\n",
        "where\n",
        "\n",
        "a_i = A_i C^{-1/2}\n",
        "b_j = B_j C^{-1/2}\n",
        "\n",
        "A_i = goals landed per game by team i\n",
        "B_j = goals conceded per game by team j\n",
        "C   = average goals per game of all teams\n",
        "\n",
        "\n",
        "The historic 1980's max likelihood models\n",
        "=========================================\n",
        "\n",
        "Starting with Maher, the 1980's max likelihood model starts with this guess and\n",
        "perfects it by max likelihood, when team i lands k goals agaist team j\n",
        "loss was minus the log of the predicted probability by Poisson\n",
        "\n",
        "- log ( e^{-a_ib_j}(a_ib_j)^k /k!)\n",
        "\n",
        "\n",
        "A gitgub user said chi squared shows HST,AST,HR,AR have a significant effect\n",
        "\n",
        "HST = home shots on target\n",
        "AST = away shots on target\n",
        "HR  = home red cards\n",
        "AR  = away red cards\n",
        "HS  = home shots\n",
        "AS  = away shots\n",
        "HC  = home quarter kicks\n",
        "AC  = away corner kicks\n",
        "HF  = home fouls\n",
        "AF  = away fouls\n",
        "\n",
        "\n",
        "New Cross-entropy AI model with a neural layer\n",
        "==========================================\n",
        "\n",
        "Since gradient descent generalizes max likelihood we can replace a_ib_j by\n",
        "\n",
        "a_i b_j  +  (c_0 sigma ( c_3 HST + c_4 HR +c_5 HS + c_6 HC _c_7 HF)\n",
        "             + ...\n",
        "             +c_2 sigma(c_13 HST + c_14 HR + c_15 HS + c_16 HCC + c_17 HF) )b_j\n",
        "\n",
        "when i is the home team and\n",
        "\n",
        "a_i b_j  +  c_0 sigma ( c_1 AST + c_2 AR  ..... +AF  ) b_j\n",
        "\n",
        "when i is the away team, with sigma being the sigmoid function\n",
        "\n",
        "\n",
        "   sigma(x)=softmax(0,x) = e^x/(e^0+e^x) = 1/(1+e^{-x})\n",
        "\n",
        "\n",
        "\n",
        "This puts a *neural layer* behind the standard max likelihood model from the 1980s\n",
        "\n",
        "The weights are now the a_i,  b_i,   and c_i\n",
        "\n",
        "Since the c_i are shared by all teams the training rate for the c_i should be lower\n",
        "\n",
        "As in the model which this generalizes, the training is cross entropy versus the Poisson distribution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "A comment about the way the databases are stored, variables like HST and AST refer to 'home'\n",
        "and 'away' team but we do not make a distinction between home versus away.\n",
        "\n",
        "This means that each row of a data table is interpreted as if it were two rows,\n",
        "one giving information about team i against team j, the other giving information\n",
        "about team j against team i.\n",
        "\n",
        "For instance to calculate the average goals scored by any team over all games\n",
        "each row gives goals scored by a home team and goals scored by an away team\n",
        "and we have to add 2 to total games.\n",
        "\n",
        "That is when we say total games it really means the sum over all teams\n",
        "of the number of games that team played in, which is twice the number\n",
        "of games.\n",
        "\n",
        "That explains the line  totalgames=totalgames+2 each time a row is read in.\n",
        "\n",
        "There is no need to change this architecture to include things causing a home\n",
        "team advantage. This starts with a constant taking the value 1 in the first line\n",
        "\n",
        "loss -=  ...\n",
        "\n",
        "and taking the value 0 in the second line\n",
        "\n",
        "loss -= ...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "import torch as t\n",
        "import torch.nn as n\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "\n",
        "def sigma(x):\n",
        "  return t.exp(x)/(t.exp(t.tensor(1.0))+t.exp(x))-t.tensor(0.5)\n",
        "\n",
        "\n",
        "\n",
        "t.set_printoptions(precision=10)\n",
        "#print(\"beep boop\")\n",
        "#print(\"Aston Villa loses\")\n",
        "print(\"=============================================================\")\n",
        "\n",
        "#GITHUB LOCATION:\n",
        "#https://github.com/Pavlos01232/Match_Outcome_Prediction\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#pd.read_csv('https://raw.githubusercontent.com/Pavlos01232/Match_Outcome_Prediction/main/TRAINING%20DATA/PL0304.csv?raw=true')\n",
        "\n",
        "\n",
        "#\"DEEP learning\" just means \"hidden\" layers\n",
        "\n",
        "\n",
        "#df.to_csv(r'C:\\Users\\Pavlos\\Desktop\\export_dataframe.csv', sep='\\t', encoding='utf-8')\n",
        "#print (df[2])\n",
        "#file_list = os.listdir('https://raw.githubusercontent.com/Pavlos01232/Match_Outcome_Prediction/main/TRAINING%20DATA/')\n",
        "#df = pd.read_csv('https://raw.githubusercontent.com/Pavlos01232/Match_Outcome_Prediction/main/TRAINING%20DATA/PL0405.csv?raw=true',sep='\\t', lineterminator='\\r')\n",
        "#print(df)\n",
        "\n",
        "#read function\n",
        "\n",
        "first = \"https://raw.githubusercontent.com/Pavlos01232/Match_Outcome_Prediction/main/TRAINING%20DATA/PL\"\n",
        "last = \".csv?raw=true\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Starting with an array of data frames,\n",
        "and an array of column names, make a\n",
        "single array with the chosen columns\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def combine(dataFrames,columnNames):\n",
        " t=[]\n",
        " for i in range(0,len(dataFrames)):\n",
        "    theseColumns=dataFrames[i].columns.values[0].split(\",\")\n",
        "    for j in range(0 ,len(dataFrames[i])):\n",
        "      row=dataFrames[i].values[j][0].split(\",\")\n",
        "      newEntry=[]\n",
        "      for k in range(0, len(columnNames)):\n",
        "         for m in range(0, len(theseColumns)):\n",
        "             if(columnNames[k]==theseColumns[m] and m<=len(row)):\n",
        "                newEntry.append(row[m])\n",
        "      t.append(newEntry)\n",
        " return t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "can read years 3 to 23, 13*********************, there's something wrong with 14\n",
        "since the first two files in the training data are formatted incorrectly\n",
        "converts csv to dataframe\n",
        "'''\n",
        "\n",
        "df=[]\n",
        "\n",
        "for i in range(23, 24):\n",
        "  result = first + str('{:02.0f}'.format(i)) + str('{:02.0f}'.format(i+1)) + last\n",
        "  x = pd.read_csv(result, sep='\\t', encoding = 'unicode_escape', lineterminator='\\r')\n",
        "  df.append(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Get an array with each (home) team listed once\n",
        "from an array of data frames with column \"HomeTeam\"\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def getTeams(df):\n",
        " teams=[]\n",
        " homeTeams=combine(df,[\"HomeTeam\"])\n",
        " for i in range(len(homeTeams)):\n",
        "  if(len(homeTeams[i])>0):\n",
        "   found=False\n",
        "   for j in range(len(teams)):\n",
        "    if homeTeams[i][0] == teams[j]:\n",
        "      found=True\n",
        "      break\n",
        "   if found:\n",
        "    continue\n",
        "   teams.append(homeTeams[i][0])\n",
        " return teams\n",
        "\n",
        "\n",
        "'''\n",
        "Get the list of teams from the array of data frames called df\n",
        "and print it to the console\n",
        "'''\n",
        "\n",
        "\n",
        "teams=getTeams(df)\n",
        "print(\"\\nteams:\")\n",
        "print(teams)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Create an array called Data with just the team names and scores\n",
        "from the data framees in the array of frames df, and print it\n",
        "\n",
        "The list [\"HomeTeam\",\"AwayTeam\",\"FTHG\",\"FTAG\",\"HST\",\"AST\",\"HR\",\"AR\"] can be\n",
        "made longer if other columnts may be useful to use\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "Data=combine(df, [\"HomeTeam\",\"AwayTeam\",\"FTHG\",\"FTAG\",\"HST\",\"AST\",\"HR\",\"AR\", \"HS\",\"AS\",\"HC\",\"AC\",\"HF\",\"AF\"])\n",
        "print(\"\\n\\ndata: (team names respective goals scored, respective shots on target, respective red cards)\")\n",
        "print(Data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Get the numerical index of a team name x in the array teams\n",
        "otherwise just return x\n",
        "'''\n",
        "\n",
        "def getIndex(x,teams):\n",
        "  for i in range(len(teams)):\n",
        "   if(teams[i]==x):\n",
        "    return i\n",
        "  return x\n",
        "\n",
        "\n",
        "print(\"\\n\\nIndex assigned to Everton:\")\n",
        "print(getIndex(\"Everton\",teams))\n",
        "\n",
        "\n",
        "'''\n",
        "Replace any occurrence of names from the array teams\n",
        "which occur anywhere in A by their actual  numbers\n",
        "'''\n",
        "\n",
        "def teamsToNumbers(A,teams):\n",
        "  B=[]\n",
        "  for i in range(len(A)):\n",
        "    B.append([])\n",
        "    for j in range(len(A[i])):\n",
        "      B[i].append(getIndex(A[i][j],teams))\n",
        "  return B\n",
        "\n",
        "\n",
        "'''\n",
        "Create Data2 which is a copy of Data but with team names\n",
        "replaced by their index\n",
        "'''\n",
        "\n",
        "print(\"\\n\\ndata2, using the team's index number instead of name\")\n",
        "Data2=teamsToNumbers(Data,teams)\n",
        "print(Data2)\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "Assume Data2 has team indices in column 0 and 1 and scores\n",
        "in cols 2 and 3\n",
        "\n",
        "A[i] is array of average goals landed per game by tean i\n",
        "B[i] is array of average goals conceded per game by team i\n",
        "C is total games played by all teams (twide the number of games)\n",
        "games[i]=total games played by team i\n",
        "a[i]*b[j]=first approx of expected goals landed by i when playing\n",
        "    against j\n",
        "'''\n",
        "\n",
        "A=[0]*len(teams)\n",
        "B=[0]*len(teams)\n",
        "games=[0]*len(teams)\n",
        "a=[0]*len(teams)\n",
        "b=[0]*len(teams)\n",
        "C=0\n",
        "totalGames=0\n",
        "\n",
        "for i in range(len(Data2)):\n",
        "  if(len(Data2[i])<2):\n",
        "    continue\n",
        "  games[Data2[i][0]]+=1\n",
        "  games[Data2[i][1]]+=1\n",
        "  A[Data2[i][0]]+=int(Data2[i][2])\n",
        "  B[Data2[i][0]]+=int(Data2[i][3])\n",
        "  A[Data2[i][1]]+=int(Data2[i][3])\n",
        "  B[Data2[i][1]]+=int(Data2[i][2])\n",
        "  C+=int(Data2[i][2])+int(Data2[i][3])\n",
        "  totalGames+=2\n",
        "\n",
        "\n",
        "'''\n",
        "Initial estimates of a,b,c\n",
        "'''\n",
        "\n",
        "for i in range(len(A)):\n",
        "  a[i]=A[i]/games[i]*(C/totalGames)**(-1/2)\n",
        "\n",
        "for i in range(len(B)):\n",
        "  b[i]=B[i]/games[i]*(C/totalGames)**(-1/2)\n",
        "\n",
        "#c is another set of hidden weights for our weightrix. they are initally nonzero to avoid a stationary point.\n",
        "\n",
        "c=[0.001,0.002,0.004,-0.001,-0.002,-0.004,0.0005,0.0001,0.01,0.002,0.005,0.007,0.009,0.003,0.007,0.009,0.002,-0.001]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "AI training function\n",
        "\n",
        "The training is by gradient descent, the loss\n",
        "function will be cross entropy loss function against Poisson\n",
        "using loss.backward()\n",
        "\n",
        "The hidden weights at the moment are the entries of a,b,c\n",
        "the array c  is shared for all teams.\n",
        "These enter into the calculation of mu (which we\n",
        "call muHome or muAway during training) and are\n",
        "hidden as they have no direct meaning.\n",
        "\n",
        "Thus mu as a function of the entries of a,b,c is\n",
        "learned by training, the weights are the entries\n",
        "of the three arrays.\n",
        "\n",
        "\n",
        "\n",
        "tau is the training rate for c which should be small\n",
        "compared to eta\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "'''\n",
        "flag=0   exclude nothing\n",
        "flag=1   exclude entries of exclusions\n",
        "flag=2   exclude entries not in exclusions\n",
        "'''\n",
        "\n",
        "def elementOf(i,A):\n",
        "  for j in range(len(A)):\n",
        "    if(A[j]==i):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def train(eta,tau,flag,exclusions):\n",
        "  loss=t.tensor(0.0)\n",
        "\n",
        "\n",
        "\n",
        "  atensor=t.tensor(a,requires_grad=True)\n",
        "  btensor=t.tensor(b,requires_grad=True)\n",
        "  ctensor=t.tensor(c,requires_grad=True)\n",
        "\n",
        "\n",
        "  for i in range(len(Data2)):\n",
        "    if(len(Data2[i])==0):\n",
        "      continue\n",
        "    if (flag==1 and elementOf(i,exclusions)):\n",
        "      continue\n",
        "    if (flag==2 and not elementOf(i,exclusions)):\n",
        "      continue\n",
        "    homeTeam=int(Data2[i][0])\n",
        "    awayTeam=int(Data2[i][1])\n",
        "    homeGoals=int(Data2[i][2])\n",
        "    awayGoals=int(Data2[i][3])\n",
        "    HST=t.tensor(float(Data2[i][4]))\n",
        "    AST=t.tensor(float(Data2[i][5]))\n",
        "    HR=t.tensor(float(Data2[i][6]))\n",
        "    AR=t.tensor(float(Data2[i][7]))\n",
        "    HS=t.tensor(float(Data2[i][8]))\n",
        "    AS=t.tensor(float(Data2[i][9]))\n",
        "    HC=t.tensor(float(Data2[i][10]))\n",
        "    AC=t.tensor(float(Data2[i][11]))\n",
        "    HF=t.tensor(float(Data2[i][12]))\n",
        "    AF=t.tensor(float(Data2[i][13]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    The reason there are two lines of code for the loss is that\n",
        "    each game can be thought of as  two 'rows' of data where we label\n",
        "    the home team as team i  or team j.\n",
        "\n",
        "    Thus teams are interpreted symmetrically and there is not yet any\n",
        "    home team advantage but this can be put in\n",
        "    without modifying the architecture as a constant which is 1 in the\n",
        "    first line and 0 in the second\n",
        "    '''\n",
        "\n",
        "\n",
        "    muHome=atensor[homeTeam]*btensor[awayTeam]\n",
        "    neural=ctensor[0]*sigma(ctensor[3]*HST+ctensor[4]*HR+ctensor[5]*HS+ctensor[6]*HC+ctensor[7]*HF)\n",
        "    neural+=ctensor[1]*sigma(ctensor[8]*HST+ctensor[9]*HR+ctensor[10]*HS+ctensor[11]*HC+ctensor[12]*HF)\n",
        "    neural+=ctensor[2]*sigma(ctensor[13]*HST+ctensor[14]*HR+ctensor[15]*HS+ctensor[16]*HC+ctensor[17]*HF)\n",
        "    muHome=muHome+neural*btensor[awayTeam]\n",
        "\n",
        "    muAway=atensor[awayTeam]*btensor[homeTeam]\n",
        "    neural=ctensor[0]*sigma(ctensor[3]*AST+ctensor[4]*AR+ctensor[5]*AS+ctensor[6]*AC+ctensor[7]*AF)\n",
        "    neural+=ctensor[1]*sigma(ctensor[8]*AST+ctensor[9]*AR+ctensor[10]*AS+ctensor[11]*AC+ctensor[12]*AF)\n",
        "    neural+=ctensor[2]*sigma(ctensor[13]*AST+ctensor[14]*AR+ctensor[15]*AS+ctensor[16]*AC+ctensor[17]*AF)\n",
        "    muAway=muAway+neural*btensor[homeTeam]\n",
        "\n",
        "\n",
        "    loss-=t.log(t.exp(-muHome)*t.pow(muHome,homeGoals)/math.factorial(homeGoals))\n",
        "    loss-=t.log(t.exp(-muAway)*t.pow(muAway,awayGoals)/math.factorial(awayGoals))\n",
        "\n",
        "  loss.backward()\n",
        "  for i in range(len(c)):\n",
        "    c[i]=c[i]-tau*ctensor.grad[i]\n",
        "  for i in range(len(a)):\n",
        "    a[i]=a[i]-eta*atensor.grad[i]\n",
        "  for i in range(len(b)):\n",
        "    b[i]=b[i]-eta*btensor.grad[i]\n",
        "  print(\"\\n\\nCross-entropy loss vs Poisson: \"+str(loss))\n",
        "  print(\"\\n\\nWeights:\\n\\na:  \"+str(a))\n",
        "  print(\"b:  \"+str(b))\n",
        "  print(\"c:  \"+str(c))\n",
        "  print(\"\\n\\n\\n\")\n",
        "  print(\"Partial derivatives of loss w/r to hidden weights:\")\n",
        "  print(\"\\natensor.grad: \"+str(atensor.grad))\n",
        "  print(\"btensor.grad: \"+str(btensor.grad))\n",
        "  print(\"ctensor.grad: \"+str(ctensor.grad))\n",
        "  print(\"\\n\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Use weights to construct predicted expected goals scored by i\n",
        "against j and then find probability of k goals scored using\n",
        "Poisson when given values of R S ST  C F are provided\n",
        "'''\n",
        "\n",
        "# non-tensor version of sigma for using in the field\n",
        "\n",
        "def mathsigma(x):\n",
        "  return math.exp(x)/(math.exp(0)+math.exp(x))-0.5\n",
        "\n",
        "def goalProb(i,j,k,ST,R,S,C,F):\n",
        "  mu=a[i]*b[j]\n",
        "  mu+=c[0]*mathsigma(c[3]*ST+c[4]*R+c[5]*S+c[6]*C+c[7]*F)\n",
        "  mu+=c[1]*mathsigma(c[8]*ST+c[9]*R+c[10]*S+c[11]*C+c[12]*F)\n",
        "  mu+=c[2]*mathsigma(c[13]*ST+c[14]*R+c[15]*S+c[16]*C+c[17]*F)\n",
        "  return math.exp(-mu)*mu**k/math.factorial(k)\n",
        "\n",
        "'''\n",
        "Test training a bit\n",
        "'''\n",
        "\n",
        "print(\"\\n\\nest probability before training of team 2 landing 5 goals against team 3\\n when team 2 has (ST,R,S,C,F)= (1,0,2,1,3): \"+str(goalProb(2,3,5,1,0,2,1,3)))\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\nexclude [4,5,6] as unseen validation set\")\n",
        "\n",
        "# TRAINING\n",
        "#NUMBER OF ITRATIONS,\n",
        "#TRAINING RATE FOR ETA, TAU.\n",
        "for i in range(200):\n",
        "    train(0.005,0.0005,1, [4,5,6])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\nprobability after training of team 2 landing 5 goals against 3: \"+str(goalProb(2,3,5,1,0,2,1,3)))\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "    VALIDATION TESTS\n",
        "\n",
        "With the hidden weights a,b,c still saved, we run it on unseen  data to see\n",
        "what is the loss,  eta=0, tau=0\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "for i in range(20):\n",
        "  print(\"*************************************************\")\n",
        "print(\"\\n Validation:\\n\")\n",
        "print(\"test unseen validation set using only earlier traning\")\n",
        "for i in range(1):\n",
        "    train(0.,0.,2, [4,5,6])\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "The validation set will be able to reduce its loss\n",
        "if we allow it to train on itself (no longer unseen)\n",
        "but if the reduction is small that is good evidence\n",
        "that the  loss when unseen is still acceptable.\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "#allow validation set to train further on itself\n",
        "\n",
        "for i in range(10):\n",
        "  train(.001,0,2, [4,5,6])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"=============================================================\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yb6-hsGw363e"
      }
    }
  ]
}