{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAkso5gnYqk1+oxSBoK0MA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavlos01232/Match_Outcome_Prediction/blob/main/game_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzVKKLMBRPxZ",
        "outputId": "e43c8f25-1deb-460e-f743-8fc12e285fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================================================\n",
            "\n",
            "teams:\n",
            "['Arsenal', 'Birmingham', 'Blackburn', 'Fulham', 'Leicester', 'Man United', 'Portsmouth', 'Charlton', 'Leeds', 'Liverpool', 'Bolton', 'Chelsea', 'Everton', 'Man City', 'Newcastle', 'Southampton', 'Tottenham', 'Wolves', 'Aston Villa', 'Middlesbrough']\n",
            "\n",
            "\n",
            "data: (team names respective goals scored, respective shots on target, respective red cards, respective shots, respective corner-kicks, respective fouls)\n",
            "[['Arsenal', 'Everton', '2', '1', '5', '7', '1', '1', '11', '13', '6', '9', '8', '15'], ['Birmingham', 'Tottenham', '1', '0', '5', '7', '0', '0', '10', '15', '1', '4', '20', '27'], ['Blackburn', 'Wolves', '5', '1', '13', '5', '0', '0', '25', '8', '6', '2', '8', '14'], ['Fulham', 'Middlesbrough', '3', '2', '9', '5', '0', '0', '17', '8', '7', '6', '18', '16'], ['Leicester', 'Southampton', '2', '2', '7', '10', '0', '0', '12', '13', '2', '7', '27', '15'], ['Man United', 'Bolton', '4', '0', '6', '5', '0', '0', '13', '15', '8', '4', '12', '8'], ['Portsmouth', 'Aston Villa', '2', '1', '3', '5', '0', '1', '4', '9', '7', '9', '18', '22'], ['Charlton', 'Man City', '0', '3', '5', '8', '1', '0', '10', '14', '4', '7', '12', '16'], ['Leeds', 'Newcastle', '2', '2', '3', '10', '0', '0', '8', '19', '4', '8', '19', '16'], ['Liverpool', 'Chelsea', '1', '2', '7', '6', '0', '0', '12', '10', '8', '6', '13', '12'], ['Bolton', 'Blackburn', '2', '2', '10', '5', '0', '1', '16', '10', '9', '2', '11', '15'], ['Chelsea', 'Leicester', '2', '1', '7', '1', '1', '2', '17', '5', '7', '2', '12', '18'], ['Everton', 'Fulham', '3', '1', '8', '15', '0', '0', '10', '23', '4', '10', '15', '14'], ['Man City', 'Portsmouth', '1', '1', '11', '2', '0', '0', '21', '4', '11', '7', '8', '22'], ['Newcastle', 'Man United', '1', '2', '5', '8', '0', '0', '7', '11', '2', '4', '18', '14'], ['Southampton', 'Birmingham', '0', '0', '7', '5', '0', '0', '14', '12', '2', '7', '15', '19'], ['Tottenham', 'Leeds', '2', '1', '4', '2', '0', '0', '20', '5', '6', '0', '14', '14'], ['Wolves', 'Charlton', '0', '4', '4', '6', '0', '1', '10', '8', '5', '2', '11', '7'], ['Aston Villa', 'Liverpool', '0', '0', '9', '9', '0', '0', '14', '15', '8', '9', '16', '7'], ['Middlesbrough', 'Arsenal', '0', '4', '4', '10', '0', '0', '10', '14', '3', '5', '11', '7'], ['Blackburn', 'Man City', '2', '3', '10', '5', '0', '0', '14', '13', '9', '0', '14', '10'], ['Charlton', 'Everton', '2', '2', '4', '4', '0', '0', '10', '13', '6', '8', '8', '8'], ['Leeds', 'Southampton', '0', '0', '6', '8', '0', '0', '15', '14', '6', '10', '10', '11'], ['Leicester', 'Middlesbrough', '0', '0', '4', '3', '0', '0', '12', '13', '6', '4', '17', '16'], ['Portsmouth', 'Bolton', '4', '0', '8', '4', '0', '0', '13', '13', '0', '4', '12', '14'], ['Arsenal', 'Aston Villa', '2', '0', '6', '3', '0', '0', '14', '6', '2', '6', '16', '16'], ['Liverpool', 'Tottenham', '0', '0', '10', '4', '0', '0', '22', '9', '8', '5', '20', '27'], ['Man United', 'Wolves', '1', '0', '5', '2', '0', '0', '14', '12', '10', '2', '6', '12'], ['Aston Villa', 'Leicester', '3', '1', '8', '4', '0', '1', '10', '5', '11', '1', '18', '17'], ['Bolton', 'Charlton', '0', '0', '9', '1', '0', '0', '13', '7', '12', '3', '18', '16'], ['Chelsea', 'Blackburn', '2', '2', '5', '4', '0', '0', '12', '7', '3', '4', '11', '19'], ['Everton', 'Liverpool', '0', '3', '5', '11', '0', '0', '11', '18', '9', '5', '22', '17'], ['Middlesbrough', 'Leeds', '2', '3', '16', '4', '0', '0', '27', '8', '6', '3', '17', '21'], ['Newcastle', 'Birmingham', '0', '1', '10', '3', '0', '0', '19', '7', '9', '6', '15', '15'], ['Tottenham', 'Fulham', '0', '3', '6', '5', '0', '0', '18', '9', '9', '4', '15', '13'], ['Wolves', 'Portsmouth', '0', '0', '2', '2', '0', '0', '11', '9', '4', '6', '15', '16'], ['Man City', 'Arsenal', '1', '2', '7', '5', '0', '0', '11', '10', '5', '5', '12', '11'], ['Southampton', 'Man United', '1', '0', '5', '9', '0', '0', '12', '10', '9', '5', '8', '10'], ['Arsenal', 'Portsmouth', '1', '1', '7', '2', '0', '0', '12', '8', '7', '1', '11', '19'], ['Blackburn', 'Liverpool', '1', '3', '5', '14', '1', '0', '8', '21', '5', '10', '13', '11'], ['Bolton', 'Middlesbrough', '2', '0', '8', '6', '0', '0', '13', '7', '10', '1', '17', '14'], ['Charlton', 'Man United', '0', '2', '3', '9', '1', '0', '8', '14', '3', '3', '19', '18'], ['Chelsea', 'Tottenham', '4', '2', '6', '3', '0', '0', '12', '9', '10', '3', '16', '20'], ['Everton', 'Newcastle', '2', '2', '7', '2', '1', '1', '9', '4', '6', '3', '20', '21'], ['Southampton', 'Wolves', '2', '0', '10', '3', '0', '0', '15', '10', '7', '3', '16', '20'], ['Birmingham', 'Fulham', '2', '2', '9', '6', '1', '1', '15', '8', '8', '1', '16', '21'], ['Man City', 'Aston Villa', '4', '1', '9', '4', '0', '0', '17', '8', '4', '3', '11', '11'], ['Leicester', 'Leeds', '4', '0', '11', '2', '0', '0', '19', '14', '9', '5', '10', '10'], ['Aston Villa', 'Charlton', '2', '1', '6', '3', '0', '0', '15', '8', '10', '2', '13', '13'], ['Fulham', 'Man City', '2', '2', '9', '6', '0', '0', '13', '7', '2', '4', '14', '19'], ['Leeds', 'Birmingham', '0', '2', '6', '3', '1', '0', '12', '7', '6', '1', '15', '14'], ['Liverpool', 'Leicester', '2', '1', '8', '3', '0', '0', '19', '9', '4', '4', '10', '9'], ['Newcastle', 'Bolton', '0', '0', '7', '6', '0', '0', '14', '8', '7', '5', '15', '12'], ['Portsmouth', 'Blackburn', '1', '2', '6', '10', '0', '0', '9', '12', '7', '6', '17', '18'], ['Tottenham', 'Southampton', '1', '3', '6', '10', '0', '0', '13', '12', '4', '7', '15', '14'], ['Wolves', 'Chelsea', '0', '5', '4', '8', '0', '0', '8', '14', '1', '3', '15', '15'], ['Man United', 'Arsenal', '0', '0', '7', '1', '0', '1', '9', '6', '4', '3', '11', '15'], ['Middlesbrough', 'Everton', '1', '0', '4', '5', '0', '0', '9', '9', '4', '6', '12', '14'], ['Arsenal', 'Newcastle', '3', '2', '7', '4', '0', '0', '11', '5', '3', '4', '13', '17'], ['Birmingham', 'Portsmouth', '2', '0', '5', '5', '0', '0', '7', '10', '4', '4', '10', '16'], ['Bolton', 'Wolves', '1', '1', '14', '4', '0', '0', '22', '8', '12', '3', '16', '4'], ['Chelsea', 'Aston Villa', '1', '0', '5', '1', '0', '0', '10', '7', '6', '5', '7', '9'], ['Leicester', 'Man United', '1', '4', '4', '9', '0', '0', '10', '11', '7', '3', '7', '11'], ['Southampton', 'Middlesbrough', '0', '1', '6', '9', '1', '0', '10', '12', '4', '4', '12', '19'], ['Blackburn', 'Fulham', '0', '2', '0', '2', '0', '0', '6', '7', '5', '5', '14', '11'], ['Charlton', 'Liverpool', '3', '2', '5', '9', '0', '0', '14', '17', '7', '5', '11', '9'], ['Everton', 'Leeds', '4', '0', '9', '2', '0', '0', '20', '6', '11', '4', '11', '15'], ['Man City', 'Tottenham', '0', '0', '10', '2', '0', '0', '21', '4', '6', '6', '7', '15'], ['Fulham', 'Leicester', '2', '0', '8', '4', '0', '0', '16', '8', '4', '4', '14', '10'], ['Leeds', 'Blackburn', '2', '1', '5', '9', '0', '0', '15', '17', '2', '5', '18', '20'], ['Liverpool', 'Arsenal', '1', '2', '7', '8', '0', '0', '13', '12', '11', '3', '12', '20'], ['Man United', 'Birmingham', '3', '0', '8', '2', '0', '1', '10', '5', '5', '1', '13', '11'], ['Newcastle', 'Southampton', '1', '0', '9', '4', '0', '0', '14', '7', '8', '4', '14', '10'], ['Portsmouth', 'Charlton', '1', '2', '8', '6', '0', '0', '16', '11', '6', '9', '20', '14'], ['Tottenham', 'Everton', '3', '0', '7', '4', '0', '0', '13', '12', '2', '6', '15', '14'], ['Wolves', 'Man City', '1', '0', '4', '5', '0', '0', '8', '9', '3', '10', '13', '7'], ['Aston Villa', 'Bolton', '1', '1', '8', '5', '0', '0', '14', '15', '9', '5', '14', '16'], ['Middlesbrough', 'Chelsea', '1', '2', '6', '6', '0', '0', '15', '10', '2', '8', '14', '18'], ['Birmingham', 'Chelsea', '0', '0', '2', '8', '0', '0', '6', '13', '2', '18', '10', '14'], ['Arsenal', 'Chelsea', '2', '1', '9', '3', '0', '0', '13', '7', '6', '3', '11', '13'], ['Fulham', 'Wolves', '0', '0', '4', '6', '0', '0', '9', '14', '4', '11', '12', '11'], ['Leeds', 'Man United', '0', '1', '2', '10', '0', '0', '3', '18', '7', '2', '19', '8'], ['Man City', 'Bolton', '6', '2', '13', '8', '1', '0', '16', '12', '7', '4', '11', '8'], ['Middlesbrough', 'Newcastle', '0', '1', '7', '3', '0', '0', '11', '4', '8', '2', '17', '12'], ['Portsmouth', 'Liverpool', '1', '0', '6', '7', '0', '0', '10', '13', '5', '3', '22', '10'], ['Birmingham', 'Aston Villa', '0', '0', '3', '1', '0', '0', '4', '2', '3', '4', '16', '20'], ['Everton', 'Southampton', '0', '0', '6', '7', '0', '0', '13', '19', '8', '6', '11', '6'], ['Leicester', 'Tottenham', '1', '2', '15', '4', '0', '0', '22', '7', '5', '1', '12', '19'], ['Blackburn', 'Charlton', '0', '1', '6', '5', '0', '0', '15', '10', '5', '3', '17', '12'], ['Fulham', 'Newcastle', '2', '3', '4', '7', '0', '0', '4', '11', '4', '8', '14', '16'], ['Aston Villa', 'Everton', '0', '0', '6', '2', '0', '0', '16', '8', '9', '3', '11', '12'], ['Bolton', 'Birmingham', '0', '1', '7', '3', '0', '0', '16', '7', '7', '3', '14', '16'], ['Chelsea', 'Man City', '1', '0', '4', '6', '0', '0', '7', '9', '1', '5', '8', '8'], ['Liverpool', 'Leeds', '3', '1', '9', '5', '0', '0', '20', '7', '9', '3', '11', '13'], ['Man United', 'Fulham', '1', '3', '9', '7', '0', '0', '17', '12', '10', '2', '10', '14'], ['Newcastle', 'Portsmouth', '3', '0', '8', '4', '0', '0', '10', '9', '6', '6', '12', '14'], ['Southampton', 'Blackburn', '2', '0', '15', '3', '0', '1', '22', '6', '5', '3', '17', '14'], ['Wolves', 'Leicester', '4', '3', '8', '5', '0', '0', '12', '7', '2', '6', '6', '13'], ['Charlton', 'Arsenal', '1', '1', '4', '6', '0', '0', '6', '11', '7', '5', '15', '13'], ['Tottenham', 'Middlesbrough', '0', '0', '8', '10', '0', '0', '12', '16', '8', '5', '14', '10'], ['Everton', 'Chelsea', '0', '1', '4', '7', '0', '0', '12', '17', '3', '1', '5', '11'], ['Leeds', 'Arsenal', '1', '4', '5', '9', '0', '0', '9', '13', '4', '3', '12', '11'], ['Man United', 'Portsmouth', '3', '0', '4', '3', '0', '0', '10', '9', '3', '3', '13', '12'], ['Middlesbrough', 'Wolves', '2', '0', '11', '2', '0', '1', '14', '9', '7', '3', '8', '12'], ['Newcastle', 'Aston Villa', '1', '1', '13', '6', '0', '1', '22', '11', '15', '3', '9', '17'], ['Southampton', 'Man City', '0', '2', '5', '9', '0', '0', '8', '13', '4', '6', '10', '16'], ['Tottenham', 'Bolton', '0', '1', '6', '15', '0', '0', '10', '25', '7', '5', '18', '6'], ['Fulham', 'Liverpool', '1', '2', '6', '6', '1', '0', '10', '10', '4', '8', '13', '10'], ['Leicester', 'Blackburn', '2', '0', '3', '2', '0', '0', '4', '10', '2', '6', '11', '11'], ['Birmingham', 'Charlton', '1', '2', '13', '9', '0', '0', '14', '13', '15', '8', '14', '18'], ['Arsenal', 'Tottenham', '2', '1', '3', '2', '0', '0', '9', '5', '9', '5', '8', '22'], ['Aston Villa', 'Middlesbrough', '0', '2', '4', '3', '0', '0', '12', '8', '5', '2', '19', '16'], ['Bolton', 'Southampton', '0', '0', '11', '5', '0', '1', '18', '8', '8', '6', '10', '14'], ['Charlton', 'Fulham', '3', '1', '7', '7', '0', '0', '12', '11', '1', '5', '10', '12'], ['Portsmouth', 'Leeds', '6', '1', '6', '5', '0', '0', '14', '6', '3', '2', '9', '11'], ['Wolves', 'Birmingham', '1', '1', '4', '2', '0', '0', '11', '4', '8', '1', '13', '12'], ['Chelsea', 'Newcastle', '5', '0', '8', '3', '0', '1', '15', '4', '2', '0', '13', '5'], ['Liverpool', 'Man United', '1', '2', '4', '4', '0', '0', '10', '6', '2', '6', '16', '9'], ['Man City', 'Leicester', '0', '3', '4', '3', '0', '0', '14', '6', '12', '3', '7', '12'], ['Blackburn', 'Everton', '2', '1', '12', '2', '0', '0', '18', '8', '12', '3', '16', '9'], ['Birmingham', 'Arsenal', '0', '3', '1', '6', '0', '0', '7', '9', '8', '6', '8', '11'], ['Everton', 'Wolves', '2', '0', '15', '4', '0', '0', '23', '8', '8', '3', '7', '23'], ['Leeds', 'Bolton', '0', '2', '10', '5', '0', '0', '13', '10', '8', '2', '15', '11'], ['Leicester', 'Charlton', '1', '1', '7', '4', '0', '0', '13', '7', '3', '3', '15', '15'], ['Man United', 'Blackburn', '2', '1', '8', '6', '0', '0', '14', '13', '7', '4', '6', '15'], ['Middlesbrough', 'Liverpool', '0', '0', '3', '1', '0', '0', '8', '8', '3', '4', '16', '15'], ['Newcastle', 'Man City', '3', '0', '10', '1', '0', '0', '17', '5', '4', '2', '13', '16'], ['Southampton', 'Chelsea', '0', '1', '3', '4', '0', '0', '13', '8', '3', '3', '7', '13'], ['Tottenham', 'Aston Villa', '2', '1', '5', '6', '0', '0', '10', '13', '3', '3', '14', '15'], ['Fulham', 'Portsmouth', '2', '0', '4', '6', '0', '1', '8', '12', '2', '11', '9', '16'], ['Aston Villa', 'Southampton', '1', '0', '12', '3', '0', '0', '22', '7', '9', '4', '13', '13'], ['Blackburn', 'Tottenham', '1', '0', '12', '3', '0', '0', '18', '9', '9', '6', '10', '13'], ['Bolton', 'Everton', '2', '0', '6', '3', '0', '0', '13', '7', '7', '7', '11', '18'], ['Charlton', 'Leeds', '0', '1', '6', '6', '0', '0', '13', '12', '3', '4', '11', '17'], ['Portsmouth', 'Leicester', '0', '2', '7', '3', '0', '0', '12', '7', '11', '4', '12', '14'], ['Wolves', 'Newcastle', '1', '1', '4', '4', '0', '0', '10', '7', '5', '3', '14', '14'], ['Arsenal', 'Fulham', '0', '0', '14', '1', '0', '0', '22', '7', '9', '0', '13', '11'], ['Chelsea', 'Man United', '1', '0', '4', '3', '0', '0', '12', '5', '2', '4', '11', '12'], ['Liverpool', 'Birmingham', '3', '1', '7', '4', '0', '0', '10', '7', '6', '4', '24', '17'], ['Man City', 'Middlesbrough', '0', '1', '14', '0', '0', '0', '24', '2', '12', '0', '15', '12'], ['Birmingham', 'Blackburn', '0', '4', '2', '7', '1', '0', '6', '11', '10', '7', '23', '15'], ['Fulham', 'Bolton', '2', '1', '3', '5', '0', '0', '10', '10', '3', '2', '15', '11'], ['Leeds', 'Chelsea', '1', '1', '4', '10', '0', '0', '8', '19', '2', '8', '14', '11'], ['Leicester', 'Arsenal', '1', '1', '1', '5', '0', '1', '4', '8', '7', '5', '13', '12'], ['Man United', 'Aston Villa', '4', '0', '8', '3', '0', '0', '12', '10', '6', '5', '6', '11'], ['Middlesbrough', 'Portsmouth', '0', '0', '3', '2', '0', '1', '5', '6', '6', '5', '17', '20'], ['Newcastle', 'Liverpool', '1', '1', '6', '3', '0', '0', '13', '7', '8', '1', '13', '13'], ['Tottenham', 'Wolves', '5', '2', '10', '8', '0', '0', '12', '16', '4', '5', '14', '8'], ['Everton', 'Man City', '0', '0', '2', '7', '0', '0', '9', '15', '3', '5', '11', '13'], ['Southampton', 'Charlton', '3', '2', '14', '14', '0', '0', '18', '20', '8', '9', '12', '12'], ['Chelsea', 'Bolton', '1', '2', '5', '2', '0', '0', '9', '4', '8', '3', '13', '11'], ['Leicester', 'Birmingham', '0', '2', '5', '4', '2', '0', '8', '9', '6', '7', '19', '16'], ['Liverpool', 'Southampton', '1', '2', '10', '4', '0', '0', '18', '8', '9', '5', '6', '8'], ['Man United', 'Man City', '3', '1', '7', '9', '0', '0', '10', '12', '2', '5', '8', '10'], ['Middlesbrough', 'Charlton', '0', '0', '6', '3', '0', '0', '12', '10', '3', '7', '13', '11'], ['Newcastle', 'Tottenham', '4', '0', '11', '4', '0', '0', '19', '4', '11', '7', '10', '12'], ['Portsmouth', 'Everton', '1', '2', '10', '4', '0', '0', '12', '9', '7', '10', '13', '13'], ['Arsenal', 'Blackburn', '1', '0', '7', '1', '0', '0', '11', '5', '5', '6', '14', '14'], ['Aston Villa', 'Wolves', '3', '2', '8', '5', '0', '0', '11', '8', '4', '6', '12', '14'], ['Leeds', 'Fulham', '3', '2', '11', '7', '0', '0', '14', '10', '6', '5', '17', '11'], ['Blackburn', 'Aston Villa', '0', '2', '5', '7', '0', '0', '12', '15', '9', '1', '7', '11'], ['Bolton', 'Arsenal', '1', '1', '13', '4', '0', '0', '19', '9', '8', '1', '11', '13'], ['Charlton', 'Newcastle', '0', '0', '10', '5', '0', '0', '18', '11', '7', '9', '11', '9'], ['Everton', 'Leicester', '3', '2', '8', '4', '0', '0', '15', '6', '11', '7', '13', '18'], ['Fulham', 'Chelsea', '0', '1', '2', '9', '0', '0', '7', '11', '2', '8', '11', '10'], ['Southampton', 'Portsmouth', '3', '0', '7', '7', '0', '0', '12', '11', '8', '5', '7', '21'], ['Tottenham', 'Man United', '1', '2', '8', '7', '0', '0', '14', '12', '7', '8', '12', '8'], ['Man City', 'Leeds', '1', '1', '11', '4', '0', '0', '19', '6', '8', '5', '7', '8'], ['Arsenal', 'Wolves', '3', '0', '10', '1', '0', '0', '15', '5', '14', '3', '15', '17'], ['Birmingham', 'Man City', '2', '1', '3', '5', '0', '0', '5', '9', '9', '3', '18', '14'], ['Blackburn', 'Middlesbrough', '2', '2', '10', '3', '0', '0', '13', '5', '14', '1', '11', '10'], ['Charlton', 'Chelsea', '4', '2', '4', '8', '0', '0', '8', '15', '8', '6', '14', '10'], ['Fulham', 'Southampton', '2', '0', '7', '2', '0', '0', '14', '6', '11', '5', '13', '12'], ['Leeds', 'Aston Villa', '0', '0', '3', '4', '0', '0', '6', '13', '7', '5', '15', '13'], ['Leicester', 'Newcastle', '1', '1', '5', '6', '0', '0', '6', '12', '6', '7', '11', '10'], ['Liverpool', 'Bolton', '3', '1', '8', '2', '0', '0', '13', '7', '7', '1', '10', '18'], ['Man United', 'Everton', '3', '2', '11', '6', '0', '0', '19', '10', '7', '2', '8', '10'], ['Portsmouth', 'Tottenham', '2', '0', '8', '3', '0', '0', '10', '5', '3', '6', '10', '10'], ['Aston Villa', 'Fulham', '3', '0', '8', '3', '0', '0', '12', '9', '8', '3', '17', '7'], ['Bolton', 'Leicester', '2', '2', '8', '6', '0', '0', '15', '7', '3', '7', '16', '17'], ['Chelsea', 'Portsmouth', '3', '0', '8', '3', '0', '0', '15', '7', '7', '1', '8', '14'], ['Everton', 'Birmingham', '1', '0', '6', '2', '0', '0', '16', '5', '5', '2', '7', '13'], ['Man City', 'Liverpool', '2', '2', '8', '9', '0', '0', '16', '11', '7', '7', '6', '14'], ['Middlesbrough', 'Man United', '0', '1', '2', '6', '0', '1', '11', '10', '4', '2', '11', '15'], ['Newcastle', 'Blackburn', '0', '1', '11', '3', '0', '0', '15', '11', '8', '8', '6', '13'], ['Tottenham', 'Charlton', '0', '1', '9', '8', '0', '0', '18', '10', '11', '11', '8', '13'], ['Wolves', 'Leeds', '3', '1', '4', '4', '0', '1', '11', '9', '6', '10', '11', '14'], ['Southampton', 'Arsenal', '0', '1', '3', '9', '0', '0', '6', '17', '2', '3', '14', '10'], ['Aston Villa', 'Portsmouth', '2', '1', '13', '4', '0', '0', '18', '11', '9', '6', '17', '14'], ['Bolton', 'Man United', '1', '2', '5', '7', '0', '0', '15', '11', '10', '6', '4', '8'], ['Chelsea', 'Liverpool', '0', '1', '2', '1', '0', '1', '9', '4', '8', '3', '15', '9'], ['Everton', 'Arsenal', '1', '1', '4', '5', '0', '0', '8', '9', '5', '4', '13', '16'], ['Man City', 'Charlton', '1', '1', '10', '4', '0', '0', '18', '9', '2', '2', '9', '11'], ['Middlesbrough', 'Fulham', '2', '1', '5', '4', '0', '0', '10', '9', '9', '1', '14', '17'], ['Newcastle', 'Leeds', '1', '0', '6', '5', '0', '0', '13', '9', '5', '3', '14', '17'], ['Southampton', 'Leicester', '0', '0', '14', '8', '0', '0', '14', '9', '4', '5', '12', '15'], ['Tottenham', 'Birmingham', '4', '1', '7', '3', '0', '0', '11', '9', '1', '6', '15', '6'], ['Wolves', 'Blackburn', '2', '2', '5', '5', '0', '0', '10', '9', '2', '7', '13', '20'], ['Arsenal', 'Middlesbrough', '4', '1', '13', '4', '0', '0', '20', '5', '7', '3', '12', '21'], ['Birmingham', 'Southampton', '2', '1', '6', '6', '0', '1', '11', '9', '7', '10', '14', '23'], ['Blackburn', 'Bolton', '3', '4', '3', '10', '0', '0', '8', '16', '4', '7', '15', '13'], ['Charlton', 'Wolves', '2', '0', '4', '4', '0', '0', '10', '7', '6', '5', '6', '12'], ['Fulham', 'Everton', '2', '1', '10', '5', '0', '0', '14', '11', '5', '7', '19', '9'], ['Leeds', 'Tottenham', '0', '1', '1', '8', '0', '0', '7', '15', '4', '5', '17', '13'], ['Liverpool', 'Aston Villa', '1', '0', '4', '2', '0', '0', '12', '8', '3', '6', '14', '15'], ['Portsmouth', 'Man City', '4', '2', '8', '6', '0', '0', '11', '15', '2', '7', '7', '8'], ['Leicester', 'Chelsea', '0', '4', '3', '6', '0', '0', '6', '11', '6', '2', '17', '7'], ['Man United', 'Newcastle', '0', '0', '7', '3', '0', '0', '12', '7', '2', '3', '13', '11'], ['Bolton', 'Portsmouth', '1', '0', '6', '3', '0', '1', '13', '8', '2', '2', '9', '13'], ['Everton', 'Charlton', '0', '1', '7', '4', '0', '0', '17', '7', '10', '5', '6', '14'], ['Man City', 'Blackburn', '1', '1', '7', '3', '0', '0', '10', '6', '4', '2', '7', '13'], ['Middlesbrough', 'Leicester', '3', '3', '7', '8', '0', '0', '13', '14', '6', '6', '15', '12'], ['Southampton', 'Leeds', '2', '1', '6', '6', '0', '0', '18', '11', '1', '6', '16', '8'], ['Tottenham', 'Liverpool', '2', '1', '3', '4', '0', '0', '7', '10', '5', '6', '18', '9'], ['Wolves', 'Man United', '1', '0', '6', '6', '0', '0', '11', '15', '4', '12', '13', '5'], ['Aston Villa', 'Arsenal', '0', '2', '5', '9', '0', '0', '12', '13', '3', '2', '17', '21'], ['Chelsea', 'Birmingham', '0', '0', '9', '1', '0', '0', '16', '2', '6', '2', '13', '8'], ['Newcastle', 'Fulham', '3', '1', '9', '6', '0', '0', '10', '13', '7', '4', '10', '8'], ['Wolves', 'Liverpool', '1', '1', '6', '10', '0', '0', '9', '14', '7', '5', '14', '16'], ['Birmingham', 'Newcastle', '1', '1', '5', '2', '0', '0', '15', '4', '2', '3', '13', '11'], ['Charlton', 'Bolton', '1', '2', '7', '10', '0', '0', '14', '14', '5', '6', '9', '9'], ['Fulham', 'Tottenham', '2', '1', '10', '4', '0', '0', '16', '4', '10', '13', '6', '12'], ['Leeds', 'Middlesbrough', '0', '3', '4', '6', '1', '0', '8', '15', '7', '6', '14', '6'], ['Leicester', 'Aston Villa', '0', '5', '9', '10', '0', '0', '13', '14', '5', '9', '12', '7'], ['Liverpool', 'Everton', '0', '0', '9', '4', '0', '0', '21', '6', '8', '3', '7', '11'], ['Man United', 'Southampton', '3', '2', '7', '11', '0', '0', '12', '17', '1', '10', '9', '11'], ['Portsmouth', 'Wolves', '0', '0', '10', '4', '0', '0', '17', '8', '6', '6', '9', '6'], ['Arsenal', 'Man City', '2', '1', '9', '8', '0', '1', '11', '9', '5', '4', '13', '13'], ['Blackburn', 'Chelsea', '2', '3', '7', '9', '0', '0', '13', '17', '5', '6', '9', '14'], ['Aston Villa', 'Leeds', '2', '0', '7', '4', '0', '0', '15', '7', '3', '10', '15', '16'], ['Bolton', 'Liverpool', '2', '2', '6', '6', '0', '0', '12', '11', '3', '5', '15', '15'], ['Everton', 'Man United', '3', '4', '8', '9', '0', '0', '12', '19', '7', '7', '11', '14'], ['Middlesbrough', 'Blackburn', '0', '1', '7', '2', '0', '0', '15', '6', '8', '3', '6', '12'], ['Newcastle', 'Leicester', '3', '1', '9', '3', '0', '0', '15', '7', '9', '1', '17', '11'], ['Southampton', 'Fulham', '0', '0', '6', '8', '0', '0', '11', '11', '17', '3', '12', '18'], ['Tottenham', 'Portsmouth', '4', '3', '13', '9', '0', '0', '15', '16', '6', '5', '16', '13'], ['Wolves', 'Arsenal', '1', '3', '5', '7', '0', '0', '12', '10', '6', '4', '18', '18'], ['Chelsea', 'Charlton', '1', '0', '6', '0', '0', '0', '16', '5', '4', '3', '9', '17'], ['Man City', 'Birmingham', '0', '0', '12', '2', '0', '0', '21', '7', '11', '5', '11', '10'], ['Arsenal', 'Southampton', '2', '0', '6', '6', '0', '0', '11', '10', '5', '9', '13', '12'], ['Leeds', 'Wolves', '4', '1', '8', '5', '0', '0', '20', '11', '4', '3', '15', '14'], ['Leicester', 'Bolton', '1', '1', '15', '9', '0', '0', '15', '9', '8', '7', '16', '13'], ['Birmingham', 'Everton', '3', '0', '11', '3', '0', '0', '15', '5', '8', '11', '10', '14'], ['Blackburn', 'Newcastle', '1', '1', '7', '7', '0', '0', '17', '14', '8', '6', '12', '10'], ['Charlton', 'Tottenham', '2', '4', '14', '10', '0', '0', '18', '12', '10', '4', '13', '14'], ['Fulham', 'Aston Villa', '1', '2', '6', '3', '1', '0', '13', '10', '6', '5', '16', '17'], ['Liverpool', 'Man City', '2', '1', '7', '3', '0', '0', '12', '6', '6', '3', '7', '8'], ['Man United', 'Middlesbrough', '2', '3', '13', '8', '0', '0', '23', '12', '10', '5', '13', '17'], ['Portsmouth', 'Chelsea', '0', '2', '5', '4', '0', '0', '11', '10', '9', '10', '8', '13'], ['Bolton', 'Man City', '1', '3', '11', '13', '0', '0', '16', '17', '12', '11', '9', '10'], ['Charlton', 'Blackburn', '3', '2', '7', '12', '0', '0', '11', '18', '8', '12', '7', '6'], ['Chelsea', 'Arsenal', '1', '2', '4', '7', '1', '0', '10', '9', '11', '5', '16', '18'], ['Man United', 'Leeds', '1', '1', '7', '3', '0', '0', '24', '7', '12', '7', '12', '17'], ['Newcastle', 'Middlesbrough', '2', '1', '9', '4', '0', '0', '16', '8', '7', '3', '20', '21'], ['Southampton', 'Everton', '3', '3', '5', '6', '0', '0', '9', '12', '6', '5', '14', '19'], ['Wolves', 'Fulham', '2', '1', '10', '5', '0', '0', '12', '9', '8', '6', '13', '16'], ['Aston Villa', 'Birmingham', '2', '2', '8', '9', '0', '0', '11', '13', '7', '5', '15', '14'], ['Tottenham', 'Leicester', '4', '4', '9', '7', '0', '1', '10', '14', '4', '3', '9', '14'], ['Arsenal', 'Charlton', '2', '1', '11', '3', '0', '0', '21', '6', '12', '3', '8', '10'], ['Blackburn', 'Southampton', '1', '1', '7', '6', '0', '0', '16', '10', '6', '9', '10', '8'], ['Everton', 'Aston Villa', '2', '0', '7', '8', '0', '0', '15', '12', '5', '11', '13', '18'], ['Fulham', 'Man United', '1', '1', '3', '7', '0', '0', '7', '13', '4', '3', '13', '19'], ['Leicester', 'Wolves', '0', '0', '6', '3', '0', '0', '10', '6', '6', '3', '7', '9'], ['Man City', 'Chelsea', '0', '1', '4', '4', '0', '0', '14', '9', '7', '1', '8', '11'], ['Leeds', 'Liverpool', '2', '2', '6', '13', '0', '0', '12', '22', '6', '8', '13', '11'], ['Portsmouth', 'Newcastle', '1', '1', '8', '2', '0', '0', '18', '5', '8', '6', '9', '9'], ['Birmingham', 'Middlesbrough', '3', '1', '5', '6', '0', '1', '9', '8', '4', '5', '13', '20'], ['Birmingham', 'Bolton', '2', '0', '6', '2', '0', '0', '10', '10', '3', '5', '10', '15'], ['Middlesbrough', 'Tottenham', '1', '0', '6', '2', '0', '0', '10', '10', '3', '5', '10', '15'], ['Birmingham', 'Leicester', '0', '1', '4', '2', '0', '0', '6', '4', '8', '6', '12', '26'], ['Blackburn', 'Arsenal', '0', '2', '5', '5', '0', '0', '10', '14', '8', '3', '12', '11'], ['Bolton', 'Chelsea', '0', '2', '11', '8', '0', '0', '20', '12', '8', '6', '8', '13'], ['Charlton', 'Middlesbrough', '1', '0', '7', '9', '0', '0', '14', '15', '4', '7', '13', '9'], ['Everton', 'Portsmouth', '1', '0', '6', '3', '0', '0', '13', '5', '6', '4', '10', '12'], ['Fulham', 'Leeds', '2', '0', '10', '6', '0', '0', '19', '9', '4', '7', '14', '13'], ['Man City', 'Man United', '4', '1', '11', '9', '0', '0', '17', '17', '7', '4', '18', '14'], ['Southampton', 'Liverpool', '2', '0', '3', '12', '0', '0', '7', '18', '1', '7', '20', '8'], ['Tottenham', 'Newcastle', '1', '0', '4', '4', '0', '0', '11', '6', '3', '12', '13', '13'], ['Wolves', 'Aston Villa', '0', '4', '1', '7', '0', '0', '9', '15', '8', '13', '10', '14'], ['Liverpool', 'Portsmouth', '3', '0', '13', '4', '0', '0', '20', '4', '10', '8', '9', '20'], ['Arsenal', 'Bolton', '2', '1', '8', '2', '0', '0', '11', '8', '6', '1', '12', '14'], ['Aston Villa', 'Blackburn', '0', '2', '7', '7', '0', '0', '10', '16', '4', '6', '11', '14'], ['Chelsea', 'Fulham', '2', '1', '8', '1', '0', '0', '13', '5', '9', '1', '12', '13'], ['Leicester', 'Everton', '1', '1', '4', '3', '0', '1', '10', '7', '9', '2', '12', '21'], ['Liverpool', 'Wolves', '1', '0', '4', '6', '0', '0', '12', '8', '14', '4', '5', '12'], ['Man United', 'Tottenham', '3', '0', '6', '3', '0', '0', '11', '8', '4', '2', '14', '10'], ['Middlesbrough', 'Birmingham', '5', '3', '9', '12', '0', '0', '13', '18', '4', '4', '11', '13'], ['Newcastle', 'Charlton', '3', '1', '10', '2', '0', '0', '15', '6', '6', '6', '11', '12'], ['Portsmouth', 'Southampton', '1', '0', '8', '8', '0', '0', '16', '13', '6', '4', '16', '12'], ['Leeds', 'Man City', '2', '1', '3', '14', '0', '1', '4', '21', '4', '5', '13', '14'], ['Birmingham', 'Leeds', '4', '1', '7', '7', '0', '0', '17', '11', '7', '7', '11', '18'], ['Blackburn', 'Portsmouth', '1', '2', '9', '4', '0', '0', '14', '8', '5', '3', '11', '10'], ['Charlton', 'Aston Villa', '1', '2', '9', '11', '0', '0', '11', '19', '3', '12', '11', '14'], ['Chelsea', 'Wolves', '5', '2', '10', '4', '0', '0', '15', '9', '7', '4', '6', '12'], ['Everton', 'Middlesbrough', '1', '1', '7', '5', '0', '0', '14', '10', '8', '4', '16', '13'], ['Man City', 'Fulham', '0', '0', '4', '2', '0', '0', '12', '5', '3', '1', '12', '10'], ['Southampton', 'Tottenham', '1', '0', '11', '9', '0', '0', '18', '15', '10', '6', '8', '16'], ['Arsenal', 'Man United', '1', '1', '10', '8', '0', '0', '17', '13', '8', '7', '15', '18'], ['Bolton', 'Newcastle', '1', '0', '12', '7', '0', '0', '20', '15', '7', '7', '11', '10'], ['Leicester', 'Liverpool', '0', '0', '9', '12', '0', '0', '13', '19', '7', '10', '15', '20'], ['Fulham', 'Birmingham', '0', '0', '5', '1', '0', '0', '6', '6', '4', '2', '24', '22'], ['Middlesbrough', 'Bolton', '2', '0', '6', '8', '0', '0', '10', '13', '7', '8', '13', '15'], ['Newcastle', 'Everton', '4', '2', '8', '6', '0', '0', '12', '13', '5', '9', '11', '7'], ['Tottenham', 'Chelsea', '0', '1', '7', '7', '0', '0', '12', '10', '5', '4', '10', '10'], ['Wolves', 'Southampton', '1', '4', '3', '10', '0', '0', '8', '13', '3', '6', '12', '8'], ['Aston Villa', 'Man City', '1', '1', '3', '4', '0', '0', '6', '7', '5', '4', '13', '13'], ['Liverpool', 'Blackburn', '4', '0', '11', '2', '0', '0', '24', '9', '6', '4', '8', '10'], ['Leeds', 'Leicester', '3', '2', '10', '9', '1', '0', '15', '14', '7', '11', '19', '14'], ['Arsenal', 'Liverpool', '4', '2', '7', '5', '0', '0', '12', '12', '2', '8', '16', '9'], ['Everton', 'Tottenham', '3', '1', '10', '7', '0', '1', '13', '12', '8', '4', '9', '14'], ['Birmingham', 'Man United', '1', '2', '8', '6', '0', '0', '11', '10', '0', '3', '11', '10'], ['Blackburn', 'Leeds', '1', '2', '7', '3', '0', '0', '9', '8', '6', '4', '14', '13'], ['Bolton', 'Aston Villa', '2', '2', '7', '3', '0', '0', '16', '7', '6', '4', '10', '12'], ['Charlton', 'Portsmouth', '1', '1', '3', '8', '0', '0', '9', '10', '6', '2', '14', '8'], ['Chelsea', 'Middlesbrough', '0', '0', '9', '5', '0', '0', '19', '9', '6', '2', '10', '8'], ['Leicester', 'Fulham', '0', '2', '7', '4', '0', '0', '10', '9', '15', '4', '13', '15'], ['Man City', 'Wolves', '3', '3', '8', '9', '0', '0', '14', '15', '5', '6', '9', '12'], ['Newcastle', 'Arsenal', '0', '0', '5', '5', '0', '0', '9', '11', '5', '4', '14', '12'], ['Aston Villa', 'Chelsea', '3', '2', '3', '2', '0', '0', '5', '6', '7', '2', '8', '14'], ['Fulham', 'Blackburn', '3', '4', '7', '7', '0', '0', '10', '11', '6', '1', '12', '14'], ['Liverpool', 'Charlton', '0', '1', '16', '3', '0', '0', '25', '6', '7', '4', '12', '17'], ['Middlesbrough', 'Southampton', '3', '1', '18', '8', '0', '0', '25', '16', '6', '3', '11', '14'], ['Portsmouth', 'Birmingham', '3', '1', '6', '2', '0', '1', '12', '6', '4', '4', '19', '11'], ['Tottenham', 'Man City', '1', '1', '10', '8', '0', '0', '15', '9', '4', '3', '10', '21'], ['Wolves', 'Bolton', '1', '2', '3', '4', '0', '0', '8', '13', '6', '9', '12', '11'], ['Leeds', 'Everton', '1', '1', '7', '4', '0', '0', '14', '8', '10', '5', '12', '12'], ['Man United', 'Leicester', '1', '0', '12', '5', '0', '0', '16', '12', '7', '4', '11', '11'], ['Arsenal', 'Leeds', '5', '0', '8', '2', '0', '0', '15', '7', '3', '8', '10', '10'], ['Blackburn', 'Leicester', '1', '0', '4', '4', '0', '0', '12', '8', '2', '4', '16', '14'], ['Bolton', 'Tottenham', '2', '0', '10', '0', '0', '0', '15', '4', '11', '5', '18', '21'], ['Charlton', 'Birmingham', '1', '1', '5', '4', '0', '0', '12', '7', '9', '3', '14', '9'], ['Chelsea', 'Everton', '0', '0', '6', '4', '0', '0', '16', '5', '8', '4', '11', '10'], ['Liverpool', 'Fulham', '0', '0', '10', '7', '0', '0', '18', '11', '14', '7', '16', '10'], ['Man City', 'Southampton', '1', '3', '7', '5', '0', '0', '15', '9', '6', '3', '11', '9'], ['Portsmouth', 'Man United', '1', '0', '4', '12', '0', '0', '9', '19', '3', '13', '14', '8'], ['Wolves', 'Middlesbrough', '2', '0', '8', '10', '0', '0', '12', '16', '6', '8', '10', '10'], ['Aston Villa', 'Newcastle', '0', '0', '1', '4', '0', '1', '10', '5', '7', '3', '17', '13'], ['Man United', 'Charlton', '2', '0', '6', '0', '0', '0', '10', '5', '8', '3', '10', '8'], ['Everton', 'Blackburn', '0', '1', '9', '7', '0', '0', '16', '10', '8', '5', '8', '22'], ['Fulham', 'Charlton', '2', '0', '6', '3', '0', '0', '8', '8', '4', '7', '15', '13'], ['Leicester', 'Man City', '1', '1', '5', '5', '0', '0', '12', '11', '4', '2', '13', '14'], ['Man United', 'Liverpool', '0', '1', '4', '4', '0', '0', '11', '9', '3', '4', '19', '15'], ['Middlesbrough', 'Aston Villa', '1', '2', '21', '9', '0', '1', '31', '12', '12', '8', '12', '15'], ['Southampton', 'Bolton', '1', '2', '3', '8', '0', '0', '9', '11', '2', '2', '13', '16'], ['Birmingham', 'Wolves', '2', '2', '9', '7', '0', '0', '14', '11', '9', '2', '11', '13'], ['Leeds', 'Portsmouth', '1', '2', '6', '5', '0', '0', '14', '7', '9', '2', '9', '21'], ['Newcastle', 'Chelsea', '2', '1', '12', '6', '0', '0', '21', '17', '7', '5', '12', '12'], ['Tottenham', 'Arsenal', '2', '2', '7', '7', '0', '0', '13', '9', '7', '4', '14', '15'], ['Arsenal', 'Birmingham', '0', '0', '1', '3', '0', '0', '7', '3', '2', '3', '13', '16'], ['Blackburn', 'Man United', '1', '0', '8', '5', '0', '0', '12', '9', '5', '4', '11', '10'], ['Charlton', 'Leicester', '2', '2', '7', '5', '0', '1', '8', '10', '5', '4', '15', '7'], ['Chelsea', 'Southampton', '4', '0', '7', '3', '0', '0', '12', '5', '12', '3', '6', '5'], ['Man City', 'Newcastle', '1', '0', '3', '6', '0', '0', '7', '7', '7', '5', '7', '9'], ['Portsmouth', 'Fulham', '1', '1', '7', '7', '0', '0', '14', '11', '10', '3', '14', '13'], ['Wolves', 'Everton', '2', '1', '11', '6', '0', '0', '20', '10', '12', '7', '7', '12'], ['Aston Villa', 'Tottenham', '1', '0', '6', '5', '0', '0', '11', '10', '5', '5', '15', '20'], ['Bolton', 'Leeds', '4', '1', '14', '4', '0', '1', '21', '6', '9', '3', '14', '20'], ['Liverpool', 'Middlesbrough', '2', '0', '8', '6', '0', '0', '15', '12', '7', '3', '12', '14'], ['Portsmouth', 'Arsenal', '1', '1', '6', '9', '0', '0', '11', '20', '5', '12', '13', '10'], ['Birmingham', 'Liverpool', '0', '3', '2', '8', '1', '0', '3', '15', '3', '5', '11', '12'], ['Everton', 'Bolton', '1', '2', '9', '3', '0', '0', '16', '10', '7', '3', '14', '9'], ['Leeds', 'Charlton', '3', '3', '7', '6', '0', '0', '13', '12', '3', '2', '12', '9'], ['Leicester', 'Portsmouth', '3', '1', '9', '7', '0', '0', '13', '14', '8', '3', '11', '15'], ['Man United', 'Chelsea', '1', '1', '7', '7', '0', '1', '12', '11', '6', '2', '9', '19'], ['Middlesbrough', 'Man City', '2', '1', '7', '6', '0', '0', '12', '14', '5', '4', '9', '14'], ['Southampton', 'Aston Villa', '1', '1', '10', '7', '0', '0', '18', '14', '4', '4', '10', '13'], ['Tottenham', 'Blackburn', '1', '0', '13', '2', '0', '0', '16', '14', '7', '7', '9', '17'], ['Fulham', 'Arsenal', '0', '1', '5', '5', '0', '0', '12', '7', '6', '7', '13', '19'], ['Newcastle', 'Wolves', '1', '1', '8', '7', '0', '0', '19', '15', '13', '3', '13', '11'], ['Southampton', 'Newcastle', '3', '3', '12', '12', '0', '0', '15', '22', '3', '5', '13', '16'], ['Arsenal', 'Leicester', '2', '1', '10', '1', '0', '0', '17', '2', '7', '5', '15', '13'], ['Aston Villa', 'Man United', '0', '2', '8', '8', '0', '2', '16', '12', '9', '4', '21', '15'], ['Blackburn', 'Birmingham', '1', '1', '5', '5', '0', '0', '10', '9', '6', '8', '11', '12'], ['Bolton', 'Fulham', '0', '2', '9', '6', '0', '0', '17', '10', '11', '3', '9', '14'], ['Charlton', 'Southampton', '2', '1', '5', '4', '0', '0', '10', '12', '7', '10', '13', '10'], ['Chelsea', 'Leeds', '1', '0', '9', '0', '0', '0', '19', '4', '9', '2', '5', '9'], ['Liverpool', 'Newcastle', '1', '1', '4', '5', '0', '0', '8', '6', '8', '1', '11', '17'], ['Man City', 'Everton', '5', '1', '11', '0', '0', '0', '13', '2', '7', '3', '5', '8'], ['Portsmouth', 'Middlesbrough', '5', '1', '10', '4', '0', '0', '16', '19', '7', '2', '12', '8'], ['Wolves', 'Tottenham', '0', '2', '10', '12', '1', '0', '18', '14', '5', '3', '6', '11'], []]\n",
            "\n",
            "\n",
            "Index assigned to Everton:\n",
            "12\n",
            "\n",
            "\n",
            "data2, using the team's index number instead of name\n",
            "\n",
            "\n",
            " Pre-training score table\n",
            "                 Arsenal          Birmingham       Blackburn        Fulham           Leicester        Man United       Portsmouth       Charlton         Leeds            Liverpool        Bolton           Chelsea          Everton          Man City         Newcastle        Southampton      Tottenham        Wolves           Aston Villa      Middlesbrough    \n",
            "Arsenal          0.987            1.823            2.240            1.747            2.468            1.329            2.050            1.936            3.000            1.405            2.126            1.139            2.164            2.050            1.519            1.709            2.164            2.924            1.671            1.974            \n",
            "Birmingham       0.582            1.074            1.320            1.029            1.454            0.783            1.208            1.141            1.767            0.828            1.253            0.671            1.275            1.208            0.895            1.007            1.275            1.722            0.984            1.163            \n",
            "Blackburn        0.690            1.273            1.565            1.220            1.724            0.929            1.433            1.353            2.096            0.982            1.486            0.796            1.512            1.433            1.061            1.194            1.512            2.043            1.167            1.379            \n",
            "Fulham           0.703            1.298            1.596            1.244            1.758            0.947            1.461            1.379            2.137            1.001            1.515            0.812            1.542            1.461            1.082            1.217            1.542            2.083            1.190            1.407            \n",
            "Leicester        0.649            1.198            1.473            1.149            1.623            0.874            1.348            1.273            1.972            0.924            1.398            0.749            1.423            1.348            0.999            1.124            1.423            1.922            1.099            1.298            \n",
            "Man United       0.866            1.598            1.964            1.531            2.164            1.165            1.798            1.698            2.630            1.232            1.864            0.999            1.897            1.798            1.332            1.498            1.897            2.563            1.465            1.731            \n",
            "Portsmouth       0.636            1.173            1.442            1.125            1.589            0.856            1.320            1.247            1.931            0.905            1.369            0.734            1.394            1.320            0.978            1.100            1.394            1.882            1.076            1.271            \n",
            "Charlton         0.690            1.273            1.565            1.220            1.724            0.929            1.432            1.353            2.096            0.982            1.486            0.796            1.512            1.433            1.061            1.194            1.512            2.043            1.167            1.379            \n",
            "Leeds            0.541            0.999            1.228            0.957            1.352            0.728            1.124            1.061            1.644            0.770            1.165            0.624            1.186            1.124            0.832            0.936            1.186            1.602            0.916            1.082            \n",
            "Liverpool        0.744            1.373            1.688            1.316            1.860            1.001            1.545            1.459            2.260            1.059            1.602            0.858            1.631            1.545            1.144            1.287            1.631            2.203            1.259            1.488            \n",
            "Bolton           0.649            1.198            1.473            1.149            1.623            0.874            1.348            1.273            1.972            0.924            1.398            0.749            1.423            1.348            0.999            1.124            1.423            1.922            1.099            1.298            \n",
            "Chelsea          0.906            1.673            2.056            1.603            2.265            1.220            1.882            1.777            2.753            1.290            1.952            1.046            1.986            1.882            1.394            1.568            1.986            2.683            1.533            1.812            \n",
            "Everton          0.609            1.124            1.381            1.077            1.521            0.819            1.264            1.194            1.849            0.866            1.311            0.702            1.334            1.264            0.936            1.053            1.334            1.802            1.030            1.217            \n",
            "Man City         0.744            1.373            1.688            1.316            1.860            1.001            1.545            1.459            2.260            1.059            1.602            0.858            1.631            1.545            1.144            1.287            1.631            2.203            1.259            1.488            \n",
            "Newcastle        0.703            1.298            1.596            1.244            1.758            0.947            1.461            1.379            2.137            1.001            1.515            0.812            1.542            1.461            1.082            1.217            1.542            2.083            1.190            1.407            \n",
            "Southampton      0.595            1.099            1.350            1.053            1.488            0.801            1.236            1.167            1.808            0.847            1.282            0.687            1.305            1.236            0.916            1.030            1.305            1.762            1.007            1.190            \n",
            "Tottenham        0.636            1.173            1.442            1.125            1.589            0.856            1.320            1.247            1.931            0.905            1.369            0.734            1.394            1.320            0.978            1.100            1.394            1.882            1.076            1.271            \n",
            "Wolves           0.514            0.949            1.166            0.909            1.285            0.692            1.067            1.008            1.561            0.731            1.107            0.593            1.127            1.067            0.791            0.890            1.127            1.522            0.870            1.028            \n",
            "Aston Villa      0.649            1.198            1.473            1.149            1.623            0.874            1.348            1.273            1.972            0.924            1.398            0.749            1.423            1.348            0.999            1.124            1.423            1.922            1.099            1.298            \n",
            "Middlesbrough    0.595            1.099            1.350            1.053            1.488            0.801            1.236            1.167            1.808            0.847            1.282            0.687            1.305            1.236            0.916            1.030            1.305            1.762            1.007            1.190            \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.2281494141, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6593495607), tensor(0.9803454280), tensor(1.1652396917), tensor(1.1850808859), tensor(1.0982165337), tensor(1.4561821222), tensor(1.0729066133), tensor(1.1634229422), tensor(0.9190233946), tensor(1.2514206171), tensor(1.0961550474), tensor(1.5234485865), tensor(1.0279892683), tensor(1.2552995682), tensor(1.1837055683), tensor(1.0024526119), tensor(1.0735890865), tensor(0.8729763627), tensor(1.0934202671), tensor(1.0040503740)]\n",
            "b:  [tensor(0.5983177423), tensor(1.0931818485), tensor(1.3458638191), tensor(1.0496227741), tensor(1.4820083380), tensor(0.8015084863), tensor(1.2309250832), tensor(1.1634161472), tensor(1.7994489670), tensor(0.8450680375), tensor(1.2767660618), tensor(0.6881728768), tensor(1.2988818884), tensor(1.2327573299), tensor(0.9127970338), tensor(1.0249892473), tensor(1.2993361950), tensor(1.7533869743), tensor(1.0031030178), tensor(1.1846274137)]\n",
            "c:  [tensor(0.0006062721), tensor(0.0027711296), tensor(0.0045413692), tensor(-0.0009349895), tensor(-0.0020010569), tensor(-0.0039517521), tensor(0.0004897971), tensor(9.3208451290e-05), tensor(0.0101539176), tensor(0.0019977000), tensor(0.0051195230), tensor(0.0069804932), tensor(0.0089956690), tensor(0.0032902521), tensor(0.0069956803), tensor(0.0092242649), tensor(0.0019629886), tensor(-0.0010075390)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.0852760077,  0.0552037656, -0.4353895187,  0.1573715210,\n",
            "        -0.7138704062,  0.6695060730, -0.2129136920, -0.0720609426,\n",
            "        -1.3634805679,  0.5725347400, -0.3015759587,  0.8992905617,\n",
            "        -0.3515031338, -0.2032588720,  0.4324503541,  0.1948223710,\n",
            "        -0.3494086266, -1.2761261463,  0.2453706563, -0.1247330308])\n",
            "btensor.grad: tensor([-1.0767723322,  0.2930524349, -0.0719879121, -0.1171643138,\n",
            "         0.0652877986, -0.6656390429,  0.1106087863, -0.0706847906,\n",
            "         0.4315741658, -0.2554848194,  0.0644592047, -0.8036730886,\n",
            "         0.2023440599, -0.2558389902, -0.1182068586,  0.2485086918,\n",
            "         0.1114909276,  0.5219116211,  0.0647269487,  0.2480689287])\n",
            "ctensor.grad: tensor([ 0.7874559164, -1.5422589779, -1.0827381611, -0.1300211102,\n",
            "         0.0021134901, -0.0964957550,  0.0204059090,  0.0135830874,\n",
            "        -0.3078348041,  0.0046004443, -0.2390466183,  0.0390141830,\n",
            "         0.0086619314, -0.5805041194,  0.0086398311, -0.4485312402,\n",
            "         0.0740230381,  0.0150778312])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.1778564453, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6546599865), tensor(0.9800957441), tensor(1.1669816971), tensor(1.1844192743), tensor(1.1010440588), tensor(1.4533405304), tensor(1.0737234354), tensor(1.1636933088), tensor(0.9241685867), tensor(1.2490428686), tensor(1.0973306894), tensor(1.5196076632), tensor(1.0293370485), tensor(1.2561206818), tensor(1.1819219589), tensor(1.0016560555), tensor(1.0749480724), tensor(0.8777065873), tensor(1.0924108028), tensor(1.0045017004)]\n",
            "b:  [tensor(0.6016495824), tensor(1.0919803381), tensor(1.3461600542), tensor(1.0500507355), tensor(1.4817382097), tensor(0.8038669825), tensor(1.2304542065), tensor(1.1636778116), tensor(1.7975926399), tensor(0.8459599614), tensor(1.2764878273), tensor(0.6908422112), tensor(1.2980306149), tensor(1.2337944508), tensor(0.9131984711), tensor(1.0239738226), tensor(1.2988618612), tensor(1.7511392832), tensor(1.0028110743), tensor(1.1835947037)]\n",
            "c:  [tensor(0.0002907712), tensor(0.0036180886), tensor(0.0051828008), tensor(-0.0008956563), tensor(-0.0020017014), tensor(-0.0039227088), tensor(0.0004835049), tensor(8.8618886366e-05), tensor(0.0103668859), tensor(0.0019944925), tensor(0.0052842065), tensor(0.0069529498), tensor(0.0089873374), tensor(0.0036198420), tensor(0.0069907443), tensor(0.0094780419), tensor(0.0019202956), tensor(-0.0010192704)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.9379101396,  0.0499315858, -0.3483972549,  0.1323330402,\n",
            "        -0.5655038953,  0.5683211088, -0.1633728147, -0.0540832281,\n",
            "        -1.0290403366,  0.4755597711, -0.2351308465,  0.7681930065,\n",
            "        -0.2695463002, -0.1642137766,  0.3567189574,  0.1593212485,\n",
            "        -0.2717915773, -0.9460504055,  0.2018869817, -0.0902615786])\n",
            "btensor.grad: tensor([-0.6663656235,  0.2403029203, -0.0592589229, -0.0855952501,\n",
            "         0.0540194809, -0.4717047215,  0.0941826552, -0.0523257256,\n",
            "         0.3712763190, -0.1783847213,  0.0556542873, -0.5338655710,\n",
            "         0.1702569425, -0.2074248791, -0.0802927017,  0.2030760646,\n",
            "         0.0948743671,  0.4495377541,  0.0583793521,  0.2065472603])\n",
            "ctensor.grad: tensor([ 6.3100171089e-01, -1.6939181089e+00, -1.2828633785e+00,\n",
            "        -7.8666321933e-02,  1.2889561476e-03, -5.8086924255e-02,\n",
            "         1.2584329583e-02,  9.1791274026e-03, -4.2593574524e-01,\n",
            "         6.4147370867e-03, -3.2936719060e-01,  5.5086467415e-02,\n",
            "         1.6663096845e-02, -6.5917998552e-01,  9.8721114919e-03,\n",
            "        -5.0755470991e-01,  8.5386082530e-02,  2.3462770507e-02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.1457519531, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6506365538), tensor(0.9799172282), tensor(1.1684169769), tensor(1.1839042902), tensor(1.1033285856), tensor(1.4509650469), tensor(1.0743912458), tensor(1.1639361382), tensor(0.9281085134), tensor(1.2471081018), tensor(1.0982880592), tensor(1.5163613558), tensor(1.0304121971), tensor(1.2568235397), tensor(1.1804918051), tensor(1.0010480881), tensor(1.0760467052), tensor(0.8812693954), tensor(1.0916224718), tensor(1.0048679113)]\n",
            "b:  [tensor(0.6037464142), tensor(1.0910301208), tensor(1.3464384079), tensor(1.0503947735), tensor(1.4815483093), tensor(0.8055706024), tensor(1.2300881147), tensor(1.1639034748), tensor(1.7960239649), tensor(0.8466117978), tensor(1.2762825489), tensor(0.6926472187), tensor(1.2973483801), tensor(1.2346709967), tensor(0.9134996533), tensor(1.0231786966), tensor(1.2984921932), tensor(1.7492319345), tensor(1.0025858879), tensor(1.1827692986)]\n",
            "c:  [tensor(7.2711263783e-06), tensor(0.0045156018), tensor(0.0058905096), tensor(-0.0008767839), tensor(-0.0020020115), tensor(-0.0039087860), tensor(0.0004804813), tensor(8.6321575509e-05), tensor(0.0106454240), tensor(0.0019902901), tensor(0.0054995669), tensor(0.0069170021), tensor(0.0089754136), tensor(0.0039971764), tensor(0.0069850907), tensor(0.0097687589), tensor(0.0018717248), tensor(-0.0010336170)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.8046898246,  0.0357051194, -0.2870471478,  0.1030058861,\n",
            "        -0.4569038749,  0.4750952721, -0.1335732341, -0.0485759974,\n",
            "        -0.7879820466,  0.3869651556, -0.1914665103,  0.6492557526,\n",
            "        -0.2150201201, -0.1405782700,  0.2860268652,  0.1215863824,\n",
            "        -0.2197226286, -0.7125667334,  0.1576603651, -0.0732474923])\n",
            "btensor.grad: tensor([-0.4193683863,  0.1900316477, -0.0556708425, -0.0688133836,\n",
            "         0.0379794836, -0.3407195807,  0.0732299238, -0.0451266766,\n",
            "         0.3137232661, -0.1303696632,  0.0410667658, -0.3610071242,\n",
            "         0.1364527196, -0.1753058434, -0.0602326393,  0.1590297818,\n",
            "         0.0739366710,  0.3814648390,  0.0450282097,  0.1650758982])\n",
            "ctensor.grad: tensor([ 5.6700015068e-01, -1.7950265408e+00, -1.4154171944e+00,\n",
            "        -3.7744872272e-02,  6.2017445453e-04, -2.7845937759e-02,\n",
            "         6.0472316109e-03,  4.5946184546e-03, -5.5707544088e-01,\n",
            "         8.4049459547e-03, -4.3072089553e-01,  7.1895733476e-02,\n",
            "         2.3847544566e-02, -7.5466853380e-01,  1.1306793429e-02,\n",
            "        -5.8143484592e-01,  9.7141660750e-02,  2.8693156317e-02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.1232910156, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6471993923), tensor(0.9798171520), tensor(1.1696230173), tensor(1.1835277081), tensor(1.1052008867), tensor(1.4489986897), tensor(1.0749617815), tensor(1.1641762257), tensor(0.9311600924), tensor(1.2455561161), tensor(1.0990914106), tensor(1.5136358738), tensor(1.0312950611), tensor(1.2574464083), tensor(1.1793686152), tensor(1.0006101131), tensor(1.0769594908), tensor(0.8839876056), tensor(1.0910316706), tensor(1.0051900148)]\n",
            "b:  [tensor(0.6050850749), tensor(1.0902988911), tensor(1.3467155695), tensor(1.0506908894), tensor(1.4814381599), tensor(0.8068212867), tensor(1.2298234701), tensor(1.1641162634), tensor(1.7947127819), tensor(0.8471076488), tensor(1.2761524916), tensor(0.6938876510), tensor(1.2968207598), tensor(1.2354316711), tensor(0.9137452841), tensor(1.0225753784), tensor(1.2982236147), tensor(1.7476278543), tensor(1.0024321079), tensor(1.1821290255)]\n",
            "c:  [tensor(-0.0002668338), tensor(0.0054562897), tensor(0.0066519929), tensor(-0.0008763113), tensor(-0.0020020192), tensor(-0.0039084372), tensor(0.0004804060), tensor(8.6263258709e-05), tensor(0.0109941876), tensor(0.0019850340), tensor(0.0057696989), tensor(0.0068725310), tensor(0.0089604948), tensor(0.0044280235), tensor(0.0069786515), tensor(0.0101015270), tensor(0.0018171541), tensor(-0.0010494754)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.6874321699,  0.0200182199, -0.2412016392,  0.0753210783,\n",
            "        -0.3744567037,  0.3932774067, -0.1141182184, -0.0480099916,\n",
            "        -0.6103163958,  0.3103943467, -0.1606680751,  0.5450921059,\n",
            "        -0.1765737832, -0.1245725155,  0.2246438265,  0.0875991583,\n",
            "        -0.1825650930, -0.5436379910,  0.1181572974, -0.0644200444])\n",
            "btensor.grad: tensor([-0.2677299082,  0.1462534070, -0.0554390848, -0.0592179894,\n",
            "         0.0220312476, -0.2501317263,  0.0529203266, -0.0425537825,\n",
            "         0.2622376978, -0.0991760492,  0.0260108709, -0.2480866462,\n",
            "         0.1055253223, -0.1521447897, -0.0491216183,  0.1206654906,\n",
            "         0.0537098199,  0.3208115101,  0.0307567716,  0.1280627251])\n",
            "ctensor.grad: tensor([ 5.4820978642e-01, -1.8813755512e+00, -1.5229669809e+00,\n",
            "        -9.4509590417e-04,  1.5536335923e-05, -6.9784221705e-04,\n",
            "         1.5059500583e-04,  1.1663616169e-04, -6.9752752781e-01,\n",
            "         1.0512085631e-02, -5.4026412964e-01,  8.8942550123e-02,\n",
            "         2.9838606715e-02, -8.6169427633e-01,  1.2878291309e-02,\n",
            "        -6.6553705931e-01,  1.0914145410e-01,  3.1716827303e-02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.1074218750, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6442708969), tensor(0.9797877669), tensor(1.1706498861), tensor(1.1832704544), tensor(1.1067519188), tensor(1.4473820925), tensor(1.0754632950), tensor(1.1644210815), tensor(0.9335463643), tensor(1.2443250418), tensor(1.0997792482), tensor(1.5113579035), tensor(1.0320355892), tensor(1.2580085993), tensor(1.1785017252), tensor(1.0003138781), tensor(1.0777328014), tensor(0.8860845566), tensor(1.0906065702), tensor(1.0054867268)]\n",
            "b:  [tensor(0.6059522033), tensor(1.0897496939), tensor(1.3469957113), tensor(1.0509567261), tensor(1.4813979864), tensor(0.8077532053), tensor(1.2296476364), tensor(1.1643245220), tensor(1.7936246395), tensor(0.8474984765), tensor(1.2760896683), tensor(0.6947541833), tensor(1.2964258194), tensor(1.2361030579), tensor(0.9139581919), tensor(1.0221304893), tensor(1.2980432510), tensor(1.7462869883), tensor(1.0023423433), tensor(1.1816452742)]\n",
            "c:  [tensor(-0.0005425505), tensor(0.0064419243), tensor(0.0074655376), tensor(-0.0008936776), tensor(-0.0020017338), tensor(-0.0039212783), tensor(0.0004831527), tensor(8.8410706667e-05), tensor(0.0114173153), tensor(0.0019786740), tensor(0.0060982690), tensor(0.0068194522), tensor(0.0089432197), tensor(0.0049171890), tensor(0.0069713695), tensor(0.0104805697), tensor(0.0017564483), tensor(-0.0010659767)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.5857040286,  0.0058750212, -0.2053780556,  0.0514429808,\n",
            "        -0.3101983666,  0.3233244419, -0.1003040075, -0.0489609241,\n",
            "        -0.4772563577,  0.2462083399, -0.1375680566,  0.4556017220,\n",
            "        -0.1481151283, -0.1124294996,  0.1733812690,  0.0592439175,\n",
            "        -0.1546548605, -0.4193940759,  0.0850144625, -0.0593346953])\n",
            "btensor.grad: tensor([-0.1734197438,  0.1098330617, -0.0560379028, -0.0531589985,\n",
            "         0.0080339015, -0.1863881350,  0.0351728499, -0.0416424274,\n",
            "         0.2176370621, -0.0781652331,  0.0125682354, -0.1733071208,\n",
            "         0.0789765418, -0.1342892647, -0.0425873995,  0.0889804959,\n",
            "         0.0360744596,  0.2681826353,  0.0179463625,  0.0967603922])\n",
            "ctensor.grad: tensor([ 5.5143338442e-01, -1.9712691307e+00, -1.6270896196e+00,\n",
            "         3.4732513130e-02, -5.7076208759e-04,  2.5682596490e-02,\n",
            "        -5.4934169166e-03, -4.2948890477e-03, -8.4625512362e-01,\n",
            "         1.2719826773e-02, -6.5714043379e-01,  1.0615759343e-01,\n",
            "         3.4550555050e-02, -9.7833079100e-01,  1.4563851990e-02,\n",
            "        -7.5808542967e-01,  1.2141154706e-01,  3.3002488315e-02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.0961914062, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6417801380), tensor(0.9798167944), tensor(1.1715323925), tensor(1.1831114292), tensor(1.1080480814), tensor(1.4460601807), tensor(1.0759121180), tensor(1.1646711826), tensor(0.9354287386), tensor(1.2433581352), tensor(1.1003763676), tensor(1.5094602108), tensor(1.0326669216), tensor(1.2585203648), tensor(1.1778440475), tensor(1.0001310110), tensor(1.0783971548), tensor(0.8877193332), tensor(1.0903156996), tensor(1.0057662725)]\n",
            "b:  [tensor(0.6065239310), tensor(1.0893484354), tensor(1.3472781181), tensor(1.0512013435), tensor(1.4814156294), tensor(0.8084582686), tensor(1.2295455933), tensor(1.1645301580), tensor(1.7927265167), tensor(0.8478166461), tensor(1.2760831118), tensor(0.6953709722), tensor(1.2961412668), tensor(1.2367025614), tensor(0.9141506553), tensor(1.0218125582), tensor(1.2979359627), tensor(1.7451714277), tensor(1.0023058653), tensor(1.1812900305)]\n",
            "c:  [tensor(-0.0008253278), tensor(0.0074790698), tensor(0.0083349925), tensor(-0.0009290311), tensor(-0.0020011531), tensor(-0.0039474578), tensor(0.0004887045), tensor(9.2773509095e-05), tensor(0.0119191445), tensor(0.0019711570), tensor(0.0064890729), tensor(0.0067576272), tensor(0.0089242300), tensor(0.0054693860), tensor(0.0069631883), tensor(0.0109099718), tensor(0.0016894218), tensor(-0.0010823580)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.4981560707, -0.0058058798, -0.1765050888,  0.0317938328,\n",
            "        -0.2592297792,  0.2643918991, -0.0897635818, -0.0500161648,\n",
            "        -0.3764773607,  0.1933837533, -0.1194145679,  0.3795486987,\n",
            "        -0.1262646914, -0.1023570299,  0.1315329969,  0.0365703702,\n",
            "        -0.1328715086, -0.3269594908,  0.0581729114, -0.0559141636])\n",
            "btensor.grad: tensor([-0.1143400073,  0.0802583098, -0.0564866364, -0.0489196181,\n",
            "        -0.0035352707, -0.1410079002,  0.0204189718, -0.0411387682,\n",
            "         0.1796129644, -0.0636373162,  0.0013214350, -0.1233603209,\n",
            "         0.0569199957, -0.1198993921, -0.0384962559,  0.0635743737,\n",
            "         0.0214565843,  0.2231169939,  0.0072841644,  0.0710413456])\n",
            "ctensor.grad: tensor([ 5.6555461884e-01, -2.0742905140e+00, -1.7389086485e+00,\n",
            "         7.0707030594e-02, -1.1613243259e-03,  5.2359029651e-02,\n",
            "        -1.1103529483e-02, -8.7256086990e-03, -1.0036581755e+00,\n",
            "         1.5033649281e-02, -7.8160732985e-01,  1.2364968657e-01,\n",
            "         3.7979610264e-02, -1.1043940783e+00,  1.6362715513e-02,\n",
            "        -8.5880500078e-01,  1.3405287266e-01,  3.2762467861e-02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.0844726562, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6396644115), tensor(0.9798918962), tensor(1.1722961664), tensor(1.1830312014), tensor(1.1091398001), tensor(1.4449843168), tensor(1.0763187408), tensor(1.1649246216), tensor(0.9369266033), tensor(1.2426061630), tensor(1.1008996964), tensor(1.5078836679), tensor(1.0332121849), tensor(1.2589880228), tensor(1.1773548126), tensor(1.0000364780), tensor(1.0789743662), tensor(0.8890076280), tensor(1.0901312828), tensor(1.0060324669)]\n",
            "b:  [tensor(0.6069102883), tensor(1.0890656710), tensor(1.3475607634), tensor(1.0514299870), tensor(1.4814796448), tensor(0.8090007305), tensor(1.2295032740), tensor(1.1647331715), tensor(1.7919893265), tensor(0.8480839133), tensor(1.2761220932), tensor(0.6958205104), tensor(1.2959467173), tensor(1.2372426987), tensor(0.9143297672), tensor(1.0215947628), tensor(1.2978876829), tensor(1.7442476749), tensor(1.0023123026), tensor(1.1810389757)]\n",
            "c:  [tensor(-0.0011180555), tensor(0.0085769473), tensor(0.0092672072), tensor(-0.0009828573), tensor(-0.0020002692), tensor(-0.0039873649), tensor(0.0004971072), tensor(9.9400007457e-05), tensor(0.0125046270), tensor(0.0019624219), tensor(0.0069463751), tensor(0.0066868332), tensor(0.0089041842), tensor(0.0060897111), tensor(0.0069540455), tensor(0.0113941003), tensor(0.0016158298), tensor(-0.0010978730)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.4231373370, -0.0150190294, -0.1527585983,  0.0160534382,\n",
            "        -0.2183442712,  0.2151620388, -0.0813154578, -0.0506876707,\n",
            "        -0.2995704412,  0.1504050791, -0.1046773791,  0.3152976930,\n",
            "        -0.1090562940, -0.0935285091,  0.0978504643,  0.0189082623,\n",
            "        -0.1154356003, -0.2576532960,  0.0368881822, -0.0532355905])\n",
            "btensor.grad: tensor([-0.0772725940,  0.0565557480, -0.0565215200, -0.0457196832,\n",
            "        -0.0128074884, -0.1084947586,  0.0084580481, -0.0405921936,\n",
            "         0.1474455595, -0.0534566641, -0.0078037977, -0.0899055749,\n",
            "         0.0389113016, -0.1080262661, -0.0358214378,  0.0435481668,\n",
            "         0.0096611381,  0.1847404242, -0.0012854934,  0.0502222776])\n",
            "ctensor.grad: tensor([ 5.8545541763e-01, -2.1957550049e+00, -1.8644300699e+00,\n",
            "         1.0765235871e-01, -1.7674510600e-03,  7.9814165831e-02,\n",
            "        -1.6805510968e-02, -1.3253000565e-02, -1.1709647179e+00,\n",
            "         1.7470397055e-02, -9.1460466385e-01,  1.4158765972e-01,\n",
            "         4.0091775358e-02, -1.2406498194e+00,  1.8285499886e-02,\n",
            "        -9.6825754642e-01,  1.4718405902e-01,  3.1030051410e-02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.0739746094, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6378693581), tensor(0.9800024033), tensor(1.1729609966), tensor(1.1830129623), tensor(1.1100664139), tensor(1.4441131353), tensor(1.0766904354), tensor(1.1651791334), tensor(0.9381296039), tensor(1.2420276403), tensor(1.1013619900), tensor(1.5065777302), tensor(1.0336885452), tensor(1.2594158649), tensor(1.1769998074), tensor(1.0000094175), tensor(1.0794806480), tensor(0.8900347948), tensor(1.0900300741), tensor(1.0062869787)]\n",
            "b:  [tensor(0.6071810126), tensor(1.0888773203), tensor(1.3478415012), tensor(1.0516459942), tensor(1.4815802574), tensor(0.8094265461), tensor(1.2295089960), tensor(1.1649324894), tensor(1.7913876772), tensor(0.8483155370), tensor(1.2761976719), tensor(0.6961583495), tensor(1.2958251238), tensor(1.2377334833), tensor(0.9144999981), tensor(1.0214551687), tensor(1.2978862524), tensor(1.7434871197), tensor(1.0023525953), tensor(1.1808714867)]\n",
            "c:  [tensor(-0.0014225213), tensor(0.0097464733), tensor(0.0102708470), tensor(-0.0010558082), tensor(-0.0019990716), tensor(-0.0040414999), tensor(0.0005084463), tensor(0.0001083716), tensor(0.0131795770), tensor(0.0019523953), tensor(0.0074751289), tensor(0.0066067567), tensor(0.0088837901), tensor(0.0067839203), tensor(0.0069438708), tensor(0.0119378567), tensor(0.0015353693), tensor(-0.0011117250)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.3590040803, -0.0220989585, -0.1329767704,  0.0036535263,\n",
            "        -0.1853345633,  0.1742397547, -0.0743288994, -0.0508934259,\n",
            "        -0.2405950427,  0.1157163605, -0.0924671888,  0.2611970603,\n",
            "        -0.0952827632, -0.0855619907,  0.0710048005,  0.0054141879,\n",
            "        -0.1012479067, -0.2054363191,  0.0202433467, -0.0509058237])\n",
            "btensor.grad: tensor([-0.0541391969,  0.0376656055, -0.0561543554, -0.0432026386,\n",
            "        -0.0201133192, -0.0851638317, -0.0011344254, -0.0398732424,\n",
            "         0.1203303635, -0.0463257432, -0.0151177645, -0.0675638914,\n",
            "         0.0243273750, -0.0981576443, -0.0340503454,  0.0279251933,\n",
            "         0.0002907366,  0.1521147490, -0.0080628395,  0.0335092545])\n",
            "ctensor.grad: tensor([ 0.6089314818, -2.3390517235, -2.0072801113,  0.1459017396,\n",
            "        -0.0023951926,  0.1082699001, -0.0226782206, -0.0179430898,\n",
            "        -1.3499004841,  0.0200532600, -1.0575075150,  0.1601527482,\n",
            "         0.0407880172, -1.3884183168,  0.0203490537, -1.0875136852,\n",
            "         0.1609209627,  0.0277040619])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.0629882812, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6363481283), tensor(0.9801397324), tensor(1.1735428572), tensor(1.1830431223), tensor(1.1108593941), tensor(1.4434114695), tensor(1.0770328045), tensor(1.1654326916), tensor(0.9391058683), tensor(1.2415881157), tensor(1.1017730236), tensor(1.5054991245), tensor(1.0341092348), tensor(1.2598072290), tensor(1.1767510176), tensor(1.0000331402), tensor(1.0799286366), tensor(0.8908647895), tensor(1.0899933577), tensor(1.0065307617)]\n",
            "b:  [tensor(0.6073805690), tensor(1.0887641907), tensor(1.3481190205), tensor(1.0518521070), tensor(1.4817093611), tensor(0.8097689152), tensor(1.2295529842), tensor(1.1651275158), tensor(1.7909001112), tensor(0.8485226035), tensor(1.2763025761), tensor(0.6964223981), tensor(1.2957623005), tensor(1.2381833792), tensor(0.9146646261), tensor(1.0213760138), tensor(1.2979216576), tensor(1.7428653240), tensor(1.0024197102), tensor(1.1807708740)]\n",
            "c:  [tensor(-0.0017401171), tensor(0.0109998677), tensor(0.0113558928), tensor(-0.0011486301), tensor(-0.0019975475), tensor(-0.0041104187), tensor(0.0005228356), tensor(0.0001197990), tensor(0.0139508555), tensor(0.0019409904), tensor(0.0080811363), tensor(0.0065169926), tensor(0.0088638412), tensor(0.0075586191), tensor(0.0069325836), tensor(0.0125468513), tensor(0.0014476832), tensor(-0.0011230129)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.3042506278, -0.0274677277, -0.1163694859, -0.0060268641,\n",
            "        -0.1585971117,  0.1403331757, -0.0684685111, -0.0507185459,\n",
            "        -0.1952476501,  0.0878932029, -0.0821989775,  0.2157247961,\n",
            "        -0.0841493309, -0.0782659054,  0.0497590080, -0.0047428608,\n",
            "        -0.0895906687, -0.1659937799,  0.0073537230, -0.0487560630])\n",
            "btensor.grad: tensor([-0.0399151444,  0.0226233006, -0.0555042773, -0.0412108898,\n",
            "        -0.0258276761, -0.0684775114, -0.0087991953, -0.0390008688,\n",
            "         0.0975065976, -0.0414148569, -0.0209825039, -0.0528147668,\n",
            "         0.0125556588, -0.0899891853, -0.0329287052,  0.0158254504,\n",
            "        -0.0070895702,  0.1243619919, -0.0134138465,  0.0201342106])\n",
            "ctensor.grad: tensor([ 0.6351916790, -2.5067877769, -2.1700911522,  0.1856437624,\n",
            "        -0.0030483326,  0.1378380507, -0.0287786592, -0.0228549186,\n",
            "        -1.5425564051,  0.0228096507, -1.2120147943,  0.1795279980,\n",
            "         0.0398976207, -1.5493975878,  0.0225741901, -1.2179890871,\n",
            "         0.1753721088,  0.0225758329])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.0506591797, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6350603104), tensor(0.9802972674), tensor(1.1740545034), tensor(1.1831107140), tensor(1.1115440130), tensor(1.4428499937), tensor(1.0773503780), tensor(1.1656841040), tensor(0.9399075508), tensor(1.2412594557), tensor(1.1021403074), tensor(1.5046113729), tensor(1.0344846249), tensor(1.2601648569), tensor(1.1765856743), tensor(1.0000944138), tensor(1.0803283453), tensor(0.8915456533), tensor(1.0900061131), tensor(1.0067642927)]\n",
            "b:  [tensor(0.6075378060), tensor(1.0887111425), tensor(1.3483924866), tensor(1.0520503521), tensor(1.4818607569), tensor(0.8100521564), tensor(1.2296277285), tensor(1.1653175354), tensor(1.7905085087), tensor(0.8487134576), tensor(1.2764312029), tensor(0.6966388822), tensor(1.2957470417), tensor(1.2385998964), tensor(0.9148262143), tensor(1.0213434696), tensor(1.2979859114), tensor(1.7423616648), tensor(1.0025080442), tensor(1.1807236671)]\n",
            "c:  [tensor(-0.0020721364), tensor(0.0123505918), tensor(0.0125335082), tensor(-0.0012621362), tensor(-0.0019956825), tensor(-0.0041947132), tensor(0.0005404134), tensor(0.0001338226), tensor(0.0148265148), tensor(0.0019281053), tensor(0.0087711802), tensor(0.0064170426), tensor(0.0088452464), tensor(0.0084214117), tensor(0.0069200913), tensor(0.0132275373), tensor(0.0013523609), tensor(-0.0011306892)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.2575542033, -0.0315120220, -0.1023342609, -0.0135291815,\n",
            "        -0.1369122267,  0.1123030186, -0.0635041595, -0.0502825975,\n",
            "        -0.1603336334,  0.0657235160, -0.0734666586,  0.1775491238,\n",
            "        -0.0750801861, -0.0715328455,  0.0330669768, -0.0122476816,\n",
            "        -0.0799417496, -0.1361681521, -0.0025396049, -0.0467163920])\n",
            "btensor.grad: tensor([-0.0314509273,  0.0106161833, -0.0546891540, -0.0396501422,\n",
            "        -0.0302910209, -0.0566428900, -0.0149487257, -0.0380005836,\n",
            "         0.0783239156, -0.0381693840, -0.0257270336, -0.0433021933,\n",
            "         0.0030550212, -0.0833038092, -0.0323152542,  0.0065054297,\n",
            "        -0.0128569156,  0.1007267237, -0.0176649094,  0.0094457865])\n",
            "ctensor.grad: tensor([ 0.6640385389, -2.7014477253, -2.3552317619,  0.2270121723,\n",
            "        -0.0037298421,  0.1685890257, -0.0351554863, -0.0280471295,\n",
            "        -1.7513180971,  0.0257704649, -1.3800877333,  0.1998996884,\n",
            "         0.0371887125, -1.7255853415,  0.0249848459, -1.3613723516,\n",
            "         0.1906444430,  0.0153525602])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.0378417969, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6339714527), tensor(0.9804699421), tensor(1.1745064259), tensor(1.1832072735), tensor(1.1121406555), tensor(1.4424040318), tensor(1.0776467323), tensor(1.1659325361), tensor(0.9405747056), tensor(1.2410184145), tensor(1.1024699211), tensor(1.5038837194), tensor(1.0348227024), tensor(1.2604911327), tensor(1.1764853001), tensor(1.0001826286), tensor(1.0806877613), tensor(0.8921136260), tensor(1.0900564194), tensor(1.0069879293)]\n",
            "b:  [tensor(0.6076714396), tensor(1.0887061357), tensor(1.3486615419), tensor(1.0522426367), tensor(1.4820296764), tensor(0.8102939725), tensor(1.2297272682), tensor(1.1655020714), tensor(1.7901972532), tensor(0.8488944173), tensor(1.2765793800), tensor(0.6968260407), tensor(1.2957700491), tensor(1.2389895916), tensor(0.9149867296), tensor(1.0213464499), tensor(1.2980724573), tensor(1.7419587374), tensor(1.0026134253), tensor(1.1807191372)]\n",
            "c:  [tensor(-0.0024198755), tensor(0.0138134481), tensor(0.0138161117), tensor(-0.0013971984), tensor(-0.0019934613), tensor(-0.0042950031), tensor(0.0005613414), tensor(0.0001506134), tensor(0.0158159379), tensor(0.0019136202), tensor(0.0095531391), tensor(0.0063063060), tensor(0.0088290526), tensor(0.0093810428), tensor(0.0069062873), tensor(0.0139873335), tensor(0.0012489349), tensor(-0.0011335249)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.2177770734, -0.0345393419, -0.0903961658, -0.0193058252,\n",
            "        -0.1193183064,  0.0891977549, -0.0592687726, -0.0496857166,\n",
            "        -0.1334328651,  0.0482133776, -0.0659340620,  0.1455362737,\n",
            "        -0.0676262081, -0.0652655363,  0.0200796872, -0.0176459551,\n",
            "        -0.0718939304, -0.1135993004, -0.0100539625, -0.0447333455])\n",
            "btensor.grad: tensor([-0.0267254114,  0.0009906292, -0.0538012236, -0.0384616256,\n",
            "        -0.0337728858, -0.0483633280, -0.0198984146, -0.0369007587,\n",
            "         0.0622574128, -0.0361947417, -0.0296258926, -0.0374368131,\n",
            "        -0.0045998469, -0.0779312849, -0.0321061611, -0.0006027818,\n",
            "        -0.0173153728,  0.0805795193, -0.0210838914,  0.0009107590])\n",
            "ctensor.grad: tensor([ 0.6954782605, -2.9257123470, -2.5652062893,  0.2701244950,\n",
            "        -0.0044425139,  0.2005798370, -0.0418559723, -0.0335815474,\n",
            "        -1.9788476229,  0.0289702229, -1.5639182329,  0.2214727998,\n",
            "         0.0323880799, -1.9192624092,  0.0276080687, -1.5195924044,\n",
            "         0.2068519890,  0.0056714360])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.0219726562, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6330516338), tensor(0.9806538224), tensor(1.1749070883), tensor(1.1833257675), tensor(1.1126658916), tensor(1.4420528412), tensor(1.0779247284), tensor(1.1661775112), tensor(0.9411381483), tensor(1.2408454418), tensor(1.1027665138), tensor(1.5032899380), tensor(1.0351297855), tensor(1.2607878447), tensor(1.1764346361), tensor(1.0002892017), tensor(1.0810132027), tensor(0.8925961256), tensor(1.0901346207), tensor(1.0072015524)]\n",
            "b:  [tensor(0.6077936888), tensor(1.0887399912), tensor(1.3489260674), tensor(1.0524305105), tensor(1.4822119474), tensor(0.8105074763), tensor(1.2298467159), tensor(1.1656805277), tensor(1.7899526358), tensor(0.8490704298), tensor(1.2767437696), tensor(0.6969966888), tensor(1.2958236933), tensor(1.2393581867), tensor(0.9151479006), tensor(1.0213761330), tensor(1.2981758118), tensor(1.7416415215), tensor(1.0027327538), tensor(1.1807484627)]\n",
            "c:  [tensor(-0.0027846361), tensor(0.0154047655), tensor(0.0152175352), tensor(-0.0015547435), tensor(-0.0019908666), tensor(-0.0044119316), tensor(0.0005858063), tensor(0.0001703773), tensor(0.0169299878), tensor(0.0018973963), tensor(0.0104360953), tensor(0.0061840629), tensor(0.0088164490), tensor(0.0104475394), tensor(0.0068910499), tensor(0.0148347449), tensor(0.0011368695), tensor(-0.0011300847)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.1839685738, -0.0367724895, -0.0801312923, -0.0237101316,\n",
            "        -0.1050423384,  0.0702382326, -0.0556048751, -0.0490032434,\n",
            "        -0.1126875877,  0.0345845222, -0.0593132973,  0.1187446117,\n",
            "        -0.0614148378, -0.0593473911,  0.0101374462, -0.0213249326,\n",
            "        -0.0650883913, -0.0964998603, -0.0156372488, -0.0427296162])\n",
            "btensor.grad: tensor([-0.0244498253, -0.0067644119, -0.0528971851, -0.0375782251,\n",
            "        -0.0364620388, -0.0426993370, -0.0238938928, -0.0356825590,\n",
            "         0.0489137061, -0.0352047086, -0.0328764915, -0.0341273695,\n",
            "        -0.0107386038, -0.0737205744, -0.0322333574, -0.0059351921,\n",
            "        -0.0206757635,  0.0634312630, -0.0238644481, -0.0058691502])\n",
            "ctensor.grad: tensor([ 0.7295213938, -3.1826353073, -2.8028478622,  0.3150900900,\n",
            "        -0.0051891673,  0.2338566333, -0.0489298478, -0.0395278931,\n",
            "        -2.2281012535,  0.0324476399, -1.7659132481,  0.2444861233,\n",
            "         0.0252071545, -2.1329932213,  0.0304744560, -1.6948217154,\n",
            "         0.2241306305, -0.0068802997])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.0032958984, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6322749853), tensor(0.9808455706), tensor(1.1752629280), tensor(1.1834607124), tensor(1.1131330729), tensor(1.4417787790), tensor(1.0781865120), tensor(1.1664187908), tensor(0.9416213036), tensor(1.2407242060), tensor(1.1030330658), tensor(1.5028078556), tensor(1.0354102850), tensor(1.2610559464), tensor(1.1764209270), tensor(1.0004068613), tensor(1.0813091993), tensor(0.8930135369), tensor(1.0902327299), tensor(1.0074045658)]\n",
            "b:  [tensor(0.6079126596), tensor(1.0888050795), tensor(1.3491859436), tensor(1.0526150465), tensor(1.4824044704), tensor(0.8107022047), tensor(1.2299822569), tensor(1.1658519506), tensor(1.7897626162), tensor(0.8492452502), tensor(1.2769219875), tensor(0.6971597672), tensor(1.2959017754), tensor(1.2397108078), tensor(0.9153109193), tensor(1.0214250088), tensor(1.2982912064), tensor(1.7413970232), tensor(1.0028634071), tensor(1.1808043718)]\n",
            "c:  [tensor(-0.0031676847), tensor(0.0171426553), tensor(0.0167532638), tensor(-0.0017357488), tensor(-0.0019878803), tensor(-0.0045461580), tensor(0.0006140219), tensor(0.0001933606), tensor(0.0181811545), tensor(0.0018792731), tensor(0.0114304386), tensor(0.0060494430), tensor(0.0088087600), tensor(0.0116323708), tensor(0.0068742405), tensor(0.0157794785), tensor(0.0010155434), tensor(-0.0011187099)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.1553371698, -0.0383506119, -0.0711593628, -0.0269846916,\n",
            "        -0.0934320092,  0.0548036098, -0.0523504019, -0.0482610464,\n",
            "        -0.0966291428,  0.0242396444, -0.0533011556,  0.0964077413,\n",
            "        -0.0561093390, -0.0536296368,  0.0027428716, -0.0235383511,\n",
            "        -0.0592051744, -0.0834842771, -0.0196297765, -0.0405954123])\n",
            "btensor.grad: tensor([-0.0237902999, -0.0130248070, -0.0519733578, -0.0369160771,\n",
            "        -0.0384935439, -0.0389410257, -0.0271074474, -0.0342833996,\n",
            "         0.0380057357, -0.0349662304, -0.0356317759, -0.0326208025,\n",
            "        -0.0156057701, -0.0705281496, -0.0326073170, -0.0097671747,\n",
            "        -0.0230770260,  0.0488951206, -0.0261258483, -0.0111839771])\n",
            "ctensor.grad: tensor([ 0.7660968304, -3.4757812023, -3.0714564323,  0.3620106876,\n",
            "        -0.0059726718,  0.2684523463, -0.0564312413, -0.0459666029,\n",
            "        -2.5023317337,  0.0362463742, -1.9886868000,  0.2692396045,\n",
            "         0.0153772961, -2.3696620464,  0.0336188190, -1.8894675970,\n",
            "         0.2426522672, -0.0227497350])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.9799804688, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6316187382), tensor(0.9810422063), tensor(1.1755784750), tensor(1.1836071014), tensor(1.1135526896), tensor(1.4415667057), tensor(1.0784331560), tensor(1.1666560173), tensor(0.9420417547), tensor(1.2406404018), tensor(1.1032711267), tensor(1.5024182796), tensor(1.0356671810), tensor(1.2612956762), tensor(1.1764330864), tensor(1.0005289316), tensor(1.0815788507), tensor(0.8933807611), tensor(1.0903439522), tensor(1.0075954199)]\n",
            "b:  [tensor(0.6080335975), tensor(1.0888954401), tensor(1.3494409323), tensor(1.0527969599), tensor(1.4826040268), tensor(0.8108849525), tensor(1.2301304340), tensor(1.1660150290), tensor(1.7896157503), tensor(0.8494217396), tensor(1.2771117687), tensor(0.6973217726), tensor(1.2959984541), tensor(1.2400518656), tensor(0.9154766798), tensor(1.0214864016), tensor(1.2984141111), tensor(1.7412134409), tensor(1.0030031204), tensor(1.1808805466)]\n",
            "c:  [tensor(-0.0035701571), tensor(0.0190472826), tensor(0.0184407122), tensor(-0.0019412320), tensor(-0.0019844824), tensor(-0.0046983454), tensor(0.0006462323), tensor(0.0002198571), tensor(0.0195836984), tensor(0.0018590649), tensor(0.0125479456), tensor(0.0059013786), tensor(0.0088074049), tensor(0.0129486201), tensor(0.0068556997), tensor(0.0168325659), tensor(0.0008842169), tensor(-0.0010975208)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.1312409937, -0.0393294394, -0.0631122589, -0.0292887688,\n",
            "        -0.0839278102,  0.0424219370, -0.0493198633, -0.0474348068,\n",
            "        -0.0840957165,  0.0167647004, -0.0476146936,  0.0779159367,\n",
            "        -0.0513882935, -0.0479357243, -0.0024388134, -0.0244146585,\n",
            "        -0.0539387465, -0.0734468848, -0.0222356915, -0.0381791592])\n",
            "btensor.grad: tensor([-0.0241919756, -0.0180641413, -0.0509995222, -0.0363826752,\n",
            "        -0.0399106443, -0.0365545750, -0.0296332240, -0.0326167345,\n",
            "         0.0293667428, -0.0353024602, -0.0379606485, -0.0324001461,\n",
            "        -0.0193340257, -0.0682135820, -0.0331563950, -0.0122900009,\n",
            "        -0.0245714933,  0.0367115736, -0.0279377699, -0.0152312517])\n",
            "ctensor.grad: tensor([ 8.0494469404e-01, -3.8092541695e+00, -3.3748979568e+00,\n",
            "         4.1096624732e-01, -6.7958636209e-03,  3.0437448621e-01,\n",
            "        -6.4420700073e-02, -5.2992917597e-02, -2.8050889969e+00,\n",
            "         4.0416419506e-02, -2.2350134850e+00,  2.9612889886e-01,\n",
            "         2.7095428668e-03, -2.6324987411e+00,  3.7081185728e-02,\n",
            "        -2.1061744690e+00,  2.6265293360e-01, -4.2378142476e-02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.9545898438, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6310628653), tensor(0.9812406898), tensor(1.1758565903), tensor(1.1837606430), tensor(1.1139328480), tensor(1.4414029121), tensor(1.0786646605), tensor(1.1668883562), tensor(0.9424123764), tensor(1.2405809164), tensor(1.1034808159), tensor(1.5021042824), tensor(1.0359017849), tensor(1.2615058422), tensor(1.1764611006), tensor(1.0006487370), tensor(1.0818237066), tensor(0.8937081695), tensor(1.0904616117), tensor(1.0077719688)]\n",
            "b:  [tensor(0.6081600785), tensor(1.0890057087), tensor(1.3496903181), tensor(1.0529762506), tensor(1.4828076363), tensor(0.8110605478), tensor(1.2302879095), tensor(1.1661676168), tensor(1.7895010710), tensor(0.8496019840), tensor(1.2773113251), tensor(0.6974871755), tensor(1.2961084843), tensor(1.2403850555), tensor(0.9156455398), tensor(1.0215543509), tensor(1.2985397577), tensor(1.7410799265), tensor(1.0031497478), tensor(1.1809710264)]\n",
            "c:  [tensor(-0.0039929659), tensor(0.0211411491), tensor(0.0202995222), tensor(-0.0021722321), tensor(-0.0019806516), tensor(-0.0048691398), tensor(0.0006827154), tensor(0.0002502174), tensor(0.0211538095), tensor(0.0018365573), tensor(0.0138018243), tensor(0.0057385312), tensor(0.0088138124), tensor(0.0144111617), tensor(0.0068352455), tensor(0.0180064607), tensor(0.0007419827), tensor(-0.0010644428)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.1111829653, -0.0396983325, -0.0556235313, -0.0307013988,\n",
            "        -0.0760353208,  0.0327553749, -0.0463051796, -0.0464673042,\n",
            "        -0.0741293430,  0.0118955597, -0.0419394970,  0.0627979934,\n",
            "        -0.0469276607, -0.0420334339, -0.0056070909, -0.0239570141,\n",
            "        -0.0489594936, -0.0654873401, -0.0235394835, -0.0353009701])\n",
            "btensor.grad: tensor([-0.0252961516, -0.0220546722, -0.0498828292, -0.0358532667,\n",
            "        -0.0407196879, -0.0351140499, -0.0315003395, -0.0305249691,\n",
            "         0.0229383297, -0.0360537171, -0.0399012566, -0.0330851674,\n",
            "        -0.0219970196, -0.0666329861, -0.0337736607, -0.0135823488,\n",
            "        -0.0251404345,  0.0267128944, -0.0293146968, -0.0181014538])\n",
            "ctensor.grad: tensor([ 0.8456174731, -4.1877312660, -3.7176208496,  0.4620002508,\n",
            "        -0.0076613571,  0.3415882885, -0.0729661956, -0.0607206635,\n",
            "        -3.1402211189,  0.0450152159, -2.5077574253,  0.3256947696,\n",
            "        -0.0128149716, -2.9250824451,  0.0409080200, -2.3477909565,\n",
            "         0.2844682634, -0.0661561117])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.9191894531, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6305888891), tensor(0.9814374447), tensor(1.1760981083), tensor(1.1839166880), tensor(1.1142792702), tensor(1.4412750006), tensor(1.0788799524), tensor(1.1671146154), tensor(0.9427419305), tensor(1.2405332327), tensor(1.1036603451), tensor(1.5018507242), tensor(1.0361137390), tensor(1.2616840601), tensor(1.1764951944), tensor(1.0007590055), tensor(1.0820432901), tensor(0.8940023780), tensor(1.0905792713), tensor(1.0079303980)]\n",
            "b:  [tensor(0.6082943082), tensor(1.0891311169), tensor(1.3499327898), tensor(1.0531520844), tensor(1.4830118418), tensor(0.8112318516), tensor(1.2304513454), tensor(1.1663066149), tensor(1.7894071341), tensor(0.8497874141), tensor(1.2775183916), tensor(0.6976591945), tensor(1.2962263823), tensor(1.2407131195), tensor(0.9158173203), tensor(1.0216224194), tensor(1.2986631393), tensor(1.7409857512), tensor(1.0033007860), tensor(1.1810700893)]\n",
            "c:  [tensor(-0.0044366354), tensor(0.0234493949), tensor(0.0223518983), tensor(-0.0024297831), tensor(-0.0019763659), tensor(-0.0050591389), tensor(0.0007237880), tensor(0.0002848618), tensor(0.0229097065), tensor(0.0018115025), tensor(0.0152066890), tensor(0.0055591809), tensor(0.0088292621), tensor(0.0160368327), tensor(0.0068126689), tensor(0.0193151105), tensor(0.0005876902), tensor(-0.0010172814)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0947958976, -0.0393524468, -0.0482962132, -0.0312082767,\n",
            "        -0.0692940354,  0.0255861282, -0.0430591106, -0.0452470779,\n",
            "        -0.0659120083,  0.0095248967, -0.0359073877,  0.0507197976,\n",
            "        -0.0423789620, -0.0356382132, -0.0068194717, -0.0220608115,\n",
            "        -0.0439224243, -0.0588364154, -0.0235428512, -0.0316793919])\n",
            "btensor.grad: tensor([-0.0268430710, -0.0250843763, -0.0484889299, -0.0351768732,\n",
            "        -0.0408307314, -0.0342653990, -0.0326772630, -0.0277991295,\n",
            "         0.0187836774, -0.0370855331, -0.0414181948, -0.0344086587,\n",
            "        -0.0235694349, -0.0656239986, -0.0343549252, -0.0136068463,\n",
            "        -0.0246875286,  0.0188459158, -0.0302078128, -0.0198103189])\n",
            "ctensor.grad: tensor([ 0.8873391151, -4.6164927483, -4.1047539711,  0.5151019692,\n",
            "        -0.0085714031,  0.3799981475, -0.0821453184, -0.0692887530,\n",
            "        -3.5117921829,  0.0501096025, -2.8097286224,  0.3587004840,\n",
            "        -0.0308987498, -3.2513406277,  0.0451536886, -2.6172981262,\n",
            "         0.3085850477, -0.0943226889])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.8787841797, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6301797628), tensor(0.9816280603), tensor(1.1763017178), tensor(1.1840702295), tensor(1.1145955324), tensor(1.4411708117), tensor(1.0790762901), tensor(1.1673326492), tensor(0.9430354834), tensor(1.2404848337), tensor(1.1038058996), tensor(1.5016434193), tensor(1.0363005400), tensor(1.2618260384), tensor(1.1765252352), tensor(1.0008515120), tensor(1.0822354555), tensor(0.8942663670), tensor(1.0906897783), tensor(1.0080653429)]\n",
            "b:  [tensor(0.6084375381), tensor(1.0892670155), tensor(1.3501659632), tensor(1.0533229113), tensor(1.4832123518), tensor(0.8114004135), tensor(1.2306165695), tensor(1.1664274931), tensor(1.7893217802), tensor(0.8499786854), tensor(1.2777305841), tensor(0.6978400350), tensor(1.2963461876), tensor(1.2410382032), tensor(0.9159910679), tensor(1.0216836929), tensor(1.2987782955), tensor(1.7409199476), tensor(1.0034533739), tensor(1.1811714172)]\n",
            "c:  [tensor(-0.0049011461), tensor(0.0260000434), tensor(0.0246229265), tensor(-0.0027148710), tensor(-0.0019716022), tensor(-0.0052688490), tensor(0.0007698113), tensor(0.0003242946), tensor(0.0248716883), tensor(0.0017836137), tensor(0.0167784188), tensor(0.0053610657), tensor(0.0088546164), tensor(0.0178445838), tensor(0.0067877276), tensor(0.0207739528), tensor(0.0004198290), tensor(-0.0009538670)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0818307772, -0.0381282568, -0.0407104492, -0.0307159424,\n",
            "        -0.0632570386,  0.0208266973, -0.0392746925, -0.0436060429,\n",
            "        -0.0587093830,  0.0096787438, -0.0291037560,  0.0414664745,\n",
            "        -0.0373521447, -0.0283883810, -0.0060135350, -0.0185044408,\n",
            "        -0.0384434462, -0.0527952462, -0.0221084654, -0.0269963145])\n",
            "btensor.grad: tensor([-0.0286473632, -0.0271693468, -0.0466238409, -0.0341758132,\n",
            "        -0.0400934815, -0.0337182283, -0.0330560505, -0.0241652727,\n",
            "         0.0170741864, -0.0382514596, -0.0424307585, -0.0361648947,\n",
            "        -0.0239524767, -0.0650242567, -0.0347547531, -0.0122505426,\n",
            "        -0.0230288059,  0.0131542683, -0.0305293798, -0.0202716589])\n",
            "ctensor.grad: tensor([ 0.9290210009, -5.1012954712, -4.5420570374,  0.5701755285,\n",
            "        -0.0095275147,  0.4194199145, -0.0920465216, -0.0788656771,\n",
            "        -3.9239621162,  0.0557776727, -3.1434588432,  0.3962305486,\n",
            "        -0.0507093109, -3.6155014038,  0.0498823598, -2.9176857471,\n",
            "         0.3357223868, -0.1268288195])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.8281250000, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6298189163), tensor(0.9818068743), tensor(1.1764636040), tensor(1.1842155457), tensor(1.1148829460), tensor(1.4410783052), tensor(1.0792492628), tensor(1.1675392389), tensor(0.9432947040), tensor(1.2404221296), tensor(1.1039110422), tensor(1.5014686584), tensor(1.0364575386), tensor(1.2619252205), tensor(1.1765402555), tensor(1.0009162426), tensor(1.0823957920), tensor(0.8944998384), tensor(1.0907849073), tensor(1.0081695318)]\n",
            "b:  [tensor(0.6085903645), tensor(1.0894081593), tensor(1.3503861427), tensor(1.0534859896), tensor(1.4834038019), tensor(0.8115662932), tensor(1.2307789326), tensor(1.1665238142), tensor(1.7892311811), tensor(0.8501757383), tensor(1.2779445648), tensor(0.6980309486), tensor(1.2964609861), tensor(1.2413613796), tensor(0.9161651134), tensor(1.0217300653), tensor(1.2988777161), tensor(1.7408709526), tensor(1.0036039352), tensor(1.1812680960)]\n",
            "c:  [tensor(-0.0053856983), tensor(0.0288241599), tensor(0.0271408632), tensor(-0.0030283779), tensor(-0.0019663372), tensor(-0.0054986253), tensor(0.0008211970), tensor(0.0003691234), tensor(0.0270620696), tensor(0.0017525580), tensor(0.0185338259), tensor(0.0051411451), tensor(0.0088898987), tensor(0.0198555645), tensor(0.0067601423), tensor(0.0223998055), tensor(0.0002363601), tensor(-0.0008723132)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0721706524, -0.0357587039, -0.0323791504, -0.0290534496,\n",
            "        -0.0574749708,  0.0184987783, -0.0345884562, -0.0413215160,\n",
            "        -0.0518442392,  0.0125461072, -0.0210397243,  0.0349469185,\n",
            "        -0.0314055681, -0.0198469162, -0.0029957145, -0.0129364133,\n",
            "        -0.0320752859, -0.0466955006, -0.0190146863, -0.0208414793])\n",
            "btensor.grad: tensor([-0.0305681825, -0.0282180309, -0.0440304875, -0.0326145291,\n",
            "        -0.0382835865, -0.0331770182, -0.0324724913, -0.0192730427,\n",
            "         0.0181261376, -0.0394086242, -0.0427944660, -0.0381800234,\n",
            "        -0.0229569077, -0.0646401644, -0.0348119736, -0.0092855692,\n",
            "        -0.0198851824,  0.0097942352, -0.0301234126, -0.0193266869])\n",
            "ctensor.grad: tensor([ 0.9691041112, -5.6482334137, -5.0358719826,  0.6270138621,\n",
            "        -0.0105302176,  0.4595530927, -0.1027713567, -0.0896574333,\n",
            "        -4.3807606697,  0.0621113628, -3.5108141899,  0.4398410022,\n",
            "        -0.0705641732, -4.0219612122,  0.0551701672, -3.2517046928,\n",
            "         0.3669377565, -0.1631077230])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.7661132812, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6294897795), tensor(0.9819663763), tensor(1.1765774488), tensor(1.1843452454), tensor(1.1151403189), tensor(1.4409844875), tensor(1.0793919563), tensor(1.1677297354), tensor(0.9435178638), tensor(1.2403298616), tensor(1.1039667130), tensor(1.5013127327), tensor(1.0365777016), tensor(1.2619725466), tensor(1.1765273809), tensor(1.0009405613), tensor(1.0825172663), tensor(0.8946991563), tensor(1.0908544064), tensor(1.0082330704)]\n",
            "b:  [tensor(0.6087527275), tensor(1.0895485878), tensor(1.3505880833), tensor(1.0536370277), tensor(1.4835791588), tensor(0.8117281199), tensor(1.2309322357), tensor(1.1665872335), tensor(1.7891192436), tensor(0.8503776789), tensor(1.2781560421), tensor(0.6982325315), tensor(1.2965624332), tensor(1.2416826487), tensor(0.9163366556), tensor(1.0217519999), tensor(1.2989521027), tensor(1.7408256531), tensor(1.0037478209), tensor(1.1813516617)]\n",
            "c:  [tensor(-0.0058884663), tensor(0.0319558680), tensor(0.0299373306), tensor(-0.0033710075), tensor(-0.0019605479), tensor(-0.0057485970), tensor(0.0008784150), tensor(0.0004200805), tensor(0.0295049213), tensor(0.0017179486), tensor(0.0204900503), tensor(0.0048952661), tensor(0.0089336298), tensor(0.0220931042), tensor(0.0067295884), tensor(0.0242105443), tensor(3.4462223994e-05), tensor(-0.0007714440)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0658186004, -0.0318955183, -0.0227577686, -0.0259485245,\n",
            "        -0.0514768362,  0.0187618732, -0.0285483003, -0.0380963087,\n",
            "        -0.0446296930,  0.0184583366, -0.0111404657,  0.0311970413,\n",
            "        -0.0240246356, -0.0094745159,  0.0025722831, -0.0048643947,\n",
            "        -0.0242869854, -0.0398641527, -0.0139087439, -0.0127000213])\n",
            "btensor.grad: tensor([-0.0324698687, -0.0280927420, -0.0403823406, -0.0302109122,\n",
            "        -0.0350796282, -0.0323704481, -0.0306624770, -0.0126883984,\n",
            "         0.0223911442, -0.0403932333, -0.0423018932, -0.0403137952,\n",
            "        -0.0202892944, -0.0642486811, -0.0343099833, -0.0043907166,\n",
            "        -0.0148866475,  0.0090559721, -0.0287746787, -0.0167121887])\n",
            "ctensor.grad: tensor([ 1.0055360794, -6.2634143829, -5.5929341316,  0.6852592826,\n",
            "        -0.0115785617,  0.4999432266, -0.1144359037, -0.1019142866,\n",
            "        -4.8857021332,  0.0692189559, -3.9124481678,  0.4917578101,\n",
            "        -0.0874617994, -4.4750795364,  0.0611078404, -3.6214778423,\n",
            "         0.4037956595, -0.2017383128])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.6892089844, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6291751862), tensor(0.9820967913), tensor(1.1766334772), tensor(1.1844503880), tensor(1.1153640747), tensor(1.4408750534), tensor(1.0794950724), tensor(1.1678975821), tensor(0.9436997175), tensor(1.2401903868), tensor(1.1039602757), tensor(1.5011608601), tensor(1.0366506577), tensor(1.2619556189), tensor(1.1764715910), tensor(1.0009089708), tensor(1.0825895071), tensor(0.8948570490), tensor(1.0908861160), tensor(1.0082428455)]\n",
            "b:  [tensor(0.6089238524), tensor(1.0896813869), tensor(1.3507643938), tensor(1.0537700653), tensor(1.4837294817), tensor(0.8118830323), tensor(1.2310687304), tensor(1.1666065454), tensor(1.7889667749), tensor(0.8505827785), tensor(1.2783594131), tensor(0.6984446049), tensor(1.2966402769), tensor(1.2420005798), tensor(0.9165016413), tensor(1.0217376947), tensor(1.2989898920), tensor(1.7407689095), tensor(1.0038788319), tensor(1.1814119816)]\n",
            "c:  [tensor(-0.0064062811), tensor(0.0354320928), tensor(0.0330473632), tensor(-0.0037431901), tensor(-0.0019542130), tensor(-0.0060185692), tensor(0.0009420010), tensor(0.0004780491), tensor(0.0322255455), tensor(0.0016793346), tensor(0.0226635411), tensor(0.0046176999), tensor(0.0089818649), tensor(0.0245824847), tensor(0.0066956864), tensor(0.0262244977), tensor(-0.0001898242), tensor(-0.0006514605)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0629079714, -0.0260777473, -0.0112025738, -0.0210400820,\n",
            "        -0.0447566509,  0.0218875408, -0.0206137300, -0.0335578918,\n",
            "        -0.0363669395,  0.0279043764,  0.0012887716,  0.0303738117,\n",
            "        -0.0145923793,  0.0033897161,  0.0111541376,  0.0063295364,\n",
            "        -0.0144490004, -0.0315729529, -0.0063339472, -0.0019651651])\n",
            "btensor.grad: tensor([-0.0342298746, -0.0265593529, -0.0352680981, -0.0266146064,\n",
            "        -0.0300691128, -0.0309859514, -0.0273024440, -0.0038626194,\n",
            "         0.0304852445, -0.0410193205, -0.0406726599, -0.0424189419,\n",
            "        -0.0155755281, -0.0635895729, -0.0329995155,  0.0028712749,\n",
            "        -0.0075494796,  0.0113470554, -0.0262064338, -0.0120667219])\n",
            "ctensor.grad: tensor([ 1.0356296301, -6.9524531364, -6.2200646400,  0.7443649173,\n",
            "        -0.0126696713,  0.5399444699, -0.1271721125, -0.1159372181,\n",
            "        -5.4412503242,  0.0772279501, -4.3469829559,  0.5551321507,\n",
            "        -0.0964695960, -4.9787621498,  0.0678038821, -4.0279064178,\n",
            "         0.4485727847, -0.2399670482])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.5947265625, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6288566589), tensor(0.9821855426), tensor(1.1766184568), tensor(1.1845196486), tensor(1.1155478954), tensor(1.4407335520), tensor(1.0795457363), tensor(1.1680338383), tensor(0.9438312650), tensor(1.2399828434), tensor(1.1038750410), tensor(1.5009970665), tensor(1.0366626978), tensor(1.2618579865), tensor(1.1763547659), tensor(1.0008018017), tensor(1.0825986862), tensor(0.8949622512), tensor(1.0908645391), tensor(1.0081825256)]\n",
            "b:  [tensor(0.6091024876), tensor(1.0897979736), tensor(1.3509052992), tensor(1.0538772345), tensor(1.4838430882), tensor(0.8120266199), tensor(1.2311785221), tensor(1.1665673256), tensor(1.7887508869), tensor(0.8507881761), tensor(1.2785471678), tensor(0.6986663938), tensor(1.2966818810), tensor(1.2423124313), tensor(0.9166545868), tensor(1.0216723680), tensor(1.2989763021), tensor(1.7406828403), tensor(1.0039893389), tensor(1.1814366579)]\n",
            "c:  [tensor(-0.0069342856), tensor(0.0392919257), tensor(0.0365091488), tensor(-0.0041449647), tensor(-0.0019473140), tensor(-0.0063079111), tensor(0.0010125636), tensor(0.0005440880), tensor(0.0352495536), tensor(0.0016361908), tensor(0.0250685327), tensor(0.0043005226), tensor(0.0090268310), tensor(0.0273504406), tensor(0.0066579925), tensor(0.0284594111), tensor(-0.0004420982), tensor(-0.0005149461)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0636965930, -0.0177500248,  0.0030035973, -0.0138620138,\n",
            "        -0.0367562175,  0.0282940865, -0.0101261139, -0.0272538662,\n",
            "        -0.0263134241,  0.0415193960,  0.0170477629,  0.0327555537,\n",
            "        -0.0024005175,  0.0195201635,  0.0233587176,  0.0214221478,\n",
            "        -0.0018444061, -0.0210345685,  0.0043115020,  0.0120614767])\n",
            "btensor.grad: tensor([-0.0357265472, -0.0233112574, -0.0281886905, -0.0214372277,\n",
            "        -0.0227293074, -0.0287139416, -0.0219651759,  0.0078552961,\n",
            "         0.0431815423, -0.0410811901, -0.0375595093, -0.0443600565,\n",
            "        -0.0083201379, -0.0623651743, -0.0305862427,  0.0130548477,\n",
            "         0.0027242899,  0.0172132254, -0.0220915079, -0.0049318075])\n",
            "ctensor.grad: tensor([ 1.0560088158, -7.7196664810, -6.9235696793,  0.8035491705,\n",
            "        -0.0137980627,  0.5786834955, -0.1411252171, -0.1320777833,\n",
            "        -6.0480127335,  0.0862874091, -4.8099837303,  0.6343541741,\n",
            "        -0.0899320841, -5.5359125137,  0.0753876343, -4.4698271751,\n",
            "         0.5045479536, -0.2730289102])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.4782714844, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6285138130), tensor(0.9822168946), tensor(1.1765151024), tensor(1.1845389605), tensor(1.1156823635), tensor(1.4405411482), tensor(1.0795274973), tensor(1.1681271791), tensor(0.9438997507), tensor(1.2396825552), tensor(1.1036899090), tensor(1.5008033514), tensor(1.0365959406), tensor(1.2616589069), tensor(1.1761552095), tensor(1.0005953312), tensor(1.0825269222), tensor(0.8949992061), tensor(1.0907709599), tensor(1.0080317259)]\n",
            "b:  [tensor(0.6092867255), tensor(1.0898878574), tensor(1.3509981632), tensor(1.0539484024), tensor(1.4839054346), tensor(0.8121526837), tensor(1.2312493324), tensor(1.1664513350), tensor(1.7884439230), tensor(0.8509899974), tensor(1.2787100077), tensor(0.6988964081), tensor(1.2966716290), tensor(1.2426136732), tensor(0.9167882204), tensor(1.0215384960), tensor(1.2988932133), tensor(1.7405462265), tensor(1.0040695667), tensor(1.1814105511)]\n",
            "c:  [tensor(-0.0074656312), tensor(0.0435754210), tensor(0.0403633192), tensor(-0.0045758444), tensor(-0.0019398365), tensor(-0.0066154264), tensor(0.0010907863), tensor(0.0006194515), tensor(0.0386014394), tensor(0.0015879062), tensor(0.0277148839), tensor(0.0039328355), tensor(0.0090551320), tensor(0.0304242279), tensor(0.0066159866), tensor(0.0309308656), tensor(-0.0007302609), tensor(-0.0003682847)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0685592368, -0.0062704086,  0.0206625462, -0.0038653612,\n",
            "        -0.0268896222,  0.0384925604,  0.0036478043, -0.0186684132,\n",
            "        -0.0136942863,  0.0600657538,  0.0370237231,  0.0387344956,\n",
            "         0.0133432746,  0.0398068428,  0.0399024077,  0.0413056612,\n",
            "         0.0143507719, -0.0073888451,  0.0187125504,  0.0301593542])\n",
            "btensor.grad: tensor([-0.0368488431, -0.0179868937, -0.0185791850, -0.0142245889,\n",
            "        -0.0124604106, -0.0252143145, -0.0141638517,  0.0232005119,\n",
            "         0.0614013709, -0.0403610468, -0.0325633287, -0.0460006148,\n",
            "         0.0020395443, -0.0602458715, -0.0267294645,  0.0267710686,\n",
            "         0.0166158378,  0.0273156166, -0.0160559416,  0.0052238703])\n",
            "ctensor.grad: tensor([ 1.0626914501, -8.5669898987, -7.7083392143,  0.8617589474,\n",
            "        -0.0149549572,  0.6150306463, -0.1564453989, -0.1507270187,\n",
            "        -6.7037744522,  0.0965692326, -5.2927031517,  0.7353736758,\n",
            "        -0.0566029027, -6.1475739479,  0.0840120539, -4.9429073334,\n",
            "         0.5763254762, -0.2933226824])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.3344726562, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6281241179), tensor(0.9821716547), tensor(1.1763020754), tensor(1.1844912767), tensor(1.1157552004), tensor(1.4402756691), tensor(1.0794199705), tensor(1.1681634188), tensor(0.9438884258), tensor(1.2392606735), tensor(1.1033791304), tensor(1.5005594492), tensor(1.0364285707), tensor(1.2613328695), tensor(1.1758474112), tensor(1.0002605915), tensor(1.0823518038), tensor(0.8949479461), tensor(1.0905828476), tensor(1.0077662468)]\n",
            "b:  [tensor(0.6094743013), tensor(1.0899389982), tensor(1.3510272503), tensor(1.0539710522), tensor(1.4838984013), tensor(0.8122534752), tensor(1.2312662601), tensor(1.1662365198), tensor(1.7880132198), tensor(0.8511832952), tensor(1.2788362503), tensor(0.6991325617), tensor(1.2965910435), tensor(1.2428981066), tensor(0.9168937206), tensor(1.0213149786), tensor(1.2987189293), tensor(1.7403342724), tensor(1.0041081905), tensor(1.1813157797)]\n",
            "c:  [tensor(-0.0079912217), tensor(0.0483217537), tensor(0.0446516573), tensor(-0.0050346688), tensor(-0.0019317728), tensor(-0.0069392282), tensor(0.0011774220), tensor(0.0007055936), tensor(0.0423026793), tensor(0.0015337730), tensor(0.0306053255), tensor(0.0034998595), tensor(0.0090455590), tensor(0.0338301882), tensor(0.0065690586), tensor(0.0336500295), tensor(-0.0010653473), tensor(-0.0002235421)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.0779371709,  0.0090452731,  0.0426003933,  0.0095359087,\n",
            "        -0.0145629048,  0.0531004667,  0.0215091109, -0.0072402954,\n",
            "         0.0022696257,  0.0843767971,  0.0621485114,  0.0487847030,\n",
            "         0.0334692299,  0.0652068853,  0.0615543760,  0.0669442415,\n",
            "         0.0350199938,  0.0102576762,  0.0376132131,  0.0531069040])\n",
            "btensor.grad: tensor([-0.0375172496, -0.0102169514, -0.0058290064, -0.0045203567,\n",
            "         0.0013950467, -0.0201576948, -0.0033757389,  0.0429517031,\n",
            "         0.0861475095, -0.0386557579, -0.0252445936, -0.0472255051,\n",
            "         0.0161154792, -0.0568864346, -0.0211060047,  0.0446962118,\n",
            "         0.0348549187,  0.0423891544, -0.0077329874,  0.0189540386])\n",
            "ctensor.grad: tensor([ 1.0511813164, -9.4926691055, -8.5766792297,  0.9176491499,\n",
            "        -0.0161274988,  0.6476036906, -0.1732713878, -0.1722842157,\n",
            "        -7.4024825096,  0.1082663313, -5.7808818817,  0.8659522533,\n",
            "         0.0191467274, -6.8119230270,  0.0938554630, -5.4383263588,\n",
            "         0.6701727509, -0.2894852757])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.1605224609, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6276626587), tensor(0.9820274115), tensor(1.1759542227), tensor(1.1843566895), tensor(1.1157515049), tensor(1.4399119616), tensor(1.0791987181), tensor(1.1681255102), tensor(0.9437770844), tensor(1.2386844158), tensor(1.1029126644), tensor(1.5002424717), tensor(1.0361347198), tensor(1.2608495951), tensor(1.1754021645), tensor(0.9997643232), tensor(1.0820467472), tensor(0.8947840929), tensor(1.0902742147), tensor(1.0073583126)]\n",
            "b:  [tensor(0.6096629500), tensor(1.0899373293), tensor(1.3509740829), tensor(1.0539307594), tensor(1.4838011265), tensor(0.8123198748), tensor(1.2312117815), tensor(1.1658972502), tensor(1.7874211073), tensor(0.8513624668), tensor(1.2789124250), tensor(0.6993725300), tensor(1.2964186668), tensor(1.2431579828), tensor(0.9169608951), tensor(1.0209778547), tensor(1.2984282970), tensor(1.7400184870), tensor(1.0040923357), tensor(1.1811319590)]\n",
            "c:  [tensor(-0.0084996903), tensor(0.0535667054), tensor(0.0494150259), tensor(-0.0055194707), tensor(-0.0019231238), tensor(-0.0072766356), tensor(0.0012732703), tensor(0.0008041404), tensor(0.0463693365), tensor(0.0014729800), tensor(0.0337323174), tensor(0.0029820208), tensor(0.0089667477), tensor(0.0375917368), tensor(0.0065164990), tensor(0.0366207771), tensor(-0.0014624712), tensor(-0.0001007532)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.0922994241, 0.0288450420, 0.0695774555, 0.0269086361, 0.0007431507,\n",
            "        0.0727359056, 0.0442410111, 0.0075773001, 0.0222679377, 0.1152435839,\n",
            "        0.0932941437, 0.0634005666, 0.0587591827, 0.0966576338, 0.0890454799,\n",
            "        0.0992484689, 0.0610023737, 0.0327730775, 0.0617168546, 0.0815792680])\n",
            "btensor.grad: tensor([-0.0377312899,  0.0003223419,  0.0106340647,  0.0080617666,\n",
            "         0.0194624662, -0.0132838488,  0.0108861625,  0.0678564310,\n",
            "         0.1184140295, -0.0358347297, -0.0152283907, -0.0479951650,\n",
            "         0.0344711617, -0.0519860983, -0.0134353638,  0.0674347878,\n",
            "         0.0581340641,  0.0631560087,  0.0031793714,  0.0367561579])\n",
            "ctensor.grad: tensor([  1.0169366598, -10.4899015427,  -9.5267333984,   0.9696036577,\n",
            "         -0.0172980335,   0.6748149395,  -0.1916967332,  -0.1970935613,\n",
            "         -8.1333169937,   0.1215859130,  -6.2539825439,   1.0356770754,\n",
            "          0.1576219499,  -7.5230946541,   0.1051196456,  -5.9414920807,\n",
            "          0.7942475677,  -0.2455777824])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1098.9487304688, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6271026134), tensor(0.9817595482), tensor(1.1754435301), tensor(1.1841133833), tensor(1.1156547070), tensor(1.4394223690), tensor(1.0788363218), tensor(1.1679944992), tensor(0.9435433149), tensor(1.2379181385), tensor(1.1022571325), tensor(1.4998275042), tensor(1.0356856585), tensor(1.2601748705), tensor(1.1747877598), tensor(0.9990697503), tensor(1.0815819502), tensor(0.8944798708), tensor(1.0898165703), tensor(1.0067784786)]\n",
            "b:  [tensor(0.6098511815), tensor(1.0898686647), tensor(1.3508179188), tensor(1.0538121462), tensor(1.4835900068), tensor(0.8123422861), tensor(1.2310670614), tensor(1.1654049158), tensor(1.7866261005), tensor(0.8515221477), tensor(1.2789238691), tensor(0.6996144652), tensor(1.2961312532), tensor(1.2433848381), tensor(0.9169788957), tensor(1.0205010176), tensor(1.2979935408), tensor(1.7395675182), tensor(1.0040082932), tensor(1.1808373928)]\n",
            "c:  [tensor(-0.0089777168), tensor(0.0593396127), tensor(0.0546905696), tensor(-0.0060273735), tensor(-0.0019139020), tensor(-0.0076241363), tensor(0.0013791302), tensor(0.0009168080), tensor(0.0508096516), tensor(0.0014046126), tensor(0.0370751023), tensor(0.0023542589), tensor(0.0087752249), tensor(0.0417268947), tensor(0.0064574876), tensor(0.0398364589), tensor(-0.0019417360), tensor(-3.0309689464e-05)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.1120181084, 0.0535690486, 0.1021413803, 0.0486602783, 0.0193580389,\n",
            "        0.0979278088, 0.0724734664, 0.0261927843, 0.0467526913, 0.1532632709,\n",
            "        0.1311179996, 0.0829909742, 0.0898014009, 0.1349487305, 0.1228870675,\n",
            "        0.1389153004, 0.0929704905, 0.0608409494, 0.0915335715, 0.1159608960])\n",
            "btensor.grad: tensor([-0.0376490355,  0.0137354136,  0.0312375873,  0.0237129331,\n",
            "         0.0422153175, -0.0044822693,  0.0289479345,  0.0984740257,\n",
            "         0.1589915752, -0.0319308043, -0.0022791624, -0.0483837426,\n",
            "         0.0574847162, -0.0453654528, -0.0036050081,  0.0953744054,\n",
            "         0.0869452506,  0.0901819468,  0.0167981982,  0.0589220524])\n",
            "ctensor.grad: tensor([  0.9560530782, -11.5458164215, -10.5510883331,   1.0158052444,\n",
            "         -0.0184436291,   0.6950010657,  -0.2117196620,  -0.2253352404,\n",
            "         -8.8806333542,   0.1367349476,  -6.6855716705,   1.2555238008,\n",
            "          0.3830464482,  -8.2703151703,   0.1180224344,  -6.4313611984,\n",
            "          0.9585295320,  -0.1408869177])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1098.6943359375, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6264164448), tensor(0.9813432097), tensor(1.1747415066), tensor(1.1837389469), tensor(1.1154483557), tensor(1.4387775660), tensor(1.0783039331), tensor(1.1677508354), tensor(0.9431646466), tensor(1.2369251251), tensor(1.1013780832), tensor(1.4992887974), tensor(1.0350518227), tensor(1.2592723370), tensor(1.1739718914), tensor(0.9981389046), tensor(1.0809258223), tensor(0.8940059543), tensor(1.0891807079), tensor(1.0059975386)]\n",
            "b:  [tensor(0.6100395918), tensor(1.0897196531), tensor(1.3505375385), tensor(1.0536007881), tensor(1.4832412004), tensor(0.8123118877), tensor(1.2308130264), tensor(1.1647300720), tensor(1.7855849266), tensor(0.8516584039), tensor(1.2788562775), tensor(0.6998578906), tensor(1.2957054377), tensor(1.2435702085), tensor(0.9169378877), tensor(1.0198584795), tensor(1.2973866463), tensor(1.7389491796), tensor(1.0038437843), tensor(1.1804106236)]\n",
            "c:  [tensor(-0.0094108656), tensor(0.0656604990), tensor(0.0605084561), tensor(-0.0065545738), tensor(-0.0019041339), tensor(-0.0079774521), tensor(0.0014957174), tensor(0.0010452461), tensor(0.0556221195), tensor(0.0013276648), tensor(0.0405978821), tensor(0.0015859015), tensor(0.0084146680), tensor(0.0462457240), tensor(0.0063910969), tensor(0.0432769284), tensor(-0.0025288488), tensor(-5.4870492022e-05)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.1372259259, 0.0832703412, 0.1404092312, 0.0748908520, 0.0412670374,\n",
            "        0.1289583445, 0.1064867973, 0.0487428904, 0.0757366419, 0.1985923350,\n",
            "        0.1758178473, 0.1077387929, 0.1267663538, 0.1804965734, 0.1631653905,\n",
            "        0.1861674786, 0.1312154531, 0.0947816223, 0.1271720827, 0.1561768055])\n",
            "btensor.grad: tensor([-0.0376764536,  0.0297993422,  0.0560761839,  0.0422700644,\n",
            "         0.0697682202,  0.0060787201,  0.0508166850,  0.1349625587,\n",
            "         0.2082402110, -0.0272477865,  0.0135220289, -0.0486823916,\n",
            "         0.0851619467, -0.0370768309,  0.0082045794,  0.1284991503,\n",
            "         0.1213765219,  0.1236639023,  0.0328904986,  0.0853422880])\n",
            "ctensor.grad: tensor([  0.8662966490, -12.6417741776, -11.6357755661,   1.0544002056,\n",
            "         -0.0195361655,   0.7066307068,  -0.2331745028,  -0.2568761110,\n",
            "         -9.6249341965,   0.1538955718,  -7.0455589294,   1.5367146730,\n",
            "          0.7211135030,  -9.0376558304,   0.1327812672,  -6.8809370995,\n",
            "          1.1742258072,   0.0491216071])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1098.3927001953, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6255781651), tensor(0.9807563424), tensor(1.1738221645), tensor(1.1832131147), tensor(1.1151188612), tensor(1.4379491806), tensor(1.0775740147), tensor(1.1673762798), tensor(0.9426218867), tensor(1.2356715202), tensor(1.1002435684), tensor(1.4986015558), tensor(1.0342060328), tensor(1.2581067085), tensor(1.1729253531), tensor(0.9969364405), tensor(1.0800489187), tensor(0.8933343887), tensor(1.0883404016), tensor(1.0049903393)]\n",
            "b:  [tensor(0.6102324724), tensor(1.0894811153), tensor(1.3501138687), tensor(1.0532855988), tensor(1.4827327728), tensor(0.8122228980), tensor(1.2304331064), tensor(1.1638457775), tensor(1.7842559814), tensor(0.8517710567), tensor(1.2786983252), tensor(0.7001053095), tensor(1.2951209545), tensor(1.2437080145), tensor(0.9168311357), tensor(1.0190278292), tensor(1.2965822220), tensor(1.7381331921), tensor(1.0035901070), tensor(1.1798342466)]\n",
            "c:  [tensor(-0.0097850496), tensor(0.0725380331), tensor(0.0668887645), tensor(-0.0070964387), tensor(-0.0018938623), tensor(-0.0083317542), tensor(0.0016235473), tensor(0.0011907965), tensor(0.0607949533), tensor(0.0012410694), tensor(0.0442502759), tensor(0.0006414871), tensor(0.0078174612), tensor(0.0511483625), tensor(0.0063163042), tensor(0.0469068661), tensor(-0.0032550504), tensor(-0.0002298435)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.1676523983, 0.1173688471, 0.1838636398, 0.1051653624, 0.0659012794,\n",
            "        0.1656759977, 0.1459878087, 0.0749124289, 0.1085573435, 0.2507235408,\n",
            "        0.2269028425, 0.1374372542, 0.1691697240, 0.2331328392, 0.2092984021,\n",
            "        0.2404925227, 0.1753818989, 0.1343111247, 0.1680651009, 0.2014324665])\n",
            "btensor.grad: tensor([-0.0385704637,  0.0477035046,  0.0847317576,  0.0630311370,\n",
            "         0.1016830504,  0.0178018808,  0.0759786516,  0.1768636703,\n",
            "         0.2657890916, -0.0225282907,  0.0315914154, -0.0494855493,\n",
            "         0.1169063598, -0.0275698900,  0.0213521719,  0.1661372185,\n",
            "         0.1608958691,  0.1632016897,  0.0507428050,  0.1152869463])\n",
            "ctensor.grad: tensor([  0.7483677864, -13.7550611496, -12.7606163025,   1.0837296247,\n",
            "         -0.0205433350,   0.7086047530,  -0.2556596994,  -0.2911006808,\n",
            "        -10.3456668854,   0.1731907874,  -7.3047904968,   1.8888287544,\n",
            "          1.1944136620,  -9.8052730560,   0.1495851576,  -7.2598767281,\n",
            "          1.4524029493,   0.3499459326])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1098.0405273438, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6245657206), tensor(0.9799839854), tensor(1.1726663113), tensor(1.1825212240), tensor(1.1146588326), tensor(1.4369124174), tensor(1.0766245127), tensor(1.1668573618), tensor(0.9419034719), tensor(1.2341299057), tensor(1.0988284349), tensor(1.4977449179), tensor(1.0331275463), tensor(1.2566469908), tensor(1.1716259718), tensor(0.9954341054), tensor(1.0789273977), tensor(0.8924427032), tensor(1.0872762203), tensor(1.0037398338)]\n",
            "b:  [tensor(0.6104400754), tensor(1.0891515017), tensor(1.3495333195), tensor(1.0528626442), tensor(1.4820491076), tensor(0.8120751381), tensor(1.2299169302), tensor(1.1627311707), tensor(1.7826043367), tensor(0.8518662453), tensor(1.2784447670), tensor(0.7003640532), tensor(1.2943642139), tensor(1.2437969446), tensor(0.9166580439), tensor(1.0179936886), tensor(1.2955614328), tensor(1.7370952368), tensor(1.0032449961), tensor(1.1790980101)]\n",
            "c:  [tensor(-0.0100884726), tensor(0.0799694061), tensor(0.0738394782), tensor(-0.0076477500), tensor(-0.0018831467), tensor(-0.0086820368), tensor(0.0017627957), tensor(0.0013541908), tensor(0.0663076416), tensor(0.0011437460), tensor(0.0479709059), tensor(-0.0005172332), tensor(0.0069092847), tensor(0.0564244129), tensor(0.0062320256), tensor(0.0506765097), tensor(-0.0041560112), tensor(-0.0006214427)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.2024924457, 0.1544726491, 0.2311694622, 0.1383826733, 0.0920169950,\n",
            "        0.2073593140, 0.1899076104, 0.1037868261, 0.1436854601, 0.3083189130,\n",
            "        0.2830329537, 0.1713328660, 0.2156943381, 0.2919343710, 0.2598699033,\n",
            "        0.3004644513, 0.2243087292, 0.1783372611, 0.2128318250, 0.2501102686])\n",
            "btensor.grad: tensor([-0.0415160656,  0.0659340620,  0.1161123365,  0.0845797062,\n",
            "         0.1367435157,  0.0295542479,  0.1032431573,  0.2229158878,\n",
            "         0.3303269744, -0.0190430880,  0.0507049561, -0.0517469645,\n",
            "         0.1513573974, -0.0177884102,  0.0346170664,  0.2068251967,\n",
            "         0.2041550279,  0.2075936794,  0.0690264702,  0.1472573280])\n",
            "ctensor.grad: tensor([  0.6068468094, -14.8627386093, -13.9014253616,   1.1026225090,\n",
            "         -0.0214311555,   0.7005648017,  -0.2784967721,  -0.3267885745,\n",
            "        -11.0253753662,   0.1946469098,  -7.4412560463,   2.3174402714,\n",
            "          1.8163527250, -10.5520973206,   0.1685577035,  -7.5392885208,\n",
            "          1.8019212484,   0.7831983566])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1097.6329345703, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6233638525), tensor(0.9790222645), tensor(1.1712653637), tensor(1.1816575527), tensor(1.1140705347), tensor(1.4356490374), tensor(1.0754426718), tensor(1.1661882401), tensor(0.9410099983), tensor(1.2322839499), tensor(1.0971183777), tensor(1.4967043400), tensor(1.0318068266), tensor(1.2548711300), tensor(1.1700628996), tensor(0.9936156273), tensor(1.0775476694), tensor(0.8913182020), tensor(1.0859801769), tensor(1.0022407770)]\n",
            "b:  [tensor(0.6106805205), tensor(1.0887403488), tensor(1.3487912416), tensor(1.0523387194), tensor(1.4811844826), tensor(0.8118767142), tensor(1.2292633057), tensor(1.1613759995), tensor(1.7806066275), tensor(0.8519592285), tensor(1.2781000137), tensor(0.7006478310), tensor(1.2934324741), tensor(1.2438429594), tensor(0.9164271355), tensor(1.0167522430), tensor(1.2943166494), tensor(1.7358213663), tensor(1.0028160810), tensor(1.1782033443)]\n",
            "c:  [tensor(-0.0103137372), tensor(0.0879425779), tensor(0.0813565180), tensor(-0.0082030762), tensor(-0.0018720627), tensor(-0.0090235872), tensor(0.0019131714), tensor(0.0015352515), tensor(0.0721347332), tensor(0.0010346645), tensor(0.0516941324), tensor(-0.0019282233), tensor(0.0056167827), tensor(0.0620544553), tensor(0.0061371671), tensor(0.0545255132), tensor(-0.0052695386), tensor(-0.0013016399)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.2403700948, 0.1923467815, 0.2801802158, 0.1727293730, 0.1176639795,\n",
            "        0.2526834011, 0.2363698483, 0.1338213682, 0.1786944866, 0.3691985607,\n",
            "        0.3420149386, 0.2081042230, 0.2641483545, 0.3551834822, 0.3126227260,\n",
            "        0.3637010753, 0.2759453654, 0.2249020487, 0.2592024803, 0.2998026609])\n",
            "btensor.grad: tensor([-0.0480912328,  0.0822239518,  0.1484124810,  0.1047816277,\n",
            "         0.1729178727,  0.0396802425,  0.1307307035,  0.2710270882,\n",
            "         0.3995463252, -0.0186003447,  0.0689407587, -0.0567556322,\n",
            "         0.1863498241, -0.0091981888,  0.0461857319,  0.2482909560,\n",
            "         0.2489648908,  0.2547646761,  0.0857942700,  0.1789320707])\n",
            "ctensor.grad: tensor([  0.4505285621, -15.9463443756, -15.0340824127,   1.1106517315,\n",
            "         -0.0221679322,   0.6831001639,  -0.3007512987,  -0.3621214926,\n",
            "        -11.6541852951,   0.2181629688,  -7.4464492798,   2.8219802380,\n",
            "          2.5850040913, -11.2600812912,   0.1897169799,  -7.6980061531,\n",
            "          2.2270550728,   1.3603943586])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1097.1679687500, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6219664812), tensor(0.9778816700), tensor(1.1696245670), tensor(1.1806282997), tensor(1.1133687496), tensor(1.4341497421), tensor(1.0740284920), tensor(1.1653733253), tensor(0.9399576187), tensor(1.2301307917), tensor(1.0951131582), tensor(1.4954744577), tensor(1.0302484035), tensor(1.2527681589), tensor(1.1682393551), tensor(0.9914798141), tensor(1.0759098530), tensor(0.8899613619), tensor(1.0844589472), tensor(1.0005028248)]\n",
            "b:  [tensor(0.6109810472), tensor(1.0882716179), tensor(1.3478949070), tensor(1.0517339706), tensor(1.4801470041), tensor(0.8116459846), tensor(1.2284833193), tensor(1.1597834826), tensor(1.7782548666), tensor(0.8520763516), tensor(1.2776808739), tensor(0.7009778619), tensor(1.2923369408), tensor(1.2438613176), tensor(0.9161580205), tensor(1.0153138638), tensor(1.2928540707), tensor(1.7343115807), tensor(1.0023226738), tensor(1.1771663427)]\n",
            "c:  [tensor(-0.0104594873), tensor(0.0964406058), tensor(0.0894261375), tensor(-0.0087572159), tensor(-0.0018606980), tensor(-0.0093524624), tensor(0.0020738496), tensor(0.0017326964), tensor(0.0782511532), tensor(0.0009129143), tensor(0.0553585105), tensor(-0.0036256055), tensor(0.0038770419), tensor(0.0680136383), tensor(0.0060306937), tensor(0.0583895817), tensor(-0.0066323909), tensor(-0.0023403806)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.2794852257, 0.2281189561, 0.3281500340, 0.2058415413, 0.1403610110,\n",
            "        0.2998694181, 0.2828301191, 0.1629740000, 0.2104796171, 0.4306247532,\n",
            "        0.4010516703, 0.2459673882, 0.3116900623, 0.4206039906, 0.3647120595,\n",
            "        0.4271661639, 0.3275708556, 0.2713665068, 0.3042554259, 0.3475786448])\n",
            "btensor.grad: tensor([-0.0601001978,  0.0937371850,  0.1792769283,  0.1209573150,\n",
            "         0.2074995041,  0.0461409092,  0.1560044438,  0.3184919357,\n",
            "         0.4703591466, -0.0234189034,  0.0838214159, -0.0660099536,\n",
            "         0.2191009223, -0.0036765337,  0.0538254976,  0.2876789570,\n",
            "         0.2925108075,  0.3019535542,  0.0986804366,  0.2074028254])\n",
            "ctensor.grad: tensor([  0.2915005386, -16.9960556030, -16.1392326355,   1.1082800627,\n",
            "         -0.0227293838,   0.6577497125,  -0.3213565350,  -0.3948899209,\n",
            "        -12.2328338623,   0.2435002476,  -7.3287544250,   3.3947641850,\n",
            "          3.4794816971, -11.9183626175,   0.2129465342,  -7.7281384468,\n",
            "          2.7257046700,   2.0774812698])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1096.6431884766, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6203768253), tensor(0.9765880704), tensor(1.1677635908), tensor(1.1794523001), tensor(1.1125812531), tensor(1.4324147701), tensor(1.0723959208), tensor(1.1644281149), tensor(0.9387789965), tensor(1.2276819944), tensor(1.0928268433), tensor(1.4940594435), tensor(1.0284719467), tensor(1.2503393888), tensor(1.1661733389), tensor(0.9890413880), tensor(1.0740287304), tensor(0.8883872032), tensor(1.0827345848), tensor(0.9985504746)]\n",
            "b:  [tensor(0.6113774180), tensor(1.0877842903), tensor(1.3468641043), tensor(1.0510826111), tensor(1.4789595604), tensor(0.8114116192), tensor(1.2276009321), tensor(1.1579712629), tensor(1.7755579948), tensor(0.8522552252), tensor(1.2772175074), tensor(0.7013825178), tensor(1.2911038399), tensor(1.2438774109), tensor(0.9158819914), tensor(1.0137037039), tensor(1.2911951542), tensor(1.7325810194), tensor(1.0017963648), tensor(1.1760183573)]\n",
            "c:  [tensor(-0.0105309924), tensor(0.1054465175), tensor(0.0980290622), tensor(-0.0093056150), tensor(-0.0018491461), tensor(-0.0096658273), tensor(0.0022435077), tensor(0.0019441448), tensor(0.0846375078), tensor(0.0007777655), tensor(0.0589147471), tensor(-0.0056364886), tensor(0.0016467485), tensor(0.0742765367), tensor(0.0059116981), tensor(0.0622083545), tensor(-0.0082769096), tensor(-0.0037965712)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.3179257512, 0.2587172687, 0.3721981049, 0.2351897955, 0.1574898362,\n",
            "        0.3470021486, 0.3265179992, 0.1890312433, 0.2357212305, 0.4897497892,\n",
            "        0.4572556317, 0.2829980254, 0.3552815318, 0.4857617617, 0.4131931067,\n",
            "        0.4876843095, 0.3762298822, 0.3148337603, 0.3448684514, 0.3904739022])\n",
            "btensor.grad: tensor([-0.0792717338,  0.0974540114,  0.2061673701,  0.1302827597,\n",
            "         0.2374967933,  0.0468759537,  0.1764691174,  0.3624365330,\n",
            "         0.5393830538, -0.0357785225,  0.0926725864, -0.0809261054,\n",
            "         0.2466297001, -0.0032145977,  0.0552077293,  0.3220424652,\n",
            "         0.3317865729,  0.3461035490,  0.1052561998,  0.2295998335])\n",
            "ctensor.grad: tensor([  0.1430110037, -18.0118141174, -17.2058410645,   1.0967986584,\n",
            "         -0.0231036954,   0.6267291307,  -0.3393160403,  -0.4228967428,\n",
            "        -12.7727050781,   0.2702976465,  -7.1124753952,   4.0217657089,\n",
            "          4.4605865479, -12.5258026123,   0.2379912436,  -7.6375417709,\n",
            "          3.2890369892,   2.9123811722])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1096.0551757812, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6186064482), tensor(0.9751808047), tensor(1.1657143831), tensor(1.1781595945), tensor(1.1117475033), tensor(1.4304523468), tensor(1.0705710649), tensor(1.1633778811), tensor(0.9375215769), tensor(1.2249609232), tensor(1.0902857780), tensor(1.4924718142), tensor(1.0265107155), tensor(1.2475962639), tensor(1.1638954878), tensor(0.9863285422), tensor(1.0719320774), tensor(0.8866235018), tensor(1.0808432102), tensor(0.9964202046)]\n",
            "b:  [tensor(0.6119120121), tensor(1.0873306990), tensor(1.3457299471), tensor(1.0504311323), tensor(1.4776587486), tensor(0.8112105727), tensor(1.2266517878), tensor(1.1559693813), tensor(1.7725400925), tensor(0.8525433540), tensor(1.2767519951), tensor(0.7018952966), tensor(1.2897722721), tensor(1.2439250946), tensor(0.9156401157), tensor(1.0119591951), tensor(1.2893743515), tensor(1.7306590080), tensor(1.0012788773), tensor(1.1748040915)]\n",
            "c:  [tensor(-0.0105393277), tensor(0.1149470508), tensor(0.1071449295), tensor(-0.0098446589), tensor(-0.0018374987), tensor(-0.0099620642), tensor(0.0024204710), tensor(0.0021663518), tensor(0.0912837908), tensor(0.0006287107), tensor(0.0623308495), tensor(-0.0079789590), tensor(-0.0010912023), tensor(0.0808218569), tensor(0.0057794573), tensor(0.0659322143), tensor(-0.0102283405), tensor(-0.0057100495)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.3540706635, 0.2814588547, 0.4098436832, 0.2585523129, 0.1667531729,\n",
            "        0.3924748898, 0.3649706841, 0.2100363970, 0.2514878511, 0.5442141294,\n",
            "        0.5082103014, 0.3175205886, 0.3922568262, 0.5486229658, 0.4555800557,\n",
            "        0.5425729752, 0.4193255901, 0.3527362049, 0.3782714009, 0.4260494709])\n",
            "btensor.grad: tensor([-0.1069138646,  0.0907165408,  0.2268418670,  0.1302921772,\n",
            "         0.2601535320,  0.0402135849,  0.1898346543,  0.4003818035,\n",
            "         0.6035715938, -0.0576281548,  0.0930923223, -0.1025548577,\n",
            "         0.2663130164, -0.0095336437,  0.0483778715,  0.3488965631,\n",
            "         0.3641678095,  0.3843982220,  0.1035033464,  0.2428553104])\n",
            "ctensor.grad: tensor([ 1.6671571881e-02, -1.9001071930e+01, -1.8231737137e+01,\n",
            "         1.0780879259e+00, -2.3294597864e-02,  5.9247416258e-01,\n",
            "        -3.5392653942e-01, -4.4441378117e-01, -1.3292566299e+01,\n",
            "         2.9810962081e-01, -6.8322033882e+00,  4.6849408150e+00,\n",
            "         5.4759011269e+00, -1.3090641022e+01,  2.6448187232e-01,\n",
            "        -7.4477119446e+00,  3.9028618336e+00,  3.8269569874e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1095.4042968750, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6166718006), tensor(0.9737080932), tensor(1.1635171175), tensor(1.1767873764), tensor(1.1109143496), tensor(1.4282757044), tensor(1.0685883760), tensor(1.1622544527), tensor(0.9362426400), tensor(1.2219979763), tensor(1.0875234604), tensor(1.4907295704), tensor(1.0244065523), tensor(1.2445564270), tensor(1.1614438295), tensor(0.9833776355), tensor(1.0696563721), tensor(0.8847067952), tensor(1.0788302422), tensor(0.9941561818)]\n",
            "b:  [tensor(0.6126300693), tensor(1.0869721174), tensor(1.3445309401), tensor(1.0498344898), tensor(1.4762914181), tensor(0.8110844493), tensor(1.2256789207), tensor(1.1538156271), tensor(1.7692363262), tensor(0.8529942632), tensor(1.2763350010), tensor(0.7025518417), tensor(1.2883905172), tensor(1.2440435886), tensor(0.9154793620), tensor(1.0101256371), tensor(1.2874349356), tensor(1.7285851240), tensor(1.0008178949), tensor(1.1735771894)]\n",
            "c:  [tensor(-0.0104993219), tensor(0.1249339432), tensor(0.1167554334), tensor(-0.0103717884), tensor(-0.0018258381), tensor(-0.0102406396), tensor(0.0026029369), tensor(0.0023956243), tensor(0.0981904790), tensor(0.0004654848), tensor(0.0655931681), tensor(-0.0106615890), tensor(-0.0043250322), tensor(0.0876354501), tensor(0.0056334673), tensor(0.0695260987), tensor(-0.0125034843), tensor(-0.0080964901)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.3869287968, 0.2945474684, 0.4394609928, 0.2744520903, 0.1666271687,\n",
            "        0.4353241920, 0.3965281844, 0.2246791124, 0.2557889223, 0.5925781727,\n",
            "        0.5524527431, 0.3484594822, 0.4208330512, 0.6079752445, 0.4903403521,\n",
            "        0.5901787281, 0.4551298618, 0.3833371997, 0.4026029110, 0.4528007507])\n",
            "btensor.grad: tensor([-0.1436172724,  0.0717104673,  0.2397993803,  0.1193202734,\n",
            "         0.2734610140,  0.0252292156,  0.1945843846,  0.4307442904,\n",
            "         0.6607483029, -0.0901830196,  0.0834032297, -0.1313127577,\n",
            "         0.2763508558, -0.0237079859,  0.0321464539,  0.3667158484,\n",
            "         0.3878888786,  0.4147735834,  0.0921936035,  0.2453893423])\n",
            "ctensor.grad: tensor([ -0.0800118893, -19.9737854004, -19.2210025787,   1.0542587042,\n",
            "         -0.0233212076,   0.5571500063,  -0.3649316430,  -0.4585452378,\n",
            "        -13.8133821487,   0.3264518380,  -6.5246329308,   5.3652606010,\n",
            "          6.4676589966, -13.6271896362,   0.2919801772,  -7.1877751350,\n",
            "          4.5502862930,   4.7728810310])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1094.6839599609, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6145901680), tensor(0.9722213149), tensor(1.1612145901), tensor(1.1753753424), tensor(1.1101315022), tensor(1.4258985519), tensor(1.0664852858), tensor(1.1610918045), tensor(0.9350033402), tensor(1.2188254595), tensor(1.0845750570), tensor(1.4888519049), tensor(1.0222047567), tensor(1.2412382364), tensor(1.1588584185), tensor(0.9802271724), tensor(1.0672409534), tensor(0.8826765418), tensor(1.0767445564), tensor(0.9918043017)]\n",
            "b:  [tensor(0.6135757565), tensor(1.0867733955), tensor(1.3433083296), tensor(1.0493503809), tensor(1.4749090672), tensor(0.8110747337), tensor(1.2247279882), tensor(1.1515504122), tensor(1.7656866312), tensor(0.8536627293), tensor(1.2760202885), tensor(0.7033863664), tensor(1.2870101929), tensor(1.2442734241), tensor(0.9154478908), tensor(1.0082496405), tensor(1.2854232788), tensor(1.7264040709), tensor(1.0004624128), tensor(1.1723942757)]\n",
            "c:  [tensor(-0.0104268389), tensor(0.1354026198), tensor(0.1268452555), tensor(-0.0108854370), tensor(-0.0018142309), tensor(-0.0105017936), tensor(0.0027892084), tensor(0.0026282845), tensor(0.1053668782), tensor(0.0002880623), tensor(0.0687036961), tensor(-0.0136842895), tensor(-0.0080154287), tensor(0.0947111472), tensor(0.0054734531), tensor(0.0729698017), tensor(-0.0151107470), tensor(-0.0109460056)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.4163245559, 0.2973567247, 0.4605171680, 0.2824040651, 0.1565794349,\n",
            "        0.4754364491, 0.4206168652, 0.2325178385, 0.2478613853, 0.6344951987,\n",
            "        0.5896749496, 0.3755410612, 0.4403632283, 0.6636351347, 0.5170832276,\n",
            "        0.6300967932, 0.4830888510, 0.4060471952, 0.4171352386, 0.4703806043])\n",
            "btensor.grad: tensor([-0.1891422570,  0.0397542715,  0.2445264757,  0.0968183875,\n",
            "         0.2764742374,  0.0019400120,  0.1901921481,  0.4530503750,\n",
            "         0.7099389434, -0.1336926222,  0.0629515648, -0.1669043750,\n",
            "         0.2760684490, -0.0459617376,  0.0062923431,  0.3751893044,\n",
            "         0.4023230672,  0.4362057447,  0.0711042285,  0.2365858555])\n",
            "ctensor.grad: tensor([ -0.1449651867, -20.9373645782, -20.1796550751,   1.0272972584,\n",
            "         -0.0232143067,   0.5223081708,  -0.3725427687,  -0.4653204978,\n",
            "        -14.3527917862,   0.3548449278,  -6.2210602760,   6.0454015732,\n",
            "          7.3807921410, -14.1513929367,   0.3200281560,  -6.8873996735,\n",
            "          5.2145247459,   5.6990308762])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1093.8911132812, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6123758554), tensor(0.9707692266), tensor(1.1588469744), tensor(1.1739606857), tensor(1.1094459295), tensor(1.4233310223), tensor(1.0642963648), tensor(1.1599218845), tensor(0.9338622093), tensor(1.2154723406), tensor(1.0814719200), tensor(1.4868556261), tensor(1.0199481249), tensor(1.2376564741), tensor(1.1561758518), tensor(0.9769116640), tensor(1.0647219419), tensor(0.8805695772), tensor(1.0746331215), tensor(0.9894067049)]\n",
            "b:  [tensor(0.6147881150), tensor(1.0867964029), tensor(1.3421007395), tensor(1.0490337610), tensor(1.4735621214), tensor(0.8112184405), tensor(1.2238422632), tensor(1.1492106915), tensor(1.7619298697), tensor(0.8545999527), tensor(1.2758594751), tensor(0.7044281363), tensor(1.2856805325), tensor(1.2446515560), tensor(0.9155899882), tensor(1.0063741207), tensor(1.2833834887), tensor(1.7241603136), tensor(1.0002573729), tensor(1.1713093519)]\n",
            "c:  [tensor(-0.0103360880), tensor(0.1463490576), tensor(0.1374009103), tensor(-0.0113848411), tensor(-0.0018027258), tensor(-0.0107461736), tensor(0.0029778755), tensor(0.0028610586), tensor(0.1128274202), tensor(9.6636387752e-05), tensor(0.0716745481), tensor(-0.0170401242), tensor(-0.0121001732), tensor(0.1020492539), tensor(0.0052993591), tensor(0.0762551054), tensor(-0.0180512629), tensor(-0.0142251030)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.4428555071, 0.2904182374, 0.4735321999, 0.2829240561, 0.1371028423,\n",
            "        0.5134978294, 0.4377759695, 0.2339891195, 0.2282308340, 0.6706271172,\n",
            "        0.6206328869, 0.3992591798, 0.4513254464, 0.7163565159, 0.5365151167,\n",
            "        0.6630988121, 0.5038134456, 0.4213874340, 0.4222757518, 0.4795154333])\n",
            "btensor.grad: tensor([-0.2424680889, -0.0046036243,  0.2415240407,  0.0633282661,\n",
            "         0.2693783343, -0.0287431479,  0.1771500111,  0.4679359198,\n",
            "         0.7513440251, -0.1874428391,  0.0321609974, -0.2083535492,\n",
            "         0.2659201622, -0.0756167173, -0.0284186602,  0.3751135468,\n",
            "         0.4079501033,  0.4487510920,  0.0410010815,  0.2169951200])\n",
            "ctensor.grad: tensor([ -0.1815009564, -21.8928718567, -21.1113128662,   0.9988081455,\n",
            "         -0.0230101217,   0.4887591898,  -0.3773343563,  -0.4655481577,\n",
            "        -14.9210815430,   0.3828518391,  -5.9416980743,   6.7116699219,\n",
            "          8.1694889069, -14.6762132645,   0.3481881320,  -6.5706057549,\n",
            "          5.8810305595,   6.5581955910])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1093.0260009766, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6100374460), tensor(0.9693933129), tensor(1.1564478874), tensor(1.1725740433), tensor(1.1088985205), tensor(1.4205772877), tensor(1.0620493889), tensor(1.1587707996), tensor(0.9328699112), tensor(1.2119607925), tensor(1.0782377720), tensor(1.4847521782), tensor(1.0176728964), tensor(1.2338187695), tensor(1.1534252167), tensor(0.9734578729), tensor(1.0621278286), tensor(0.8784158230), tensor(1.0725364685), tensor(0.9869982004)]\n",
            "b:  [tensor(0.6162981987), tensor(1.0870954990), tensor(1.3409403563), tensor(1.0489324331), tensor(1.4722956419), tensor(0.8115445375), tensor(1.2230584621), tensor(1.1468266249), tensor(1.7579994202), tensor(0.8558494449), tensor(1.2758976221), tensor(0.7056993842), tensor(1.2844442129), tensor(1.2452080250), tensor(0.9159423113), tensor(1.0045331717), tensor(1.2813528776), tensor(1.7218935490), tensor(1.0002403259), tensor(1.1703687906)]\n",
            "c:  [tensor(-0.0102376100), tensor(0.1577660888), tensor(0.1484082639), tensor(-0.0118697705), tensor(-0.0017913542), tensor(-0.0109744947), tensor(0.0031679049), tensor(0.0030913011), tensor(0.1205870956), tensor(-0.0001084173), tensor(0.0745213255), tensor(-0.0207175221), tensor(-0.0165008008), tensor(0.1096537635), tensor(0.0051113251), tensor(0.0793812796), tensor(-0.0213205274), tensor(-0.0178808719)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.4676919580, 0.2751842141, 0.4798159599, 0.2773339748, 0.1094925404,\n",
            "        0.5507472754, 0.4493943453, 0.2302134037, 0.1984597445, 0.7023119926,\n",
            "        0.6468287706, 0.4206823707, 0.4550409615, 0.7675350904, 0.5501289368,\n",
            "        0.6907618046, 0.5188232064, 0.4307553768, 0.4193270206, 0.4817005396])\n",
            "btensor.grad: tensor([-0.3020108044, -0.0598243475,  0.2320873588,  0.0202772617,\n",
            "         0.2532972693, -0.0652198792,  0.1567565799,  0.4768196344,\n",
            "         0.7860862613, -0.2498981357, -0.0076349974, -0.2542507946,\n",
            "         0.2472617626, -0.1112849712, -0.0704675913,  0.3681782484,\n",
            "         0.4061176777,  0.4533505440,  0.0034121275,  0.1881074905])\n",
            "ctensor.grad: tensor([-1.9695541263e-01, -2.2834062576e+01, -2.2014713287e+01,\n",
            "         9.6985954046e-01, -2.2743476555e-02,  4.5664298534e-01,\n",
            "        -3.8005894423e-01, -4.6048504114e-01, -1.5519351006e+01,\n",
            "         4.1010740399e-01, -5.6935529709e+00,  7.3547959328e+00,\n",
            "         8.8012552261e+00, -1.5209023476e+01,  3.7606811523e-01,\n",
            "        -6.2523527145e+00,  6.5385270119e+00,  7.3115377426e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1092.0842285156, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6075760126), tensor(0.9681251049), tensor(1.1540422440), tensor(1.1712367535), tensor(1.1085206270), tensor(1.4176338911), tensor(1.0597625971), tensor(1.1576572657), tensor(0.9320659041), tensor(1.2083050013), tensor(1.0748872757), tensor(1.4825464487), tensor(1.0154063702), tensor(1.2297247648), tensor(1.1506261826), tensor(0.9698826671), tensor(1.0594770908), tensor(0.8762357831), tensor(1.0704859495), tensor(0.9846040010)]\n",
            "b:  [tensor(0.6181277633), tensor(1.0877135992), tensor(1.3398504257), tensor(1.0490840673), tensor(1.4711456299), tensor(0.8120722771), tensor(1.2224044800), tensor(1.1444189548), tensor(1.7539203167), tensor(0.8574444056), tensor(1.2761700153), tensor(0.7072141171), tensor(1.2833341360), tensor(1.2459635735), tensor(0.9165317416), tensor(1.0027508736), tensor(1.2793595791), tensor(1.7196362019), tensor(1.0004386902), tensor(1.1696088314)]\n",
            "c:  [tensor(-0.0101371752), tensor(0.1696403623), tensor(0.1598499715), tensor(-0.0123402588), tensor(-0.0017801330), tensor(-0.0111873029), tensor(0.0033586319), tensor(0.0033170504), tensor(0.1286569387), tensor(-0.0003265899), tensor(0.0772567540), tensor(-0.0247024782), tensor(-0.0211300552), tensor(0.1175289452), tensor(0.0049096555), tensor(0.0823501945), tensor(-0.0249100849), tensor(-0.0218462385)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.4922935963, 0.2536370754, 0.4811224937, 0.2674477100, 0.0755841136,\n",
            "        0.5886842012, 0.4573590159, 0.2227041721, 0.1607968807, 0.7311605215,\n",
            "        0.6700897217, 0.4411552250, 0.4533099830, 0.8188043833, 0.5598121881,\n",
            "        0.7150356770, 0.5301472545, 0.4360121787, 0.4101008773, 0.4788426161])\n",
            "btensor.grad: tensor([-0.3659116030, -0.1236318350,  0.2179770470, -0.0303344131,\n",
            "         0.2300056815, -0.1055431366,  0.1307918876,  0.4815411568,\n",
            "         0.8158116937, -0.3189948201, -0.0544748306, -0.3029521108,\n",
            "         0.2220218480, -0.1511125565, -0.1178876162,  0.3564632535,\n",
            "         0.3986568451,  0.4514783621, -0.0396747589,  0.1519808769])\n",
            "ctensor.grad: tensor([-2.0086903870e-01, -2.3748537064e+01, -2.2883413315e+01,\n",
            "         9.4097590446e-01, -2.2442318499e-02,  4.2561611533e-01,\n",
            "        -3.8145399094e-01, -4.5149883628e-01, -1.6139675140e+01,\n",
            "         4.3634510040e-01, -5.4708585739e+00,  7.9699125290e+00,\n",
            "         9.2585086823e+00, -1.5750367165e+01,  4.0333867073e-01,\n",
            "        -5.9378223419e+00,  7.1791129112e+00,  7.9307322502e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1091.0668945312, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6049854755), tensor(0.9669857025), tensor(1.1516457796), tensor(1.1699606180), tensor(1.1083337069), tensor(1.4144902229), tensor(1.0574444532), tensor(1.1565920115), tensor(0.9314770699), tensor(1.2045116425), tensor(1.0714263916), tensor(1.4802365303), tensor(1.0131664276), tensor(1.2253664732), tensor(1.1477890015), tensor(0.9661938548), tensor(1.0567774773), tensor(0.8740406036), tensor(1.0685033798), tensor(0.9822397232)]\n",
            "b:  [tensor(0.6202892661), tensor(1.0886807442), tensor(1.3388451338), tensor(1.0495156050), tensor(1.4701380730), tensor(0.8128109574), tensor(1.2218986750), tensor(1.1419994831), tensor(1.7497091293), tensor(0.8594066501), tensor(1.2767006159), tensor(0.7089785337), tensor(1.2823727131), tensor(1.2469290495), tensor(0.9173747301), tensor(1.0010402203), tensor(1.2774220705), tensor(1.7174123526), tensor(1.0008695126), tensor(1.1690545082)]\n",
            "c:  [tensor(-0.0100357179), tensor(0.1819504648), tensor(0.1717033237), tensor(-0.0127963582), tensor(-0.0017690709), tensor(-0.0113848448), tensor(0.0035496780), tensor(0.0035369419), tensor(0.1370405704), tensor(-0.0005572945), tensor(0.0798858106), tensor(-0.0289803650), tensor(-0.0258988254), tensor(0.1256763637), tensor(0.0046947841), tensor(0.0851621330), tensor(-0.0288089104), tensor(-0.0260452870)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.5181022286, 0.2278854400, 0.4792897701, 0.2552205324, 0.0373834968,\n",
            "        0.6287239790, 0.4636397362, 0.2130460739, 0.1177688837, 0.7586725354,\n",
            "        0.6921695471, 0.4619862735, 0.4479923844, 0.8716518879, 0.5674477816,\n",
            "        0.7377625704, 0.5399217010, 0.4390375316, 0.3965228498, 0.4728554487])\n",
            "btensor.grad: tensor([-0.4322987199, -0.1934218407,  0.2010670602, -0.0863158703,\n",
            "         0.2015131414, -0.1477352381,  0.1011498272,  0.4839048386,\n",
            "         0.8422436714, -0.3924519420, -0.1061208248, -0.3528831005,\n",
            "         0.1922807395, -0.1931041479, -0.1685968637,  0.3421207666,\n",
            "         0.3874924779,  0.4447740316, -0.0861726403,  0.1108744144])\n",
            "ctensor.grad: tensor([-2.0291557908e-01, -2.4620208740e+01, -2.3706695557e+01,\n",
            "         9.1219806671e-01, -2.2124307230e-02,  3.9508342743e-01,\n",
            "        -3.8209241629e-01, -4.3978288770e-01, -1.6767250061e+01,\n",
            "         4.6140918136e-01, -5.2581095695e+00,  8.5557737350e+00,\n",
            "         9.5375385284e+00, -1.6294839859e+01,  4.2974281311e-01,\n",
            "        -5.6238837242e+00,  7.7976489067e+00,  8.3980970383e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1089.9766845703, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.6022540331), tensor(0.9659864902), tensor(1.1492661238), tensor(1.1687482595), tensor(1.1083496809), tensor(1.4111305475), tensor(1.0550947189), tensor(1.1555789709), tensor(0.9311179519), tensor(1.2005819082), tensor(1.0678542852), tensor(1.4778155088), tensor(1.0109629631), tensor(1.2207309008), tensor(1.1449159384), tensor(0.9623920918), tensor(1.0540274382), tensor(0.8718336225), tensor(1.0666018724), tensor(0.9799128771)]\n",
            "b:  [tensor(0.6227867603), tensor(1.0900137424), tensor(1.3379299641), tensor(1.0502434969), tensor(1.4692893028), tensor(0.8137612343), tensor(1.2215509415), tensor(1.1395726204), tensor(1.7453749180), tensor(0.8617469072), tensor(1.2775025368), tensor(0.7109919786), tensor(1.2815728188), tensor(1.2481060028), tensor(0.9184781909), tensor(0.9994052649), tensor(1.2755504847), tensor(1.7152388096), tensor(1.0015404224), tensor(1.1687200069)]\n",
            "c:  [tensor(-0.0099300602), tensor(0.1946664751), tensor(0.1839391589), tensor(-0.0132379634), tensor(-0.0017581729), tensor(-0.0115670487), tensor(0.0037408264), tensor(0.0037500411), tensor(0.1457322687), tensor(-0.0007999223), tensor(0.0824029446), tensor(-0.0335370675), tensor(-0.0307216104), tensor(0.1340926737), tensor(0.0044672331), tensor(0.0878129974), tensor(-0.0330043510), tensor(-0.0303979553)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.5462925434,  0.1998433024,  0.4759354591,  0.2424684763,\n",
            "        -0.0031948090,  0.6719305515,  0.4699434042,  0.2026166916,\n",
            "         0.0718203783,  0.7859455943,  0.7144296169,  0.4842033088,\n",
            "         0.4406882524,  0.9271200895,  0.5746124983,  0.7603572607,\n",
            "         0.5500074625,  0.4413971901,  0.3802951276,  0.4653728008])\n",
            "btensor.grad: tensor([-0.4995035231, -0.2666107416,  0.1830351204, -0.1455898285,\n",
            "         0.1697628498, -0.1900504827,  0.0695410967,  0.4853750467,\n",
            "         0.8668397665, -0.4680477977, -0.1603919268, -0.4026877880,\n",
            "         0.1599692404, -0.2353914976, -0.2206888199,  0.3269869685,\n",
            "         0.3743099272,  0.4347110987, -0.1341721416,  0.0669028759])\n",
            "ctensor.grad: tensor([-2.1131451428e-01, -2.5432004929e+01, -2.4471683502e+01,\n",
            "         8.8320958614e-01, -2.1796040237e-02,  3.6440753937e-01,\n",
            "        -3.8229680061e-01, -4.2619851232e-01, -1.7383392334e+01,\n",
            "         4.8525571823e-01, -5.0342664719e+00,  9.1134014130e+00,\n",
            "         9.6455698013e+00, -1.6832624435e+01,  4.5510181785e-01,\n",
            "        -5.3017253876e+00,  8.3908767700e+00,  8.7053375244e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1088.8160400391, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5993658304), tensor(0.9651315808), tensor(1.1469047070), tensor(1.1675950289), tensor(1.1085722446), tensor(1.4075362682), tensor(1.0527073145), tensor(1.1546169519), tensor(0.9309927225), tensor(1.1965142488), tensor(1.0641659498), tensor(1.4752736092), tensor(1.0088003874), tensor(1.2158026695), tensor(1.1420041323), tensor(0.9584742188), tensor(1.0512186289), tensor(0.8696131110), tensor(1.0647884607), tensor(0.9776251316)]\n",
            "b:  [tensor(0.6256176233), tensor(1.0917181969), tensor(1.3371043205), tensor(1.0512756109), tensor(1.4686074257), tensor(0.8149169683), tensor(1.2213644981), tensor(1.1371382475), tensor(1.7409222126), tensor(0.8644660711), tensor(1.2785794735), tensor(0.7132487297), tensor(1.2809398174), tensor(1.2494881153), tensor(0.9198412299), tensor(0.9978433251), tensor(1.2737486362), tensor(1.7131270170), tensor(1.0024510622), tensor(1.1686110497)]\n",
            "c:  [tensor(-0.0098142000), tensor(0.2077504545), tensor(0.1965218484), tensor(-0.0136647131), tensor(-0.0017474457), tensor(-0.0117335878), tensor(0.0039318870), tensor(0.0039556571), tensor(0.1547167599), tensor(-0.0010538889), tensor(0.0847917646), tensor(-0.0383593105), tensor(-0.0355197974), tensor(0.1427685469), tensor(0.0042275740), tensor(0.0902930424), tensor(-0.0374825858), tensor(-0.0348237902)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.5776358843,  0.1709837765,  0.4722797871,  0.2306548357,\n",
            "        -0.0445219874,  0.7188664675,  0.4774770737,  0.1924083233,\n",
            "         0.0250493288,  0.8135247827,  0.7376554012,  0.5083833933,\n",
            "         0.4325084090,  0.9856559038,  0.5823673606,  0.7835799456,\n",
            "         0.5617692471,  0.4441031218,  0.3626909256,  0.4575549364])\n",
            "btensor.grad: tensor([-0.5661743283, -0.3408840895,  0.1651356071, -0.2064253688,\n",
            "         0.1363770664, -0.2311493158,  0.0372930020,  0.4868643284,\n",
            "         0.8905347586, -0.5438301563, -0.2153884172, -0.4513459802,\n",
            "         0.1266118884, -0.2764309645, -0.2726100683,  0.3123906851,\n",
            "         0.3603663743,  0.4223682880, -0.1821211576,  0.0218027830])\n",
            "ctensor.grad: tensor([-2.3171959817e-01, -2.6167968750e+01, -2.5165384293e+01,\n",
            "         8.5350012779e-01, -2.1454466507e-02,  3.3307778835e-01,\n",
            "        -3.8212078810e-01, -4.1123196483e-01, -1.7968994141e+01,\n",
            "         5.0793325901e-01, -4.7776422501e+00,  9.6444835663e+00,\n",
            "         9.5963706970e+00, -1.7351749420e+01,  4.7931855917e-01,\n",
            "        -4.9600939751e+00,  8.9564723969e+00,  8.8516693115e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1087.5906982422, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5963035822), tensor(0.9644200802), tensor(1.1445592642), tensor(1.1664909124), tensor(1.1089988947), tensor(1.4036885500), tensor(1.0502728224), tensor(1.1537021399), tensor(0.9310971498), tensor(1.1923072338), tensor(1.0603557825), tensor(1.4726004601), tensor(1.0066801310), tensor(1.2105672359), tensor(1.1390478611), tensor(0.9544366002), tensor(1.0483387709), tensor(0.8673752546), tensor(1.0630661249), tensor(0.9753747582)]\n",
            "b:  [tensor(0.6287740469), tensor(1.0937898159), tensor(1.3363635540), tensor(1.0526131392), tensor(1.4680948257), tensor(0.8162676096), tensor(1.2213381529), tensor(1.1346948147), tensor(1.7363537550), tensor(0.8675569892), tensor(1.2799274921), tensor(0.7157395482), tensor(1.2804733515), tensor(1.2510635853), tensor(0.9214573503), tensor(0.9963477254), tensor(1.2720165253), tensor(1.7110853195), tensor(1.0035954714), tensor(1.1687266827)]\n",
            "c:  [tensor(-0.0096806958), tensor(0.2211579084), tensor(0.2094099820), tensor(-0.0140759703), tensor(-0.0017369009), tensor(-0.0118839946), tensor(0.0041225813), tensor(0.0041531832), tensor(0.1639703661), tensor(-0.0013186692), tensor(0.0870266259), tensor(-0.0434342921), tensor(-0.0402229354), tensor(0.1516885012), tensor(0.0039763842), tensor(0.0925868526), tensor(-0.0422287509), tensor(-0.0392447896)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.6124501824,  0.1423002034,  0.4690933228,  0.2208137512,\n",
            "        -0.0853367448,  0.7695552111,  0.4868901968,  0.1829652786,\n",
            "        -0.0208892822,  0.8413916826,  0.7620235085,  0.5346223116,\n",
            "         0.4240439832,  1.0470769405,  0.5912438631,  0.8075225353,\n",
            "         0.5759727359,  0.4475745857,  0.3444721699,  0.4500781298])\n",
            "btensor.grad: tensor([-0.6312887669, -0.4143166542,  0.1481526047, -0.2675006986,\n",
            "         0.1025301814, -0.2701325417,  0.0052657276,  0.4886959791,\n",
            "         0.9136841297, -0.6181875467, -0.2695970535, -0.4981637001,\n",
            "         0.0932818055, -0.3150861263, -0.3232194185,  0.2991198897,\n",
            "         0.3464138508,  0.4083477259, -0.2288932800, -0.0231282711])\n",
            "ctensor.grad: tensor([-2.6700744033e-01, -2.6814903259e+01, -2.5776281357e+01,\n",
            "         8.2251358032e-01, -2.1089656278e-02,  3.0081415176e-01,\n",
            "        -3.8138833642e-01, -3.9505201578e-01, -1.8507207870e+01,\n",
            "         5.2956044674e-01, -4.4697194099e+00,  1.0149964333e+01,\n",
            "         9.4062719345e+00, -1.7839900970e+01,  5.0237941742e-01,\n",
            "        -4.5876169205e+00,  9.4923334122e+00,  8.8419981003e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1086.3068847656, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5930503607), tensor(0.9638484120), tensor(1.1422255039), tensor(1.1654230356), tensor(1.1096224785), tensor(1.3995709419), tensor(1.0477813482), tensor(1.1528300047), tensor(0.9314210415), tensor(1.1879618168), tensor(1.0564197302), tensor(1.4697875977), tensor(1.0046031475), tensor(1.2050137520), tensor(1.1360414028), tensor(0.9502780437), tensor(1.0453746319), tensor(0.8651167154), tensor(1.0614364147), tensor(0.9731587768)]\n",
            "b:  [tensor(0.6322445273), tensor(1.0962167978), tensor(1.3357014656), tensor(1.0542526245), tensor(1.4677498341), tensor(0.8177999854), tensor(1.2214686871), tensor(1.1322413683), tensor(1.7316733599), tensor(0.8710061908), tensor(1.2815369368), tensor(0.7184531689), tensor(1.2801704407), tensor(1.2528165579), tensor(0.9233160615), tensor(0.9949102998), tensor(1.2703526020), tensor(1.7091212273), tensor(1.0049642324), tensor(1.1690617800)]\n",
            "c:  [tensor(-0.0095219417), tensor(0.2348394841), tensor(0.2225576192), tensor(-0.0144708548), tensor(-0.0017265568), tensor(-0.0120177977), tensor(0.0043124622), tensor(0.0043419921), tensor(0.1734628975), tensor(-0.0015938189), tensor(0.0890753642), tensor(-0.0487489477), tensor(-0.0447685532), tensor(0.1608314663), tensor(0.0037142092), tensor(0.0946741626), tensor(-0.0472268537), tensor(-0.0435875170)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.6506534815,  0.1143372059,  0.4667546749,  0.2135777473,\n",
            "        -0.1247103810,  0.8235290051,  0.4983006716,  0.1744245291,\n",
            "        -0.0647841692,  0.8690752983,  0.7872017622,  0.5625833273,\n",
            "         0.4153965414,  1.1107039452,  0.6012905836,  0.8317164779,\n",
            "         0.5928311944,  0.4517073929,  0.3259512186,  0.4431958199])\n",
            "btensor.grad: tensor([-0.6940984726, -0.4853994846,  0.1324292570, -0.3279076219,\n",
            "         0.0689886212, -0.3064796925, -0.0260971338,  0.4906915426,\n",
            "         0.9360889792, -0.6898387671, -0.3219003677, -0.5427247882,\n",
            "         0.0605860911, -0.3505957127, -0.3717378378,  0.2874906063,\n",
            "         0.3327735066,  0.3928085566, -0.2737453580, -0.0670280457])\n",
            "ctensor.grad: tensor([-3.1750833988e-01, -2.7363153458e+01, -2.6295274734e+01,\n",
            "         7.8976964951e-01, -2.0688135177e-02,  2.6760599017e-01,\n",
            "        -3.7976139784e-01, -3.7761747837e-01, -1.8985065460e+01,\n",
            "         5.5029952526e-01, -4.0974774361e+00,  1.0629308701e+01,\n",
            "         9.0912370682e+00, -1.8285940170e+01,  5.2434998751e-01,\n",
            "        -4.1746230125e+00,  9.9962043762e+00,  8.6854553223e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1084.9733886719, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5895910263), tensor(0.9634116888), tensor(1.1398986578), tensor(1.1643766165), tensor(1.1104322672), tensor(1.3951710463), tensor(1.0452240705), tensor(1.1519968510), tensor(0.9319498539), tensor(1.1834827662), tensor(1.0523573160), tensor(1.4668294191), tensor(1.0025714636), tensor(1.1991362572), tensor(1.1329802275), tensor(0.9460014701), tensor(1.0423139334), tensor(0.8628365397), tensor(1.0599008799), tensor(0.9709743261)]\n",
            "b:  [tensor(0.6360146403), tensor(1.0989816189), tensor(1.3351114988), tensor(1.0561877489), tensor(1.4675689936), tensor(0.8194997311), tensor(1.2217519283), tensor(1.1297796965), tensor(1.7268875837), tensor(0.8747950196), tensor(1.2833944559), tensor(0.7213769555), tensor(1.2800264359), tensor(1.2547291517), tensor(0.9254043698), tensor(0.9935229421), tensor(1.2687553167), tensor(1.7072433233), tensor(1.0065451860), tensor(1.1696084738)]\n",
            "c:  [tensor(-0.0093310736), tensor(0.2487428188), tensor(0.2359158546), tensor(-0.0148483245), tensor(-0.0017164389), tensor(-0.0121346433), tensor(0.0045008743), tensor(0.0045213951), tensor(0.1831598729), tensor(-0.0018789904), tensor(0.0909022689), tensor(-0.0542890914), tensor(-0.0491014570), tensor(0.1701717526), tensor(0.0034415249), tensor(0.0965311006), tensor(-0.0524596460), tensor(-0.0477846488)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.6918606758,  0.0873463899,  0.4653587341,  0.2092785835,\n",
            "        -0.1619655490,  0.8799726963,  0.5114485025,  0.1666371822,\n",
            "        -0.1057592630,  0.8958045840,  0.8124938607,  0.5916289091,\n",
            "         0.4063436091,  1.1755037308,  0.6122308969,  0.8553195000,\n",
            "         0.6121512651,  0.4560398757,  0.3071127236,  0.4368941784])\n",
            "btensor.grad: tensor([-0.7540207505, -0.5529718399,  0.1179824099, -0.3870304227,\n",
            "         0.0361713767, -0.3399510384, -0.0566514581,  0.4923232794,\n",
            "         0.9571623802, -0.7577710152, -0.3715076447, -0.5847567320,\n",
            "         0.0288120974, -0.3825221062, -0.4176576138,  0.2774766684,\n",
            "         0.3194565773,  0.3755747080, -0.3161921501, -0.1093440056])\n",
            "ctensor.grad: tensor([-3.8173550367e-01, -2.7806667328e+01, -2.6716472626e+01,\n",
            "         7.5494021177e-01, -2.0235879347e-02,  2.3369178176e-01,\n",
            "        -3.7682434916e-01, -3.5880550742e-01, -1.9393959045e+01,\n",
            "         5.7034301758e-01, -3.6538164616e+00,  1.1080287933e+01,\n",
            "         8.6658067703e+00, -1.8680583954e+01,  5.4536849260e-01,\n",
            "        -3.7138800621e+00,  1.0465584755e+01,  8.3942651749e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1083.5987548828, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5859135389), tensor(0.9631047249), tensor(1.1375744343), tensor(1.1633363962), tensor(1.1114152670), tensor(1.3904819489), tensor(1.0425950289), tensor(1.1512004137), tensor(0.9326657653), tensor(1.1788793802), tensor(1.0481722355), tensor(1.4637248516), tensor(1.0005891323), tensor(1.1929349899), tensor(1.1298621893), tensor(0.9416149855), tensor(1.0391467810), tensor(0.8605368733), tensor(1.0584621429), tensor(0.9688192010)]\n",
            "b:  [tensor(0.6400675774), tensor(1.1020623446), tensor(1.3345885277), tensor(1.0584100485), tensor(1.4675476551), tensor(0.8213520646), tensor(1.2221843004), tensor(1.1273154020), tensor(1.7220073938), tensor(0.8789008260), tensor(1.2854837179), tensor(0.7244974375), tensor(1.2800363302), tensor(1.2567824125), tensor(0.9277076721), tensor(0.9921786785), tensor(1.2672238350), tensor(1.7054619789), tensor(1.0083249807), tensor(1.1703572273)]\n",
            "c:  [tensor(-0.0091025373), tensor(0.2628143430), tensor(0.2494343817), tensor(-0.0152072655), tensor(-0.0017065787), tensor(-0.0122344010), tensor(0.0046869502), tensor(0.0046906481), tensor(0.1930245310), tensor(-0.0021739413), tensor(0.0924708247), tensor(-0.0600387380), tensor(-0.0531728864), tensor(0.1796801984), tensor(0.0031587090), tensor(0.0981315970), tensor(-0.0579084717), tensor(-0.0517760329)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.7354928255,  0.0613911599,  0.4648413658,  0.2080354691,\n",
            "        -0.1965929270,  0.9378310442,  0.5258110762,  0.1592863798,\n",
            "        -0.1431787014,  0.9206768274,  0.8370088339,  0.6209144592,\n",
            "         0.3964630067,  1.2402606010,  0.6235996485,  0.8772995472,\n",
            "         0.6334376335,  0.4599322975,  0.2877472639,  0.4310276508])\n",
            "btensor.grad: tensor([-0.8105839491, -0.6161450148,  0.1046042070, -0.4444568157,\n",
            "         0.0042706430, -0.3704724312, -0.0864706784,  0.4928627014,\n",
            "         0.9760476351, -0.8211593628, -0.4178618193, -0.6240916252,\n",
            "        -0.0019874908, -0.4106451273, -0.4606550932,  0.2688539624,\n",
            "         0.3063016236,  0.3562675714, -0.3559507132, -0.1497392654])\n",
            "ctensor.grad: tensor([-4.5707276464e-01, -2.8143062592e+01, -2.7037050247e+01,\n",
            "         7.1788227558e-01, -1.9720461220e-02,  1.9951444864e-01,\n",
            "        -3.7215197086e-01, -3.3850634098e-01, -1.9729326248e+01,\n",
            "         5.8990186453e-01, -3.1371150017e+00,  1.1499288559e+01,\n",
            "         8.1428613663e+00, -1.9016880035e+01,  5.6563192606e-01,\n",
            "        -3.2009940147e+00,  1.0897648811e+01,  7.9827685356e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1082.1920166016, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5820090771), tensor(0.9629222155), tensor(1.1352490187), tensor(1.1622871161), tensor(1.1125559807), tensor(1.3855021000), tensor(1.0398911238), tensor(1.1504404545), tensor(0.9335485101), tensor(1.1741654873), tensor(1.0438733101), tensor(1.4604771137), tensor(0.9986627102), tensor(1.1864162683), tensor(1.1266877651), tensor(0.9371318817), tensor(1.0358664989), tensor(0.8582233191), tensor(1.0571241379), tensor(0.9666919708)]\n",
            "b:  [tensor(0.6443843842), tensor(1.1054333448), tensor(1.3341284990), tensor(1.0609093904), tensor(1.4676809311), tensor(0.8233424425), tensor(1.2227628231), tensor(1.1248575449), tensor(1.7170484066), tensor(0.8832973838), tensor(1.2877866030), tensor(0.7278003693), tensor(1.2801957130), tensor(1.2589569092), tensor(0.9302100539), tensor(0.9908720851), tensor(1.2657583952), tensor(1.7037898302), tensor(1.0102890730), tensor(1.1712971926)]\n",
            "c:  [tensor(-0.0088322982), tensor(0.2770009339), tensor(0.2630630136), tensor(-0.0155465780), tensor(-0.0016970125), tensor(-0.0123172244), tensor(0.0048696366), tensor(0.0048490018), tensor(0.2030193955), tensor(-0.0024785425), tensor(0.0937456861), tensor(-0.0659796819), tensor(-0.0569401570), tensor(0.1893253326), tensor(0.0028660188), tensor(0.0994486585), tensor(-0.0635531917), tensor(-0.0555093884)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.7808830142,  0.0365012735,  0.4650828838,  0.2098598480,\n",
            "        -0.2281425595,  0.9959599972,  0.5407865047,  0.1519809961,\n",
            "        -0.1765444279,  0.9427859187,  0.8597883582,  0.6495435834,\n",
            "         0.3852813244,  1.3037327528,  0.6348865628,  0.8966199160,\n",
            "         0.6560552120,  0.4627139568,  0.2675994039,  0.4254440069])\n",
            "btensor.grad: tensor([-0.8633624911, -0.6742006540,  0.0920068622, -0.4998717904,\n",
            "        -0.0266568661, -0.3980784416, -0.1157008857,  0.4915606976,\n",
            "         0.9918042421, -0.8793166876, -0.4605726004, -0.6605844498,\n",
            "        -0.0318741910, -0.4348877668, -0.5004769564,  0.2613232732,\n",
            "         0.2930892110,  0.3344346285, -0.3928226233, -0.1879929900])\n",
            "ctensor.grad: tensor([-5.4047733545e-01, -2.8373184204e+01, -2.7257255554e+01,\n",
            "         6.7862504721e-01, -1.9132392481e-02,  1.6564720869e-01,\n",
            "        -3.6537247896e-01, -3.1670692563e-01, -1.9989728928e+01,\n",
            "         6.0920244455e-01, -2.5497257710e+00,  1.1881892204e+01,\n",
            "         7.5345435143e+00, -1.9290266037e+01,  5.8538061380e-01,\n",
            "        -2.6341273785e+00,  1.1289437294e+01,  7.4667143822e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1080.7624511719, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5778725147), tensor(0.9628586769), tensor(1.1329193115), tensor(1.1612137556), tensor(1.1138372421), tensor(1.3802362680), tensor(1.0371123552), tensor(1.1497188807), tensor(0.9345757961), tensor(1.1693588495), tensor(1.0394737720), tensor(1.4570940733), tensor(0.9968010783), tensor(1.1795926094), tensor(1.1234598160), tensor(0.9325702786), tensor(1.0324699879), tensor(0.8559044600), tensor(1.0558919907), tensor(0.9645918608)]\n",
            "b:  [tensor(0.6489443183), tensor(1.1090663671), tensor(1.3337292671), tensor(1.0636746883), tensor(1.4679640532), tensor(0.8254566789), tensor(1.2234855890), tensor(1.1224191189), tensor(1.7120310068), tensor(0.8879558444), tensor(1.2902834415), tensor(0.7312710285), tensor(1.2805005312), tensor(1.2612333298), tensor(0.9328948855), tensor(0.9895992279), tensor(1.2643604279), tensor(1.7022417784), tensor(1.0124224424), tensor(1.1724169254)]\n",
            "c:  [tensor(-0.0085179117), tensor(0.2912513316), tensor(0.2767530978), tensor(-0.0158652570), tensor(-0.0016877797), tensor(-0.0123835914), tensor(0.0050477334), tensor(0.0049957545), tensor(0.2131076008), tensor(-0.0027927826), tensor(0.0946943089), tensor(-0.0720912814), tensor(-0.0603662804), tensor(0.1990746707), tensor(0.0025635802), tensor(0.1004558727), tensor(-0.0693720579), tensor(-0.0589403734)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.8273208737,  0.0127059519,  0.4659495354,  0.2146831751,\n",
            "        -0.2562415600,  1.0531656742,  0.5557475090,  0.1443228722,\n",
            "        -0.2054520845,  0.9613184333,  0.8799111843,  0.6765991449,\n",
            "         0.3723315895,  1.3647298813,  0.6456003189,  0.9123173356,\n",
            "         0.6792936325,  0.4637659788,  0.2464202046,  0.4200266600])\n",
            "btensor.grad: tensor([-0.9119847417, -0.7265965939,  0.0798475221, -0.5530478358,\n",
            "        -0.0566222966, -0.4228428602, -0.1445460171,  0.4876940250,\n",
            "         1.0034710169, -0.9316938519, -0.4993628263, -0.6941285133,\n",
            "        -0.0609584302, -0.4552916288, -0.5369622707,  0.2545747757,\n",
            "         0.2795941234,  0.3096075058, -0.4266848564, -0.2239542007])\n",
            "ctensor.grad: tensor([-6.2877368927e-01, -2.8500814438e+01, -2.7380144119e+01,\n",
            "         6.3735872507e-01, -1.8465522677e-02,  1.3273453712e-01,\n",
            "        -3.5619336367e-01, -2.9350516200e-01, -2.0176416397e+01,\n",
            "         6.2848001719e-01, -1.8972454071e+00,  1.2223201752e+01,\n",
            "         6.8522486687e+00, -1.9498672485e+01,  6.0487735271e-01,\n",
            "        -2.0144240856e+00,  1.1637731552e+01,  6.8619666100e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1079.3187255859, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5735018253), tensor(0.9629081488), tensor(1.1305824518), tensor(1.1601015329), tensor(1.1152397394), tensor(1.3746947050), tensor(1.0342615843), tensor(1.1490389109), tensor(0.9357234836), tensor(1.1644808054), tensor(1.0349909067), tensor(1.4535877705), tensor(0.9950147867), tensor(1.1724815369), tensor(1.1201829910), tensor(0.9279521108), tensor(1.0289576054), tensor(0.8535913825), tensor(1.0547716618), tensor(0.9625179768)]\n",
            "b:  [tensor(0.6537247896), tensor(1.1129307747), tensor(1.3333901167), tensor(1.0666934252), tensor(1.4683922529), tensor(0.8276810050), tensor(1.2243515253), tensor(1.1200156212), tensor(1.7069799900), tensor(0.8928449750), tensor(1.2929536104), tensor(0.7348940372), tensor(1.2809473276), tensor(1.2635930777), tensor(0.9357446432), tensor(0.9883575439), tensor(1.2630320787), tensor(1.7008347511), tensor(1.0147095919), tensor(1.1737042665)]\n",
            "c:  [tensor(-0.0081583187), tensor(0.3055173457), tensor(0.2904585600), tensor(-0.0161624439), tensor(-0.0016789212), tensor(-0.0124343000), tensor(0.0052199508), tensor(0.0051303231), tensor(0.2232536674), tensor(-0.0031167718), tensor(0.0952876955), tensor(-0.0783505440), tensor(-0.0634202138), tensor(0.2088956535), tensor(0.0022513825), tensor(0.1011283174), tensor(-0.0753417313), tensor(-0.0620326623)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.8741367459, -0.0098914504,  0.4673612118,  0.2224330902,\n",
            "        -0.2805023193,  1.1083229780,  0.5701550245,  0.1360014677,\n",
            "        -0.2295364141,  0.9756149054,  0.8965817690,  0.7012524009,\n",
            "         0.3572625518,  1.4222202301,  0.6553615928,  0.9236307740,\n",
            "         0.7024825215,  0.4626143575,  0.2240587324,  0.4147825241])\n",
            "btensor.grad: tensor([-0.9560975432, -0.7728931904,  0.0678297281, -0.6037464142,\n",
            "        -0.0856350213, -0.4448626041, -0.1731865853,  0.4806923866,\n",
            "         1.0101935863, -0.9778209329, -0.5340349674, -0.7246053219,\n",
            "        -0.0893585086, -0.4719444513, -0.5699501038,  0.2483422756,\n",
            "         0.2656757832,  0.2814165354, -0.4574332833, -0.2574738264])\n",
            "ctensor.grad: tensor([-7.1918523312e-01, -2.8532020569e+01, -2.7410894394e+01,\n",
            "         5.9437525272e-01, -1.7717119306e-02,  1.0141793638e-01,\n",
            "        -3.4443506598e-01, -2.6913711429e-01, -2.0292121887e+01,\n",
            "         6.4797836542e-01, -1.1867702007e+00,  1.2518527031e+01,\n",
            "         6.1078643799e+00, -1.9641954422e+01,  6.2439554930e-01,\n",
            "        -1.3448822498e+00,  1.1939345360e+01,  6.1845803261e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1077.8687744141, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5688984394), tensor(0.9630638957), tensor(1.1282361746), tensor(1.1589365005), tensor(1.1167427301), tensor(1.3688927889), tensor(1.0313436985), tensor(1.1484051943), tensor(0.9369660020), tensor(1.1595548391), tensor(1.0304453373), tensor(1.4499739408), tensor(0.9933157563), tensor(1.1651048660), tensor(1.1168636084), tensor(0.9233021140), tensor(1.0253326893), tensor(0.8512967825), tensor(1.0537693501), tensor(0.9604690075)]\n",
            "b:  [tensor(0.6587019563), tensor(1.1169946194), tensor(1.3331117630), tensor(1.0699523687), tensor(1.4689607620), tensor(0.8300023675), tensor(1.2253605127), tensor(1.1176651716), tensor(1.7019238472), tensor(0.8979317546), tensor(1.2957760096), tensor(0.7386538386), tensor(1.2815332413), tensor(1.2660180330), tensor(0.9387413859), tensor(0.9871455431), tensor(1.2617758512), tensor(1.6995868683), tensor(1.0171346664), tensor(1.1751464605)]\n",
            "c:  [tensor(-0.0077536912), tensor(0.3197546899), tensor(0.3041369319), tensor(-0.0164374691), tensor(-0.0016704776), tensor(-0.0124704521), tensor(0.0053849630), tensor(0.0052522919), tensor(0.2334241420), tensor(-0.0034507422), tensor(0.0955011621), tensor(-0.0847322047), tensor(-0.0660767034), tensor(0.2187565714), tensor(0.0019292815), tensor(0.1014437601), tensor(-0.0814372003), tensor(-0.0647574514)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.9206835628, -0.0311449617,  0.4692625999,  0.2330019474,\n",
            "        -0.3005908728,  1.1603794098,  0.5835676193,  0.1267536879,\n",
            "        -0.2485053539,  0.9851944447,  0.9091132879,  0.7227669954,\n",
            "         0.3398026526,  1.4753378630,  0.6638783813,  0.9299989939,\n",
            "         0.7249863148,  0.4589237273,  0.2004512846,  0.4097994566])\n",
            "btensor.grad: tensor([-0.9954291582, -0.8127663136,  0.0556746759, -0.6517878771,\n",
            "        -0.1137113273, -0.4642754793, -0.2017911077,  0.4700884819,\n",
            "         1.0112330914, -1.0173614025, -0.5644738674, -0.7519543767,\n",
            "        -0.1171801537, -0.4849926233, -0.5993427634,  0.2424035072,\n",
            "         0.2512342334,  0.2495734692, -0.4850057364, -0.2884399295])\n",
            "ctensor.grad: tensor([-8.0925542116e-01, -2.8474683762e+01, -2.7356742859e+01,\n",
            "         5.5005061626e-01, -1.6887180507e-02,  7.2303630412e-02,\n",
            "        -3.3002394438e-01, -2.4393753707e-01, -2.0340940475e+01,\n",
            "         6.6794067621e-01, -4.2693656683e-01,  1.2763316154e+01,\n",
            "         5.3129858971e+00, -1.9721836090e+01,  6.4420175552e-01,\n",
            "        -6.3088166714e-01,  1.2190931320e+01,  5.4495749474e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1076.4221191406, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5640664101), tensor(0.9633180499), tensor(1.1258777380), tensor(1.1577049494), tensor(1.1183235645), tensor(1.3628507853), tensor(1.0283652544), tensor(1.1478229761), tensor(0.9382764697), tensor(1.1546059847), tensor(1.0258603096), tensor(1.4462713003), tensor(0.9917166233), tensor(1.1574878693), tensor(1.1135084629), tensor(0.9186465740), tensor(1.0216013193), tensor(0.8490340710), tensor(1.0528910160), tensor(0.9584426284)]\n",
            "b:  [tensor(0.6638506651), tensor(1.1212245226), tensor(1.3328958750), tensor(1.0734372139), tensor(1.4696649313), tensor(0.8324084282), tensor(1.2265129089), tensor(1.1153870821), tensor(1.6968938112), tensor(0.9031820893), tensor(1.2987290621), tensor(0.7425343990), tensor(1.2822557688), tensor(1.2684910297), tensor(0.9418667555), tensor(0.9859625697), tensor(1.2605946064), tensor(1.6985172033), tensor(1.0196815729), tensor(1.1767301559)]\n",
            "c:  [tensor(-0.0073051350), tensor(0.3339237273), tensor(0.3177500069), tensor(-0.0166898631), tensor(-0.0016624886), tensor(-0.0124934064), tensor(0.0055414629), tensor(0.0053614574), tensor(0.2435879558), tensor(-0.0037950457), tensor(0.0953145325), tensor(-0.0912090391), tensor(-0.0683166087), tensor(0.2286272645), tensor(0.0015970054), tensor(0.1013832316), tensor(-0.0876319334), tensor(-0.0670932159)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 0.9663951397, -0.0508251786,  0.4716759920,  0.2463020086,\n",
            "        -0.3161780834,  1.2084021568,  0.5956885815,  0.1164340973,\n",
            "        -0.2620880604,  0.9897686839,  0.9170062542,  0.7405377626,\n",
            "         0.3198293149,  1.5234040022,  0.6710336208,  0.9311044216,\n",
            "         0.7462723255,  0.4525389969,  0.1756594777,  0.4052773714])\n",
            "btensor.grad: tensor([-1.0297414064, -0.8459792137,  0.0431731306, -0.6969807148,\n",
            "        -0.1408296824, -0.4812164307, -0.2304910272,  0.4556165934,\n",
            "         1.0060186386, -1.0500702858, -0.5906064510, -0.7761147022,\n",
            "        -0.1444965601, -0.4946086407, -0.6250690222,  0.2365975380,\n",
            "         0.2362585366,  0.2139295340, -0.5093700290, -0.3167405725])\n",
            "ctensor.grad: tensor([-8.9711207151e-01, -2.8338054657e+01, -2.7226175308e+01,\n",
            "         5.0478845835e-01, -1.5978064388e-02,  4.5908790082e-02,\n",
            "        -3.1299966574e-01, -2.1833093464e-01, -2.0327629089e+01,\n",
            "         6.8860697746e-01,  3.7326338887e-01,  1.2953675270e+01,\n",
            "         4.4798045158e+00, -1.9741394043e+01,  6.6455215216e-01,\n",
            "         1.2105547637e-01,  1.2389470100e+01,  4.6715335846e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1074.9814453125, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5590126514), tensor(0.9636614323), tensor(1.1235045195), tensor(1.1563938856), tensor(1.1199585199), tensor(1.3565927744), tensor(1.0253334045), tensor(1.1472980976), tensor(0.9396269321), tensor(1.1496598721), tensor(1.0212607384), tensor(1.4425008297), tensor(0.9902300239), tensor(1.1496582031), tensor(1.1101243496), tensor(0.9140122533), tensor(1.0177718401), tensor(0.8468168974), tensor(1.0521417856), tensor(0.9564352632)]\n",
            "b:  [tensor(0.6691451073), tensor(1.1255865097), tensor(1.3327450752), tensor(1.0771330595), tensor(1.4704996347), tensor(0.8348876834), tensor(1.2278099060), tensor(1.1132013798), tensor(1.6919231415), tensor(0.9085612297), tensor(1.3017911911), tensor(0.7465198636), tensor(1.2831125259), tensor(1.2709960938), tensor(0.9451022744), tensor(0.9848085642), tensor(1.2594906092), tensor(1.6976448298), tensor(1.0223342180), tensor(1.1784415245)]\n",
            "c:  [tensor(-0.0068144565), tensor(0.3479897976), tensor(0.3312642872), tensor(-0.0169193652), tensor(-0.0016549918), tensor(-0.0125047350), tensor(0.0056882109), tensor(0.0054578464), tensor(0.2537166476), tensor(-0.0041501489), tensor(0.0947123244), tensor(-0.0977521315), tensor(-0.0701267719), tensor(0.2384796292), tensor(0.0012541633), tensor(0.1009316295), tensor(-0.0938979611), tensor(-0.0690252557)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.0107635260, -0.0686809272,  0.4746413231,  0.2622208595,\n",
            "        -0.3269963861,  1.2515945435,  0.6063666344,  0.1049844027,\n",
            "        -0.2700879574,  0.9892222285,  0.9199132919,  0.7540980577,\n",
            "         0.2973233163,  1.5659338236,  0.6768123507,  0.9268630743,\n",
            "         0.7659040093,  0.4434361458,  0.1498496085,  0.4014773369])\n",
            "btensor.grad: tensor([-1.0588855743, -0.8724029064,  0.0301639959, -0.7391623259,\n",
            "        -0.1669399142, -0.4958457947, -0.2593951821,  0.4371390343,\n",
            "         0.9941361547, -1.0758234262, -0.6124311686, -0.7970930934,\n",
            "        -0.1713628024, -0.5010019541, -0.6471012235,  0.2307985425,\n",
            "         0.2207888663,  0.1744686365, -0.5305324197, -0.3422769904])\n",
            "ctensor.grad: tensor([-9.8135715723e-01, -2.8132152557e+01, -2.7028572083e+01,\n",
            "         4.5900350809e-01, -1.4993591234e-02,  2.2656861693e-02,\n",
            "        -2.9349562526e-01, -1.9277848303e-01, -2.0257408142e+01,\n",
            "         7.1020686626e-01,  1.2044209242e+00,  1.3086184502e+01,\n",
            "         3.6203339100e+00, -1.9704734802e+01,  6.8568414450e-01,\n",
            "         9.0319836140e-01,  1.2532050133e+01,  3.8640758991e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1073.5551757812, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5537458658), tensor(0.9640836120), tensor(1.1211133003), tensor(1.1549906731), tensor(1.1216226816), tensor(1.3501462936), tensor(1.0222555399), tensor(1.1468358040), tensor(0.9409888387), tensor(1.1447417736), tensor(1.0166724920), tensor(1.4386851788), tensor(0.9888681173), tensor(1.1416450739), tensor(1.1067177057), tensor(0.9094252586), tensor(1.0138540268), tensor(0.8446582556), tensor(1.0515253544), tensor(0.9544416666)]\n",
            "b:  [tensor(0.6745589972), tensor(1.1300464869), tensor(1.3326623440), tensor(1.0810239315), tensor(1.4714595079), tensor(0.8374294043), tensor(1.2292528152), tensor(1.1111280918), tensor(1.6870464087), tensor(0.9140341878), tensor(1.3049411774), tensor(0.7505944967), tensor(1.2841016054), tensor(1.2735180855), tensor(0.9484295845), tensor(0.9836839437), tensor(1.2584661245), tensor(1.6969882250), tensor(1.0250769854), tensor(1.1802663803)]\n",
            "c:  [tensor(-0.0062839147), tensor(0.3619233966), tensor(0.3446510732), tensor(-0.0171259101), tensor(-0.0016480226), tensor(-0.0125061637), tensor(0.0058240755), tensor(0.0055417209), tensor(0.2637844980), tensor(-0.0045166276), tensor(0.0936837569), tensor(-0.1043311581), tensor(-0.0715001002), tensor(0.2482878715), tensor(0.0009002559), tensor(0.1000780463), tensor(-0.1002060398), tensor(-0.0705453604)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.0533611774, -0.0844308883,  0.4782416821,  0.2806406021,\n",
            "        -0.3328278661,  1.2892917395,  0.6155648232,  0.0924488306,\n",
            "        -0.2723768950,  0.9836130142,  0.9176459312,  0.7631188631,\n",
            "         0.2723816931,  1.6026200056,  0.6813180447,  0.9174045324,\n",
            "         0.7835561633,  0.4317285717,  0.1232828125,  0.3987203836])\n",
            "btensor.grad: tensor([-1.0827798843, -0.8919888735,  0.0165387020, -0.7781839967,\n",
            "        -0.1919768751, -0.5083451271, -0.2885738015,  0.4146671295,\n",
            "         0.9753380418, -1.0945961475, -0.6300016642, -0.8149276376,\n",
            "        -0.1978097558, -0.5043951273, -0.6654679775,  0.2249252200,\n",
            "         0.2049078494,  0.1313160658, -0.5485531092, -0.3649811149])\n",
            "ctensor.grad: tensor([-1.0610841513e+00, -2.7867185593e+01, -2.6773588181e+01,\n",
            "         4.1308912635e-01, -1.3938461430e-02,  2.8578734491e-03,\n",
            "        -2.7172908187e-01, -1.6774877906e-01, -2.0135726929e+01,\n",
            "         7.3295736313e-01,  2.0571312904e+00,  1.3158048630e+01,\n",
            "         2.7466506958e+00, -1.9616491318e+01,  7.0781481266e-01,\n",
            "         1.7071651220e+00,  1.2616151810e+01,  3.0402066708e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1072.1461181641, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5482769012), tensor(0.9645727277), tensor(1.1187005043), tensor(1.1534836292), tensor(1.1232904196), tensor(1.3435413837), tensor(1.0191386938), tensor(1.1464411020), tensor(0.9423334599), tensor(1.1398761272), tensor(1.0121217966), tensor(1.4348481894), tensor(0.9876422286), tensor(1.1334785223), tensor(1.1032940149), tensor(0.9049100876), tensor(1.0098590851), tensor(0.8425701857), tensor(1.0510438681), tensor(0.9524549842)]\n",
            "b:  [tensor(0.6800661087), tensor(1.1345704794), tensor(1.3326512575), tensor(1.0850937366), tensor(1.4725387096), tensor(0.8400240541), tensor(1.2308433056), tensor(1.1091864109), tensor(1.6822987795), tensor(0.9195666313), tensor(1.3081582785), tensor(0.7547430396), tensor(1.2852208614), tensor(1.2760432959), tensor(0.9518309236), tensor(0.9825893641), tensor(1.2575225830), tensor(1.6965647936), tensor(1.0278946161), tensor(1.1821905375)]\n",
            "c:  [tensor(-0.0057160491), tensor(0.3757000864), tensor(0.3578865528), tensor(-0.0173096135), tensor(-0.0016416138), tensor(-0.0124995215), tensor(0.0059480648), tensor(0.0056135589), tensor(0.2737685740), tensor(-0.0048951553), tensor(0.0922229216), tensor(-0.1109146625), tensor(-0.0724352822), tensor(0.2580287755), tensor(0.0005346866), tensor(0.0988160223), tensor(-0.1065258682), tensor(-0.0716513395)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.0938025713, -0.0978173018,  0.4825619459,  0.3014014959,\n",
            "        -0.3335437775,  1.3209718466,  0.6233632565,  0.0789291859,\n",
            "        -0.2689250708,  0.9731291533,  0.9101494551,  0.7674002051,\n",
            "         0.2451749444,  1.6333062649,  0.6847454309,  0.9030394554,\n",
            "         0.7989780307,  0.4176144004,  0.0962871909,  0.3973315954])\n",
            "btensor.grad: tensor([-1.1014252901, -0.9047967196,  0.0022116899, -0.8139569759,\n",
            "        -0.2158453614, -0.5189255476, -0.3181013763,  0.3883306980,\n",
            "         0.9495180249, -1.1064931154, -0.6434233189, -0.8297126889,\n",
            "        -0.2238554806, -0.5050513744, -0.6802650690,  0.2189192176,\n",
            "         0.1887169182,  0.0846931934, -0.5635279417, -0.3848247528])\n",
            "ctensor.grad: tensor([-1.1357306242e+00, -2.7553365707e+01, -2.6470977783e+01,\n",
            "         3.6740839481e-01, -1.2817561626e-02, -1.3284836896e-02,\n",
            "        -2.4797880650e-01, -1.4367644489e-01, -1.9968162537e+01,\n",
            "         7.5705569983e-01,  2.9216666222e+00,  1.3167013168e+01,\n",
            "         1.8703625202e+00, -1.9481824875e+01,  7.3113852739e-01,\n",
            "         2.5240514278e+00,  1.2639650345e+01,  2.2119612694e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1070.7579345703, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5426179171), tensor(0.9651157260), tensor(1.1162620783), tensor(1.1518620253), tensor(1.1249358654), tensor(1.3368101120), tensor(1.0159890652), tensor(1.1461180449), tensor(0.9436323047), tensor(1.1350857019), tensor(1.0076341629), tensor(1.4310137033), tensor(0.9865624309), tensor(1.1251887083), tensor(1.0998570919), tensor(0.9004888535), tensor(1.0057988167), tensor(0.8405632973), tensor(1.0506975651), tensor(0.9504668117)]\n",
            "b:  [tensor(0.6856404543), tensor(1.1391252279), tensor(1.3327155113), tensor(1.0893256664), tensor(1.4737309217), tensor(0.8426631093), tensor(1.2325834036), tensor(1.1073945761), tensor(1.6777151823), tensor(0.9251250625), tensor(1.3114225864), tensor(0.7589509487), tensor(1.2864683867), tensor(1.2785594463), tensor(0.9552889466), tensor(0.9815256596), tensor(1.2566608191), tensor(1.6963899136), tensor(1.0307725668), tensor(1.1841994524)]\n",
            "c:  [tensor(-0.0051134755), tensor(0.3893002868), tensor(0.3709515929), tensor(-0.0174707547), tensor(-0.0016357960), tensor(-0.0124866841), tensor(0.0060593523), tensor(0.0056740292), tensor(0.2836486101), tensor(-0.0052864966), tensor(0.0903285295), tensor(-0.1174704432), tensor(-0.0729368478), tensor(0.2676816583), tensor(0.0001567721), tensor(0.0971435234), tensor(-0.1128263474), tensor(-0.0723468959)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.1317919493, -0.1086000055,  0.4876968861,  0.3243248463,\n",
            "        -0.3290936947,  1.3462523222,  0.6299310923,  0.0646158457,\n",
            "        -0.2597695589,  0.9580898881,  0.8975170851,  0.7668904066,\n",
            "         0.2159582675,  1.6579740047,  0.6873817444,  0.8842450380,\n",
            "         0.8120435476,  0.4013785124,  0.0692580193,  0.3976386786])\n",
            "btensor.grad: tensor([-1.1148732901, -0.9109492302, -0.0128572434, -0.8463829756,\n",
            "        -0.2384337038, -0.5278072357, -0.3480247557,  0.3583582640,\n",
            "         0.9167265892, -1.1116847992, -0.6528533697, -0.8415799737,\n",
            "        -0.2494993806, -0.5032284260, -0.6916000843,  0.2127370238,\n",
            "         0.1723413765,  0.0349723101, -0.5756000280, -0.4017878771])\n",
            "ctensor.grad: tensor([-1.2051470280e+00, -2.7200407028e+01, -2.6130048752e+01,\n",
            "         3.2228058577e-01, -1.1635583825e-02, -2.5673795491e-02,\n",
            "        -2.2257490456e-01, -1.2094070762e-01, -1.9760049820e+01,\n",
            "         7.8268235922e-01,  3.7887914181e+00,  1.3111566544e+01,\n",
            "         1.0031317472e+00, -1.9305765152e+01,  7.5582897663e-01,\n",
            "         3.3450024128e+00,  1.2600957870e+01,  1.3911135197e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1069.3946533203, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5367826223), tensor(0.9656988382), tensor(1.1137934923), tensor(1.1501160860), tensor(1.1265336275), tensor(1.3299857378), tensor(1.0128116608), tensor(1.1458693743), tensor(0.9448578358), tensor(1.1303913593), tensor(1.0032346249), tensor(1.4272055626), tensor(0.9856373668), tensor(1.1168051958), tensor(1.0964095592), tensor(0.8961808681), tensor(1.0016855001), tensor(0.8386467099), tensor(1.0504845381), tensor(0.9484673142)]\n",
            "b:  [tensor(0.6912567616), tensor(1.1436786652), tensor(1.3328590393), tensor(1.0937027931), tensor(1.4750291109), tensor(0.8453392982), tensor(1.2344753742), tensor(1.1057692766), tensor(1.6733295918), tensor(0.9306773543), tensor(1.3147151470), tensor(0.7632045150), tensor(1.2878421545), tensor(1.2810555696), tensor(0.9587873816), tensor(0.9804940224), tensor(1.2558814287), tensor(1.6964770555), tensor(1.0336973667), tensor(1.1862791777)]\n",
            "c:  [tensor(-0.0044788327), tensor(0.4027089477), tensor(0.3838313222), tensor(-0.0176097453), tensor(-0.0016305977), tensor(-0.0124695357), tensor(0.0061572893), tensor(0.0057239430), tensor(0.2934070230), tensor(-0.0056914920), tensor(0.0880041569), tensor(-0.1239657030), tensor(-0.0730145946), tensor(0.2772285044), tensor(-0.0002342435), tensor(0.0950632021), tensor(-0.1190757602), tensor(-0.0726410225)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.1670522690, -0.1166198850,  0.4937123060,  0.3491783142,\n",
            "        -0.3195445538,  1.3648755550,  0.6354721785,  0.0497274399,\n",
            "        -0.2451018095,  0.9388788939,  0.8799142838,  0.7616248131,\n",
            "         0.1850165129,  1.6767003536,  0.6895113587,  0.8615947366,\n",
            "         0.8226665854,  0.3833150864,  0.0426038951,  0.3998992443])\n",
            "btensor.grad: tensor([-1.1232670546, -0.9106860161, -0.0287056118, -0.8754327297,\n",
            "        -0.2596398294, -0.5352337360, -0.3783865869,  0.3250502348,\n",
            "         0.8771127462, -1.1104632616, -0.6585083008, -0.8507157564,\n",
            "        -0.2747627795, -0.4992187023, -0.6996862888,  0.2063267231,\n",
            "         0.1558710784, -0.0174206495, -0.5849685669, -0.4159421325])\n",
            "ctensor.grad: tensor([-1.2692853212e+00, -2.6817300797e+01, -2.5759454727e+01,\n",
            "         2.7798184752e-01, -1.0396488942e-02, -3.4297123551e-02,\n",
            "        -1.9587355852e-01, -9.9827565253e-02, -1.9516855240e+01,\n",
            "         8.0999100208e-01,  4.6487421989e+00,  1.2990515709e+01,\n",
            "         1.5549796820e-01, -1.9093702316e+01,  7.8203111887e-01,\n",
            "         4.1606488228e+00,  1.2498820305e+01,  5.8825373650e-01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1068.0552978516, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5307856798), tensor(0.9663075805), tensor(1.1112900972), tensor(1.1482375860), tensor(1.1280587912), tensor(1.3231021166), tensor(1.0096105337), tensor(1.1456966400), tensor(0.9459836483), tensor(1.1258114576), tensor(0.9989463687), tensor(1.4234466553), tensor(0.9848738909), tensor(1.1083569527), tensor(1.0929521322), tensor(0.8920019865), tensor(0.9975312352), tensor(0.8368278146), tensor(1.0504006147), tensor(0.9464456439)]\n",
            "b:  [tensor(0.6968905926), tensor(1.1482001543), tensor(1.3330856562), tensor(1.0982080698), tensor(1.4764257669), tensor(0.8480464220), tensor(1.2365213633), tensor(1.1043252945), tensor(1.6691747904), tensor(0.9361932278), tensor(1.3180183172), tensor(0.7674911022), tensor(1.2893402576), tensor(1.2835220098), tensor(0.9623110294), tensor(0.9794957042), tensor(1.2551842928), tensor(1.6968367100), tensor(1.0366566181), tensor(1.1884158850)]\n",
            "c:  [tensor(-0.0038146249), tensor(0.4159148633), tensor(0.3965147436), tensor(-0.0177271143), tensor(-0.0016260460), tensor(-0.0124499211), tensor(0.0062414161), tensor(0.0057642115), tensor(0.3030287027), tensor(-0.0061110505), tensor(0.0852578953), tensor(-0.1303674877), tensor(-0.0726837665), tensor(0.2866536975), tensor(-0.0006391801), tensor(0.0925820768), tensor(-0.1252421439), tensor(-0.0725479946)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.1993956566, -0.1217507273,  0.5006692410,  0.3757013083,\n",
            "        -0.3050262928,  1.3767235279,  0.6402364969,  0.0345354080,\n",
            "        -0.2251639366,  0.9159724712,  0.8576525450,  0.7517806292,\n",
            "         0.1526954770,  1.6896530390,  0.6914826632,  0.8357719779,\n",
            "         0.8308519125,  0.3637737930,  0.0167869162,  0.4043372869])\n",
            "btensor.grad: tensor([-1.1267707348, -0.9042875767, -0.0453264713, -0.9010653496,\n",
            "        -0.2793337703, -0.5414245129, -0.4091956317,  0.2887901068,\n",
            "         0.8309628963, -1.1031711102, -0.6606287956, -0.8573140502,\n",
            "        -0.2996203303, -0.4932960272, -0.7047290802,  0.1996614337,\n",
            "         0.1394214928, -0.0719276667, -0.5918394327, -0.4273356795])\n",
            "ctensor.grad: tensor([-1.3284156322e+00, -2.6411827087e+01, -2.5366861343e+01,\n",
            "         2.3473930359e-01, -9.1034676880e-03, -3.9228931069e-02,\n",
            "        -1.6825351119e-01, -8.0537118018e-02, -1.9243354797e+01,\n",
            "         8.3911651373e-01,  5.4925293922e+00,  1.2803572655e+01,\n",
            "        -6.6165816784e-01, -1.8850362778e+01,  8.0987310410e-01,\n",
            "         4.9622492790e+00,  1.2332766533e+01, -1.8606036901e-01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1066.7457275391, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5246424675), tensor(0.9669274688), tensor(1.1087472439), tensor(1.1462198496), tensor(1.1294878721), tensor(1.3161932230), tensor(1.0063883066), tensor(1.1456000805), tensor(0.9469854832), tensor(1.1213622093), tensor(0.9947910309), tensor(1.4197586775), tensor(0.9842773080), tensor(1.0998717546), tensor(1.0894840956), tensor(0.8879646659), tensor(0.9933482409), tensor(0.8351125121), tensor(1.0504395962), tensor(0.9443903565)]\n",
            "b:  [tensor(0.7025188208), tensor(1.1526608467), tensor(1.3333992958), tensor(1.1028245687), tensor(1.4779129028), tensor(0.8507795930), tensor(1.2387237549), tensor(1.1030753851), tensor(1.6652816534), tensor(0.9416444898), tensor(1.3213158846), tensor(0.7717991471), tensor(1.2909606695), tensor(1.2859508991), tensor(0.9658461213), tensor(0.9785323143), tensor(1.2545690536), tensor(1.6974765062), tensor(1.0396389961), tensor(1.1905964613)]\n",
            "c:  [tensor(-0.0031232738), tensor(0.4289102554), tensor(0.4089941680), tensor(-0.0178234838), tensor(-0.0016221667), tensor(-0.0124296201), tensor(0.0063114632), tensor(0.0057957885), tensor(0.3125009835), tensor(-0.0065461313), tensor(0.0821026415), tensor(-0.1366427988), tensor(-0.0719641969), tensor(0.2959440649), tensor(-0.0010589042), tensor(0.0897118822), tensor(-0.1312934011), tensor(-0.0720865652)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.2286370993, -0.1239811629,  0.5085675716,  0.4035581350,\n",
            "        -0.2858162522,  1.3817743063,  0.6444358826,  0.0193078518,\n",
            "        -0.2003711462,  0.8898497224,  0.8310618401,  0.7375913858,\n",
            "         0.1193194389,  1.6970371008,  0.6935999990,  0.8074665070,\n",
            "         0.8365979195,  0.3430586457, -0.0077917781,  0.4110518694])\n",
            "btensor.grad: tensor([-1.1256422997, -0.8921399713, -0.0627353117, -0.9232993722,\n",
            "        -0.2974265218, -0.5466343760, -0.4404745102,  0.2499892712,\n",
            "         0.7786252499, -1.0902481079, -0.6595168114, -0.8616129160,\n",
            "        -0.3240800202, -0.4857716560, -0.7070126534,  0.1926786304,\n",
            "         0.1230461970, -0.1279629469, -0.5964838266, -0.4361117482])\n",
            "ctensor.grad: tensor([-1.3827018738e+00, -2.5990785599e+01, -2.4958866119e+01,\n",
            "         1.9274033606e-01, -7.7585815452e-03, -4.0602311492e-02,\n",
            "        -1.4009438455e-01, -6.3153937459e-02, -1.8944570541e+01,\n",
            "         8.7016123533e-01,  6.3105015755e+00,  1.2550630569e+01,\n",
            "        -1.4391347170e+00, -1.8580757141e+01,  8.3944827318e-01,\n",
            "         5.7403864861e+00,  1.2102525711e+01, -9.2285668850e-01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1065.4626464844, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5183690786), tensor(0.9675440788), tensor(1.1061600447), tensor(1.1440577507), tensor(1.1307990551), tensor(1.3092924356), tensor(1.0031468868), tensor(1.1455782652), tensor(0.9478413463), tensor(1.1170568466), tensor(0.9907880425), tensor(1.4161615372), tensor(0.9838508368), tensor(1.0913760662), tensor(1.0860031843), tensor(0.8840774894), tensor(0.9891483188), tensor(0.8335049152), tensor(1.0505928993), tensor(0.9422898889)]\n",
            "b:  [tensor(0.7081193924), tensor(1.1570341587), tensor(1.3338036537), tensor(1.1075351238), tensor(1.4794818163), tensor(0.8535348177), tensor(1.2410845757), tensor(1.1020296812), tensor(1.6616786718), tensor(0.9470052123), tensor(1.3245930672), tensor(0.7761182785), tensor(1.2927011251), tensor(1.2883353233), tensor(0.9693800807), tensor(0.9776054025), tensor(1.2540348768), tensor(1.6984006166), tensor(1.0426347256), tensor(1.1928082705)]\n",
            "c:  [tensor(-0.0024069690), tensor(0.4416900277), tensor(0.4212645888), tensor(-0.0178995486), tensor(-0.0016189852), tensor(-0.0124103129), tensor(0.0063673528), tensor(0.0058196252), tensor(0.3218132257), tensor(-0.0069977352), tensor(0.0785554275), tensor(-0.1427591741), tensor(-0.0708806887), tensor(0.3050885499), tensor(-0.0014943221), tensor(0.0864683986), tensor(-0.1371978819), tensor(-0.0712802634)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.2546750307, -0.1233228594,  0.5174291134,  0.4324147701,\n",
            "        -0.2622255683,  1.3801660538,  0.6482908726,  0.0043711662,\n",
            "        -0.1711723804,  0.8610623479,  0.8005988002,  0.7194290161,\n",
            "         0.0852885842,  1.6991372108,  0.6961876154,  0.7774360180,\n",
            "         0.8399819732,  0.3215152621, -0.0306623727,  0.4200932980])\n",
            "btensor.grad: tensor([-1.1201144457, -0.8746533394, -0.0808765516, -0.9421105385,\n",
            "        -0.3137827218, -0.5510475636, -0.4721604288,  0.2091414928,\n",
            "         0.7205950022, -1.0721487999, -0.6554448605, -0.8638321757,\n",
            "        -0.3480928838, -0.4768965244, -0.7067879438,  0.1853872538,\n",
            "         0.1068456694, -0.1848295927, -0.5991441011, -0.4423736334])\n",
            "ctensor.grad: tensor([-1.4326097965e+00, -2.5559524536e+01, -2.4540842056e+01,\n",
            "         1.5212972462e-01, -6.3630416989e-03, -3.8615413010e-02,\n",
            "        -1.1177875847e-01, -4.7673713416e-02, -1.8624498367e+01,\n",
            "         9.0320742130e-01,  7.0944247246e+00,  1.2232747078e+01,\n",
            "        -2.1670200825e+00, -1.8288959503e+01,  8.7083572149e-01,\n",
            "         6.4869675636e+00,  1.1808949471e+01, -1.6126040220e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1064.2086181641, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5119820833), tensor(0.9681438208), tensor(1.1035243273), tensor(1.1417486668), tensor(1.1319726706), tensor(1.3024320602), tensor(0.9998873472), tensor(1.1456284523), tensor(0.9485324025), tensor(1.1129064560), tensor(0.9869545698), tensor(1.4126731157), tensor(0.9835963249), tensor(1.0828951597), tensor(1.0825058222), tensor(0.8803458810), tensor(0.9849433303), tensor(0.8320080638), tensor(1.0508502722), tensor(0.9401332736)]\n",
            "b:  [tensor(0.7136721015), tensor(1.1612958908), tensor(1.3343024254), tensor(1.1123229265), tensor(1.4811235666), tensor(0.8563093543), tensor(1.2436057329), tensor(1.1011961699), tensor(1.6583917141), tensor(0.9522523880), tensor(1.3278369904), tensor(0.7804394960), tensor(1.2945594788), tensor(1.2906701565), tensor(0.9729020596), tensor(0.9767168760), tensor(1.2535806894), tensor(1.6996098757), tensor(1.0456353426), tensor(1.1950399876)]\n",
            "c:  [tensor(-0.0016678697), tensor(0.4542510509), tensor(0.4333229959), tensor(-0.0179560594), tensor(-0.0016165267), tensor(-0.0123935640), tensor(0.0064091883), tensor(0.0058366158), tensor(0.3309571147), tensor(-0.0074668820), tensor(0.0746381432), tensor(-0.1486845762), tensor(-0.0694614202), tensor(0.3140783310), tensor(-0.0019463568), tensor(0.0828721449), tensor(-0.1429242194), tensor(-0.0701558143)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.2773946524, -0.1199502498,  0.5271470547,  0.4618124962,\n",
            "        -0.2347207069,  1.3720856905,  0.6519021988, -0.0100271702,\n",
            "        -0.1382139921,  0.8300854564,  0.7666898966,  0.6976758242,\n",
            "         0.0509082377,  1.6961909533,  0.6994698048,  0.7463259697,\n",
            "         0.8409974575,  0.2993703187, -0.0514861308,  0.4313184023])\n",
            "btensor.grad: tensor([-1.1105419397, -0.8523496389, -0.0997443870, -0.9575548172,\n",
            "        -0.3283502460, -0.5549033284, -0.5042289495,  0.1667091846,\n",
            "         0.6573834419, -1.0494381189, -0.6487753391, -0.8642483950,\n",
            "        -0.3716615736, -0.4669767618, -0.7043958902,  0.1777019501,\n",
            "         0.0908258706, -0.2418509722, -0.6001275778, -0.4463431835])\n",
            "ctensor.grad: tensor([-1.4781982899e+00, -2.5122072220e+01, -2.4116827011e+01,\n",
            "         1.1302120984e-01, -4.9168900587e-03, -3.3498711884e-02,\n",
            "        -8.3670541644e-02, -3.3981602639e-02, -1.8287792206e+01,\n",
            "         9.3829315901e-01,  7.8345699310e+00,  1.1850803375e+01,\n",
            "        -2.8385312557e+00, -1.7979576111e+01,  9.0406954288e-01,\n",
            "         7.1925053596e+00,  1.1452686310e+01, -2.2488932610e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1062.9865722656, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5054979324), tensor(0.9687134624), tensor(1.1008356810), tensor(1.1392916441), tensor(1.1329911947), tensor(1.2956423759), tensor(0.9966101050), tensor(1.1457459927), tensor(0.9490426779), tensor(1.1089189053), tensor(0.9833048582), tensor(1.4093086720), tensor(0.9835129380), tensor(1.0744524002), tensor(1.0789871216), tensor(0.8767714500), tensor(0.9807444215), tensor(0.8306229711), tensor(1.0511990786), tensor(0.9379101396)]\n",
            "b:  [tensor(0.7191578746), tensor(1.1654241085), tensor(1.3348983526), tensor(1.1171705723), tensor(1.4828282595), tensor(0.8591006398), tensor(1.2462880611), tensor(1.1005795002), tensor(1.6554430723), tensor(0.9573652744), tensor(1.3310356140), tensor(0.7847545743), tensor(1.2965326309), tensor(1.2929511070), tensor(0.9764022827), tensor(0.9758683443), tensor(1.2532050610), tensor(1.7011008263), tensor(1.0486334562), tensor(1.1972804070)]\n",
            "c:  [tensor(-0.0009077546), tensor(0.4665915966), tensor(0.4451677501), tensor(-0.0179938078), tensor(-0.0016148168), tensor(-0.0123807956), tensor(0.0064372527), tensor(0.0058475677), tensor(0.3399254382), tensor(-0.0079546068), tensor(0.0703755841), tensor(-0.1543885916), tensor(-0.0677395910), tensor(0.3229058683), tensor(-0.0024159478), tensor(0.0789465457), tensor(-0.1484425515), tensor(-0.0687446669)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.2968196869, -0.1139318794,  0.5377330780,  0.4914146662,\n",
            "        -0.2037075162,  1.3579338789,  0.6554443836, -0.0235003233,\n",
            "        -0.1020514965,  0.7975181341,  0.7299435139,  0.6728893518,\n",
            "         0.0166807771,  1.6885635853,  0.7037376761,  0.7148908377,\n",
            "         0.8397855759,  0.2770135999, -0.0697664842,  0.4446289539])\n",
            "btensor.grad: tensor([-1.0971548557, -0.8256523013, -0.1191778556, -0.9695341587,\n",
            "        -0.3409464955, -0.5582554340, -0.5364729166,  0.1233265400,\n",
            "         0.5897166729, -1.0225734711, -0.6397305727, -0.8630146384,\n",
            "        -0.3946336210, -0.4561848640, -0.7000415325,  0.1697095037,\n",
            "         0.0751153007, -0.2981909513, -0.5996146202, -0.4480860233])\n",
            "ctensor.grad: tensor([-1.5202301741e+00, -2.4681064606e+01, -2.3689523697e+01,\n",
            "         7.5495816767e-02, -3.4197345376e-03, -2.5536289439e-02,\n",
            "        -5.6129064411e-02, -2.1903458983e-02, -1.7936674118e+01,\n",
            "         9.7544944286e-01,  8.5251245499e+00,  1.1408020020e+01,\n",
            "        -3.4436547756e+00, -1.7655082703e+01,  9.3918198347e-01,\n",
            "         7.8512001038e+00,  1.1036671638e+01, -2.8222930431e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1061.7926025391, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4989339113), tensor(0.9692420959), tensor(1.0980913639), tensor(1.1366888285), tensor(1.1338406801), tensor(1.2889524698), tensor(0.9933164716), tensor(1.1459257603), tensor(0.9493610859), tensor(1.1051005125), tensor(0.9798512459), tensor(1.4060813189), tensor(0.9835991859), tensor(1.0660703182), tensor(1.0754423141), tensor(0.8733538985), tensor(0.9765635729), tensor(0.8293508291), tensor(1.0516259670), tensor(0.9356126189)]\n",
            "b:  [tensor(0.7245602012), tensor(1.1694006920), tensor(1.3355945349), tensor(1.1220617294), tensor(1.4845867157), tensor(0.8619077206), tensor(1.2491325140), tensor(1.1001825333), tensor(1.6528522968), tensor(0.9623268843), tensor(1.3341796398), tensor(0.7890570760), tensor(1.2986180782), tensor(1.2951755524), tensor(0.9798731804), tensor(0.9750622511), tensor(1.2529070377), tensor(1.7028670311), tensor(1.0516234636), tensor(1.1995202303)]\n",
            "c:  [tensor(-0.0001287757), tensor(0.4787105620), tensor(0.4567980468), tensor(-0.0180136133), tensor(-0.0016138819), tensor(-0.0123732891), tensor(0.0064519891), tensor(0.0058531519), tensor(0.3487138748), tensor(-0.0084619122), tensor(0.0657985359), tensor(-0.1598411053), tensor(-0.0657484531), tensor(0.3315663934), tensor(-0.0029040065), tensor(0.0747208446), tensor(-0.1537232399), tensor(-0.0670782328)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.3128042221, -0.1057275832,  0.5488535166,  0.5205683708,\n",
            "        -0.1699089408,  1.3379930258,  0.6587250233, -0.0359581709,\n",
            "        -0.0636814833,  0.7636828423,  0.6907181740,  0.6454743147,\n",
            "        -0.0172491670,  1.6764062643,  0.7089554667,  0.6835120916,\n",
            "         0.8361653090,  0.2544327378, -0.0853892565,  0.4595061541])\n",
            "btensor.grad: tensor([-1.0804666281, -0.7953205705, -0.1392304301, -0.9782403111,\n",
            "        -0.3516793549, -0.5614186525, -0.5688829422,  0.0793815851,\n",
            "         0.5181530714, -0.9923184514, -0.6288065910, -0.8604958057,\n",
            "        -0.4170984328, -0.4448819160, -0.6941832304,  0.1612145901,\n",
            "         0.0595983192, -0.3532440662, -0.5980129242, -0.4479686618])\n",
            "ctensor.grad: tensor([-1.5579577684e+00, -2.4237945557e+01, -2.3260604858e+01,\n",
            "         3.9612103254e-02, -1.8699564971e-03, -1.5013257973e-02,\n",
            "        -2.9472297058e-02, -1.1168598197e-02, -1.7576843262e+01,\n",
            "         1.0146112442e+00,  9.1540908813e+00,  1.0905026436e+01,\n",
            "        -3.9822731018e+00, -1.7321058273e+01,  9.7611719370e-01,\n",
            "         8.4514074326e+00,  1.0561364174e+01, -3.3328664303e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1060.6323242188, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4923055172), tensor(0.9697176814), tensor(1.0952874422), tensor(1.1339426041), tensor(1.1345081329), tensor(1.2823868990), tensor(0.9900058508), tensor(1.1461594105), tensor(0.9494779110), tensor(1.1014534235), tensor(0.9766012430), tensor(1.4029996395), tensor(0.9838489890), tensor(1.0577687025), tensor(1.0718642473), tensor(0.8700880408), tensor(0.9724107981), tensor(0.8281887770), tensor(1.0521136522), tensor(0.9332325459)]\n",
            "b:  [tensor(0.7298623919), tensor(1.1732079983), tensor(1.3363915682), tensor(1.1269776821), tensor(1.4863870144), tensor(0.8647279143), tensor(1.2521367073), tensor(1.1000031233), tensor(1.6506328583), tensor(0.9671210051), tensor(1.3372590542), tensor(0.7933398485), tensor(1.3008106947), tensor(1.2973401546), tensor(0.9833066463), tensor(0.9742988348), tensor(1.2526835203), tensor(1.7048963308), tensor(1.0545992851), tensor(1.2017489672)]\n",
            "c:  [tensor(0.0006681219), tensor(0.4906069934), tensor(0.4682131708), tensor(-0.0180163216), tensor(-0.0016137485), tensor(-0.0123721547), tensor(0.0064539993), tensor(0.0058539021), tensor(0.3573163748), tensor(-0.0089898156), tensor(0.0609356426), tensor(-0.1650165617), tensor(-0.0635302067), tensor(0.3400536776), tensor(-0.0034114607), tensor(0.0702224225), tensor(-0.1587408483), tensor(-0.0651963130)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.3256878853, -0.0951186270,  0.5607899427,  0.5492362976,\n",
            "        -0.1334983706,  1.3131190538,  0.6621291637, -0.0467181206,\n",
            "        -0.0233644247,  0.7294223309,  0.6500044465,  0.6163465977,\n",
            "        -0.0499554276,  1.6603268385,  0.7156170607,  0.6531661153,\n",
            "         0.8305585384,  0.2324053049, -0.0975333229,  0.4760150909])\n",
            "btensor.grad: tensor([-1.0604351759, -0.7614716291, -0.1593982875, -0.9832010865,\n",
            "        -0.3600692749, -0.5640445948, -0.6008307934,  0.0358933210,\n",
            "         0.4438959062, -0.9588271379, -0.6158840656, -0.8565523624,\n",
            "        -0.4385298193, -0.4329212904, -0.6866924763,  0.1526801586,\n",
            "         0.0447070822, -0.4058647752, -0.5951695442, -0.4457405210])\n",
            "ctensor.grad: tensor([-1.5937951803e+00, -2.3792890549e+01, -2.2830268860e+01,\n",
            "         5.4165162146e-03, -2.6678052382e-04, -2.2695083171e-03,\n",
            "        -4.0206233971e-03, -1.5007611364e-03, -1.7205015182e+01,\n",
            "         1.0558069944e+00,  9.7257881165e+00,  1.0350906372e+01,\n",
            "        -4.4364962578e+00, -1.6974578857e+01,  1.0149080753e+00,\n",
            "         8.9968385696e+00,  1.0035223961e+01, -3.7638342381e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1059.5053710938, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4856314659), tensor(0.9701353908), tensor(1.0924258232), tensor(1.1310628653), tensor(1.1349881887), tensor(1.2759711742), tensor(0.9866833687), tensor(1.1464419365), tensor(0.9493940473), tensor(1.0979820490), tensor(0.9735644460), tensor(1.4000728130), tensor(0.9842603207), tensor(1.0495693684), tensor(1.0682504177), tensor(0.8669722080), tensor(0.9683011174), tensor(0.8271396160), tensor(1.0526493788), tensor(0.9307698607)]\n",
            "b:  [tensor(0.7350539565), tensor(1.1768366098), tensor(1.3372932673), tensor(1.1319046021), tensor(1.4882222414), tensor(0.8675635457), tensor(1.2553011179), tensor(1.1000405550), tensor(1.6487983465), tensor(0.9717393517), tensor(1.3402699232), tensor(0.7976005077), tensor(1.3031091690), tensor(1.2994463444), tensor(0.9867002368), tensor(0.9735831022), tensor(1.2525352240), tensor(1.7071770430), tensor(1.0575599670), tensor(1.2039616108)]\n",
            "c:  [tensor(0.0014794867), tensor(0.5022796988), tensor(0.4794123769), tensor(-0.0180027727), tensor(-0.0016144450), tensor(-0.0123783443), tensor(0.0064440090), tensor(0.0058501838), tensor(0.3657349050), tensor(-0.0095391748), tensor(0.0558308326), tensor(-0.1698855609), tensor(-0.0611127056), tensor(0.3483691514), tensor(-0.0039390954), tensor(0.0654933229), tensor(-0.1634662598), tensor(-0.0631250143)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.3348209858, -0.0835461169,  0.5723291636,  0.5759447813,\n",
            "        -0.0960116982,  1.2831541300,  0.6644966602, -0.0564963818,\n",
            "         0.0167745352,  0.6942731738,  0.6073619127,  0.5853608251,\n",
            "        -0.0822624266,  1.6398706436,  0.7227683067,  0.6231640577,\n",
            "         0.8219373822,  0.2098287344, -0.1071441993,  0.4925423861])\n",
            "btensor.grad: tensor([-1.0383117199, -0.7257329226, -0.1803312004, -0.9853843451,\n",
            "        -0.3670378327, -0.5671273470, -0.6328802109, -0.0074777603,\n",
            "         0.3669061661, -0.9236681461, -0.6021620035, -0.8521346450,\n",
            "        -0.4596956968, -0.4212284088, -0.6787207127,  0.1431447864,\n",
            "         0.0296529084, -0.4561492205, -0.5921471119, -0.4425340891])\n",
            "ctensor.grad: tensor([-1.6227296591e+00, -2.3345457077e+01, -2.2398405075e+01,\n",
            "        -2.7096945792e-02,  1.3930673013e-03,  1.2379836291e-02,\n",
            "         1.9981058314e-02,  7.4362806045e-03, -1.6837053299e+01,\n",
            "         1.0987188816e+00,  1.0209618568e+01,  9.7379903793e+00,\n",
            "        -4.8350033760e+00, -1.6630920410e+01,  1.0552691221e+00,\n",
            "         9.4582004547e+00,  9.4508295059e+00, -4.1425909996e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1058.4108886719, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4789210558), tensor(0.9704777598), tensor(1.0894966125), tensor(1.1280490160), tensor(1.1352666616), tensor(1.2697178125), tensor(0.9833421707), tensor(1.1467552185), tensor(0.9490985274), tensor(1.0946775675), tensor(0.9707348943), tensor(1.3972973824), tensor(0.9848135710), tensor(1.0414832830), tensor(1.0645865202), tensor(0.8639891148), tensor(0.9642375112), tensor(0.8261888027), tensor(1.0532042980), tensor(0.9282130599)]\n",
            "b:  [tensor(0.7401150465), tensor(1.1802669764), tensor(1.3382918835), tensor(1.1368156672), tensor(1.4900729656), tensor(0.8704048991), tensor(1.2586135864), tensor(1.1002790928), tensor(1.6473461390), tensor(0.9761641622), tensor(1.3431977034), tensor(0.8018277287), tensor(1.3054996729), tensor(1.3014863729), tensor(0.9900411963), tensor(0.9729070663), tensor(1.2524517775), tensor(1.7096832991), tensor(1.0604943037), tensor(1.2061419487)]\n",
            "c:  [tensor(0.0023084281), tensor(0.5137265325), tensor(0.4903939068), tensor(-0.0179738756), tensor(-0.0016159989), tensor(-0.0123926699), tensor(0.0064228643), tensor(0.0058421548), tensor(0.3739546239), tensor(-0.0101110488), tensor(0.0504975803), tensor(-0.1744374186), tensor(-0.0585646257), tensor(0.3564983904), tensor(-0.0044878889), tensor(0.0605469719), tensor(-0.1678880453), tensor(-0.0609290600)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.3420768976, -0.0684749484,  0.5858328342,  0.6027667522,\n",
            "        -0.0557054877,  1.2506810427,  0.6682405472, -0.0626683235,\n",
            "         0.0591045618,  0.6608924866,  0.5659149885,  0.5550825596,\n",
            "        -0.1106475294,  1.6172142029,  0.7327823639,  0.5966172218,\n",
            "         0.8127202392,  0.1901651472, -0.1109839454,  0.5113604069])\n",
            "btensor.grad: tensor([-1.0122194290, -0.6860741973, -0.1997180730, -0.9822107553,\n",
            "        -0.3701419830, -0.5682749748, -0.6624855995, -0.0476963520,\n",
            "         0.2904372215, -0.8849645257, -0.5855675936, -0.8454425335,\n",
            "        -0.4780910015, -0.4080117941, -0.6681874990,  0.1352122426,\n",
            "         0.0166833848, -0.5012562275, -0.5868778229, -0.4360610247])\n",
            "ctensor.grad: tensor([-1.6578825712e+00, -2.2893680573e+01, -2.1963056564e+01,\n",
            "        -5.7793859392e-02,  3.1078238972e-03,  2.8651131317e-02,\n",
            "         4.2289108038e-02,  1.6057658941e-02, -1.6439434052e+01,\n",
            "         1.1437473297e+00,  1.0666506767e+01,  9.1037130356e+00,\n",
            "        -5.0961632729e+00, -1.6258485794e+01,  1.0975868702e+00,\n",
            "         9.8927040100e+00,  8.8435716629e+00, -4.3919057846e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1057.3524169922, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4722065926), tensor(0.9707663059), tensor(1.0865253210), tensor(1.1249356270), tensor(1.1353633404), tensor(1.2636607885), tensor(0.9800106287), tensor(1.1471122503), tensor(0.9486271143), tensor(1.0915591717), tensor(0.9681375027), tensor(1.3946920633), tensor(0.9855280519), tensor(1.0335450172), tensor(1.0608910322), tensor(0.8611571193), tensor(0.9602560401), tensor(0.8253640532), tensor(1.0537886620), tensor(0.9255911112)]\n",
            "b:  [tensor(0.7450568676), tensor(1.1835165024), tensor(1.3394058943), tensor(1.1417168379), tensor(1.4919513464), tensor(0.8732733130), tensor(1.2620881796), tensor(1.1007314920), tensor(1.6462993622), tensor(0.9804126620), tensor(1.3460596800), tensor(0.8060361743), tensor(1.3079975843), tensor(1.3034781218), tensor(0.9933475256), tensor(0.9722952843), tensor(1.2524504662), tensor(1.7124136686), tensor(1.0634207726), tensor(1.2083061934)]\n",
            "c:  [tensor(0.0031409715), tensor(0.5249450207), tensor(0.5011560321), tensor(-0.0179303307), tensor(-0.0016184418), tensor(-0.0124156009), tensor(0.0063915541), tensor(0.0058300649), tensor(0.3820079863), tensor(-0.0107056815), tensor(0.0450372212), tensor(-0.1786222011), tensor(-0.0558462739), tensor(0.3644719422), tensor(-0.0050580688), tensor(0.0554801784), tensor(-0.1719573587), tensor(-0.0585703440)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.3429003954, -0.0577116311,  0.5942490101,  0.6226782799,\n",
            "        -0.0193328857,  1.2113931179,  0.6663074493, -0.0714061260,\n",
            "         0.0942780972,  0.6236750484,  0.5194817185,  0.5210700631,\n",
            "        -0.1428931355,  1.5876500607,  0.7390994430,  0.5663965940,\n",
            "         0.7962908745,  0.1649527699, -0.1168846115,  0.5243953466])\n",
            "btensor.grad: tensor([-9.8835825920e-01, -6.4990979433e-01, -2.2280332446e-01,\n",
            "        -9.8022854328e-01, -3.7567803264e-01, -5.7368868589e-01,\n",
            "        -6.9491529465e-01, -9.0469837189e-02,  2.0936456323e-01,\n",
            "        -8.4969574213e-01, -5.7239568233e-01, -8.4168398380e-01,\n",
            "        -4.9958333373e-01, -3.9835238457e-01, -6.6126489639e-01,\n",
            "         1.2235969305e-01,  2.6263296604e-04, -5.4607260227e-01,\n",
            "        -5.8528840542e-01, -4.3285280466e-01])\n",
            "ctensor.grad: tensor([-1.6650869846e+00, -2.2437025070e+01, -2.1524213791e+01,\n",
            "        -8.7089248002e-02,  4.8856954090e-03,  4.5862134546e-02,\n",
            "         6.2619820237e-02,  2.4180306122e-02, -1.6106716156e+01,\n",
            "         1.1892652512e+00,  1.0920720100e+01,  8.3695535660e+00,\n",
            "        -5.4367046356e+00, -1.5947084427e+01,  1.1403597593e+00,\n",
            "         1.0133588791e+01,  8.1386375427e+00, -4.7174305916e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1056.3322753906, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4654542208), tensor(0.9709192514), tensor(1.0834430456), tensor(1.1216669083), tensor(1.1352145672), tensor(1.2577600479), tensor(0.9766223431), tensor(1.1474362612), tensor(0.9479005933), tensor(1.0885604620), tensor(0.9657001495), tensor(1.3922013044), tensor(0.9863060713), tensor(1.0257177353), tensor(1.0570930243), tensor(0.8583903313), tensor(0.9563014507), tensor(0.8245711327), tensor(1.0543010235), tensor(0.9228309989)]\n",
            "b:  [tensor(0.7498111129), tensor(1.1865099669), tensor(1.3405759335), tensor(1.1465220451), tensor(1.4937822819), tensor(0.8761034012), tensor(1.2656574249), tensor(1.1013195515), tensor(1.6455907822), tensor(0.9844151139), tensor(1.3487893343), tensor(0.8101701140), tensor(1.3105324507), tensor(1.3053704500), tensor(0.9965546131), tensor(0.9716799855), tensor(1.2524694204), tensor(1.7152869701), tensor(1.0662770271), tensor(1.2103822231)]\n",
            "c:  [tensor(0.0040111924), tensor(0.5359304547), tensor(0.5116941929), tensor(-0.0178735927), tensor(-0.0016217980), tensor(-0.0124482783), tensor(0.0063508200), tensor(0.0058128969), tensor(0.3897953331), tensor(-0.0113252439), tensor(0.0393048525), tensor(-0.1825150549), tensor(-0.0532234088), tensor(0.3721950352), tensor(-0.0056516742), tensor(0.0501567237), tensor(-0.1757442355), tensor(-0.0563005470)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.3504675627, -0.0305877328,  0.6164509058,  0.6537353992,\n",
            "         0.0297436118,  1.1801477671,  0.6776623726, -0.0648068190,\n",
            "         0.1453065872,  0.5997335315,  0.4874707758,  0.4981516898,\n",
            "        -0.1556006074,  1.5654618740,  0.7596092224,  0.5533581972,\n",
            "         0.7909143567,  0.1585883647, -0.1024811417,  0.5520259142])\n",
            "btensor.grad: tensor([-0.9508488178, -0.5987020135, -0.2340180874, -0.9610495567,\n",
            "        -0.3661795259, -0.5660208464, -0.7138589025, -0.1176038980,\n",
            "         0.1417163610, -0.8004913330, -0.5459216833, -0.8267869353,\n",
            "        -0.5069746971, -0.3784550428, -0.6414198875,  0.1230629086,\n",
            "        -0.0037900954, -0.5746641159, -0.5712482929, -0.4152050018])\n",
            "ctensor.grad: tensor([-1.7404413223e+00, -2.1970825195e+01, -2.1076299667e+01,\n",
            "        -1.1347559839e-01,  6.7125614733e-03,  6.5354637802e-02,\n",
            "         8.1468269229e-02,  3.4336224198e-02, -1.5574698448e+01,\n",
            "         1.2391237020e+00,  1.1464738846e+01,  7.7857103348e+00,\n",
            "        -5.2457265854e+00, -1.5446185112e+01,  1.1872104406e+00,\n",
            "         1.0646908760e+01,  7.5737419128e+00, -4.5395913124e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1055.3480224609, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4588207006), tensor(0.9711651802), tensor(1.0804640055), tensor(1.1184593439), tensor(1.1350125074), tensor(1.2521796227), tensor(0.9733951688), tensor(1.1479113102), tensor(0.9471940398), tensor(1.0858615637), tensor(0.9636272192), tensor(1.3899762630), tensor(0.9873867035), tensor(1.0181694031), tensor(1.0533896685), tensor(0.8559091091), tensor(0.9525895119), tensor(0.8240726590), tensor(1.0549676418), tensor(0.9201723933)]\n",
            "b:  [tensor(0.7545486689), tensor(1.1894545555), tensor(1.3419657946), tensor(1.1514132023), tensor(1.4957463741), tensor(0.8790817261), tensor(1.2694839239), tensor(1.1022202969), tensor(1.6453993320), tensor(0.9883666635), tensor(1.3515685797), tensor(0.8143815994), tensor(1.3132817745), tensor(1.3073151112), tensor(0.9998428226), tensor(0.9712612033), tensor(1.2526756525), tensor(1.7184441090), tensor(1.0692384243), tensor(1.2125595808)]\n",
            "c:  [tensor(0.0048116967), tensor(0.5466797948), tensor(0.5220071077), tensor(-0.0178024303), tensor(-0.0016261068), tensor(-0.0124882758), tensor(0.0063029365), tensor(0.0057940311), tensor(0.3976119757), tensor(-0.0119657554), tensor(0.0338930860), tensor(-0.1858312935), tensor(-0.0500410870), tensor(0.3799478710), tensor(-0.0062649962), tensor(0.0451396070), tensor(-0.1789762080), tensor(-0.0534975342)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.3266937733, -0.0491831154,  0.5958158970,  0.6415014267,\n",
            "         0.0404193997,  1.1160815954,  0.6454339027, -0.0950077772,\n",
            "         0.1413097382,  0.5397685170,  0.4145918190,  0.4450113475,\n",
            "        -0.2161238194,  1.5096702576,  0.7406626344,  0.4962451458,\n",
            "         0.7423866987,  0.0996908545, -0.1333158910,  0.5317157507])\n",
            "btensor.grad: tensor([-0.9475093484, -0.5889183283, -0.2779701650, -0.9782421589,\n",
            "        -0.3928196430, -0.5956648588, -0.7653113604, -0.1801465750,\n",
            "         0.0382995233, -0.7903078198, -0.5558539629, -0.8423020840,\n",
            "        -0.5498745441, -0.3889230490, -0.6576440334,  0.0837610960,\n",
            "        -0.0412546992, -0.6314314604, -0.5922869444, -0.4354717135])\n",
            "ctensor.grad: tensor([-1.6010086536e+00, -2.1498697281e+01, -2.0625881195e+01,\n",
            "        -1.4232642949e-01,  8.6175641045e-03,  7.9994477332e-02,\n",
            "         9.5767028630e-02,  3.7732020020e-02, -1.5633290291e+01,\n",
            "         1.2810225487e+00,  1.0823532104e+01,  6.6324853897e+00,\n",
            "        -6.3646416664e+00, -1.5505684853e+01,  1.2266439199e+00,\n",
            "         1.0034235954e+01,  6.4639573097e+00, -5.6060271263e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1054.4044189453, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4518707991), tensor(0.9707748294), tensor(1.0769276619), tensor(1.1146932840), tensor(1.1341677904), tensor(1.2464330196), tensor(0.9696667790), tensor(1.1479116678), tensor(0.9456964731), tensor(1.0828698874), tensor(0.9612533450), tensor(1.3875148296), tensor(0.9879561663), tensor(1.0104254484), tensor(1.0491484404), tensor(0.8529772758), tensor(0.9484937191), tensor(0.8230187297), tensor(1.0549997091), tensor(0.9168940783)]\n",
            "b:  [tensor(0.7587095499), tensor(1.1916952133), tensor(1.3430436850), tensor(1.1557469368), tensor(1.4972372055), tensor(0.8816177249), tensor(1.2730103731), tensor(1.1028122902), tensor(1.6451219320), tensor(0.9916539788), tensor(1.3538153172), tensor(0.8181826472), tensor(1.3156503439), tensor(1.3088382483), tensor(1.0026379824), tensor(0.9704113007), tensor(1.2525277138), tensor(1.7213339806), tensor(1.0717470646), tensor(1.2142211199)]\n",
            "c:  [tensor(0.0058746883), tensor(0.5571833253), tensor(0.5320824385), tensor(-0.0177254155), tensor(-0.0016313830), tensor(-0.0125466771), tensor(0.0062438883), tensor(0.0057589416), tensor(0.4045141935), tensor(-0.0126419049), tensor(0.0270692613), tensor(-0.1894392520), tensor(-0.0485341921), tensor(0.3868340850), tensor(-0.0069118319), tensor(0.0387870967), tensor(-0.1824783981), tensor(-0.0522829928)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.3899846077e+00,  7.8074723482e-02,  7.0727157593e-01,\n",
            "         7.5322294235e-01,  1.6893851757e-01,  1.1493265629e+00,\n",
            "         7.4567747116e-01, -7.4982643127e-05,  2.9951739311e-01,\n",
            "         5.9834361076e-01,  4.7478020191e-01,  4.9227643013e-01,\n",
            "        -1.1389601231e-01,  1.5488008261e+00,  8.4824621677e-01,\n",
            "         5.8636081219e-01,  8.1915289164e-01,  2.1078482270e-01,\n",
            "        -6.4171552658e-03,  6.5566408634e-01])\n",
            "btensor.grad: tensor([-0.8321796656, -0.4481210709, -0.2155732810, -0.8667535782,\n",
            "        -0.2981593013, -0.5072001219, -0.7052823305, -0.1184087992,\n",
            "         0.0554823615, -0.6574648023, -0.4493397474, -0.7602090240,\n",
            "        -0.4737251401, -0.3046351671, -0.5590260029,  0.1699848771,\n",
            "         0.0295939445, -0.5779781342, -0.5017247200, -0.3322997689])\n",
            "ctensor.grad: tensor([-2.1259832382e+00, -2.1007020950e+01, -2.0150697708e+01,\n",
            "        -1.5402826667e-01,  1.0552321561e-02,  1.1680279672e-01,\n",
            "         1.1809594184e-01,  7.0178613067e-02, -1.3804409027e+01,\n",
            "         1.3522980213e+00,  1.3647647858e+01,  7.2159051895e+00,\n",
            "        -3.0137925148e+00, -1.3772427559e+01,  1.2936713696e+00,\n",
            "         1.2705017090e+01,  7.0043745041e+00, -2.4290859699e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1053.5172119141, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4460940361), tensor(0.9721539021), tensor(1.0750397444), tensor(1.1124786139), tensor(1.1346479654), tensor(1.2421485186), tensor(0.9676634073), tensor(1.1494492292), tensor(0.9461603761), tensor(1.0815193653), tensor(0.9607539773), tensor(1.3864388466), tensor(0.9906328321), tensor(1.0041105747), tensor(1.0464643240), tensor(0.8520004749), tensor(0.9461484551), tensor(0.8241994977), tensor(1.0569190979), tensor(0.9154341817)]\n",
            "b:  [tensor(0.7641047239), tensor(1.1953824759), tensor(1.3455311060), tensor(1.1615470648), tensor(1.5001971722), tensor(0.8856302500), tensor(1.2780048847), tensor(1.1050548553), tensor(1.6466838121), tensor(0.9962925315), tensor(1.3574275970), tensor(0.8231593370), tensor(1.3195507526), tensor(1.3114943504), tensor(1.0068137646), tensor(0.9711800218), tensor(1.2537779808), tensor(1.7256346941), tensor(1.0756232738), tensor(1.2173697948)]\n",
            "c:  [tensor(0.0060944082), tensor(0.5674267411), tensor(0.5419183373), tensor(-0.0176137220), tensor(-0.0016376415), tensor(-0.0125788627), tensor(0.0061963592), tensor(0.0057647829), tensor(0.4136585593), tensor(-0.0133065404), tensor(0.0248126537), tensor(-0.1903977543), tensor(-0.0413484275), tensor(0.3958525956), tensor(-0.0075479974), tensor(0.0367745310), tensor(-0.1834466457), tensor(-0.0456709042)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 1.1553447247, -0.2758109272,  0.3775743246,  0.4429278374,\n",
            "        -0.0960456729,  0.8568973541,  0.4006786346, -0.3075031042,\n",
            "        -0.0927772522,  0.2701053917,  0.0998692513,  0.2151964307,\n",
            "        -0.5353372097,  1.2629774809,  0.5368173122,  0.1953562796,\n",
            "         0.4690499306, -0.2361482233, -0.3838812411,  0.2919769287])\n",
            "btensor.grad: tensor([-1.0790325403, -0.7374475598, -0.4974957705, -1.1600146294,\n",
            "        -0.5919995308, -0.8025069833, -0.9988937974, -0.4485019445,\n",
            "        -0.3123770654, -0.9277070761, -0.7224512100, -0.9953435659,\n",
            "        -0.7800785303, -0.5312112570, -0.8351564407, -0.1537387371,\n",
            "        -0.2500495315, -0.8601487875, -0.7752482891, -0.6297369003])\n",
            "ctensor.grad: tensor([-4.3943974376e-01, -2.0486787796e+01, -1.9671823502e+01,\n",
            "        -2.2338554263e-01,  1.2516884133e-02,  6.4370885491e-02,\n",
            "         9.5057979226e-02, -1.1682644486e-02, -1.8288757324e+01,\n",
            "         1.3292716742e+00,  4.5132169724e+00,  1.9170100689e+00,\n",
            "        -1.4371524811e+01, -1.8037048340e+01,  1.2723312378e+00,\n",
            "         4.0251350403e+00,  1.9364933968e+00, -1.3224180222e+01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1052.8568115234, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4364691973), tensor(0.9670502543), tensor(1.0672756433), tensor(1.1046836376), tensor(1.1297323704), tensor(1.2337559462), tensor(0.9597877264), tensor(1.1455594301), tensor(0.9392386079), tensor(1.0751558542), tensor(0.9546512961), tensor(1.3811266422), tensor(0.9863972664), tensor(0.9937342405), tensor(1.0381723642), tensor(0.8446877599), tensor(0.9382792711), tensor(0.8180429935), tensor(1.0520284176), tensor(0.9074972272)]\n",
            "b:  [tensor(0.7644441724), tensor(1.1931085587), tensor(1.3434680700), tensor(1.1617639065), tensor(1.4979208708), tensor(0.8845137358), tensor(1.2783055305), tensor(1.1021434069), tensor(1.6433885098), tensor(0.9953188300), tensor(1.3558510542), tensor(0.8238161802), tensor(1.3183361292), tensor(1.3099378347), tensor(1.0058926344), tensor(0.9665402770), tensor(1.2503956556), tensor(1.7254583836), tensor(1.0745781660), tensor(1.2150882483)]\n",
            "c:  [tensor(0.0092484150), tensor(0.5772939920), tensor(0.5513678193), tensor(-0.0175774395), tensor(-0.0016450657), tensor(-0.0127540957), tensor(0.0060778051), tensor(0.0055934032), tensor(0.4142226577), tensor(-0.0141227059), tensor(0.0066681597), tensor(-0.1989264786), tensor(-0.0541495457), tensor(0.3967162967), tensor(-0.0083266618), tensor(0.0196857005), tensor(-0.1916183382), tensor(-0.0580436178)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([1.9249728918, 1.0207321644, 1.5528268814, 1.5589861870, 0.9831103086,\n",
            "        1.6785249710, 1.5751404762, 0.7779706717, 1.3843584061, 1.2727093697,\n",
            "        1.2205314636, 1.0624480247, 0.8471081853, 2.0752689838, 1.6583858728,\n",
            "        1.4625408649, 1.5738375187, 1.2313022614, 0.9781290889, 1.5873916149])\n",
            "btensor.grad: tensor([-0.0678906739,  0.4547744095,  0.4126031697, -0.0433638096,\n",
            "         0.4552588165,  0.2233070731, -0.0601282492,  0.5822975636,\n",
            "         0.6590573788,  0.1947395802,  0.3153018951, -0.1313667744,\n",
            "         0.2429358065,  0.3113049865,  0.1842160225,  0.9279474616,\n",
            "         0.6764652729,  0.0352582335,  0.2090308666,  0.4563058615])\n",
            "ctensor.grad: tensor([-6.3080134392e+00, -1.9734516144e+01, -1.8898935318e+01,\n",
            "        -7.2564378381e-02,  1.4848566614e-02,  3.5046532750e-01,\n",
            "         2.3710788786e-01,  3.4275934100e-01, -1.1282197237e+00,\n",
            "         1.6323318481e+00,  3.6288986206e+01,  1.7057437897e+01,\n",
            "         2.5602237701e+01, -1.7274219990e+00,  1.5573287010e+00,\n",
            "         3.4177658081e+01,  1.6343395233e+01,  2.4745428085e+01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1054.7800292969, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4419071674), tensor(0.9861866832), tensor(1.0819439888), tensor(1.1180284023), tensor(1.1442137957), tensor(1.2422609329), tensor(0.9747772813), tensor(1.1616392136), tensor(0.9600532055), tensor(1.0889040232), tensor(0.9712573886), tensor(1.3922913074), tensor(1.0090255737), tensor(1.0004664660), tensor(1.0515371561), tensor(0.8624742627), tensor(0.9522967935), tensor(0.8407225013), tensor(1.0725599527), tensor(0.9244531393)]\n",
            "b:  [tensor(0.7815446854), tensor(1.2111268044), tensor(1.3582016230), tensor(1.1810866594), tensor(1.5143092871), tensor(0.9016138911), tensor(1.2957924604), tensor(1.1185315847), tensor(1.6594773531), tensor(1.0131095648), tensor(1.3722802401), tensor(0.8394348621), tensor(1.3357509375), tensor(1.3232568502), tensor(1.0227448940), tensor(0.9817667007), tensor(1.2641324997), tensor(1.7416123152), tensor(1.0909144878), tensor(1.2320823669)]\n",
            "c:  [tensor(0.0010914691), tensor(0.5847908854), tensor(0.5586976409), tensor(-0.0170807466), tensor(-0.0016514378), tensor(-0.0121879699), tensor(0.0063316608), tensor(0.0063570375), tensor(0.4481766820), tensor(-0.0144859459), tensor(0.0515114293), tensor(-0.1766789854), tensor(0.0088637918), tensor(0.4293486476), tensor(-0.0086798351), tensor(0.0625401363), tensor(-0.1703328639), tensor(0.0017973743)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.0876019001, -3.8272867203, -2.9336657524, -2.6689510345,\n",
            "        -2.8962917328, -1.7010066509, -2.9979150295, -3.2159566879,\n",
            "        -4.1629199982, -2.7496309280, -3.3212132454, -2.2329332829,\n",
            "        -4.5256733894, -1.3464447260, -2.6729497910, -3.5573062897,\n",
            "        -2.8035078049, -4.5358996391, -4.1063117981, -3.3911867142])\n",
            "btensor.grad: tensor([-3.4201009274, -3.6036596298, -2.9467039108, -3.8645415306,\n",
            "        -3.2776920795, -3.4200282097, -3.4973919392, -3.2776396275,\n",
            "        -3.2177600861, -3.5581450462, -3.2858448029, -3.1237316132,\n",
            "        -3.4829633236, -2.6638007164, -3.3704450130, -3.0452852249,\n",
            "        -2.7473678589, -3.2307960987, -3.2672600746, -3.3988256454])\n",
            "ctensor.grad: tensor([ 1.6313890457e+01, -1.4993817329e+01, -1.4659680367e+01,\n",
            "        -9.9338394403e-01,  1.2744260952e-02, -1.1322516203e+00,\n",
            "        -5.0771117210e-01, -1.5272685289e+00, -6.7908073425e+01,\n",
            "         7.2647923231e-01, -8.9686531067e+01, -4.4494995117e+01,\n",
            "        -1.2602666473e+02, -6.5264678955e+01,  7.0634615421e-01,\n",
            "        -8.5708869934e+01, -4.2570953369e+01, -1.1968197632e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1086.6623535156, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4041007757), tensor(0.9301060438), tensor(1.0308315754), tensor(1.0683460236), tensor(1.0953156948), tensor(1.2024633884), tensor(0.9227951765), tensor(1.1122539043), tensor(0.8980200887), tensor(1.0450242758), tensor(0.9231744409), tensor(1.3518390656), tensor(0.9536814690), tensor(0.9611628056), tensor(1.0030280352), tensor(0.8084235191), tensor(0.9014633894), tensor(0.7805761099), tensor(1.0167968273), tensor(0.8690477610)]\n",
            "b:  [tensor(0.7280865908), tensor(1.1536866426), tensor(1.3132108450), tensor(1.1270463467), tensor(1.4644420147), tensor(0.8508352637), tensor(1.2497665882), tensor(1.0706461668), tensor(1.6132093668), tensor(0.9552148581), tensor(1.3208717108), tensor(0.7947991490), tensor(1.2862268686), tensor(1.2812289000), tensor(0.9714295268), tensor(0.9303451180), tensor(1.2196471691), tensor(1.6982691288), tensor(1.0417523384), tensor(1.1799707413)]\n",
            "c:  [tensor(0.0258369148), tensor(0.5721768141), tensor(0.5465665460), tensor(-0.0171727985), tensor(-0.0016540060), tensor(-0.0124052009), tensor(0.0062108543), tensor(0.0060855537), tensor(0.4042923748), tensor(-0.0160727222), tensor(-0.0557830855), tensor(-0.2374359965), tensor(-0.1369316280), tensor(0.3870388269), tensor(-0.0102136470), tensor(-0.0405285358), tensor(-0.2286444157), tensor(-0.1386837065)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 7.5612864494, 11.2161235809, 10.2224884033,  9.9364643097,\n",
            "         9.7796249390,  7.9595046043, 10.3964252472,  9.8770542145,\n",
            "        12.4066276550,  8.7759561539,  9.6165933609,  8.0904417038,\n",
            "        11.0688247681,  7.8607263565,  9.7018327713, 10.8101520538,\n",
            "        10.1666793823, 12.0292797089, 11.1526327133, 11.0810775757])\n",
            "btensor.grad: tensor([10.6916170120, 11.4880237579,  8.9981479645, 10.8080749512,\n",
            "         9.9734468460, 10.1557235718,  9.2051668167,  9.5770902634,\n",
            "         9.2535953522, 11.5789461136, 10.2817115784,  8.9271478653,\n",
            "         9.9048099518,  8.4055833817, 10.2630786896, 10.2843217850,\n",
            "         8.8970603943,  8.6686344147,  9.8324298859, 10.4223175049])\n",
            "ctensor.grad: tensor([-4.9490890503e+01,  2.5228147507e+01,  2.4262207031e+01,\n",
            "         1.8410253525e-01,  5.1362649538e-03,  4.3446239829e-01,\n",
            "         2.4161313474e-01,  5.4296791553e-01,  8.7768608093e+01,\n",
            "         3.1735529900e+00,  2.1458901978e+02,  1.2151399994e+02,\n",
            "         2.9159082031e+02,  8.4619651794e+01,  3.0676245689e+00,\n",
            "         2.0613732910e+02,  1.1662310028e+02,  2.8096215820e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1226.0786132812, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.5246886015), tensor(1.1328759193), tensor(1.2185806036), tensor(1.2438962460), tensor(1.2412604094), tensor(1.3456006050), tensor(1.1290855408), tensor(1.2519781590), tensor(1.1369502544), tensor(1.2276210785), tensor(1.1426298618), tensor(1.4720630646), tensor(1.1715698242), tensor(1.1484485865), tensor(1.2073341608), tensor(1.0660113096), tensor(1.0988788605), tensor(1.0641990900), tensor(1.2120311260), tensor(1.0946538448)]\n",
            "b:  [tensor(0.8090395927), tensor(1.2542884350), tensor(1.4117735624), tensor(1.2239794731), tensor(1.5661951303), tensor(0.9476882219), tensor(1.3484314680), tensor(1.1821564436), tensor(1.7279082537), tensor(1.0457998514), tensor(1.4161930084), tensor(0.8757709265), tensor(1.3907477856), tensor(1.3687797785), tensor(1.0651894808), tensor(1.0445073843), tensor(1.3221595287), tensor(1.7943748236), tensor(1.1367001534), tensor(1.2850444317)]\n",
            "c:  [tensor(-0.0745380670), tensor(0.4404674768), tensor(0.4188710451), tensor(-0.0043859147), tensor(-0.0015713085), tensor(0.0094531821), tensor(0.0163423233), tensor(0.0305988751), tensor(0.6134243608), tensor(-0.0149378460), tensor(0.2843678892), tensor(-0.1011413485), tensor(0.1835658550), tensor(0.5961276293), tensor(-0.0090829926), tensor(0.3013959527), tensor(-0.0907496512), tensor(0.1828810275)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-24.1175613403, -40.5539779663, -37.5498123169, -35.1100578308,\n",
            "        -29.1889438629, -28.6274566650, -41.2580833435, -27.9448413849,\n",
            "        -47.7860260010, -36.5193481445, -43.8910980225, -24.0447940826,\n",
            "        -43.5776672363, -37.4571609497, -40.8612174988, -51.5175628662,\n",
            "        -39.4830932617, -56.7245903015, -39.0468482971, -45.1212081909])\n",
            "btensor.grad: tensor([-16.1906013489, -20.1203670502, -19.7125492096, -19.3866176605,\n",
            "        -20.3506164551, -19.3705863953, -19.7329845428, -22.3020668030,\n",
            "        -22.9397811890, -18.1169891357, -19.0642642975, -16.1943511963,\n",
            "        -20.9041938782, -17.5101871490, -18.7519912720, -22.8324546814,\n",
            "        -20.5024604797, -19.2211380005, -18.9895648956, -21.0147495270])\n",
            "ctensor.grad: tensor([ 2.0074995422e+02,  2.6341864014e+02,  2.5539094543e+02,\n",
            "        -2.5573766708e+01, -1.6539505124e-01, -4.3716762543e+01,\n",
            "        -2.0262935638e+01, -4.9026638031e+01, -4.1826391602e+02,\n",
            "        -2.2697515488e+00, -6.8030194092e+02, -2.7258929443e+02,\n",
            "        -6.4099493408e+02, -4.1817755127e+02, -2.2613089085e+00,\n",
            "        -6.8384893799e+02, -2.7578952026e+02, -6.4312945557e+02])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1220.6787109375, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4666818380), tensor(1.0303980112), tensor(1.1346487999), tensor(1.1588081121), tensor(1.1482762098), tensor(1.2823448181), tensor(1.0404715538), tensor(1.1626870632), tensor(1.0293440819), tensor(1.1513102055), tensor(1.0567258596), tensor(1.4041131735), tensor(1.0738664865), tensor(1.0834033489), tensor(1.1242021322), tensor(0.9706765413), tensor(1.0129988194), tensor(0.9565100670), tensor(1.1170805693), tensor(0.9993091226)]\n",
            "b:  [tensor(0.6626678705), tensor(1.1333932877), tensor(1.3088171482), tensor(1.1006780863), tensor(1.4619960785), tensor(0.8225933313), tensor(1.2361907959), tensor(1.0860577822), tensor(1.6435581446), tensor(0.9114033580), tensor(1.3013669252), tensor(0.7409119010), tensor(1.2833905220), tensor(1.2556904554), tensor(0.9412593246), tensor(0.9463644624), tensor(1.2246291637), tensor(1.6954569817), tensor(1.0185378790), tensor(1.1744337082)]\n",
            "c:  [tensor(-0.0564538017), tensor(0.3556698561), tensor(0.3339388371), tensor(0.0105434367), tensor(-0.0012656639), tensor(0.0416395627), tensor(0.0342242792), tensor(0.0709559545), tensor(0.6122634411), tensor(-0.0149997659), tensor(0.2808079123), tensor(-0.1037080884), tensor(0.1764780879), tensor(0.5951312184), tensor(-0.0091378391), tensor(0.2983627319), tensor(-0.0929280892), tensor(0.1767306924)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([11.6013441086, 20.4955825806, 16.7863674164, 17.0176181793,\n",
            "        18.5968303680, 12.6511573792, 17.7227954865, 17.8582172394,\n",
            "        21.5212364197, 15.2621784210, 17.1807994843, 13.5899696350,\n",
            "        19.5406665802, 13.0090484619, 16.6264019012, 19.0669593811,\n",
            "        17.1760025024, 21.5378093719, 18.9901008606, 19.0689449310])\n",
            "btensor.grad: tensor([29.2743492126, 24.1790256500, 20.5912933350, 24.6602706909,\n",
            "        20.8398132324, 25.0189819336, 22.4481239319, 19.2197227478,\n",
            "        16.8700275421, 26.8793010712, 22.9652252197, 26.9718036652,\n",
            "        21.4714431763, 22.6178588867, 24.7860279083, 19.6285820007,\n",
            "        19.5060710907, 19.7835636139, 23.6324520111, 22.1221408844])\n",
            "ctensor.grad: tensor([-3.6168533325e+01,  1.6959526062e+02,  1.6986437988e+02,\n",
            "        -2.9858701706e+01, -6.1128920317e-01, -6.4372756958e+01,\n",
            "        -3.5763912201e+01, -8.0714157104e+01,  2.3218522072e+00,\n",
            "         1.2383983284e-01,  7.1199483871e+00,  5.1334724426e+00,\n",
            "         1.4175530434e+01,  1.9927860498e+00,  1.0969220102e-01,\n",
            "         6.0664510727e+00,  4.3568744659e+00,  1.2300664902e+01])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1131.1949462891, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4464285374), tensor(0.9698549509), tensor(1.0919395685), tensor(1.1145000458), tensor(1.0956925154), tensor(1.2587819099), tensor(0.9941546917), tensor(1.1142294407), tensor(0.9631219506), tensor(1.1162749529), tensor(1.0129392147), tensor(1.3745757341), tensor(1.0176404715), tensor(1.0603555441), tensor(1.0826925039), tensor(0.9191863537), tensor(0.9701884985), tensor(0.8909012675), tensor(1.0634464025), tensor(0.9468281865)]\n",
            "b:  [tensor(0.5873227119), tensor(1.0684876442), tensor(1.2578675747), tensor(1.0341563225), tensor(1.4082566500), tensor(0.7611938715), tensor(1.1776590347), tensor(1.0448493958), tensor(1.6066939831), tensor(0.8386573792), tensor(1.2395898104), tensor(0.6721116900), tensor(1.2288140059), tensor(1.1955149174), tensor(0.8776049614), tensor(0.9063816071), tensor(1.1800527573), tensor(1.6445673704), tensor(0.9583367109), tensor(1.1186118126)]\n",
            "c:  [tensor(-0.0683818161), tensor(0.3119508922), tensor(0.2900866270), tensor(0.0139832906), tensor(-0.0011215330), tensor(0.0518055670), tensor(0.0408944599), tensor(0.0858492330), tensor(0.6115016341), tensor(-0.0150421513), tensor(0.2783488631), tensor(-0.1054661125), tensor(0.1715908200), tensor(0.5944970846), tensor(-0.0091743236), tensor(0.2963304222), tensor(-0.0943734348), tensor(0.1726182103)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([ 4.0506691933, 12.1086130142,  8.5418415070,  8.8616256714,\n",
            "        10.5167388916,  4.7125720978,  9.2633762360,  9.6915187836,\n",
            "        13.2444238663,  7.0070471764,  8.7573204041,  5.9074869156,\n",
            "        11.2452077866,  4.6095557213,  8.3019323349, 10.2980384827,\n",
            "         8.5620698929, 13.1217613220, 10.7268266678, 10.4961881638])\n",
            "btensor.grad: tensor([15.0690364838, 12.9811410904, 10.1899166107, 13.3043556213,\n",
            "        10.7478914261, 12.2798976898, 11.7063493729,  8.2416772842,\n",
            "         7.3728265762, 14.5491971970, 12.3554210663, 13.7600450516,\n",
            "        10.9153070450, 12.0351123810, 12.7308673859,  7.9965739250,\n",
            "         8.9152889252, 10.1779155731, 12.0402278900, 11.1643819809])\n",
            "ctensor.grad: tensor([ 2.3856023788e+01,  8.7437927246e+01,  8.7704391479e+01,\n",
            "        -6.8797078133e+00, -2.8826171160e-01, -2.0332008362e+01,\n",
            "        -1.3340362549e+01, -2.9786554337e+01,  1.5236077309e+00,\n",
            "         8.4770187736e-02,  4.9180836678e+00,  3.5160531998e+00,\n",
            "         9.7745389938e+00,  1.2682687044e+00,  7.2969481349e-02,\n",
            "         4.0645990372e+00,  2.8906936646e+00,  8.2249650955e+00])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1107.9185791016, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4451879263), tensor(0.9340624809), tensor(1.0720212460), tensor(1.0927876234), tensor(1.0661194324), tensor(1.2555131912), tensor(0.9716380239), tensor(1.0887619257), tensor(0.9217700958), tensor(1.1033539772), tensor(0.9925830364), tensor(1.3650741577), tensor(0.9854696989), tensor(1.0587804317), tensor(1.0640993118), tensor(0.8930631280), tensor(0.9514312744), tensor(0.8506677151), tensor(1.0335240364), tensor(0.9190771580)]\n",
            "b:  [tensor(0.5554039478), tensor(1.0345400572), tensor(1.2341550589), tensor(0.9993103743), tensor(1.3811327219), tensor(0.7352038622), tensor(1.1480720043), tensor(1.0310925245), tensor(1.5934106112), tensor(0.8017290235), tensor(1.2067111731), tensor(0.6418344975), tensor(1.2022014856), tensor(1.1641542912), tensor(0.8475193381), tensor(0.8951038718), tensor(1.1624991894), tensor(1.6186727285), tensor(0.9297600985), tensor(1.0920237303)]\n",
            "c:  [tensor(-0.0759615377), tensor(0.2911569178), tensor(0.2691596746), tensor(0.0137810148), tensor(-0.0010073304), tensor(0.0557191260), tensor(0.0447266996), tensor(0.0942252874), tensor(0.6109309196), tensor(-0.0150755690), tensor(0.2764105201), tensor(-0.1068425328), tensor(0.1677440852), tensor(0.5940335393), tensor(-0.0092024310), tensor(0.2947669625), tensor(-0.0954762101), tensor(0.1694605350)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([0.2481143773, 7.1584882736, 3.9836714268, 4.3424873352, 5.9146080017,\n",
            "        0.6537454128, 4.5033283234, 5.0935096741, 8.2703714371, 2.5841913223,\n",
            "        4.0712385178, 1.9003193378, 6.4341526031, 0.3150143623, 3.7186474800,\n",
            "        5.2246503830, 3.7514507771, 8.0467061996, 5.9844675064, 5.5502090454])\n",
            "btensor.grad: tensor([6.3837523460, 6.7895278931, 4.7424960136, 6.9691915512, 5.4247756004,\n",
            "        5.1980066299, 5.9174151421, 2.7513823509, 2.6566791534, 7.3856687546,\n",
            "        6.5757188797, 6.0554404259, 5.3224935532, 6.2721328735, 6.0171232224,\n",
            "        2.2555520535, 3.5107178688, 5.1789369583, 5.7153239250, 5.3176174164])\n",
            "ctensor.grad: tensor([ 15.1594381332,  41.5879211426,  41.8539199829,   0.4045515954,\n",
            "         -0.2284052670,  -7.8271203041,  -7.6644821167, -16.7521133423,\n",
            "          1.1413947344,   0.0668353736,   3.8766667843,   2.7528405190,\n",
            "          7.6934604645,   0.9270966053,   0.0562151186,   3.1269412041,\n",
            "          2.2055554390,   6.3153505325])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1102.2489013672, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4522019625), tensor(0.9119876027), tensor(1.0634851456), tensor(1.0824744701), tensor(1.0487724543), tensor(1.2611355782), tensor(0.9612257481), tensor(1.0752389431), tensor(0.8946653605), tensor(1.1008783579), tensor(0.9839406610), tensor(1.3648568392), tensor(0.9663251638), tensor(1.0663163662), tensor(1.0568424463), tensor(0.8802572489), tensor(0.9446266294), tensor(0.8249154687), tensor(1.0162531137), tensor(0.9043963552)]\n",
            "b:  [tensor(0.5452839136), tensor(1.0167808533), tensor(1.2238233089), tensor(0.9811652899), tensor(1.3673831224), tensor(0.7263792157), tensor(1.1332582235), tensor(1.0294697285), tensor(1.5909185410), tensor(0.7839455605), tensor(1.1889135838), tensor(0.6308841705), tensor(1.1895434856), tensor(1.1478066444), tensor(0.8344508410), tensor(0.8958582878), tensor(1.1575369835), tensor(1.6052333117), tensor(0.9170587063), tensor(1.0799872875)]\n",
            "c:  [tensor(-0.0787998289), tensor(0.2820299864), tensor(0.2598948181), tensor(0.0116458079), tensor(-0.0009100478), tensor(0.0562912896), tensor(0.0470328778), tensor(0.0990477726), tensor(0.6104411483), tensor(-0.0151055092), tensor(0.2746830583), tensor(-0.1080648601), tensor(0.1643192023), tensor(0.5936431885), tensor(-0.0092271660), tensor(0.2933990955), tensor(-0.0964363143), tensor(0.1667021513)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.4028097391,  4.4149708748,  1.7072105408,  2.0626204014,\n",
            "         3.4693989754, -1.1244714260,  2.0824608803,  2.7046067715,\n",
            "         5.4209470749,  0.4951124191,  1.7284710407,  0.0434553027,\n",
            "         3.8289062977, -1.5071790218,  1.4513702393,  2.5611748695,\n",
            "         1.3609247208,  5.1504492760,  3.4541747570,  2.9361608028])\n",
            "btensor.grad: tensor([ 2.0240056515,  3.5518479347,  2.0663540363,  3.6290159225,\n",
            "         2.7499225140,  1.7649309635,  2.9627470970,  0.3245596886,\n",
            "         0.4984251261,  3.5566987991,  3.5595293045,  2.1900703907,\n",
            "         2.5315926075,  3.2695355415,  2.6136972904, -0.1508856416,\n",
            "         0.9924347997,  2.6878764629,  2.5402750969,  2.4072923660])\n",
            "ctensor.grad: tensor([ 5.6765885353, 18.2538547516, 18.5297050476,  4.2704143524,\n",
            "        -0.1945650131, -1.1443266869, -4.6123538017, -9.6449699402,\n",
            "         0.9795029163,  0.0598804168,  3.4549493790,  2.4446527958,\n",
            "         6.8497653008,  0.7807558775,  0.0494698733,  2.7357280254,\n",
            "         1.9202027321,  5.5167579651])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.7490234375, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4618816376), tensor(0.8971504569), tensor(1.0599821806), tensor(1.0773377419), tensor(1.0375483036), tensor(1.2696640491), tensor(0.9562988281), tensor(1.0674486160), tensor(0.8754920363), tensor(1.1025062799), tensor(0.9804435372), tensor(1.3682185411), tensor(0.9538347125), tensor(1.0764751434), tensor(1.0544910431), tensor(0.8737370372), tensor(0.9429467916), tensor(0.8071074486), tensor(1.0053032637), tensor(0.8960304260)]\n",
            "b:  [tensor(0.5437283516), tensor(1.0069928169), tensor(1.2195067406), tensor(0.9713067412), tensor(1.3599320650), tensor(0.7246083617), tensor(1.1255112886), tensor(1.0321896076), tensor(1.5926364660), tensor(0.7754986882), tensor(1.1786230803), tensor(0.6280584335), tensor(1.1833268404), tensor(1.1389056444), tensor(0.8291243911), tensor(0.9003785849), tensor(1.1576545238), tensor(1.5976166725), tensor(0.9115784168), tensor(1.0745828152)]\n",
            "c:  [tensor(-0.0791376904), tensor(0.2782616317), tensor(0.2559783459), tensor(0.0086027179), tensor(-0.0008224799), tensor(0.0552523732), tensor(0.0485783219), tensor(0.1020730585), tensor(0.6099767685), tensor(-0.0151347015), tensor(0.2730091810), tensor(-0.1092483848), tensor(0.1610021740), tensor(0.5932786465), tensor(-0.0092509314), tensor(0.2920930982), tensor(-0.0973513499), tensor(0.1640712172)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.9359424114,  2.9674284458,  0.7005860806,  1.0273510218,\n",
            "         2.2448217869, -1.7056919336,  0.9853819013,  1.5580658913,\n",
            "         3.8346621990, -0.3255937397,  0.6994271278, -0.6723310947,\n",
            "         2.4980924129, -2.0317616463,  0.4702792764,  1.3040411472,\n",
            "         0.3359620571,  3.5616030693,  2.1899721622,  1.6731842756])\n",
            "btensor.grad: tensor([ 0.3111179173,  1.9576108456,  0.8633024693,  1.9717137814,\n",
            "         1.4902039766,  0.3541691303,  1.5493931770, -0.5439795256,\n",
            "        -0.3435812891,  1.6893782616,  2.0581023693,  0.5651465654,\n",
            "         1.2433289289,  1.7802108526,  1.0652854443, -0.9040614963,\n",
            "        -0.0235129446,  1.5233291388,  1.0960519314,  1.0809020996])\n",
            "ctensor.grad: tensor([ 0.6757259965,  7.5367231369,  7.8329477310,  6.0861792564,\n",
            "        -0.1751359105,  2.0778336525, -3.0908858776, -6.0505642891,\n",
            "         0.9287104607,  0.0583855137,  3.3477740288,  2.3670504093,\n",
            "         6.6340498924,  0.7290907502,  0.0475317873,  2.6119983196,\n",
            "         1.8300638199,  5.2618536949])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1100.1621093750, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4717800617), tensor(0.8862591386), tensor(1.0585186481), tensor(1.0744297504), tensor(1.0294568539), tensor(1.2784830332), tensor(0.9536958337), tensor(1.0623794794), tensor(0.8609617352), tensor(1.1053574085), tensor(0.9789946079), tensor(1.3725825548), tensor(0.9448211789), tensor(1.0865025520), tensor(1.0540320873), tensor(0.8700452447), tensor(0.9431762099), tensor(0.7938337922), tensor(0.9975539446), tensor(0.8906561136)]\n",
            "b:  [tensor(0.5448028445), tensor(1.0011460781), tensor(1.2177656889), tensor(0.9655669928), tensor(1.3554326296), tensor(0.7253051400), tensor(1.1211258173), tensor(1.0359164476), tensor(1.5956289768), tensor(0.7714426517), tensor(1.1721394062), tensor(0.6281653047), tensor(1.1800099611), tensor(1.1337436438), tensor(0.8271060586), tensor(0.9053208232), tensor(1.1594812870), tensor(1.5927141905), tensor(0.9092171788), tensor(1.0720809698)]\n",
            "c:  [tensor(-0.0784721747), tensor(0.2768435776), tensor(0.2543977797), tensor(0.0051468406), tensor(-0.0007406502), tensor(0.0534559563), tensor(0.0497490689), tensor(0.1041920036), tensor(0.6095112562), tensor(-0.0151644461), tensor(0.2713129222), tensor(-0.1104487628), tensor(0.1576410532), tensor(0.5929181576), tensor(-0.0092748227), tensor(0.2907870710), tensor(-0.0982664227), tensor(0.1614417583)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.9796937704,  2.1782603264,  0.2927024364,  0.5815930367,\n",
            "         1.6182885170, -1.7637964487,  0.5205968618,  1.0138276815,\n",
            "         2.9060621262, -0.5702309012,  0.2897917032, -0.8728018403,\n",
            "         1.8027064800, -2.0054781437,  0.0917976499,  0.7383532524,\n",
            "        -0.0458853245,  2.6547315121,  1.5498607159,  1.0748574734])\n",
            "btensor.grad: tensor([-0.2149001360,  1.1693462133,  0.3482101560,  1.1479518414,\n",
            "         0.8998970985, -0.1393615603,  0.8770842552, -0.7453762889,\n",
            "        -0.5985093713,  0.8112105727,  1.2967276573, -0.0213776231,\n",
            "         0.6633781195,  1.0323910713,  0.4036669731, -0.9884455204,\n",
            "        -0.3653416038,  0.9805039167,  0.4722489119,  0.5003769398])\n",
            "ctensor.grad: tensor([-1.3310335875,  2.8361344337,  3.1611089706,  6.9117541313,\n",
            "        -0.1636594385,  3.5928370953, -2.3414955139, -4.2378969193,\n",
            "         0.9310421944,  0.0594900399,  3.3924896717,  2.4007530212,\n",
            "         6.7222409248,  0.7209422588,  0.0477833189,  2.6120815277,\n",
            "         1.8301422596,  5.2589106560])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.8093261719, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4809703827), tensor(0.8777301311), tensor(1.0578118563), tensor(1.0724725723), tensor(1.0231212378), tensor(1.2866129875), tensor(0.9520440698), tensor(1.0586707592), tensor(0.8494251966), tensor(1.1082774401), tensor(0.9782767892), tensor(1.3769099712), tensor(0.9377935529), tensor(1.0954431295), tensor(1.0541911125), tensor(0.8676270843), tensor(0.9439599514), tensor(0.7833961844), tensor(0.9915638566), tensor(0.8867653012)]\n",
            "b:  [tensor(0.5463552475), tensor(0.9973561168), tensor(1.2170974016), tensor(0.9619756341), tensor(1.3523837328), tensor(0.7266430855), tensor(1.1184085608), tensor(1.0394150019), tensor(1.5987155437), tensor(0.7694601417), tensor(1.1677221060), tensor(0.6291286349), tensor(1.1780229807), tensor(1.1305708885), tensor(0.8264479637), tensor(0.9095808864), tensor(1.1616493464), tensor(1.5891478062), tensor(0.9081745148), tensor(1.0708407164)]\n",
            "c:  [tensor(-0.0775317922), tensor(0.2764627635), tensor(0.2538365424), tensor(0.0014847761), tensor(-0.0006625248), tensor(0.0512711555), tensor(0.0507192984), tensor(0.1058066860), tensor(0.6090314388), tensor(-0.0151953949), tensor(0.2695559263), tensor(-0.1116942242), tensor(0.1541585475), tensor(0.5925516486), tensor(-0.0092993462), tensor(0.2894518673), tensor(-0.0992027670), tensor(0.1587542444)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.8380529881,  1.7058060169,  0.1413555145,  0.3914285898,\n",
            "         1.2671270370, -1.6260025501,  0.3303508162,  0.7417497635,\n",
            "         2.3073072433, -0.5840181708,  0.1435630322, -0.8654727936,\n",
            "         1.4055263996, -1.7881122828, -0.0318157300,  0.4836283922,\n",
            "        -0.1567529440,  2.0875222683,  1.1980153322,  0.7781635523])\n",
            "btensor.grad: tensor([-0.3104768097,  0.7579904199,  0.1336635947,  0.7182681561,\n",
            "         0.6097692251, -0.2675840855,  0.5434607267, -0.6997081637,\n",
            "        -0.6173219681,  0.3964965343,  0.8834530115, -0.1926681250,\n",
            "         0.3974057138,  0.6345474720,  0.1316136122, -0.8520104885,\n",
            "        -0.4336124063,  0.7132707834,  0.2085343599,  0.2480611801])\n",
            "ctensor.grad: tensor([-1.8807711601,  0.7616407275,  1.1224950552,  7.3241286278,\n",
            "        -0.1562508196,  4.3696026802, -1.9404579401, -3.2293705940,\n",
            "         0.9596660137,  0.0618967153,  3.5140085220,  2.4909298420,\n",
            "         6.9650053978,  0.7330187559,  0.0490470529,  2.6704113483,\n",
            "         1.8726934195,  5.3750219345])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-entropy loss vs Poisson: tensor(1099.5469970703, grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "Weights:\n",
            "\n",
            "a:  [tensor(1.4891719818), tensor(0.8707800508), tensor(1.0573395491), tensor(1.0709322691), tensor(1.0179007053), tensor(1.2937655449), tensor(0.9507727623), tensor(1.0557109118), tensor(0.8400140405), tensor(1.1108582020), tensor(0.9777632356), tensor(1.3808274269), tensor(0.9320400953), tensor(1.1030801535), tensor(1.0544631481), tensor(0.8658012152), tensor(0.9447688460), tensor(0.7749144435), tensor(0.9866616130), tensor(0.8836818933)]\n",
            "b:  [tensor(0.5477458835), tensor(0.9947291017), tensor(1.2168593407), tensor(0.9595870972), tensor(1.3501107693), tensor(0.7279706001), tensor(1.1165796518), tensor(1.0423172712), tensor(1.6014703512), tensor(0.7684813142), tensor(1.1645308733), tensor(0.6302065253), tensor(1.1766769886), tensor(1.1285414696), tensor(0.8263245225), tensor(0.9129294157), tensor(1.1636533737), tensor(1.5863074064), tensor(0.9076827168), tensor(1.0701538324)]\n",
            "c:  [tensor(-0.0766412318), tensor(0.2765662670), tensor(0.2537381649), tensor(-0.0023083878), tensor(-0.0005869889), tensor(0.0488454439), tensor(0.0515658930), tensor(0.1070934981), tensor(0.6085298061), tensor(-0.0152279334), tensor(0.2677153647), tensor(-0.1130017042), tensor(0.1505082846), tensor(0.5921739340), tensor(-0.0093247611), tensor(0.2880722880), tensor(-0.1001715511), tensor(0.1559772938)]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Partial derivatives of loss w/r to hidden weights:\n",
            "\n",
            "atensor.grad: tensor([-1.6403290033,  1.3900201321,  0.0944559574,  0.3080670834,\n",
            "         1.0441138744, -1.4305129051,  0.2542585731,  0.5919736624,\n",
            "         1.8822348118, -0.5161408186,  0.1027081013, -0.7834879160,\n",
            "         1.1506912708, -1.5274028778, -0.0544117354,  0.3651695549,\n",
            "        -0.1617782712,  1.6963508129,  0.9804540277,  0.6166825294])\n",
            "btensor.grad: tensor([-0.2781292200,  0.5253986120,  0.0476040989,  0.4777059555,\n",
            "         0.4545982778, -0.2655009627,  0.3657814860, -0.5804492235,\n",
            "        -0.5509653687,  0.1957616210,  0.6382381916, -0.2155731320,\n",
            "         0.2692060173,  0.4058921337,  0.0246875286, -0.6697062850,\n",
            "        -0.4007966816,  0.5680837631,  0.0983618498,  0.1373821497])\n",
            "ctensor.grad: tensor([-1.7811230421, -0.2069980055,  0.1967402101,  7.5863275528,\n",
            "        -0.1510718614,  4.8514227867, -1.6931916475, -2.5736229420,\n",
            "         1.0032719374,  0.0650779456,  3.6811244488,  2.6149556637,\n",
            "         7.3005270958,  0.7553871870,  0.0508303307,  2.7591812611,\n",
            "         1.9375734329,  5.5539007187])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Post-training score table\n",
            "                 Arsenal          Birmingham       Blackburn        Fulham           Leicester        Man United       Portsmouth       Charlton         Leeds            Liverpool        Bolton           Chelsea          Everton          Man City         Newcastle        Southampton      Tottenham        Wolves           Aston Villa      Middlesbrough    \n",
            "Arsenal          1.049            1.716            2.045            1.663            2.244            1.319            1.896            1.787            2.618            1.378            1.968            1.173            1.987            1.915            1.464            1.594            1.966            2.597            1.584            1.828            \n",
            "Birmingham       0.712            1.100            1.294            1.070            1.410            0.870            1.206            1.142            1.628            0.904            1.249            0.784            1.259            1.219            0.954            1.030            1.247            1.616            1.024            1.167            \n",
            "Blackburn        0.812            1.286            1.520            1.248            1.661            1.004            1.414            1.336            1.926            1.046            1.465            0.900            1.478            1.427            1.107            1.199            1.463            1.912            1.192            1.365            \n",
            "Fulham           0.821            1.300            1.537            1.262            1.680            1.015            1.429            1.352            1.949            1.057            1.481            0.910            1.495            1.444            1.119            1.213            1.480            1.934            1.205            1.381            \n",
            "Leicester        0.791            1.247            1.472            1.211            1.608            0.976            1.370            1.296            1.863            1.016            1.419            0.876            1.432            1.384            1.075            1.164            1.417            1.850            1.157            1.324            \n",
            "Man United       0.943            1.523            1.809            1.477            1.982            1.177            1.679            1.585            2.307            1.228            1.741            1.051            1.758            1.695            1.304            1.417            1.740            2.289            1.408            1.620            \n",
            "Portsmouth       0.754            1.179            1.390            1.146            1.517            0.927            1.294            1.225            1.755            0.964            1.341            0.833            1.353            1.307            1.019            1.102            1.339            1.743            1.095            1.251            \n",
            "Charlton         0.813            1.285            1.519            1.248            1.660            1.005            1.413            1.336            1.925            1.046            1.464            0.901            1.477            1.427            1.107            1.199            1.462            1.910            1.192            1.365            \n",
            "Leeds            0.694            1.069            1.255            1.040            1.367            0.846            1.171            1.110            1.578            0.879            1.212            0.764            1.222            1.183            0.928            1.001            1.210            1.567            0.995            1.133            \n",
            "Liverpool        0.842            1.340            1.585            1.300            1.734            1.043            1.474            1.392            2.013            1.086            1.527            0.934            1.541            1.488            1.151            1.248            1.525            1.997            1.241            1.422            \n",
            "Bolton           0.769            1.207            1.423            1.173            1.554            0.946            1.325            1.254            1.800            0.984            1.372            0.850            1.385            1.338            1.042            1.127            1.371            1.786            1.120            1.280            \n",
            "Chelsea          0.991            1.609            1.914            1.560            2.099            1.240            1.776            1.675            2.446            1.295            1.842            1.105            1.860            1.793            1.375            1.496            1.841            2.426            1.487            1.712            \n",
            "Everton          0.745            1.162            1.368            1.129            1.493            0.914            1.275            1.207            1.726            0.950            1.320            0.822            1.331            1.287            1.004            1.086            1.318            1.714            1.079            1.232            \n",
            "Man City         0.839            1.333            1.576            1.294            1.724            1.038            1.466            1.386            2.001            1.082            1.519            0.930            1.533            1.480            1.146            1.242            1.518            1.986            1.235            1.415            \n",
            "Newcastle        0.811            1.283            1.517            1.246            1.658            1.002            1.411            1.334            1.922            1.044            1.462            0.899            1.475            1.425            1.105            1.197            1.460            1.908            1.190            1.363            \n",
            "Southampton      0.709            1.097            1.288            1.066            1.404            0.866            1.201            1.138            1.621            0.899            1.243            0.781            1.254            1.212            0.950            1.026            1.241            1.609            1.019            1.161            \n",
            "Tottenham        0.750            1.173            1.382            1.140            1.509            0.922            1.287            1.219            1.746            0.959            1.333            0.829            1.345            1.300            1.014            1.096            1.331            1.733            1.089            1.244            \n",
            "Wolves           0.660            1.006            1.178            0.979            1.281            0.800            1.100            1.044            1.475            0.830            1.137            0.724            1.147            1.111            0.875            0.943            1.136            1.465            0.937            1.065            \n",
            "Aston Villa      0.773            1.215            1.433            1.180            1.565            0.952            1.334            1.262            1.812            0.991            1.382            0.855            1.394            1.347            1.048            1.134            1.380            1.799            1.127            1.289            \n",
            "Middlesbrough    0.718            1.114            1.309            1.083            1.427            0.878            1.220            1.156            1.649            0.913            1.263            0.792            1.274            1.232            0.964            1.042            1.262            1.637            1.035            1.180            \n",
            "\n",
            "\n",
            "\n",
            "=============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "Historic Bookies Estimate:\n",
        "==========================\n",
        "\n",
        "The historic bookies estimate for goals landed by team i against team j is\n",
        "\n",
        "a_i b_j\n",
        "\n",
        "where\n",
        "\n",
        "a_i = A_i C^{-1/2}\n",
        "b_j = B_j C^{-1/2}\n",
        "\n",
        "A_i = goals landed per game by team i\n",
        "B_j = goals conceded per game by team j\n",
        "C   = average goals per game of all teams\n",
        "\n",
        "\n",
        "The historic 1980's max likelihood models\n",
        "=========================================\n",
        "\n",
        "Starting with Maher, the 1980's max likelihood model starts with this guess and\n",
        "perfects it by max likelihood, when team i lands k goals agaist team j\n",
        "loss was minus the log of the predicted probability by Poisson\n",
        "\n",
        "- log ( e^{-a_ib_j}(a_ib_j)^k /k!)\n",
        "\n",
        "\n",
        "A gitgub user said chi squared shows HST,AST,HR,AR have a significant effect\n",
        "\n",
        "HST = home shots on target\n",
        "AST = away shots on target\n",
        "HR  = home red cards\n",
        "AR  = away red cards\n",
        "HS  = home shots\n",
        "AS  = away shots\n",
        "HC  = home quarter kicks\n",
        "AC  = away corner kicks\n",
        "HF  = home fouls\n",
        "AF  = away fouls\n",
        "\n",
        "\n",
        "New Cross-entropy AI model with a neural layer\n",
        "==========================================\n",
        "\n",
        "Since gradient descent generalizes max likelihood we can replace a_ib_j by\n",
        "\n",
        "a_i b_j  +  (c_0 sigma ( c_3 HST + c_4 HR +c_5 HS + c_6 HC _c_7 HF)\n",
        "             + ...\n",
        "             +c_2 sigma(c_13 HST + c_14 HR + c_15 HS + c_16 HCC + c_17 HF) )b_j\n",
        "\n",
        "when i is the home team and\n",
        "\n",
        "a_i b_j  +  c_0 sigma ( c_1 AST + c_2 AR  ..... +AF  ) b_j\n",
        "\n",
        "when i is the away team, with sigma being the sigmoid function\n",
        "\n",
        "\n",
        "   sigma(x)=softmax(0,x) = e^x/(e^0+e^x) = 1/(1+e^{-x})\n",
        "\n",
        "\n",
        "\n",
        "This puts a *neural layer* behind the standard max likelihood model from the 1980s\n",
        "\n",
        "The weights are now the a_i,  b_i,   and c_i\n",
        "\n",
        "Since the c_i are shared by all teams the training rate for the c_i should be lower\n",
        "\n",
        "As in the model which this generalizes, the training is cross entropy versus the Poisson distribution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "A comment about the way the databases are stored, variables like HST and AST refer to 'home'\n",
        "and 'away' team but we do not make a distinction between home versus away.\n",
        "\n",
        "This means that each row of a data table is interpreted as if it were two rows,\n",
        "one giving information about team i against team j, the other giving information\n",
        "about team j against team i.\n",
        "\n",
        "For instance to calculate the average goals scored by any team over all games\n",
        "each row gives goals scored by a home team and goals scored by an away team\n",
        "and we have to add 2 to total games.\n",
        "\n",
        "That is when we say total games it really means the sum over all teams\n",
        "of the number of games that team played in, which is twice the number\n",
        "of games.\n",
        "\n",
        "That explains the line  totalgames=totalgames+2 each time a row is read in.\n",
        "\n",
        "There is no need to change this architecture to include things causing a home\n",
        "team advantage. This starts with a constant taking the value 1 in the first line\n",
        "\n",
        "loss -=  ...\n",
        "\n",
        "and taking the value 0 in the second line\n",
        "\n",
        "loss -= ...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "import torch as t\n",
        "import torch.nn as n\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "\n",
        "def sigma(x):\n",
        "  return t.exp(x)/(t.exp(t.tensor(1.0))+t.exp(x))-t.tensor(0.5)\n",
        "\n",
        "\n",
        "\n",
        "t.set_printoptions(precision=10)\n",
        "#print(\"beep boop\")\n",
        "#print(\"Aston Villa loses\")\n",
        "print(\"=============================================================\")\n",
        "\n",
        "#GITHUB LOCATION:\n",
        "#https://github.com/Pavlos01232/Match_Outcome_Prediction\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#pd.read_csv('https://raw.githubusercontent.com/Pavlos01232/Match_Outcome_Prediction/main/TRAINING%20DATA/PL0304.csv?raw=true')\n",
        "\n",
        "\n",
        "#\"DEEP learning\" just means \"hidden\" layers\n",
        "\n",
        "\n",
        "#df.to_csv(r'C:\\Users\\Pavlos\\Desktop\\export_dataframe.csv', sep='\\t', encoding='utf-8')\n",
        "#print (df[2])\n",
        "#file_list = os.listdir('https://raw.githubusercontent.com/Pavlos01232/Match_Outcome_Prediction/main/TRAINING%20DATA/')\n",
        "#df = pd.read_csv('https://raw.githubusercontent.com/Pavlos01232/Match_Outcome_Prediction/main/TRAINING%20DATA/PL0405.csv?raw=true',sep='\\t', lineterminator='\\r')\n",
        "#print(df)\n",
        "\n",
        "#read function\n",
        "\n",
        "first = \"https://raw.githubusercontent.com/Pavlos01232/Match_Outcome_Prediction/main/TRAINING%20DATA/PL\"\n",
        "last = \".csv?raw=true\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Starting with an array of data frames,\n",
        "and an array of column names, make a\n",
        "single array with the chosen columns\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def combine(dataFrames,columnNames):\n",
        " t=[]\n",
        " for i in range(0,len(dataFrames)):\n",
        "    theseColumns=dataFrames[i].columns.values[0].split(\",\")\n",
        "    for j in range(0 ,len(dataFrames[i])):\n",
        "      row=dataFrames[i].values[j][0].split(\",\")\n",
        "      newEntry=[]\n",
        "      for k in range(0, len(columnNames)):\n",
        "         for m in range(0, len(theseColumns)):\n",
        "             if(columnNames[k]==theseColumns[m] and m<=len(row)):\n",
        "                newEntry.append(row[m])\n",
        "      t.append(newEntry)\n",
        " return t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "can read years 3 to 23, 13*********************, there's something wrong with 14\n",
        "since the first two files in the training data are formatted incorrectly\n",
        "converts csv to dataframe\n",
        "'''\n",
        "\n",
        "df=[]\n",
        "\n",
        "for i in range(3, 4):\n",
        "  result = first + str('{:02.0f}'.format(i)) + str('{:02.0f}'.format(i+1)) + last\n",
        "  x = pd.read_csv(result, sep='\\t', encoding = 'unicode_escape', lineterminator='\\r')\n",
        "  df.append(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Get an array with each (home) team listed once\n",
        "from an array of data frames with column \"HomeTeam\"\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def getTeams(df):\n",
        " teams=[]\n",
        " homeTeams=combine(df,[\"HomeTeam\"])\n",
        " for i in range(len(homeTeams)):\n",
        "  if(len(homeTeams[i])>0):\n",
        "   found=False\n",
        "   for j in range(len(teams)):\n",
        "    if homeTeams[i][0] == teams[j]:\n",
        "      found=True\n",
        "      break\n",
        "   if found:\n",
        "    continue\n",
        "   teams.append(homeTeams[i][0])\n",
        " return teams\n",
        "\n",
        "\n",
        "'''\n",
        "Get the list of teams from the array of data frames called df\n",
        "and print it to the console\n",
        "'''\n",
        "\n",
        "\n",
        "teams=getTeams(df)\n",
        "print(\"\\nteams:\")\n",
        "print(teams)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Create an array called Data with just the team names and scores\n",
        "from the data framees in the array of frames df, and print it\n",
        "\n",
        "The list [\"HomeTeam\",\"AwayTeam\",\"FTHG\",\"FTAG\",\"HST\",\"AST\",\"HR\",\"AR\"] can be\n",
        "made longer if other columnts may be useful to use\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "Data=combine(df, [\"HomeTeam\",\"AwayTeam\",\"FTHG\",\"FTAG\",\"HST\",\"AST\",\"HR\",\"AR\", \"HS\",\"AS\",\"HC\",\"AC\",\"HF\",\"AF\"])\n",
        "print(\"\\n\\ndata: (team names respective goals scored, respective shots on target, respective red cards, respective shots, respective corner-kicks, respective fouls)\")\n",
        "print(Data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Get the numerical index of a team name x in the array teams\n",
        "otherwise just return x\n",
        "'''\n",
        "\n",
        "def getIndex(x,teams):\n",
        "  for i in range(len(teams)):\n",
        "   if(teams[i]==x):\n",
        "    return i\n",
        "  return x\n",
        "\n",
        "\n",
        "print(\"\\n\\nIndex assigned to Everton:\")\n",
        "print(getIndex(\"Everton\",teams))\n",
        "\n",
        "\n",
        "'''\n",
        "Replace any occurrence of names from the array teams\n",
        "which occur anywhere in A by their actual  numbers\n",
        "'''\n",
        "\n",
        "def teamsToNumbers(A,teams):\n",
        "  B=[]\n",
        "  for i in range(len(A)):\n",
        "    B.append([])\n",
        "    for j in range(len(A[i])):\n",
        "      B[i].append(getIndex(A[i][j],teams))\n",
        "  return B\n",
        "\n",
        "\n",
        "'''\n",
        "Create Data2 which is a copy of Data but with team names\n",
        "replaced by their index\n",
        "'''\n",
        "\n",
        "print(\"\\n\\ndata2, using the team's index number instead of name\")\n",
        "Data2=teamsToNumbers(Data,teams)\n",
        "#print(Data2)\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "Assume Data2 has team indices in column 0 and 1 and scores\n",
        "in cols 2 and 3\n",
        "\n",
        "A[i] is array of average goals landed per game by tean i\n",
        "B[i] is array of average goals conceded per game by team i\n",
        "C is total games played by all teams (twide the number of games)\n",
        "games[i]=total games played by team i\n",
        "a[i]*b[j]=first approx of expected goals landed by i when playing\n",
        "    against j\n",
        "'''\n",
        "\n",
        "A=[0]*len(teams)\n",
        "B=[0]*len(teams)\n",
        "games=[0]*len(teams)\n",
        "a=[0]*len(teams)\n",
        "b=[0]*len(teams)\n",
        "C=0\n",
        "totalGames=0\n",
        "\n",
        "for i in range(len(Data2)):\n",
        "  if(len(Data2[i])<2):\n",
        "    continue\n",
        "  games[Data2[i][0]]+=1\n",
        "  games[Data2[i][1]]+=1\n",
        "  A[Data2[i][0]]+=int(Data2[i][2])\n",
        "  B[Data2[i][0]]+=int(Data2[i][3])\n",
        "  A[Data2[i][1]]+=int(Data2[i][3])\n",
        "  B[Data2[i][1]]+=int(Data2[i][2])\n",
        "  C+=int(Data2[i][2])+int(Data2[i][3])\n",
        "  totalGames+=2\n",
        "\n",
        "\n",
        "'''\n",
        "Initial estimates of a,b,c\n",
        "'''\n",
        "\n",
        "for i in range(len(A)):\n",
        "  a[i]=A[i]/games[i]*(C/totalGames)**(-1/2)\n",
        "\n",
        "for i in range(len(B)):\n",
        "  b[i]=B[i]/games[i]*(C/totalGames)**(-1/2)\n",
        "\n",
        "#c is another set of hidden weights for our weightrix. they are initally nonzero to avoid a stationary point.\n",
        "\n",
        "c=[0.001,0.002,0.004,-0.001,-0.002,-0.004,0.0005,0.0001,0.01,0.002,0.005,0.007,0.009,0.003,0.007,0.009,0.002,-0.001]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "AI training function\n",
        "\n",
        "The training is by gradient descent, the loss\n",
        "function will be cross entropy loss function against Poisson\n",
        "using loss.backward()\n",
        "\n",
        "The hidden weights at the moment are the entries of a,b,c\n",
        "the array c  is shared for all teams.\n",
        "These enter into the calculation of mu (which we\n",
        "call muHome or muAway during training) and are\n",
        "hidden as they have no direct meaning.\n",
        "\n",
        "Thus mu as a function of the entries of a,b,c is\n",
        "learned by training, the weights are the entries\n",
        "of the three arrays.\n",
        "\n",
        "\n",
        "\n",
        "tau is the training rate for c which should be small\n",
        "compared to eta\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def elementOf(i,A):\n",
        "  for j in range(len(A)):\n",
        "    if(A[j]==i):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def train(eta,tau):\n",
        "  loss=t.tensor(0.0)\n",
        "\n",
        "\n",
        "\n",
        "  atensor=t.tensor(a,requires_grad=True)\n",
        "  btensor=t.tensor(b,requires_grad=True)\n",
        "  ctensor=t.tensor(c,requires_grad=True)\n",
        "\n",
        "\n",
        "  for i in range(len(Data2)):\n",
        "    if(len(Data2[i])==0):\n",
        "      continue\n",
        "    homeTeam=int(Data2[i][0])\n",
        "    awayTeam=int(Data2[i][1])\n",
        "    homeGoals=int(Data2[i][2])\n",
        "    awayGoals=int(Data2[i][3])\n",
        "    HST=t.tensor(float(Data2[i][4]))\n",
        "    AST=t.tensor(float(Data2[i][5]))\n",
        "    HR=t.tensor(float(Data2[i][6]))\n",
        "    AR=t.tensor(float(Data2[i][7]))\n",
        "    HS=t.tensor(float(Data2[i][8]))\n",
        "    AS=t.tensor(float(Data2[i][9]))\n",
        "    HC=t.tensor(float(Data2[i][10]))\n",
        "    AC=t.tensor(float(Data2[i][11]))\n",
        "    HF=t.tensor(float(Data2[i][12]))\n",
        "    AF=t.tensor(float(Data2[i][13]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    The reason there are two lines of code for the loss is that\n",
        "    each game can be thought of as  two 'rows' of data where we label\n",
        "    the home team as team i  or team j.\n",
        "\n",
        "    Thus teams are interpreted symmetrically and there is not yet any\n",
        "    home team advantage but this can be put in\n",
        "    without modifying the architecture as a constant which is 1 in the\n",
        "    first line and 0 in the second\n",
        "    '''\n",
        "\n",
        "\n",
        "    muHome=atensor[homeTeam]*btensor[awayTeam]\n",
        "    neural=ctensor[0]*sigma(ctensor[3]*HST+ctensor[4]*HR+ctensor[5]*HS+ctensor[6]*HC+ctensor[7]*HF)\n",
        "    neural+=ctensor[1]*sigma(ctensor[8]*HST+ctensor[9]*HR+ctensor[10]*HS+ctensor[11]*HC+ctensor[12]*HF)\n",
        "    neural+=ctensor[2]*sigma(ctensor[13]*HST+ctensor[14]*HR+ctensor[15]*HS+ctensor[16]*HC+ctensor[17]*HF)\n",
        "    muHome=muHome+neural*btensor[awayTeam]\n",
        "\n",
        "    muAway=atensor[awayTeam]*btensor[homeTeam]\n",
        "    neural=ctensor[0]*sigma(ctensor[3]*AST+ctensor[4]*AR+ctensor[5]*AS+ctensor[6]*AC+ctensor[7]*AF)\n",
        "    neural+=ctensor[1]*sigma(ctensor[8]*AST+ctensor[9]*AR+ctensor[10]*AS+ctensor[11]*AC+ctensor[12]*AF)\n",
        "    neural+=ctensor[2]*sigma(ctensor[13]*AST+ctensor[14]*AR+ctensor[15]*AS+ctensor[16]*AC+ctensor[17]*AF)\n",
        "    muAway=muAway+neural*btensor[homeTeam]\n",
        "\n",
        "\n",
        "    loss-=t.log(t.exp(-muHome)*t.pow(muHome,homeGoals)/math.factorial(homeGoals))\n",
        "    loss-=t.log(t.exp(-muAway)*t.pow(muAway,awayGoals)/math.factorial(awayGoals))\n",
        "\n",
        "  loss.backward()\n",
        "  for i in range(len(c)):\n",
        "    c[i]=c[i]-tau*ctensor.grad[i]\n",
        "  for i in range(len(a)):\n",
        "    a[i]=a[i]-eta*atensor.grad[i]\n",
        "  for i in range(len(b)):\n",
        "    b[i]=b[i]-eta*btensor.grad[i]\n",
        "  print(\"\\n\\nCross-entropy loss vs Poisson: \"+str(loss))\n",
        "  print(\"\\n\\nWeights:\\n\\na:  \"+str(a))\n",
        "  print(\"b:  \"+str(b))\n",
        "  print(\"c:  \"+str(c))\n",
        "  print(\"\\n\\n\\n\")\n",
        "  print(\"Partial derivatives of loss w/r to hidden weights:\")\n",
        "  print(\"\\natensor.grad: \"+str(atensor.grad))\n",
        "  print(\"btensor.grad: \"+str(btensor.grad))\n",
        "  print(\"ctensor.grad: \"+str(ctensor.grad))\n",
        "  print(\"\\n\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Use weights to construct predicted expected goals scored by i\n",
        "against j and then find probability of k goals scored using\n",
        "Poisson when given values of R S ST  C F are provided\n",
        "'''\n",
        "\n",
        "# non-tensor version of sigma for using in the field\n",
        "\n",
        "def mathsigma(x):\n",
        "  return math.exp(x)/(math.exp(0)+math.exp(x))-0.5\n",
        "\n",
        "def goalProb(i,j,k,ST,R,S,C,F):\n",
        "  mu=a[i]*b[j]\n",
        "  mu+=c[0]*mathsigma(c[3]*ST+c[4]*R+c[5]*S+c[6]*C+c[7]*F)\n",
        "  mu+=c[1]*mathsigma(c[8]*ST+c[9]*R+c[10]*S+c[11]*C+c[12]*F)\n",
        "  mu+=c[2]*mathsigma(c[13]*ST+c[14]*R+c[15]*S+c[16]*C+c[17]*F)\n",
        "  return math.exp(-mu)*mu**k/math.factorial(k)\n",
        "\n",
        "\n",
        "def goalProb2(i,j,k):\n",
        "  ST=preTrainST(i,j)\n",
        "  R=preTrainR(i,j)\n",
        "  S=preTrainS(i,j)\n",
        "  C=preTrainC(i,j)\n",
        "  F=preTrainF(i,j)\n",
        "  print(\"\\nNaive prediction of ST, R, S, C, F: \"+str(ST)+\", \"+str(R)+\", \"+str(S)+\", \"+str(C)+\", \"+str(F))\n",
        "  return goalProb(i,j,k,ST,R,S,C,F)\n",
        "\n",
        "\n",
        "'''\n",
        "Pre-training estimates of ST, R, S, C, F\n",
        "'''\n",
        "\n",
        "def preTrain(i,j,u,v):\n",
        "  X=0\n",
        "  Y=0\n",
        "  Z=0\n",
        "  for s in range(len(Data2)):\n",
        "    if(len(Data2[s])<2):\n",
        "      continue\n",
        "    if(Data2[s][0]==i):\n",
        "      X+=int(Data2[s][u])\n",
        "    if(Data2[s][0]==j):\n",
        "      Y+=int(Data2[s][u])\n",
        "    if(Data2[s][1]==i):\n",
        "      X+=int(Data2[s][v])\n",
        "    if(Data2[s][1]==j):\n",
        "      Y+=int(Data2[s][v])\n",
        "    Z+=int(Data2[s][u])+int(Data2[s][v])\n",
        "  return (X/games[i])*(Y/games[j])/(Z/totalGames)\n",
        "\n",
        "def preTrainST(i,j):\n",
        "  return preTrain(i,j,4,5)\n",
        "\n",
        "def preTrainR(i,j):\n",
        "  return preTrain(i,j,6,7)\n",
        "\n",
        "def preTrainS(i,j):\n",
        "  return preTrain(i,j,8,9)\n",
        "\n",
        "def preTrainC(i,j):\n",
        "  return preTrain(i,j,10,11)\n",
        "\n",
        "def preTrainF(i,j):\n",
        "  return preTrain(i,j,12,13)\n",
        "\n",
        "\n",
        "def expectedGoals(i,j):\n",
        "  ST=preTrainST(i,j)\n",
        "  R=preTrainR(i,j)\n",
        "  S=preTrainS(i,j)\n",
        "  C=preTrainC(i,j)\n",
        "  F=preTrainF(i,j)\n",
        "  mu=a[i]*b[j]\n",
        "  mu+=c[0]*mathsigma(c[3]*ST+c[4]*R+c[5]*S+c[6]*C+c[7]*F)\n",
        "  mu+=c[1]*mathsigma(c[8]*ST+c[9]*R+c[10]*S+c[11]*C+c[12]*F)\n",
        "  mu+=c[2]*mathsigma(c[13]*ST+c[14]*R+c[15]*S+c[16]*C+c[17]*F)\n",
        "  return mu\n",
        "\n",
        "'''\n",
        "Test training a bit\n",
        "'''\n",
        "print(\"\\n\\n Pre-training score table\")\n",
        "st=\"{:<17}\".format(\"\")\n",
        "for i in range(len(teams)):\n",
        "  st+=\"{:<17}\".format(teams[i])\n",
        "print (st)\n",
        "for i in range(len(teams)):\n",
        "  st=\"{:<17}\".format(teams[i])\n",
        "  for j in range(len(teams)):\n",
        "    st+=\"{:<17}\".format(       \"%2.3f\" % expectedGoals(i,j))\n",
        "  print(st)\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TRAINING\n",
        "#NUMBER OF ITERATIONS,\n",
        "#TRAINING RATE FOR ETA, TAU.\n",
        "\n",
        "iterations=80\n",
        "\n",
        "flag=0\n",
        "for i in range(iterations):\n",
        "    train(0.005,0.0005)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\n Post-training score table\")\n",
        "st=\"{:<17}\".format(\"\")\n",
        "for i in range(len(teams)):\n",
        "  st+=\"{:<17}\".format(teams[i])\n",
        "print (st)\n",
        "for i in range(len(teams)):\n",
        "  st=\"{:<17}\".format(teams[i])\n",
        "  for j in range(len(teams)):\n",
        "    st+=\"{:<17}\".format(       \"%2.3f\" % expectedGoals(i,j))\n",
        "  print(st)\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"=============================================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yb6-hsGw363e"
      }
    }
  ]
}